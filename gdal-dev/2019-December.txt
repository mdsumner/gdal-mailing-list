From kcindric at gmail.com  Sun Dec  1 00:23:53 2019
From: kcindric at gmail.com (=?UTF-8?Q?Kristijan_Cindri=C4=87?=)
Date: Sun, 1 Dec 2019 09:23:53 +0100
Subject: [gdal-dev] geojson to shp and vice versa
In-Reply-To: <CAHBySPajpNCDFwB61=6CBQm8ousZXfHWOcOnygdChpzshN0DBg@mail.gmail.com>
References: <CADDbS5xKUH8MvYLspOou41as-T16BdZ_kaYBO2Cj4H+2FgUOwg@mail.gmail.com>
 <1575016117710-0.post@n6.nabble.com>
 <CADDbS5zhYN3H+=A5iOXLUXB138tZKV7pnCr3q_g+pHA1Gd3GsQ@mail.gmail.com>
 <CAHBySPajpNCDFwB61=6CBQm8ousZXfHWOcOnygdChpzshN0DBg@mail.gmail.com>
Message-ID: <CADDbS5yg3q_MMNmKPe_9W+2g0-wJ5Cx0u6Yf_0QO1Fkkjdh7-A@mail.gmail.com>

Thanks Richard,

in the end I opted for a client side solution (
https://github.com/calvinmetcalf/shapefile-js) which handles geometry
collections with multiple geometry types great.

Chtis

ned, 1. pro 2019. u 03:36 Richard Greenwood <richard.greenwood at gmail.com>
napisao je:

> I don't know anything about iterating thru a .zip file, but just in case
> you aren't already familiar with it, ogr2ogr has -sql and -where options
> that can be used to filter geometry types. So if you have different
> geometry type in a single source file you can use for example:
>    -where "OGR_GEOMETRY='MULTIPOLYGON' OR OGR_GEOMETRY='POLYGON'"
> If you have geometry collections with multiple geometry types it gets
> harder. Personally, I'd pump it thru PostGIS in that case.
>
> Rich
>
> On Fri, Nov 29, 2019 at 1:42 AM Kristijan Cindrić <kcindric at gmail.com>
> wrote:
>
>> Thanks for the prompt answers! Ok, it's clear now on what's the problem
>> here.
>> Is there a way I can iterate through a .zip file containing individual
>> .shp files, each file with its own geometry type (point, line, polygon),
>> using ogre.adc4gis.com API? I could then append each feature to a
>> geojson feature class and show it to the user. If ogre.adc4gis.com
>> doesn't work I can try to run ogr2ogr in my app so suggestions in that way
>> are helpful also.
>>
>> Thanks,
>>
>> Chris
>>
>> pet, 29. stu 2019. u 09:28 jratike80 <jukka.rahkonen at maanmittauslaitos.fi>
>> napisao je:
>>
>>> Hi,
>>>
>>> You just can't save lines and polygons into same shapefile. Read
>>> https://www.esri.com/library/whitepapers/pdfs/shapefile.pdf "All the
>>> non-Null shapes in a shapefile are required to be of the same shape
>>> type."
>>>
>>>
>>> -Jukka Rahkonen-
>>>
>>>
>>> Kristijan Cindrić wrote
>>> > Dear all,
>>> >
>>> > I have a headache inducing problem. Whenever I try to convert a GeoJSON
>>> > feature collection which contains multiple different geometry shapes
>>> (i.e.
>>> > polygon, linestring and point) I get this type of error:
>>> >
>>> > "ERROR 1: Attempt to write non-polygon (LINESTRING) geometry to POLYGON
>>> > type shapefile.\nERROR 1: Unable to write feature 1 from layer
>>> > OGRGeoJSON.\nERROR 1: Terminating translation prematurely after
>>> > failed\ntranslation of layer OGRGeoJSON (use -skipfailures to skip
>>> > errors)\n"
>>> >
>>> > This is the sample GeoJSON I'm trying to convert:
>>> >
>>> > {
>>> >     "type": "FeatureCollection",
>>> >     "features": [{
>>> >         "type": "Feature",
>>> >         "properties": {},
>>> >         "geometry": {
>>> >             "type": "Polygon",
>>> >             "coordinates": [
>>> >                 [
>>> >                     [31.816406250000004, 55.27911529201564],
>>> >                     [34.27734375000001, 51.944264879028765],
>>> >                     [43.94531250000001, 51.944264879028765],
>>> >                     [46.93359375000001, 58.35563036280967],
>>> >                     [40.42968750000001, 60.1524422143808],
>>> >                     [34.45312500000001, 59.085738569819505],
>>> >                     [31.816406250000004, 55.27911529201564]
>>> >                 ]
>>> >             ]
>>> >         }
>>> >     }, {
>>> >         "type": "Feature",
>>> >         "properties": {},
>>> >         "geometry": {
>>> >             "type": "LineString",
>>> >             "coordinates": [
>>> >                 [0.5273437500000001, 21.289374355860424],
>>> >                 [30.585937500000004, 20.632784250388028]
>>> >             ]
>>> >         }
>>> >     }, {
>>> >         "type": "Feature",
>>> >         "properties": {},
>>> >         "geometry": {
>>> >             "type": "Point",
>>> >             "coordinates": [14.062500000000002, 50.064191736659104]
>>> >         }
>>> >     }]
>>> > }
>>> >
>>> >
>>> > I validated the GeoJSON on geojsonlint &lt;http://geojsonlint.com/&gt;
>>> and
>>> > it's
>>> > all good. It happens every time I have a stack of different geometry
>>> > types.
>>> > It happens using ogre.adc4gis.com or ogr2ogr. It happens in the
>>> opposite
>>> > way also and when I use the skipfailure option I just get the first
>>> > feature
>>> > in my shapefile.
>>> >
>>> > Any ideas what's going on?
>>> >
>>> >
>>> > Thanks!
>>> >
>>> >
>>> > Chris
>>> >
>>> > _______________________________________________
>>> > gdal-dev mailing list
>>>
>>> > gdal-dev at .osgeo
>>>
>>> > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>>>
>>>
>>>
>>>
>>>
>>> --
>>> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>>> _______________________________________________
>>> gdal-dev mailing list
>>> gdal-dev at lists.osgeo.org
>>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
>
> --
> Richard W. Greenwood, PLS
> www.greenwoodmap.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191201/4e9c9c9d/attachment-0001.html>

From aborruso at gmail.com  Sun Dec  1 06:59:27 2019
From: aborruso at gmail.com (aborruso)
Date: Sun, 1 Dec 2019 07:59:27 -0700 (MST)
Subject: [gdal-dev] ogr2ogr: strange results joininig non-spatial CSV to
 spatial data using SQLite dialect
Message-ID: <1575212367414-0.post@n6.nabble.com>

Hi,
I have this geosjon (map.geojson)

{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {"id": 1},
      "geometry": {
        "type": "Point",
        "coordinates": [-78.653, 35.7874]
      }
    },
    {
      "type": "Feature",
      "properties": {"id": 2},
      "geometry": {
        "type": "Point",
        "coordinates": [-78.6298, 35.7873]
      }
    },
    {
      "type": "Feature",
      "properties": {"id": 3},
      "geometry": {
        "type": "Point",
        "coordinates": [-78.6408, 35.7795]
      }
    }
  ]
}

and this CSV (tbl.csv)

id,atrr
1,ipsum
2,lorem
3,amet


If I run 

ogr2ogr -f csv \
  -dialect sqlite \
  -sql "select map.*,tbl.atrr from map join 'tbl.csv'.tbl AS tbl on
cast(map.id as text) = tbl.id" \
  /vsistdout/ map.geojson

I have

id,atrr
"1",ipsum

If I use left join instead of join I have

id,atrr
"1",ipsum
"2",lorem
"3",amet

Why do I not have three rows of result using simply join?

I'm using GDAL 2.4.2, released 2019/06/28



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Sun Dec  1 09:48:20 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 01 Dec 2019 18:48:20 +0100
Subject: [gdal-dev] ogr2ogr: strange results joininig non-spatial CSV to
	spatial data using SQLite dialect
In-Reply-To: <1575212367414-0.post@n6.nabble.com>
References: <1575212367414-0.post@n6.nabble.com>
Message-ID: <4638396.i4fJUJ0ZV3@even-i700>

> Why do I not have three rows of result using simply join?

You just hit a long-standing bug. Restricted when the joint layer is in a 
format like CSV that has no fast feature count capability.
Just fixed in master and backported to 3.0 and 2.4 branches

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jukka.rahkonen at maanmittauslaitos.fi  Sun Dec  1 11:40:46 2019
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Sun, 1 Dec 2019 19:40:46 +0000
Subject: [gdal-dev] Spatialite functions missing when reading GeoPackage
Message-ID: <932f68b8c1ec4ee6b0b8d2043647eff0@C119S212VM042.msvyvi.vaha.local>

Hi,

This works with GDAL from OSGeo4W, GDAL 3.0.2, released 2019/10/28

ogrinfo any.gpkg -dialect sqlite -sql "select spatialite_version()"
INFO: Open of `any.gpkg'
      using driver `GPKG' successful.

Layer name: SELECT
Geometry: None
Feature Count: 1
Layer SRS WKT:
(unknown)
spatialite_version(): String (0.0)
OGRFeature(SELECT):0
  spatialite_version() (String) = 4.3.0

With GDAL-del from gisinternals, GDAL 3.1.0dev, released 2019/99/99, Spatialite is not found if I make a query to GeoPackage database. The error is
ERROR 1: In ExecuteSQL(): sqlite3_prepare_v2(select spatialite_version()):
  no such function: spatialite_version

However, when datasource is not gpkg then Spatialite is found
ogrinfo any.shp -dialect sqlite -sql "select spatialite_version()"
INFO: Open of `any.shp'
      using driver `ESRI Shapefile' successful.

Layer name: SELECT
Geometry: None
Feature Count: 1
Layer SRS WKT:
(unknown)
spatialite_version(): String (0.0)
OGRFeature(SELECT):0
  spatialite_version() (String) = 4.3.0-RC1

Obviously mod_spatialite is not loaded in the gpkg case but I wonder if the issue is in GDAL-dev or in the gisinternals build.

-Jukka Rahkonen-


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191201/24f6abb4/attachment.html>

From even.rouault at spatialys.com  Sun Dec  1 12:03:10 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 01 Dec 2019 21:03:10 +0100
Subject: [gdal-dev] Spatialite functions missing when reading GeoPackage
In-Reply-To: <932f68b8c1ec4ee6b0b8d2043647eff0@C119S212VM042.msvyvi.vaha.local>
References: <932f68b8c1ec4ee6b0b8d2043647eff0@C119S212VM042.msvyvi.vaha.local>
Message-ID: <13354800.e3eX0rf6xx@even-i700>

Hi Jukka,

> Obviously mod_spatialite is not loaded in the gpkg case but I wonder if the
> issue is in GDAL-dev or in the gisinternals build.

Probably in gisinternals. I've submitted this (untested) patch to it:
https://github.com/gisinternals/buildsystem/pull/148

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From aborruso at gmail.com  Sun Dec  1 12:07:06 2019
From: aborruso at gmail.com (aborruso)
Date: Sun, 1 Dec 2019 13:07:06 -0700 (MST)
Subject: [gdal-dev] ogr2ogr: strange results joininig non-spatial CSV to
 spatial data using SQLite dialect
In-Reply-To: <4638396.i4fJUJ0ZV3@even-i700>
References: <1575212367414-0.post@n6.nabble.com> <4638396.i4fJUJ0ZV3@even-i700>
Message-ID: <1575230826438-0.post@n6.nabble.com>

It works, thank you very much



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From jef at norbit.de  Sun Dec  1 13:17:07 2019
From: jef at norbit.de (=?utf-8?Q?J=C3=BCrgen_E=2E?= Fischer)
Date: Sun, 1 Dec 2019 22:17:07 +0100
Subject: [gdal-dev] Spatialite functions missing when reading GeoPackage
In-Reply-To: <932f68b8c1ec4ee6b0b8d2043647eff0@C119S212VM042.msvyvi.vaha.local>
References: <932f68b8c1ec4ee6b0b8d2043647eff0@C119S212VM042.msvyvi.vaha.local>
Message-ID: <20191201211707.32pcca6247cogmxs@norbit.de>

Hi Jukka,

On Sun, 01. Dec 2019 at 19:40:46 +0000, Rahkonen Jukka (MML) wrote:
> This works with GDAL from OSGeo4W, GDAL 3.0.2, released 2019/10/28
> 
> ogrinfo any.gpkg -dialect sqlite -sql "select spatialite_version()"
> INFO: Open of `any.gpkg'
>       using driver `GPKG' successful.
> 
> Layer name: SELECT
> Geometry: None
> Feature Count: 1
> Layer SRS WKT:
> (unknown)
> spatialite_version(): String (0.0)
> OGRFeature(SELECT):0
>   spatialite_version() (String) = 4.3.0

gdal-dev in OSGeo4W behaves the same as 3.0.2.


Jürgen

-- 
Jürgen E. Fischer         norBIT GmbH               Tel. +49-4931-918175-31
Dipl.-Inf. (FH)           Rheinstraße 13            Fax. +49-4931-918175-50
Software Engineer         D-26506 Norden              https://www.norbit.de
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 827 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191201/9a16b2dd/attachment.sig>

From bhandari.ravi at outlook.com  Sun Dec  1 23:42:19 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 00:42:19 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster
Message-ID: <1575272539885-0.post@n6.nabble.com>

Hell All 

I have defined a derived Virtual Raster as follows.  
<VRTDataset rasterXSize="25828" rasterYSize="16749">
  <SRS>GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS
84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AUTHORITY["EPSG","4326"]]</SRS>
  <GeoTransform>  7.8318056012634287e+01,  1.1839023066784193e-04, 
0.0000000000000000e+00,  3.0866547275126596e+01,  0.0000000000000000e+00,
-7.3767782488687317e-05</GeoTransform>
    <VRTRasterBand dataType="Float32" band="1"
subClass="VRTDerivedRasterBand">
        <PixelFunctionType>add2</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>
        </PixelFunctionCode>
    <SimpleSource>
      <SourceFilename
relativeToVRT="1">S1A_IW_GRDH_1SDV_20180924T005140_20180924T005205_023833_0299C5_5216_Orb.tif</SourceFilename>
      <SourceBand>1</SourceBand>
      <SourceProperties RasterXSize="25828" RasterYSize="16749"
DataType="Float32" BlockXSize="25828" BlockYSize="16749" />
      <SrcRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
      <DstRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
    </SimpleSource>
    <SimpleSource>
      <SourceFilename
relativeToVRT="1">S1A_IW_GRDH_1SDV_20180924T005140_20180924T005205_023833_0299C5_5216_Orb.tif</SourceFilename>
      <SourceBand>2</SourceBand>
      <SourceProperties RasterXSize="25828" RasterYSize="16749"
DataType="Float32" BlockXSize="25828" BlockYSize="16749" />
      <SrcRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
      <DstRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
    </SimpleSource>
    </VRTRasterBand>
</VRTDataset>


But when try to read This virtual data as 
from osgeo import gdal
file=r'F:\Snow\snow_der.vrt'
gdal.SetConfigOption('GDAL_VRT_ENABLE_PYTHON', 'YES')
ds=gdal.Open(file)
data=ds.GetRasterBand(1)
cal=data.ReadAsArray()

print(cal)

it prints None

Please help in this 
 




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From jukka.rahkonen at maanmittauslaitos.fi  Mon Dec  2 00:04:56 2019
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Mon, 2 Dec 2019 01:04:56 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster
In-Reply-To: <1575272539885-0.post@n6.nabble.com>
References: <1575272539885-0.post@n6.nabble.com>
Message-ID: <1575273896734-0.post@n6.nabble.com>

Hi,

It seems that you have defined a Python function "add2" that does nothing
because it has no code

        <PixelFunctionType>add2</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>
        </PixelFunctionCode> 

You have perhaps tried to modify the example from
https://gdal.org/drivers/raster/vrt.html
<PixelFunctionType>add</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>
        </PixelFunctionCode>

Have you saved your add2 function into a separate Python script? In that
case follow the hillshading.py example.

-Jukka Rahkonen-


bhandari wrote
> Hell All 
> 
> I have defined a derived Virtual Raster as follows.  
> <VRTDataset rasterXSize="25828" rasterYSize="16749">
>   
> <SRS>
> GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS
> 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AUTHORITY["EPSG","4326"]]
> </SRS>
>   
> <GeoTransform>
>   7.8318056012634287e+01,  1.1839023066784193e-04, 
> 0.0000000000000000e+00,  3.0866547275126596e+01,  0.0000000000000000e+00,
> -7.3767782488687317e-05
> </GeoTransform>
>     
> <VRTRasterBand dataType="Float32" band="1"
> subClass="VRTDerivedRasterBand">
>         
> <PixelFunctionType>
> add2
> </PixelFunctionType>
>         
> <PixelFunctionLanguage>
> Python
> </PixelFunctionLanguage>
>         
> <PixelFunctionCode>
>         
> </PixelFunctionCode>
>     
> <SimpleSource>
>   

....




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From jukka.rahkonen at maanmittauslaitos.fi  Mon Dec  2 00:14:36 2019
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Mon, 2 Dec 2019 08:14:36 +0000
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
Message-ID: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>

Hi,

Re-posting because the code section that Nabble wrote as html formatted was dropped out. Did the same thing happen for you with your original mail?

It seems that you have defined a Python function "add2" that does nothing because it has no code

        <PixelFunctionType>add2</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>
        </PixelFunctionCode>

You have perhaps tried to modify the example from https://gdal.org/drivers/raster/vrt.html
<PixelFunctionType>add</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>

<![CDATA[
            import numpy as np
            def add(in_ar, out_ar, xoff, yoff, xsize, ysize, raster_xsize,
                            raster_ysize, buf_radius, gt, **kwargs):
                np.round_(np.clip(np.sum(in_ar, axis = 0, dtype = 'uint16'),0,255),
                        out = out_ar)
            ]]>
        </PixelFunctionCode>

Have you saved your add2 function into a separate Python script? In that case follow the hillshading.py example.

-Jukka Rahkonen-
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191202/e4fa18b2/attachment.html>

From bhandari.ravi at outlook.com  Mon Dec  2 00:38:15 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 01:38:15 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
In-Reply-To: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
References: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
Message-ID: <1575275895237-0.post@n6.nabble.com>

Hi 
     Jukka Rahkonen thank you for your reply

But the code of add2 function is in the same VRT file. Need I store in a
separate file as well.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bhandari.ravi at outlook.com  Mon Dec  2 00:42:23 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 01:42:23 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
In-Reply-To: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
References: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
Message-ID: <1575276143532-0.post@n6.nabble.com>

<VRTDataset rasterXSize="25828" rasterYSize="16749">
  <SRS>GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS
84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AUTHORITY["EPSG","4326"]]</SRS>
  <GeoTransform>  7.8318056012634287e+01,  1.1839023066784193e-04, 
0.0000000000000000e+00,  3.0866547275126596e+01,  0.0000000000000000e+00,
-7.3767782488687317e-05</GeoTransform>
    <VRTRasterBand dataType="Float32" band="1"
subClass="VRTDerivedRasterBand">
        <PixelFunctionType>add2</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>
        </PixelFunctionCode>
    <SimpleSource>
      <SourceFilename
relativeToVRT="1">S1A_IW_GRDH_1SDV_20180924T005140_20180924T005205_023833_0299C5_5216_Orb.tif</SourceFilename>
      <SourceBand>1</SourceBand>
      <SourceProperties RasterXSize="25828" RasterYSize="16749"
DataType="Float32" BlockXSize="25828" BlockYSize="16749" />
      <SrcRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
      <DstRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
    </SimpleSource>
    <SimpleSource>
      <SourceFilename
relativeToVRT="1">S1A_IW_GRDH_1SDV_20180924T005140_20180924T005205_023833_0299C5_5216_Orb.tif</SourceFilename>
      <SourceBand>2</SourceBand>
      <SourceProperties RasterXSize="25828" RasterYSize="16749"
DataType="Float32" BlockXSize="25828" BlockYSize="16749" />
      <SrcRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
      <DstRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
    </SimpleSource>
    </VRTRasterBand>
</VRTDataset>



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bhandari.ravi at outlook.com  Mon Dec  2 00:43:10 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 01:43:10 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
In-Reply-To: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
References: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
Message-ID: <1575276190046-0.post@n6.nabble.com>

Hi
     Jukka Rahkonen thank you for your reply

But the code of add2 function is in the same VRT file. Need I store in a
separate file as well.
 <VRTDataset rasterXSize="25828" rasterYSize="16749">
  <SRS>GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS
84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0],UNIT["degree",0.0174532925199433],AUTHORITY["EPSG","4326"]]</SRS>
  <GeoTransform>  7.8318056012634287e+01,  1.1839023066784193e-04, 
0.0000000000000000e+00,  3.0866547275126596e+01,  0.0000000000000000e+00,
-7.3767782488687317e-05</GeoTransform>
    <VRTRasterBand dataType="Float32" band="1"
subClass="VRTDerivedRasterBand">
        <PixelFunctionType>add2</PixelFunctionType>
        <PixelFunctionLanguage>Python</PixelFunctionLanguage>
        <PixelFunctionCode>
        </PixelFunctionCode>
    <SimpleSource>
      <SourceFilename
relativeToVRT="1">S1A_IW_GRDH_1SDV_20180924T005140_20180924T005205_023833_0299C5_5216_Orb.tif</SourceFilename>
      <SourceBand>1</SourceBand>
      <SourceProperties RasterXSize="25828" RasterYSize="16749"
DataType="Float32" BlockXSize="25828" BlockYSize="16749" />
      <SrcRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
      <DstRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
    </SimpleSource>
    <SimpleSource>
      <SourceFilename
relativeToVRT="1">S1A_IW_GRDH_1SDV_20180924T005140_20180924T005205_023833_0299C5_5216_Orb.tif</SourceFilename>
      <SourceBand>2</SourceBand>
      <SourceProperties RasterXSize="25828" RasterYSize="16749"
DataType="Float32" BlockXSize="25828" BlockYSize="16749" />
      <SrcRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
      <DstRect xOff="0" yOff="0" xSize="25828" ySize="16749" />
    </SimpleSource>
    </VRTRasterBand>
</VRTDataset>



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bhandari.ravi at outlook.com  Mon Dec  2 00:52:50 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 01:52:50 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
In-Reply-To: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
References: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
Message-ID: <1575276770775-0.post@n6.nabble.com>

Hi
   Jukka Rahkonen Thanks for the reply.

Actually the add2 function is inside the code. I feel the browser excluded
that portion the code was
 <PixelFunctionCode>
       
        </PixelFunctionCode>



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bhandari.ravi at outlook.com  Mon Dec  2 00:59:42 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 01:59:42 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
In-Reply-To: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
References: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
Message-ID: <1575277182822-0.post@n6.nabble.com>

Hi
   Jukka Rahkonen Thanks for the reply.

Actually the add2 function is inside the code. I feel the browser excluded
that portion the code was
 <PixelFunctionCode>
       
        </PixelFunctionCode>



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bhandari.ravi at outlook.com  Mon Dec  2 01:03:27 2019
From: bhandari.ravi at outlook.com (bhandari)
Date: Mon, 2 Dec 2019 02:03:27 -0700 (MST)
Subject: [gdal-dev] Error in Derived Band in Virtual raster (re-post)
In-Reply-To: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
References: <7162114431ea428498737dba6d228f99@C119S212VM042.msvyvi.vaha.local>
Message-ID: <1575277407046-0.post@n6.nabble.com>

Hi
   Jukka Rahkonen Thanks for the reply.

Actually the add2 function is inside the code. I feel the browser excluded
that portion the code was  
<http://osgeo-org.1560.x6.nabble.com/file/t384468/Untitled.png> 



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Mon Dec  2 06:05:26 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 02 Dec 2019 15:05:26 +0100
Subject: [gdal-dev] ogr2ogr (I)LIKE not caseINsensitive
In-Reply-To: <1932542.jbAo1YeLi3@even-i700>
References: <CAKMUAtAi9pLXay7qaqcDBb-Qxtm9CA5rDB+aRY61LQ7=tAj7=w@mail.gmail.com>
 <1932542.jbAo1YeLi3@even-i700>
Message-ID: <4808119.3dlnyTUHDE@even-i700>

> 2) more work. for WFS, have LIKE and ILIKE having two different
> translations. But if we do so, as we would need to add a new SWQ_ILIKE
> operator, and we should also probably make LIKE and ILIKE be distinct
> operations on a pure OGR SQL evaluation (client side). Which has some
> backward compatibility implication.

I finally decided for that second option in
https://github.com/OSGeo/gdal/pull/2078

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From markus.metz.giswork at gmail.com  Mon Dec  2 10:03:09 2019
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Mon, 2 Dec 2019 19:03:09 +0100
Subject: [gdal-dev] OGR C API PostGIS geometry with wrong field entries
Message-ID: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>

In the GRASS module v.in.ogr we follow pretty much the vector API tutorial.
The only difference is that we first fetch the geometry of a feature, then
the fields. When input is a PG database, sometimes the wrong field entries
are associated with the geometries, as if geometries and field entries were
mixed up. This happens when several different v.in.ogr processes are trying
to read the same features from the same PG database at the same time. When
instead using several different ogr2ogr processes, this mixing up of
geometries and field entries does not happen. I could not find any hints in
the OGR PostGIS documentation about how to avoid this problem.

Any hints are highly appreciated!

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191202/2f83ed3d/attachment.html>

From even.rouault at spatialys.com  Mon Dec  2 10:45:47 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 02 Dec 2019 19:45:47 +0100
Subject: [gdal-dev] OGR C API PostGIS geometry with wrong field entries
In-Reply-To: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>
References: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>
Message-ID: <4666076.43zhXA5MoF@even-i700>

Markus,

> In the GRASS module v.in.ogr we follow pretty much the vector API tutorial.
> The only difference is that we first fetch the geometry of a feature, then
> the fields. When input is a PG database, sometimes the wrong field entries
> are associated with the geometries, as if geometries and field entries were
> mixed up. This happens when several different v.in.ogr processes are trying
> to read the same features from the same PG database at the same time. When
> instead using several different ogr2ogr processes, this mixing up of
> geometries and field entries does not happen. I could not find any hints in
> the OGR PostGIS documentation about how to avoid this problem.

This is indeed a weird problem. I don't have a theory. The PG driver 
implements a lot of lazy loading strategy to run efficiently with databases 
with many layers, but I wouldn't expect potential issues to be triggered by 
the fact that several v.in.org processes run in parallel... And I checked that 
fields returned from the PG system tables are sorted by attnum, so they should 
always be returned in the same order.

Are you sure there's no latent memory corruption in v.in.ogr ? Did you check 
with Valgrind ?

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tony_lst3 at yahoo.com  Mon Dec  2 10:48:32 2019
From: tony_lst3 at yahoo.com (Tony L.)
Date: Mon, 2 Dec 2019 18:48:32 +0000 (UTC)
Subject: [gdal-dev] gdal_translate geotiff to netcdf: values
References: <1060331232.7731358.1575312512622.ref@mail.yahoo.com>
Message-ID: <1060331232.7731358.1575312512622@mail.yahoo.com>

HelloI have a geotiff file of sea ice concentration.When I use gdal_info it gives a series of values like:

  Metadata:

    COLORINTERP=Palette

  Color Table (RGB with 65536 entries)

    0: 9,60,112,255

    1: 9,60,112,255

    2: 9,60,112,255

    3: 9,60,112,255

    4: 9,60,112,255

    5: 9,60,112,255

    6: 9,60,112,255

    7: 9,60,112,255

    8: 9,60,112,255

    9: 9,60,112,255

   10: 9,60,112,255
etc...
When I use gdal_translate to convert to netcdf:
gdal_translate -of netCDF test.tif test.nc
and I look at the values in the test.nc file 
...
3662500 4187500 2540 

3687500 4187500 2540 

3712500 4187500 2540 

3737500 4187500 2540 

-3837500 4212500 0 

-3812500 4212500 0 

-3787500 4212500 0 

-3762500 4212500 0 

-3737500 4212500 0 

-3712500 4212500 0 

-3687500 4212500 0 

-1762500 4212500 0 

-1737500 4212500 0 

-1712500 4212500 16 

-1687500 4212500 0 

-1662500 4212500 0 

-1637500 4212500 0 

-1612500 4212500 36 

-1587500 4212500 48 

-1562500 4212500 2530 

-1537500 4212500 0 

-1512500 4212500 0 

-1487500 4212500 0 

-1462500 4212500 48 

-1437500 4212500 104 

-1412500 4212500 120 

-1387500 4212500 168 

-1362500 4212500 216 

-1337500 4212500 316 
...
My question is: when gdal_translate convert to netcdf what does the value in the third column represent?
Points that are equal to 2540 seem to be land cells, while points with 0 value are ocean cellsAre points with value rating from 0 to 1000 (where sea ice concentration exists) in per thousands? (i.e 100 = 10% sea ice concentration, 1000 = 100%?)
Tony
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191202/1aca58fa/attachment.html>

From markus.metz.giswork at gmail.com  Mon Dec  2 11:25:54 2019
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Mon, 2 Dec 2019 20:25:54 +0100
Subject: [gdal-dev] OGR C API PostGIS geometry with wrong field entries
In-Reply-To: <4666076.43zhXA5MoF@even-i700>
References: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>
 <4666076.43zhXA5MoF@even-i700>
Message-ID: <CAG+h=FFdBvJ7BULzHtjDUziNo8pMtfLBBE9rC_M9totAhbYxNA@mail.gmail.com>

Even,

On Mon, Dec 2, 2019 at 7:46 PM Even Rouault <even.rouault at spatialys.com>
wrote:
>
> Markus,
> [...]
>
> Are you sure there's no latent memory corruption in v.in.ogr ? Did you
check
> with Valgrind ?

Yes, I checked with valgrind, no memory corruption. I tried v.in.ogr with
other OGR formats, no problem. I am out of ideas, that's why I am asking
here. I will prick the users reporting the problem for more details.

Thanks a lot for your quick response!

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191202/faf82040/attachment-0001.html>

From ao at t-kartor.se  Mon Dec  2 23:25:11 2019
From: ao at t-kartor.se (Andreas Oxenstierna)
Date: Tue, 3 Dec 2019 08:25:11 +0100
Subject: [gdal-dev] OGR C API PostGIS geometry with wrong field entries
In-Reply-To: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>
References: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>
Message-ID: <d3a5c05d-ad0e-0b93-272b-65d42f2defd1@t-kartor.se>

I am no Postgre expert but we have experienced similar cases when 
running complex transactions with large geometries, i.e. faulty results.
When splitting the transaction into several pieces, i.e. enforcing 
COMMITs (Postgre doesn't support COMMIT inside functions), the correct 
results are given.
One guess is that this may happen for large geometries which are pushed 
to TOAST tables.

Check Postgre memory parameters and trace exactly what is happening in 
the database.
Test also with EXTERNAL STORAGE for the geometry if they are really large.


> In the GRASS module v.in.ogr we follow pretty much the vector API 
> tutorial. The only difference is that we first fetch the geometry of a 
> feature, then the fields. When input is a PG database, sometimes the 
> wrong field entries are associated with the geometries, as if 
> geometries and field entries were mixed up. This happens when several 
> different v.in.ogr processes are trying to read the same features from 
> the same PG database at the same time. When instead using several 
> different ogr2ogr processes, this mixing up of geometries and field 
> entries does not happen. I could not find any hints in the OGR PostGIS 
> documentation about how to avoid this problem.
>
> Any hints are highly appreciated!
>
> Markus M
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


-- 
Hälsningar

Andreas Oxenstierna
T-Kartor Geospatial AB
Olof Mohlins väg 12 Kristianstad
mobile: +46 733 206831
mailto: ao at t-kartor.se
http://www.t-kartor.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191203/3ba46b7f/attachment.html>

From sfkeller at gmail.com  Tue Dec  3 08:25:20 2019
From: sfkeller at gmail.com (Stefan Keller)
Date: Tue, 3 Dec 2019 17:25:20 +0100
Subject: [gdal-dev] Minimal requirements of a service for reader driver OGC
	API - Features?
Message-ID: <CAFcOn28Y1+EVEw36XQuRw_UHDic5XNbmUKAD5FRoFkEAgV7bqA@mail.gmail.com>

Hi,
We're implementing a minimal server of an "OGC API - Features" service
and test it with a reader driver of "OGC API - Features" [1] (ogrinfo,
ogr2ogr, QGIS). We're getting ERROR 404 with "ogrinfo
WFS3:127.0.0.1:8000 <ourlayer>" [2] obviously because some discovery
paths are not implemented at server side.

Now, my question is: What are the endpoints really required by the OGR
reader driver? /api ?

According to 7.2.2 of the OGC spec [3] and given a basic endpoint
http://path/to/OAPIF/endpoint/ theses are all endpoints of WFS3:

* http://path/to/OAPIF/endpoint/
* http://path/to/OAPIF/endpoint/api
* http://path/to/OAPIF/endpoint/api.html
* http://path/to/OAPIF/endpoint/conformance

:Stefan

[1] https://gdal.org/drivers/vector/oapif.html
[2] https://i.imgur.com/HPyl5Go.png
[3] https://docs.opengeospatial.org/DRAFTS/17-069r1.html

From even.rouault at spatialys.com  Tue Dec  3 08:45:42 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 03 Dec 2019 17:45:42 +0100
Subject: [gdal-dev] Minimal requirements of a service for reader driver
	OGC API - Features?
In-Reply-To: <CAFcOn28Y1+EVEw36XQuRw_UHDic5XNbmUKAD5FRoFkEAgV7bqA@mail.gmail.com>
References: <CAFcOn28Y1+EVEw36XQuRw_UHDic5XNbmUKAD5FRoFkEAgV7bqA@mail.gmail.com>
Message-ID: <2605045.IJSFu8SvhI@even-i700>

On mardi 3 décembre 2019 17:25:20 CET Stefan Keller wrote:
> Hi,
> We're implementing a minimal server of an "OGC API - Features" service
> and test it with a reader driver of "OGC API - Features" [1] (ogrinfo,
> ogr2ogr, QGIS). We're getting ERROR 404 with "ogrinfo
> WFS3:127.0.0.1:8000 <ourlayer>" [2] obviously because some discovery
> paths are not implemented at server side.
> 
> Now, my question is: What are the endpoints really required by the OGR
> reader driver? /api ?

Source is there:
https://github.com/OSGeo/gdal/blob/master/gdal/ogr/ogrsf_frmts/wfs/ogroapifdriver.cpp

Master implements the final spec:
http://docs.opengeospatial.org/is/17-069r3/17-069r3.html
(there have been changes w.r.t earlier drafts)

From my memories, the OGR driver needs:
- Landing page: required
- /collections: required
- /collections/{collectioname}/items: required
- /api (actually link provided in Landing page): optional
- /conformance: not used

You can enable --config CPL_DEBUG ON --config CPL_CURL_VERBOSE YES
to see which network requests are attempted (some may be attempted and if
the server doesn't implement them, execution can continue

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sfkeller at gmail.com  Tue Dec  3 12:25:10 2019
From: sfkeller at gmail.com (Stefan Keller)
Date: Tue, 3 Dec 2019 21:25:10 +0100
Subject: [gdal-dev] Minimal requirements of a service for reader driver
 OGC API - Features?
In-Reply-To: <2605045.IJSFu8SvhI@even-i700>
References: <CAFcOn28Y1+EVEw36XQuRw_UHDic5XNbmUKAD5FRoFkEAgV7bqA@mail.gmail.com>
 <2605045.IJSFu8SvhI@even-i700>
Message-ID: <CAFcOn296hf55wsriSm-v-+4n9Q+vwPs4Pfknqz8BYx5OiWbegQ@mail.gmail.com>

Hi Even

Awesome, thanks! Tu es le meilleur.

:Stefan

Am Di., 3. Dez. 2019 um 17:45 Uhr schrieb Even Rouault
<even.rouault at spatialys.com>:
>
> On mardi 3 décembre 2019 17:25:20 CET Stefan Keller wrote:
> > Hi,
> > We're implementing a minimal server of an "OGC API - Features" service
> > and test it with a reader driver of "OGC API - Features" [1] (ogrinfo,
> > ogr2ogr, QGIS). We're getting ERROR 404 with "ogrinfo
> > WFS3:127.0.0.1:8000 <ourlayer>" [2] obviously because some discovery
> > paths are not implemented at server side.
> >
> > Now, my question is: What are the endpoints really required by the OGR
> > reader driver? /api ?
>
> Source is there:
> https://github.com/OSGeo/gdal/blob/master/gdal/ogr/ogrsf_frmts/wfs/ogroapifdriver.cpp
>
> Master implements the final spec:
> http://docs.opengeospatial.org/is/17-069r3/17-069r3.html
> (there have been changes w.r.t earlier drafts)
>
> From my memories, the OGR driver needs:
> - Landing page: required
> - /collections: required
> - /collections/{collectioname}/items: required
> - /api (actually link provided in Landing page): optional
> - /conformance: not used
>
> You can enable --config CPL_DEBUG ON --config CPL_CURL_VERBOSE YES
> to see which network requests are attempted (some may be attempted and if
> the server doesn't implement them, execution can continue
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com

From markus.metz.giswork at gmail.com  Tue Dec  3 12:44:43 2019
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Tue, 3 Dec 2019 21:44:43 +0100
Subject: [gdal-dev] OGR C API PostGIS geometry with wrong field entries
In-Reply-To: <d3a5c05d-ad0e-0b93-272b-65d42f2defd1@t-kartor.se>
References: <CAG+h=FHKpOn3ZJDCZN1ruBL9_wW7_U272DAt_Lcim4sqUbMu3Q@mail.gmail.com>
 <d3a5c05d-ad0e-0b93-272b-65d42f2defd1@t-kartor.se>
Message-ID: <CAG+h=FG2vFnr1hWiXenCCkkiJNu773Ho8crBLSTMnp0ACiNE=w@mail.gmail.com>

Thanks for your feedback! I think I figured it out. The GRASS module
v.in.ogr goes through the input features twice, but only for polygons. This
is needed to properly convert non-topological polygons to topological areas
in GRASS. The order of features can be different between the first and
second pass through the input features. We are now using FID to map
features in the second pass to features in the first pass. This solution is
not ideal because in between the two passes, features might be added or
deleted. Ultimately, we will go through the input features only once and
make a local copy for the second pass.

On Tue, Dec 3, 2019 at 8:32 AM Andreas Oxenstierna <ao at t-kartor.se> wrote:

> I am no Postgre expert but we have experienced similar cases when running
> complex transactions with large geometries, i.e. faulty results.
> When splitting the transaction into several pieces, i.e. enforcing COMMITs
> (Postgre doesn't support COMMIT inside functions), the correct results are
> given.
> One guess is that this may happen for large geometries which are pushed to
> TOAST tables.
>
> Check Postgre memory parameters and trace exactly what is happening in the
> database.
> Test also with EXTERNAL STORAGE for the geometry if they are really large.
>
>
> In the GRASS module v.in.ogr we follow pretty much the vector API
> tutorial. The only difference is that we first fetch the geometry of a
> feature, then the fields. When input is a PG database, sometimes the wrong
> field entries are associated with the geometries, as if geometries and
> field entries were mixed up. This happens when several different v.in.ogr
> processes are trying to read the same features from the same PG database at
> the same time. When instead using several different ogr2ogr processes, this
> mixing up of geometries and field entries does not happen. I could not find
> any hints in the OGR PostGIS documentation about how to avoid this problem.
>
> Any hints are highly appreciated!
>
> Markus M
>
> _______________________________________________
> gdal-dev mailing listgdal-dev at lists.osgeo.orghttps://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> --
> Hälsningar
>
> Andreas Oxenstierna
> T-Kartor Geospatial AB
> Olof Mohlins väg 12 Kristianstad
> mobile: +46 733 206831
> mailto: ao at t-kartor.sehttp://www.t-kartor.com
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191203/1eb2d49d/attachment.html>

From eadam at co.lincoln.or.us  Wed Dec  4 10:00:21 2019
From: eadam at co.lincoln.or.us (Eli Adam)
Date: Wed, 4 Dec 2019 10:00:21 -0800
Subject: [gdal-dev] Doc: driver + config options summary pages [was Re:
 How to know which formats allow editing with ogrinfo?]
In-Reply-To: <CACqBkM_Qjuq6YSrR4S=WsHytC1irvANX+KU713Z5KUGRwm3A-g@mail.gmail.com>
References: <e30ffdea7e69410dbd530717d7bea7d3@C119S212VM042.msvyvi.vaha.local>
 <2190558.rXhUX7LAVk@even-i700>
 <CACqBkM_y7VEvL5a79vrCbxTCMg0ZqVuiGLKMNbf2YXjhqN5OvQ@mail.gmail.com>
 <2278378.5otQQL0sNr@even-i700>
 <CACqBkM_Qjuq6YSrR4S=WsHytC1irvANX+KU713Z5KUGRwm3A-g@mail.gmail.com>
Message-ID: <CACqBkM8Rj3LxQqmV8o+88Z82fVXUwgN6Pi4YDYWoxH0meNrnzA@mail.gmail.com>

On Sun, Nov 17, 2019 at 5:42 PM Eli Adam <eadam at co.lincoln.or.us> wrote:
> > https://gdal.org/drivers/raster/index.html
> > https://gdal.org/drivers/vector/index.html

These two tables have been updated.  Please check them over.  Let me
know if anything needs to be changed/updated.

Best regards, Eli

From hyoklee at hdfgroup.org  Wed Dec  4 10:39:26 2019
From: hyoklee at hdfgroup.org (Joe Lee)
Date: Wed, 4 Dec 2019 18:39:26 +0000
Subject: [gdal-dev] Doc: driver + config options summary pages [was Re:
 How to know which formats allow editing with ogrinfo?]
In-Reply-To: <CACqBkM8Rj3LxQqmV8o+88Z82fVXUwgN6Pi4YDYWoxH0meNrnzA@mail.gmail.com>
References: <e30ffdea7e69410dbd530717d7bea7d3@C119S212VM042.msvyvi.vaha.local>
 <2190558.rXhUX7LAVk@even-i700>
 <CACqBkM_y7VEvL5a79vrCbxTCMg0ZqVuiGLKMNbf2YXjhqN5OvQ@mail.gmail.com>
 <2278378.5otQQL0sNr@even-i700>
 <CACqBkM_Qjuq6YSrR4S=WsHytC1irvANX+KU713Z5KUGRwm3A-g@mail.gmail.com>
 <CACqBkM8Rj3LxQqmV8o+88Z82fVXUwgN6Pi4YDYWoxH0meNrnzA@mail.gmail.com>
Message-ID: <B75CBA18-7C9A-4E23-830A-E5537D509F2D@hdfgroup.org>

Hi, Eli!

  I can see two rows for both HDF4 and HDF5 in [1] which points to the same document.
  For example,  HDF4 and HDF4Image points to [2].
  Can you consolidate them into one row?

[1] https://gdal.org/drivers/raster/index.html
[2] https://gdal.org/drivers/raster/hdf4.html#raster-hdf4

﻿On 12/4/19, 12:00 PM, "gdal-dev on behalf of Eli Adam" <gdal-dev-bounces at lists.osgeo.org on behalf of eadam at co.lincoln.or.us> wrote:

    On Sun, Nov 17, 2019 at 5:42 PM Eli Adam <eadam at co.lincoln.or.us> wrote:
    > > https://gdal.org/drivers/raster/index.html
    > > https://gdal.org/drivers/vector/index.html
    
    These two tables have been updated.  Please check them over.  Let me
    know if anything needs to be changed/updated.
    
    Best regards, Eli
    _______________________________________________
    gdal-dev mailing list
    gdal-dev at lists.osgeo.org
    https://lists.osgeo.org/mailman/listinfo/gdal-dev


From even.rouault at spatialys.com  Wed Dec  4 10:48:21 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 04 Dec 2019 19:48:21 +0100
Subject: [gdal-dev] Doc: driver + config options summary pages [was Re:
	How to know which formats allow editing with ogrinfo?]
In-Reply-To: <B75CBA18-7C9A-4E23-830A-E5537D509F2D@hdfgroup.org>
References: <e30ffdea7e69410dbd530717d7bea7d3@C119S212VM042.msvyvi.vaha.local>
 <CACqBkM8Rj3LxQqmV8o+88Z82fVXUwgN6Pi4YDYWoxH0meNrnzA@mail.gmail.com>
 <B75CBA18-7C9A-4E23-830A-E5537D509F2D@hdfgroup.org>
Message-ID: <4251980.3a8kiaEUWE@even-i700>

> For example,  HDF4 and HDF4Image points to [2].
>   Can you consolidate them into one row?

Fixed. Website will be refreshed in a few mins

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sfkeller at gmail.com  Thu Dec  5 03:02:07 2019
From: sfkeller at gmail.com (Stefan Keller)
Date: Thu, 5 Dec 2019 12:02:07 +0100
Subject: [gdal-dev] Minimal requirements of a service for reader driver
 OGC API - Features?
In-Reply-To: <CAFcOn296hf55wsriSm-v-+4n9Q+vwPs4Pfknqz8BYx5OiWbegQ@mail.gmail.com>
References: <CAFcOn28Y1+EVEw36XQuRw_UHDic5XNbmUKAD5FRoFkEAgV7bqA@mail.gmail.com>
 <2605045.IJSFu8SvhI@even-i700>
 <CAFcOn296hf55wsriSm-v-+4n9Q+vwPs4Pfknqz8BYx5OiWbegQ@mail.gmail.com>
Message-ID: <CAFcOn2-WEMLou8TSf+1tv+gaEeNFdfx78XhExDcuENoOFbe+uQ@mail.gmail.com>

Even,

I seems that ogrinfo "insists" that the /api path exists, since it
throws an error 404 as reported above.
So we had to implement a dummy /api in our minimal server
implementation which returns "OK" to ogrinfo in order to bypass those
404 errors from ogrinfo.

I quickly skimmed the ogrinfo code [1] ff. and assumes that it lacks a
catch for this 404 error.
Should I create an issue?

:Stefan

[1] https://github.com/OSGeo/gdal/blob/master/gdal/ogr/ogrsf_frmts/wfs/ogroapifdriver.cpp#L509
ff.

Am Di., 3. Dez. 2019 um 21:25 Uhr schrieb Stefan Keller <sfkeller at gmail.com>:
>
> Hi Even
>
> Awesome, thanks! Tu es le meilleur.
>
> :Stefan
>
> Am Di., 3. Dez. 2019 um 17:45 Uhr schrieb Even Rouault
> <even.rouault at spatialys.com>:
> >
> > On mardi 3 décembre 2019 17:25:20 CET Stefan Keller wrote:
> > > Hi,
> > > We're implementing a minimal server of an "OGC API - Features" service
> > > and test it with a reader driver of "OGC API - Features" [1] (ogrinfo,
> > > ogr2ogr, QGIS). We're getting ERROR 404 with "ogrinfo
> > > WFS3:127.0.0.1:8000 <ourlayer>" [2] obviously because some discovery
> > > paths are not implemented at server side.
> > >
> > > Now, my question is: What are the endpoints really required by the OGR
> > > reader driver? /api ?
> >
> > Source is there:
> > https://github.com/OSGeo/gdal/blob/master/gdal/ogr/ogrsf_frmts/wfs/ogroapifdriver.cpp
> >
> > Master implements the final spec:
> > http://docs.opengeospatial.org/is/17-069r3/17-069r3.html
> > (there have been changes w.r.t earlier drafts)
> >
> > From my memories, the OGR driver needs:
> > - Landing page: required
> > - /collections: required
> > - /collections/{collectioname}/items: required
> > - /api (actually link provided in Landing page): optional
> > - /conformance: not used
> >
> > You can enable --config CPL_DEBUG ON --config CPL_CURL_VERBOSE YES
> > to see which network requests are attempted (some may be attempted and if
> > the server doesn't implement them, execution can continue
> >
> > --
> > Spatialys - Geospatial professional services
> > http://www.spatialys.com

From even.rouault at spatialys.com  Thu Dec  5 04:11:08 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 05 Dec 2019 13:11:08 +0100
Subject: [gdal-dev] Minimal requirements of a service for reader driver
	OGC API - Features?
In-Reply-To: <CAFcOn2-WEMLou8TSf+1tv+gaEeNFdfx78XhExDcuENoOFbe+uQ@mail.gmail.com>
References: <CAFcOn28Y1+EVEw36XQuRw_UHDic5XNbmUKAD5FRoFkEAgV7bqA@mail.gmail.com>
 <CAFcOn296hf55wsriSm-v-+4n9Q+vwPs4Pfknqz8BYx5OiWbegQ@mail.gmail.com>
 <CAFcOn2-WEMLou8TSf+1tv+gaEeNFdfx78XhExDcuENoOFbe+uQ@mail.gmail.com>
Message-ID: <2440547.Aa22OuHI2Y@even-i700>

Stefan,

> I seems that ogrinfo "insists" that the /api path exists, since it
> throws an error 404 as reported above.

I think it should still go on despite emitting the error. The error is
probably emitted on the /api/ (with trailing slash) at 
https://github.com/OSGeo/gdal/blob/master/gdal/ogr/ogrsf_frmts/wfs/
ogroapifdriver.cpp#L521
that isn't surrounded by error quieting.

Anyway, all this fallback logic is mostly historic material from the earlier
stages of the specification. Conformant servers should implement a API page,
not necessarily under the /api endpoint, but at the endpoint they declare in
the landing page

See http://docs.opengeospatial.org/is/17-069r3/17-069r3.html#_api_landing_page

I don't remember the exact details of the QGIS OAPIF client, but it's 
certainly
less forgiving than the OGR one, and wouldn't likely like the API to be 
missing.

> Should I create an issue?

In your implementation yes 

Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tim.jacobs at vito.be  Thu Dec  5 07:45:23 2019
From: tim.jacobs at vito.be (Jacobs Tim)
Date: Thu, 5 Dec 2019 15:45:23 +0000
Subject: [gdal-dev] gdal2tiles missing 'GRA_mode' resample method
In-Reply-To: <CAM2FmMoH7oySWPhhxfofyNRF0OG0Q8BNOoPBigndfo-C9u1yFg@mail.gmail.com>
References: <e5b4cc25f1ce49e88a3fc0c6b47973d1@VITOMAIL5.vito.local>
 <CAM2FmMoH7oySWPhhxfofyNRF0OG0Q8BNOoPBigndfo-C9u1yFg@mail.gmail.com>
Message-ID: <6e7f93bab1b845dea98f8d342b0a77fd@VITOMAIL5.vito.local>

Hi Mike

the GRA_mode resampling in gdal2tiles, that we discussed on gdal-dev back in August,
was expected for next release, but doesn’t appear to be included in the 3.0.2 release (October).

Can you pls tell me in which release it will be taken up? The 3.1 maybe?
And is the timeline already set for that release?

Thanks,
Tim Jacobs
Indien u VITO Mol bezoekt, hou aub er dan rekening mee dat de hoofdingang voortaan enkel bereikbaar is vanuit de richting Dessel-Retie, niet vanuit richting Mol, zie vito.be/route.<http://www.vito.be/route>
If you plan to visit VITO at Mol, then please note that the main entrance can only be reached coming from Dessel-Retie and no longer coming from Mol, see vito.be/en/contact/locations.<http://www.vito.be/en/contact/locations>
VITO Disclaimer: http://www.vito.be/e-maildisclaimer
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 7621 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191205/e8ee90fb/attachment.bin>

From even.rouault at spatialys.com  Thu Dec  5 07:53:10 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 05 Dec 2019 16:53:10 +0100
Subject: [gdal-dev] gdal2tiles missing 'GRA_mode' resample method
In-Reply-To: <6e7f93bab1b845dea98f8d342b0a77fd@VITOMAIL5.vito.local>
References: <e5b4cc25f1ce49e88a3fc0c6b47973d1@VITOMAIL5.vito.local>
 <CAM2FmMoH7oySWPhhxfofyNRF0OG0Q8BNOoPBigndfo-C9u1yFg@mail.gmail.com>
 <6e7f93bab1b845dea98f8d342b0a77fd@VITOMAIL5.vito.local>
Message-ID: <16946907.sPHSO4CzHx@even-i700>

On jeudi 5 décembre 2019 15:45:23 CET Jacobs Tim wrote:
> Hi Mike
> 
> the GRA_mode resampling in gdal2tiles, that we discussed on gdal-dev back in
> August,
 was expected for next release, but doesn’t appear to be included
> in the 3.0.2 release (October). 
> Can you pls tell me in which release it will be taken up? The 3.1 maybe?
> And is the timeline already set for that release?

yes 3.1 to be released ~ May 2020 presumably

In the meantime you can just grab gdal2tiles.py from master. Should run fine 
against 3.0 I think


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tim.jacobs at vito.be  Thu Dec  5 08:03:33 2019
From: tim.jacobs at vito.be (Jacobs Tim)
Date: Thu, 5 Dec 2019 16:03:33 +0000
Subject: [gdal-dev] gdal2tiles missing 'GRA_mode' resample method
In-Reply-To: <16946907.sPHSO4CzHx@even-i700>
References: <e5b4cc25f1ce49e88a3fc0c6b47973d1@VITOMAIL5.vito.local>
 <CAM2FmMoH7oySWPhhxfofyNRF0OG0Q8BNOoPBigndfo-C9u1yFg@mail.gmail.com>
 <6e7f93bab1b845dea98f8d342b0a77fd@VITOMAIL5.vito.local>
 <16946907.sPHSO4CzHx@even-i700>
Message-ID: <df292a1198fc4c6193b022684a4893b9@VITOMAIL5.vito.local>

We'll give the copy on master a try.
Thanks for the quick answer.

Tim

-----Original Message-----
From: Even Rouault <even.rouault at spatialys.com>
Sent: Thursday, 5 December 2019 16:53
To: gdal-dev at lists.osgeo.org
Cc: Jacobs Tim <tim.jacobs at vito.be>; Mike Taves <mwtoews at gmail.com>
Subject: Re: [gdal-dev] gdal2tiles missing 'GRA_mode' resample method

On jeudi 5 décembre 2019 15:45:23 CET Jacobs Tim wrote:
> Hi Mike
>
> the GRA_mode resampling in gdal2tiles, that we discussed on gdal-dev
> back in August,
 was expected for next release, but doesn’t appear to be included
> in the 3.0.2 release (October).
> Can you pls tell me in which release it will be taken up? The 3.1 maybe?
> And is the timeline already set for that release?

yes 3.1 to be released ~ May 2020 presumably

In the meantime you can just grab gdal2tiles.py from master. Should run fine against 3.0 I think


--
Spatialys - Geospatial professional services
http://www.spatialys.com
Indien u VITO Mol bezoekt, hou aub er dan rekening mee dat de hoofdingang voortaan enkel bereikbaar is vanuit de richting Dessel-Retie, niet vanuit richting Mol, zie vito.be/route.<http://www.vito.be/route>
If you plan to visit VITO at Mol, then please note that the main entrance can only be reached coming from Dessel-Retie and no longer coming from Mol, see vito.be/en/contact/locations.<http://www.vito.be/en/contact/locations>
VITO Disclaimer: http://www.vito.be/e-maildisclaimer

From andrew at aitchison.me.uk  Thu Dec  5 09:34:28 2019
From: andrew at aitchison.me.uk (Andrew C Aitchison)
Date: Thu, 5 Dec 2019 17:34:28 +0000 (GMT)
Subject: [gdal-dev] Doc: driver + config options summary pages
In-Reply-To: <CACqBkM8Rj3LxQqmV8o+88Z82fVXUwgN6Pi4YDYWoxH0meNrnzA@mail.gmail.com>
References: <e30ffdea7e69410dbd530717d7bea7d3@C119S212VM042.msvyvi.vaha.local>
 <2190558.rXhUX7LAVk@even-i700>
 <CACqBkM_y7VEvL5a79vrCbxTCMg0ZqVuiGLKMNbf2YXjhqN5OvQ@mail.gmail.com>
 <2278378.5otQQL0sNr@even-i700>
 <CACqBkM_Qjuq6YSrR4S=WsHytC1irvANX+KU713Z5KUGRwm3A-g@mail.gmail.com>
 <CACqBkM8Rj3LxQqmV8o+88Z82fVXUwgN6Pi4YDYWoxH0meNrnzA@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1912051723490.14387@warden.aitchison.me.uk>

On Wed, 4 Dec 2019, Eli Adam wrote:

> On Sun, Nov 17, 2019 at 5:42 PM Eli Adam <eadam at co.lincoln.or.us> wrote:
>>> https://gdal.org/drivers/raster/index.html
>>> https://gdal.org/drivers/vector/index.html
>
> These two tables have been updated.  Please check them over.  Let me
> know if anything needs to be changed/updated.

Screen shot from Firefox on Linux, but I have the same issue with 
Opera and Windows:
 	https://www.aitchison.me.uk/rasterdrivers.png
If the window is *only* 1080 pixels wide I see no hint that there are
more than two columns and that if I scroll to the bottom I will be able
to scroll to the right and see more info about each driver.

-- 
Andrew C. Aitchison					Kendal, UK
 			andrew at aitchison.me.uk

From bclay at infoscitex.com  Fri Dec  6 06:05:37 2019
From: bclay at infoscitex.com (Clay, Bruce)
Date: Fri, 6 Dec 2019 14:05:37 +0000
Subject: [gdal-dev] ECW to JP2000
Message-ID: <59cd6a708bd943a98b7ddd758f3f11bf@infoscitex.com>

when I use gdal_translate to convert an ECW file to JP2000 it ends up 9 times larger.  I could not find any options to control the compression like we can with Geotiff.  Is there a way to get a compressed JP2000 image?


Bruce

From daniele.romagnoli at geo-solutions.it  Fri Dec  6 06:48:49 2019
From: daniele.romagnoli at geo-solutions.it (Daniele Romagnoli)
Date: Fri, 6 Dec 2019 15:48:49 +0100
Subject: [gdal-dev] ECW to JP2000
In-Reply-To: <59cd6a708bd943a98b7ddd758f3f11bf@infoscitex.com>
References: <59cd6a708bd943a98b7ddd758f3f11bf@infoscitex.com>
Message-ID: <CAJaHrDz5nnN1Bk5kjzd1BxCgQXmfUmLiBgKFAvHM7xoaDzrqBw@mail.gmail.com>

Hi Bruce,
One of the several advantages of using JP2K is compression indeed.
Which driver are you using to convert the files?
If JP2OpenJPEG, did you check this page?
https://gdal.org/drivers/raster/jp2openjpeg.html#creation-options

I personally never tried that driver before but I think that the "Quality"
and "YCC" create options should allow for some level of compression.
You may want to play with these parameters (some other people with more
experience than me with that driver will probably chime in with some more
feedbacks).
Just my 2c.

Regards,
Daniele





On Fri, Dec 6, 2019 at 3:20 PM Clay, Bruce <bclay at infoscitex.com> wrote:

> when I use gdal_translate to convert an ECW file to JP2000 it ends up 9
> times larger.  I could not find any options to control the compression like
> we can with Geotiff.  Is there a way to get a compressed JP2000 image?
>
>
> Bruce
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Regards,
Daniele Romagnoli
==
GeoServer Professional Services from the experts! Visit http://goo.gl/it488V
for more information.
==

Ing. Daniele Romagnoli
Senior Software Engineer

GeoSolutions S.A.S.
Via di Montramito 3/A
55054  Massarosa (LU)
Italy
phone: +39 0584 962313
fax:      +39 0584 1660272

http://www.geo-solutions.it
http://twitter.com/geosolutions_it

-------------------------------------------------------

Con riferimento alla normativa sul trattamento dei dati personali (Reg. UE
2016/679 - Regolamento generale sulla protezione dei dati “GDPR”), si
precisa che ogni circostanza inerente alla presente email (il suo
contenuto, gli eventuali allegati, etc.) è un dato la cui conoscenza è
riservata al/i solo/i destinatario/i indicati dallo scrivente. Se il
messaggio Le è giunto per errore, è tenuta/o a cancellarlo, ogni altra
operazione è illecita. Le sarei comunque grato se potesse darmene notizia.

This email is intended only for the person or entity to which it is
addressed and may contain information that is privileged, confidential or
otherwise protected from disclosure. We remind that - as provided by
European Regulation 2016/679 “GDPR” - copying, dissemination or use of this
e-mail or the information herein by anyone other than the intended
recipient is prohibited. If you have received this email by mistake, please
notify us immediately by telephone or e-mail.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191206/53f0eef6/attachment.html>

From even.rouault at spatialys.com  Fri Dec  6 06:51:50 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 06 Dec 2019 15:51:50 +0100
Subject: [gdal-dev] ECW to JP2000
In-Reply-To: <59cd6a708bd943a98b7ddd758f3f11bf@infoscitex.com>
References: <59cd6a708bd943a98b7ddd758f3f11bf@infoscitex.com>
Message-ID: <2592653.BnTt1NVDE4@even-i700>

On vendredi 6 décembre 2019 14:05:37 CET Clay, Bruce wrote:
> when I use gdal_translate to convert an ECW file to JP2000 it ends up 9
> times larger.  I could not find any options to control the compression like
> we can with Geotiff.  Is there a way to get a compressed JP2000 image?

Certainly.

You need to look at the specific JPEG2000 driver you use. For example for 
JP2OpenJPEG, the doc is at:
https://gdal.org/drivers/raster/jp2openjpeg.html

For example if you use QUALITY=5, then you'll get a file whose compressed size 
is 5% of the uncompressed file size.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From vbaros at gmail.com  Sat Dec  7 11:07:52 2019
From: vbaros at gmail.com (Artz)
Date: Sat, 7 Dec 2019 12:07:52 -0700 (MST)
Subject: [gdal-dev] How to use Gdal c# bindings with .NET Core
In-Reply-To: <CACALY+QfMcG8jEaGW-sCJpZYpzeN_Fp-AxMuFOrVfkEdmpHY2w@mail.gmail.com>
References: <1544885397803-0.post@n6.nabble.com>
 <CACALY+Rxirw5zc6UihKrH2=cyJmrVdxChHpA53awxnpK9_nHKg@mail.gmail.com>
 <1544904345953-0.post@n6.nabble.com>
 <CACALY+QfMcG8jEaGW-sCJpZYpzeN_Fp-AxMuFOrVfkEdmpHY2w@mail.gmail.com>
Message-ID: <1575745672197-0.post@n6.nabble.com>

Tamas Szekeres wrote
> "Official" binaries are not being provided by GDAL directly. However, in
> the near future, I'm planning to support ".net standard 2.1" with the
> nuget
> packages derived from the binaries of https://www.gisinternals.com.
> 
> Best regards,
> 
> Tamas
> 
> 
> Gigas002 &lt;

> gigas002@

> &gt; ezt írta (időpont: 2018. dec. 15., Szo,
> 21:05):
> 
>> Thanks! That worked for me. But of course anyone would prefer official
>> release, so... Is .net core bindings planned?
>>
>>
>>
>> --
>> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>> _______________________________________________
>> gdal-dev mailing list
>> 

> gdal-dev at .osgeo

>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
> 
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev

Hi Tamara,

Are planning to offer a new .NET Standard 2.0 release soon?



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From ravitejakrishna.w at zohocorp.com  Mon Dec  9 00:02:00 2019
From: ravitejakrishna.w at zohocorp.com (Wuyyuru Ravi Teja Krishna)
Date: Mon, 09 Dec 2019 13:32:00 +0530
Subject: [gdal-dev] Regarding geometry layer creation options
Message-ID: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>

Hello Gdal team,



Iam using ogr2ogr tool for .shp or .geojson. or .kml to .csv conversion. But i want the Geometry to be as collections as show below. ( On giving GEOMETRY=AS_WKT iam getting in a normal format is there any option to get in the format i need )



format I need : { "type": "Polygon", "coordinates": [ [ [ 76.612, 33.173 ], [ 76.64, 33.162 ], [ 76.709, 33.181 ] ] ] } 

                        or  atleast to have it in this format is aceptable for us POLYGON (([76.612 , 33.173],[76.64 , 33.162],[76.709 , 33.181])) 
format iam getting :  POLYGON ((76.612 33.173,76.64 33.162,76.709 33.181)) 



Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191209/e6e996da/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Mon Dec  9 02:01:25 2019
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Mon, 9 Dec 2019 03:01:25 -0700 (MST)
Subject: [gdal-dev] Regarding geometry layer creation options
In-Reply-To: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>
References: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>
Message-ID: <1575885685721-0.post@n6.nabble.com>

Hi,

Have you tried with the syntax that is used in an example in the CSV
documentation https://gdal.org/drivers/vector/csv.html?

"This example shows using ogr2ogr to transform a shapefile into a .csv file
with geography field formatted using GeoJSON format."

ogr2ogr -f CSV -dialect sqlite -sql "select AsGeoJSON(geometry) AS geom, *
from input" output.csv input.shp

-Jukka Rahkonen-



Ravi Teja Krishna Wuyyuru wrote
> Hello Gdal team,
> 
> 
> 
> Iam using ogr2ogr tool for .shp or .geojson. or .kml to .csv conversion.
> But i want the Geometry to be as collections as show below. ( On giving
> GEOMETRY=AS_WKT iam getting in a normal format is there any option to get
> in the format i need )
> 
> 
> 
> format I need : { "type": "Polygon", "coordinates": [ [ [ 76.612, 33.173
> ], [ 76.64, 33.162 ], [ 76.709, 33.181 ] ] ] } 
> 
>                         or  atleast to have it in this format is aceptable
> for us POLYGON (([76.612 , 33.173],[76.64 , 33.162],[76.709 , 33.181])) 
> format iam getting :  POLYGON ((76.612 33.173,76.64 33.162,76.709
> 33.181)) 
> 
> 
> 
> Thanks.
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From ravitejakrishna.w at zohocorp.com  Mon Dec  9 03:54:38 2019
From: ravitejakrishna.w at zohocorp.com (Wuyyuru Ravi Teja Krishna)
Date: Mon, 09 Dec 2019 17:24:38 +0530
Subject: [gdal-dev] Regarding geometry layer creation options
In-Reply-To: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>
References: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>
Message-ID: <16eea82e871.11709586151123.5242667017212146607@zohocorp.com>

Hi,



Thanks for your reply. But we would like to use it without using databases. can the same result be obtained without using any databases?

Thanks






---- On Mon, 09 Dec 2019 13:32:00 +0530 Wuyyuru Ravi Teja Krishna <ravitejakrishna.w at zohocorp.com> wrote ----


Hello Gdal team,



Iam using ogr2ogr tool for .shp or .geojson. or .kml to .csv conversion. But i want the Geometry to be as collections as show below. ( On giving GEOMETRY=AS_WKT iam getting in a normal format is there any option to get in the format i need )



format I need : { "type": "Polygon", "coordinates": [ [ [ 76.612, 33.173 ], [ 76.64, 33.162 ], [ 76.709, 33.181 ] ] ] } 

                        or  atleast to have it in this format is aceptable for us POLYGON (([76.612 , 33.173],[76.64 , 33.162],[76.709 , 33.181])) 

format iam getting :  POLYGON ((76.612 33.173,76.64 33.162,76.709 33.181)) 



Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191209/d0369717/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Mon Dec  9 04:39:25 2019
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Mon, 9 Dec 2019 05:39:25 -0700 (MST)
Subject: [gdal-dev] Regarding geometry layer creation options
In-Reply-To: <16eea82e871.11709586151123.5242667017212146607@zohocorp.com>
References: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>
 <16eea82e871.11709586151123.5242667017212146607@zohocorp.com>
Message-ID: <1575895165844-0.post@n6.nabble.com>

Hi,

The example does not really use any database. It is utilising SQLite and a
Spatialite function but it happens through a virtual table system in the
background. You do not need to install anything extra. Did you try the
command?

-Jukka-


Ravi Teja Krishna Wuyyuru wrote
> Hi,
> 
> Thanks for your reply. But we would like to use it without using
> databases. can the same result be obtained without using any databases?
> 
> Thanks





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From DeDuikertjes at xs4all.nl  Mon Dec  9 09:10:40 2019
From: DeDuikertjes at xs4all.nl (deduikertjes)
Date: Mon, 9 Dec 2019 10:10:40 -0700 (MST)
Subject: [gdal-dev] Motion: adopt RFC 76 OGR Python drivers
In-Reply-To: <8957596.pYBE0I3rnp@even-i700>
References: <4509893.ddkccIuGDM@even-i700>
 <6265eec1-7ae8-a36e-4f36-ba9f104d56e7@xs4all.nl>
 <4670062.iUf7AHNAqO@even-i700> <8957596.pYBE0I3rnp@even-i700>
Message-ID: <1575911440680-0.post@n6.nabble.com>

RFC76 implementation is now available in master

Even

-- 

I used the Dockerfile from
https://github.com/OSGeo/gdal/tree/master/gdal/docker/ubuntu-full
to build a container from master. I copied in all example drivers and an
example cityjson file.

In this I ran the autotest pytest -vvs ogr/ succesfully.

However, trying to use the drivers from command line fails.

I've tried  things like 

   gdalinfo --config GDAL_PYTHON_DRIVER_PATH ./pydrivers/ --formats | grep
DUMMY
   gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" --formats |
grep JSON
   gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" test.json

All these are failing. The first two don't have any of the example drivers
in the format list, the last fails with the well know error for not having
the correct driver for the dataset.

What am I doing wrong?

Thanks, MArco
   



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Mon Dec  9 09:23:37 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 09 Dec 2019 18:23:37 +0100
Subject: [gdal-dev] Motion: adopt RFC 76 OGR Python drivers
In-Reply-To: <1575911440680-0.post@n6.nabble.com>
References: <4509893.ddkccIuGDM@even-i700> <8957596.pYBE0I3rnp@even-i700>
 <1575911440680-0.post@n6.nabble.com>
Message-ID: <3268221.A0i0cKGiSD@even-i700>

Marco,

> I used the Dockerfile from
> https://github.com/OSGeo/gdal/tree/master/gdal/docker/ubuntu-full
> to build a container from master. I copied in all example drivers and an
> example cityjson file.
>
> In this I ran the autotest pytest -vvs ogr/ succesfully.
>
> However, trying to use the drivers from command line fails.
>
> I've tried  things like 
>
>    gdalinfo --config GDAL_PYTHON_DRIVER_PATH ./pydrivers/ --formats | grep
> DUMMY
>    gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" --formats |
> grep JSON
>    gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" test.json
> 
> All these are failing. The first two don't have any of the example drivers
> in the format list, the last fails with the well know error for not having
> the correct driver for the dataset.
> 
> What am I doing wrong?

Probably some issue with the path you set:

>From the gdal/ subdirectory of a git checkout of GDAL, the following

$ docker run --rm -v /home:/home osgeo/gdal:ubuntu-full-latest ogrinfo --config GDAL_PYTHON_DRIVER_PATH $PWD/examples/pydrivers --format CityJSON

returns

Format Details:
  Short Name: CityJSON
  Long Name: CityJSON
  Supports: Vector
  Extension: json
  Supports: Open() - Open existing dataset.
  Supports: Virtual IO - eg. /vsimem/
  Other metadata items:
    DRIVER_LANGUAGE=PYTHON

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From deduikertjes at xs4all.nl  Mon Dec  9 09:35:59 2019
From: deduikertjes at xs4all.nl (Marco)
Date: Mon, 9 Dec 2019 18:35:59 +0100
Subject: [gdal-dev] Motion: adopt RFC 76 OGR Python drivers
In-Reply-To: <3268221.A0i0cKGiSD@even-i700>
References: <4509893.ddkccIuGDM@even-i700> <8957596.pYBE0I3rnp@even-i700>
 <1575911440680-0.post@n6.nabble.com> <3268221.A0i0cKGiSD@even-i700>
Message-ID: <94c291d7-f9a6-fa29-50f1-7c4e029a1c13@xs4all.nl>

Even,

Thanks but ...

xxxx/gdal$ docker run --rm -v /home:/home osgeo/gdal:ubuntu-full-latest 
ogrinfo --config GDAL_PYTHON_DRIVER_PATH $PWD/examples/pydrivers 
--format CityJSON
ERROR 1: --format option given with format 'CityJSON', but that format not
recognised.  Use the --formats option to get a list of available formats,
and use the short code (i.e. GTiff or HFA) as the format identifier.

I did try all sorts of quoting of options and so on with the expected 
variety of error messages.

(Docker version 18.09.5, build e8ff056)

Marco



On 09-12-19 18:23, Even Rouault wrote:
> Marco,
>
>> I used the Dockerfile from
>> https://github.com/OSGeo/gdal/tree/master/gdal/docker/ubuntu-full
>> to build a container from master. I copied in all example drivers and an
>> example cityjson file.
>>
>> In this I ran the autotest pytest -vvs ogr/ succesfully.
>>
>> However, trying to use the drivers from command line fails.
>>
>> I've tried  things like
>>
>>     gdalinfo --config GDAL_PYTHON_DRIVER_PATH ./pydrivers/ --formats | grep
>> DUMMY
>>     gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" --formats |
>> grep JSON
>>     gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" test.json
>>
>> All these are failing. The first two don't have any of the example drivers
>> in the format list, the last fails with the well know error for not having
>> the correct driver for the dataset.
>>
>> What am I doing wrong?
> Probably some issue with the path you set:
>
>  From the gdal/ subdirectory of a git checkout of GDAL, the following
>
> $ docker run --rm -v /home:/home osgeo/gdal:ubuntu-full-latest ogrinfo --config GDAL_PYTHON_DRIVER_PATH $PWD/examples/pydrivers --format CityJSON
>
> returns
>
> Format Details:
>    Short Name: CityJSON
>    Long Name: CityJSON
>    Supports: Vector
>    Extension: json
>    Supports: Open() - Open existing dataset.
>    Supports: Virtual IO - eg. /vsimem/
>    Other metadata items:
>      DRIVER_LANGUAGE=PYTHON
>
> Even
>


From deduikertjes at xs4all.nl  Mon Dec  9 09:37:58 2019
From: deduikertjes at xs4all.nl (Marco)
Date: Mon, 9 Dec 2019 18:37:58 +0100
Subject: [gdal-dev] Motion: adopt RFC 76 OGR Python drivers
In-Reply-To: <94c291d7-f9a6-fa29-50f1-7c4e029a1c13@xs4all.nl>
References: <4509893.ddkccIuGDM@even-i700> <8957596.pYBE0I3rnp@even-i700>
 <1575911440680-0.post@n6.nabble.com> <3268221.A0i0cKGiSD@even-i700>
 <94c291d7-f9a6-fa29-50f1-7c4e029a1c13@xs4all.nl>
Message-ID: <f33e7595-e2a7-b726-436e-81d8970d1154@xs4all.nl>

Even,

xxx/gdal/gdal docker run --rm -v /home:/home 
osgeo/gdal:ubuntu-full-latest ogrinfo --config GDAL_PYTHON_DRIVER_PATH 
$PWD/examples/pydrivers --format CityJSON

works.
Sorry for the noise ...

MArco

On 09-12-19 18:35, Marco wrote:
> Even,
>
> Thanks but ...
>
> xxxx/gdal$ docker run --rm -v /home:/home 
> osgeo/gdal:ubuntu-full-latest ogrinfo --config GDAL_PYTHON_DRIVER_PATH 
> $PWD/examples/pydrivers --format CityJSON
> ERROR 1: --format option given with format 'CityJSON', but that format 
> not
> recognised.  Use the --formats option to get a list of available formats,
> and use the short code (i.e. GTiff or HFA) as the format identifier.
>
> I did try all sorts of quoting of options and so on with the expected 
> variety of error messages.
>
> (Docker version 18.09.5, build e8ff056)
>
> Marco
>
>
>
> On 09-12-19 18:23, Even Rouault wrote:
>> Marco,
>>
>>> I used the Dockerfile from
>>> https://github.com/OSGeo/gdal/tree/master/gdal/docker/ubuntu-full
>>> to build a container from master. I copied in all example drivers 
>>> and an
>>> example cityjson file.
>>>
>>> In this I ran the autotest pytest -vvs ogr/ succesfully.
>>>
>>> However, trying to use the drivers from command line fails.
>>>
>>> I've tried  things like
>>>
>>>     gdalinfo --config GDAL_PYTHON_DRIVER_PATH ./pydrivers/ --formats 
>>> | grep
>>> DUMMY
>>>     gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" 
>>> --formats |
>>> grep JSON
>>>     gdalinfo --config GDAL_PYTHON_DRIVER_PATH "/python_drivers/" 
>>> test.json
>>>
>>> All these are failing. The first two don't have any of the example 
>>> drivers
>>> in the format list, the last fails with the well know error for not 
>>> having
>>> the correct driver for the dataset.
>>>
>>> What am I doing wrong?
>> Probably some issue with the path you set:
>>
>>  From the gdal/ subdirectory of a git checkout of GDAL, the following
>>
>> $ docker run --rm -v /home:/home osgeo/gdal:ubuntu-full-latest 
>> ogrinfo --config GDAL_PYTHON_DRIVER_PATH $PWD/examples/pydrivers 
>> --format CityJSON
>>
>> returns
>>
>> Format Details:
>>    Short Name: CityJSON
>>    Long Name: CityJSON
>>    Supports: Vector
>>    Extension: json
>>    Supports: Open() - Open existing dataset.
>>    Supports: Virtual IO - eg. /vsimem/
>>    Other metadata items:
>>      DRIVER_LANGUAGE=PYTHON
>>
>> Even
>>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


From nyall.dawson at gmail.com  Mon Dec  9 21:13:01 2019
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Tue, 10 Dec 2019 15:13:01 +1000
Subject: [gdal-dev] Extended tab/mrr driver questions
Message-ID: <CAB28AshbKthaxyHepnYe2AjrAGGt5LxM=xYZ0idHRJc4P0aGmg@mail.gmail.com>

Hi list,

I just read this comment on the Pitney Bowes pull request regarding
extended tab/mrr support:

"After discussing with the GDAL PSC, we will be splitting this into
two separate PRs for the two drivers. We will also be following the
plugin model for both EFAL and MRR format driver."
(https://github.com/OSGeo/gdal/pull/1882#issuecomment-563807100)

Can anyone from gdal psc elaborate on this? Why were they advised to
follow the plugin model instead of doing the "right thing" and
extending the existing tab driver?

Nyall

From mateusz at loskot.net  Tue Dec 10 00:41:29 2019
From: mateusz at loskot.net (Mateusz Loskot)
Date: Tue, 10 Dec 2019 09:41:29 +0100
Subject: [gdal-dev] Extended tab/mrr driver questions
In-Reply-To: <CAB28AshbKthaxyHepnYe2AjrAGGt5LxM=xYZ0idHRJc4P0aGmg@mail.gmail.com>
References: <CAB28AshbKthaxyHepnYe2AjrAGGt5LxM=xYZ0idHRJc4P0aGmg@mail.gmail.com>
Message-ID: <CABUeae833tW7qihTVjRt3R7D+tXwLpkQC2BeiDkoEq-SCej0cg@mail.gmail.com>

On Tue, 10 Dec 2019 at 06:13, Nyall Dawson <nyall.dawson at gmail.com> wrote:
> Hi list,
>
> I just read this comment on the Pitney Bowes pull request regarding
> extended tab/mrr support:
>
> "After discussing with the GDAL PSC, we will be splitting this into
> two separate PRs for the two drivers. We will also be following the
> plugin model for both EFAL and MRR format driver."
> (https://github.com/OSGeo/gdal/pull/1882#issuecomment-563807100)
>
> Can anyone from gdal psc elaborate on this?

I can't give authoritative explanation myself
- I'm only aware of the public conversations on GitHub, Twitter and gdal-dev

> Why were they advised to
> follow the plugin model instead of doing the "right thing" and
> extending the existing tab driver?

Presumably, the piece of advice PB received was a (natural) consequence
of what they wrote in the description of their PR:

"They only load if the respective SDK's are present. These SDK's are
free to download (...)"

It means, if GDAL driver requires a binary SDK, then natural choice is
to develop such driver as a plug-in.

Best regards,
-- 
Mateusz Loskot, http://mateusz.loskot.net

From even.rouault at spatialys.com  Tue Dec 10 04:13:34 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 10 Dec 2019 13:13:34 +0100
Subject: [gdal-dev] Extended tab/mrr driver questions
In-Reply-To: <CAB28AshbKthaxyHepnYe2AjrAGGt5LxM=xYZ0idHRJc4P0aGmg@mail.gmail.com>
References: <CAB28AshbKthaxyHepnYe2AjrAGGt5LxM=xYZ0idHRJc4P0aGmg@mail.gmail.com>
Message-ID: <1611043.yvcSyNku73@even-i700>

Nyall,

> I just read this comment on the Pitney Bowes pull request regarding
> extended tab/mrr support:
> 
> "After discussing with the GDAL PSC, we will be splitting this into
> two separate PRs for the two drivers. We will also be following the
> plugin model for both EFAL and MRR format driver."
> (https://github.com/OSGeo/gdal/pull/1882#issuecomment-563807100)
> 
> Can anyone from gdal psc elaborate on this? Why were they advised to
> follow the plugin model instead of doing the "right thing" and
> extending the existing tab driver?

For everyone understanding, I had preliminary contacts with them beginning of 
2018 about the MapInfo Extended part, when they tried to know how to get it 
into GDAL. At that time, I did suggest to them that extending MITAB would be 
the most natural thing to do, which would make MapInfo Extended "immediately" 
available to everyone using GDAL. At that time, they already floating around 
the idea of using parts of their code base. I told them this would be far less 
practical for their users, even if their SDK was open sourced (since it would 
have packaging implication). At the end, they followed the route of using 
their closed source SDK and submitted this PR mixing 2 things, and using a 
unusual model for drivers relying on SDK.
We had some email discussions with them one month ago within the GDAL PSC to 
tell them that their PR couldn't be merged as it and they should at the very 
least rework it as 2 PRs and follow the usual model, but that it would still 
require finding a reviewer keen to review them & press the merge button. That 
part is going to be problematic.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ravitejakrishna.w at zohocorp.com  Tue Dec 10 04:45:10 2019
From: ravitejakrishna.w at zohocorp.com (Wuyyuru Ravi Teja Krishna)
Date: Tue, 10 Dec 2019 18:15:10 +0530
Subject: [gdal-dev] Regarding geometry layer creation options
In-Reply-To: <16eea82e871.11709586151123.5242667017212146607@zohocorp.com>
References: <16ee9adecd9.10cee7d7942298.878259272763053939@zohocorp.com>
 <16eea82e871.11709586151123.5242667017212146607@zohocorp.com>
Message-ID: <16eefd788ca.f3eec9b54276.4656001043593163693@zohocorp.com>

I have tried it but it shows a usage text which doesn't show any option of dialect. Do I need to do anything extra than normal java bindings?. (Note i have run configure with sqlite but still it doesn't work)



Thanks.






---- On Mon, 09 Dec 2019 17:24:38 +0530 Wuyyuru Ravi Teja Krishna <ravitejakrishna.w at zohocorp.com> wrote ----


Hi,



Thanks for your reply. But we would like to use it without using databases. can the same result be obtained without using any databases?

Thanks






---- On Mon, 09 Dec 2019 13:32:00 +0530 Wuyyuru Ravi Teja Krishna <mailto:ravitejakrishna.w at zohocorp.com> wrote ----










Hello Gdal team,



Iam using ogr2ogr tool for .shp or .geojson. or .kml to .csv conversion. But i want the Geometry to be as collections as show below. ( On giving GEOMETRY=AS_WKT iam getting in a normal format is there any option to get in the format i need )



format I need : { "type": "Polygon", "coordinates": [ [ [ 76.612, 33.173 ], [ 76.64, 33.162 ], [ 76.709, 33.181 ] ] ] } 

                        or  atleast to have it in this format is aceptable for us POLYGON (([76.612 , 33.173],[76.64 , 33.162],[76.709 , 33.181])) 

format iam getting :  POLYGON ((76.612 33.173,76.64 33.162,76.709 33.181)) 



Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191210/7ff5d9d0/attachment.html>

From ravitejakrishna.w at zohocorp.com  Tue Dec 10 08:38:01 2019
From: ravitejakrishna.w at zohocorp.com (Wuyyuru Ravi Teja Krishna)
Date: Tue, 10 Dec 2019 22:08:01 +0530
Subject: [gdal-dev] Using jars generated in one system in another
Message-ID: <16ef0acb76c.1059f95c25903.4875949665802601863@zohocorp.com>

Hello,



I want to integrate "ogr2ogr" as a standalone module in a product so i am using java bindings for generation of jars and native library files to use with ogr2ogr for conversion. It worked fine while testing using terminal in the system used for generation. But upon copying those files to another system for checking it throws many native library errors. So I would like to know 



1. if it is possible for using jars and native library files generated in one system can be used in many systems of same os for ogr2ogr file conversion 

2. If yes then what are the required system specifications because it have tested but not working in most of the systems

3. If no then can u suggest me any way to work with that without installing it in servers.

Thanks in advance.

Any info or suggestions will be a lot of help for us
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191210/44126b11/attachment.html>

From nyall.dawson at gmail.com  Tue Dec 10 15:28:39 2019
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Wed, 11 Dec 2019 09:28:39 +1000
Subject: [gdal-dev] Extended tab/mrr driver questions
In-Reply-To: <1611043.yvcSyNku73@even-i700>
References: <CAB28AshbKthaxyHepnYe2AjrAGGt5LxM=xYZ0idHRJc4P0aGmg@mail.gmail.com>
 <1611043.yvcSyNku73@even-i700>
Message-ID: <CAB28AshVXCVUmeAOGg743VQYOAO-N68iXr4DJSdUGn9xhovR4A@mail.gmail.com>

On Tue, 10 Dec 2019 at 22:13, Even Rouault <even.rouault at spatialys.com> wrote:

> For everyone understanding, I had preliminary contacts with them beginning of
> 2018 about the MapInfo Extended part, when they tried to know how to get it
> into GDAL. At that time, I did suggest to them that extending MITAB would be
> the most natural thing to do, which would make MapInfo Extended "immediately"
> available to everyone using GDAL. At that time, they already floating around
> the idea of using parts of their code base. I told them this would be far less
> practical for their users, even if their SDK was open sourced (since it would
> have packaging implication). At the end, they followed the route of using
> their closed source SDK and submitted this PR mixing 2 things, and using a
> unusual model for drivers relying on SDK.
> We had some email discussions with them one month ago within the GDAL PSC to
> tell them that their PR couldn't be merged as it and they should at the very
> least rework it as 2 PRs and follow the usual model, but that it would still
> require finding a reviewer keen to review them & press the merge button. That
> part is going to be problematic.

Thanks for the clarification Even! I misread the comment as meaning
"they had GDAL PSC blessing to move ahead with the plugin approach",
not "they've been warned, and continue to waste everyone's time" ;)

I really think it would be a mistake for the community to budge here
and merge either of the new PRs. Pitney Bowes are clearly motivated to
get their code into GDAL, and we should use this motivation to force
them to abide by what's best for the community instead of what's best
for their middle management..! So I'm very glad to hear that I
misinterpreted the situation.

Nyall

From jukka.rahkonen at maanmittauslaitos.fi  Wed Dec 11 07:58:37 2019
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Wed, 11 Dec 2019 15:58:37 +0000
Subject: [gdal-dev] Why MultiLinestring in GeometryCollection is unexpected
 for SQLite dialect?
Message-ID: <8f3f00b4431243b19d765436aaf358b8@C119S212VM042.msvyvi.vaha.local>

Hi,

This command fails with SQLite dialect

ogrinfo -dialect sqlite -sql "select geometry from jump_gc as geom" jump_gc.jml
Had to open data source read-only.
INFO: Open of `jump_gc.jml'
      using driver `JML' successful.
ERROR 1: Unexpected geometry type MULTILINESTRING as part of GEOMETRYCOLLECTION

Layer name: SELECT
Geometry: Unknown (any)
Feature Count: 1
Layer SRS WKT:
(unknown)
Geometry Column = GEOMETRY
ERROR 1: Unexpected geometry type MULTILINESTRING as part of GEOMETRYCOLLECTION
OGRFeature(SELECT):0

Result is fine with OGR SQL

ogrinfo  -sql "select ogr_geometry from jump_gc as geom" jump_gc.jml
Had to open data source read-only.
INFO: Open of `jump_gc.jml'
      using driver `JML' successful.

Layer name: geom
Geometry: Unknown (any)
Feature Count: 1
Extent: (1.000000, 3.000000) - (560.000000, 500.000000)
Layer SRS WKT:
(unknown)
ogr_geometry: String (0.0)
OGRFeature(geom):0
  ogr_geometry (String) = GEOMETRYCOLLECTION
  GEOMETRYCOLLECTION (MULTILINESTRING ((280 420,540 420,560 440,540 440),(300 460,480 460,520 500)),POINT (1 3))

SQLite dialect does not complain if I convert the same geometry from WKT into geometry and back to WKT

ogrinfo -dialect sqlite -sql "select st_astext(st_geomfromtext('GEOMETRYCOLLECTION ( MULTILINESTRING (( 280 420, 540 420, 560 440, 540 440 ), ( 300 460, 480 460, 520 500 )),POINT(1 3))')) as wkt" jump_gc.jml

Here is my test data "jump_gc.jml":

<?xml version='1.0' encoding='UTF-8'?>
<JCSDataFile xmlns:gml="http://www.opengis.net/gml" xmlns:xsi="http://www.w3.org/2000/10/XMLSchema-instance" >
<JCSGMLInputTemplate>
<CollectionElement>featureCollection</CollectionElement>
<FeatureElement>feature</FeatureElement>
<GeometryElement>geometry</GeometryElement>
<CRSElement>boundedBy</CRSElement>
<ColumnDefinitions>
</ColumnDefinitions>
</JCSGMLInputTemplate>

<featureCollection>
  <gml:boundedBy>
    <gml:Box>
      <gml:coordinates decimal="." cs="," ts=" ">1.00,3.00 560.00,500.00</gml:coordinates>
    </gml:Box>
  </gml:boundedBy>
  <feature>
    <geometry>
      <gml:MultiGeometry>
        <gml:geometryMember>
        <gml:MultiLineString>
          <gml:lineStringMember>
          <gml:LineString>
            <gml:coordinates>
              280.0,420.0
              540.0,420.0
              560.0,440.0
              540.0,440.0
            </gml:coordinates>
          </gml:LineString>
          </gml:lineStringMember>
          <gml:lineStringMember>
          <gml:LineString>
            <gml:coordinates>
              300.0,460.0
              480.0,460.0
              520.0,500.0
            </gml:coordinates>
          </gml:LineString>
          </gml:lineStringMember>
        </gml:MultiLineString>
        </gml:geometryMember>
        <gml:geometryMember>
        <gml:Point>
          <gml:coordinates>
            1.0,3.0
          </gml:coordinates>
        </gml:Point>
        </gml:geometryMember>
      </gml:MultiGeometry>
    </geometry>
  </feature>
</featureCollection>
</JCSDataFile>

-Jukka Rahkonen-
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191211/0d8db8c2/attachment.html>

From are131 at psu.edu  Wed Dec 11 08:42:51 2019
From: are131 at psu.edu (Edson, Adam Robert)
Date: Wed, 11 Dec 2019 16:42:51 +0000
Subject: [gdal-dev] python GDAL issue
In-Reply-To: <003601d59520$2019ee00$604dca00$@frogmouth.net>
References: <CH2PR02MB6165C157FAD7C2C17A28573F93940@CH2PR02MB6165.namprd02.prod.outlook.com>,
 <00a401d57fab$f9b63220$ed229660$@frogmouth.net>
 <CH2PR02MB616574E752B2ADF3A6C9D09193970@CH2PR02MB6165.namprd02.prod.outlook.com>,
 <00e501d580c1$27299e20$757cda60$@frogmouth.net>
 <CH2PR02MB6165C6D7D92DA48F1E8BDB9193900@CH2PR02MB6165.namprd02.prod.outlook.com>,
 <00e901d582dd$0e5e44e0$2b1acea0$@frogmouth.net>
 <DM6PR02MB43629295455B9D9804518399937E0@DM6PR02MB4362.namprd02.prod.outlook.com>,
 <00de01d59477$68681b90$393852b0$@frogmouth.net>
 <DM6PR02MB4362B345CEF48FC3A9FBA18993790@DM6PR02MB4362.namprd02.prod.outlook.com>,
 <003601d59520$2019ee00$604dca00$@frogmouth.net>
Message-ID: <BN8PR02MB5716B27EEC108315A30D1699935A0@BN8PR02MB5716.namprd02.prod.outlook.com>

Looking through the code, I noticed the SWIG interface language. Going from that, I began looking into SWIG and what it can do. In the documentation, it talks about Byte string output conversion (in section 32.12.4). My understanding from that section of the SWIG documentation (http://swig.org/Doc4.0/SWIGDocumentation.pdf) is that SWIG assumes UTF-8 for every char when sending it to python.

Do you have any experience working with the SWIG interface language? Is your understanding similar?

Thanks!
Adam
________________________________
From: Brad Hards <bradh at frogmouth.net>
Sent: Wednesday, November 6, 2019 11:02 PM
To: Edson, Adam Robert <are131 at psu.edu>; gdal-dev at lists.osgeo.org <gdal-dev at lists.osgeo.org>
Cc: Bradley, Eliza S <esb165 at psu.edu>
Subject: RE: [gdal-dev] python GDAL issue


I think it should check the “type” value. My “maybe this could work” concept was something like:



--- a/gdal/frmts/nitf/nitffile.c

+++ b/gdal/frmts/nitf/nitffile.c

@@ -2150,6 +2150,8 @@ static char** NITFGenericMetadataReadTREInternal(char **papszMD,

             const char* pszName = CPLGetXMLValue(psIter, "name", NULL);

             const char* pszLongName = CPLGetXMLValue(psIter, "longname", NULL);

             const char* pszLength = CPLGetXMLValue(psIter, "length", NULL);

+            const char* pszType = CPLGetXMLValue(psIter, "type", "string");

+

             int nLength = -1;

             if (pszLength != NULL)

                 nLength = atoi(pszLength);

@@ -2219,7 +2221,17 @@ static char** NITFGenericMetadataReadTREInternal(char **papszMD,

                 if (psOutXMLNode != NULL)

                 {

-                    const char* pszVal = strchr(papszMD[(*pnMDSize) - 1], '=') + 1;

+

+                    char* pszVal = strchr(papszMD[(*pnMDSize) - 1], '=') + 1;

+                    if (strcmp(pszType, "IEEE754") == 0)

+                    {

+                        // TODO: fix

+                        printf("IEEE754: 0x%02x 0x%02x 0x%02x 0x%02x\n", pszVal[0], pszVal[1], pszVal[2], pszVal[3]);

+                        pszVal = "FIXME1";

+                    } else if (strcmp(pszType, "UINT") == 0) {

+                        printf("UINT: 0x%02x 0x%02x 0x%02x 0x%02x\n", pszVal[0], pszVal[1], pszVal[2], pszVal[3]);

+                        pszVal = "FIXME2";

+                    }

                     CPLXMLNode* psFieldNode;

                     CPLXMLNode* psNameNode;

                     CPLXMLNode* psValueNode;



(I think the pzVal might need to be changed to a union / class that has char*, a double or an unsigned int; I haven’t dug further than this yet).



Brad

From: Edson, Adam Robert <are131 at psu.edu>
Sent: Thursday, 7 November 2019 6:34 AM
To: Brad Hards <bradh at frogmouth.net>; gdal-dev at lists.osgeo.org
Cc: Bradley, Eliza S <esb165 at psu.edu>
Subject: Re: [gdal-dev] python GDAL issue



Looking at the code, it appears that GDAL actually hard codes any TRE that takes anything that cannot be parsed as a string (e.g. nitfimage.c NITFReadICHIPB). So, for BANDSB with its EXISTENCE_MASK and SCALE_FACTOR would need to be hard coded as opposed to being defined just within the nitf_spec.xml. Is this the correct interpretation?



Thanks!

Adam


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191211/eccd0edf/attachment-0001.html>

From even.rouault at spatialys.com  Wed Dec 11 10:06:59 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 11 Dec 2019 19:06:59 +0100
Subject: [gdal-dev] Why MultiLinestring in GeometryCollection is
	unexpected for SQLite dialect?
In-Reply-To: <8f3f00b4431243b19d765436aaf358b8@C119S212VM042.msvyvi.vaha.local>
References: <8f3f00b4431243b19d765436aaf358b8@C119S212VM042.msvyvi.vaha.local>
Message-ID: <3006611.WoLCL0Aq94@even-i700>

Jukka,

> This command fails with SQLite dialect
>
>ogrinfo -dialect sqlite -sql "select geometry from jump_gc as geom" 
>jump_gc.jml
>Had to open data source read-only.
>INFO: Open of `jump_gc.jml'
>      using driver `JML' successful.
>ERROR 1: Unexpected geometry type MULTILINESTRING as part of 
>GEOMETRYCOLLECTION

Candidate fix in https://github.com/OSGeo/gdal/pull/2095

Basically, Spatialite geometries don't support arbitrary nesting of geometry 
collections (understood as the abstract type, that is GEOMETRYCOLLECTION, 
MULTIPOINT, MULTILINESTRING, MULTIPOLYGON) in a GEOMETRYCOLLECTION. I see that 
Spatiliate ST_GeomFromText() flattens the structure in such situation

$ ogrinfo -dialect sqlite -sql "select 
st_astext(st_geomfromtext('GEOMETRYCOLLECTION(MULTIPOINT(0 1,2 3))'))" 
:memory: -al -q

Layer name: SELECT
OGRFeature(SELECT):0
  [...] = GEOMETRYCOLLECTION(POINT(0 1), POINT(2 3))

This limitation can be infered from
https://www.gaia-gis.it/gaia-sins/BLOB-Geometry.html
looking at the table below
"The following is the format expected for each one collection entity: "
where one can see that only POINT, LINESTRING and POLYGON are valid items
inside a collection.

So I'm now doing the same on conversion of OGR geometries to Spatialite ones 
when using the SQLite dialect

$ ogrinfo -dialect sqlite -sql "select geometry from test" test.jml -al -q

Layer name: SELECT
OGRFeature(SELECT):0
  GEOMETRYCOLLECTION (LINESTRING (280 420,540 420,560 440,540 440),LINESTRING 
(300 460,480 460,520 500),POINT (1 3))

Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From gdal-dev at coulmann.de  Thu Dec 12 01:58:32 2019
From: gdal-dev at coulmann.de (wulf)
Date: Thu, 12 Dec 2019 10:58:32 +0100
Subject: [gdal-dev] extract wtwdis and unlocd with distance marks from
 IENC
In-Reply-To: <20191123160519.GR29961@coulmann.de>
References: <20191123160519.GR29961@coulmann.de>
Message-ID: <20191212095832.GA15107@coulmann.de>


Hallo again,

I found bit more info, so I thing I asked the wrong question.
what I miss/need is
   wtwdis
   on some points
   unlocd

is this possible with ogr2ogr?
Or where can I get further hints.


If I check the details from Points I like to extract in opencpn I get


or points without unlocd
  distance mark (dismar)
  52 13.7280 N, 011 40.0977 E
  CATGEO   POINT
  CATDIS   distance mark not physically installed(1)
  hunits   kilometers(3)
  wtwdis   319.9 m
  unlocd   DEQWS031010000003199


or points without unlocd

  distance mark (dismar)
  52 13.6335 N, 011 40.1771 E
  CATGEO   POINT
  CATDIS   distance mark not physically installed(1)
  hunits   kilometers
  wtwdis   310.1

old post at the End
Best Wulf

> I like to extract distance marks from S57 IENC
> 
> if I run:
>   ogr2ogr -skipfailures -f CSV x.csv 1W7ML310.000 -lco GEOMETRY=AS_XY
> 
> I get:
>   X,Y,RCID,PRIM,GRUP,OBJL,RVER,AGEN,FIDN,FIDS,LNAM,LNAM_REFS,FFPT_RIND,catdis,DATEND,DATSTA,NOBJNM,OBJNAM,INFORM,NINFOM,NTXTDS,PICREP,SCAMIN,TXTDSC,updmsg,SORDAT,SORIND
>   11.5270611,52.2419757,"291","1","2","17004","1","7984","1526304445","36",1F305AF98EBD0024,,,"1",,,, , ,,,,"8000",,,,
> 
> I miss the value of the distanc mark (maybe OBJNAM or NOBJNM). If I open the data source with an editor I
> find something like
>   ¨B310.1^_µBDENQB031010000003101^_ÏB3^_"
>  
>   where 310.1 refers to "km 310.1" and 031010000003101 is a combination
>   of an waterwaynumber "031010000" and the distanz as intager "3101"
> so information is present.
> 
> How to get it extracted with every row?
> 
> 
> you find the S57 data here:
>   http://gpl.coulmann.de/tmp/1W7ML310.000
>   which is original extracted from
>   (provided by german inland waterway administration)
>   https://www.elwis.de/DE/dynamisch/IENC/download_commit.php?file=WW41_2018-06-22_0_318
> 
> Thanks for the effort
> Wulf
> 
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


From ravitejakrishna.w at zohocorp.com  Thu Dec 12 03:28:54 2019
From: ravitejakrishna.w at zohocorp.com (Wuyyuru Ravi Teja Krishna)
Date: Thu, 12 Dec 2019 16:58:54 +0530
Subject: [gdal-dev] ogr2ogr can work purely with java bindings
Message-ID: <16ef9de7056.124e697cb28230.903104465477346368@zohocorp.com>

Hello,
Iam using ogr2ogr with java bindings for file conversion. The conversion process is successful in the installed system but upon using the generated jars and library files in another system for conversion (same os configuration) it was not able to succeed since it needs proj installation. I would like to request you to suggest about any way so that i can generate in a single system and use those files for conversion on any no of systems with zero installation? the errors have occured in CentOs,Mac and linux.(CentOs is my top priority)



(If it is possible to use the files generated everywhere i mean like iam using gdal.jar and libgdalalljni.26.so, libgdal.26.so (in centos). If any more files are needed so that i can conversion doesnt cause any issues even on doing in a new system with just java installed)




CentOs:

ERROR 1: PROJ: internal_proj_create_from_wkt: Cannot find proj.db

ERROR 1: PROJ: internal_proj_create_from_wkt: Cannot find proj.db

ERROR 1: PROJ: internal_proj_identify: Cannot find proj.db

ERROR 1: PROJ: internal_proj_as_wkt: Cannot find proj.db

ERROR 1: PROJ: internal_proj_as_wkt: Cannot find proj.db

ERROR 1: PROJ: internal_proj_as_wkt: Cannot find proj.db

ERROR 1: PROJ: internal_proj_as_wkt: Cannot find proj.db

ERROR 1: PROJ: internal_proj_create: Cannot find proj.db

ERROR 1: PROJ: internal_proj_create: Cannot find proj.db

ERROR 1: PROJ: internal_proj_create_operation_factory_context: Cannot find proj.db

ERROR 1: PROJ: pj_obj_create: Cannot find proj.db

ERROR 1: PROJ: internal_proj_as_proj_string: Cannot find proj.db

ERROR 1: PROJ: pj_obj_create: Cannot find proj.db


(Note : I have installed proj from the script given in gdal/script/vagrant)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191212/cf58453d/attachment.html>

From lars.schylberg at blixtmail.se  Thu Dec 12 03:55:04 2019
From: lars.schylberg at blixtmail.se (lars.schylberg at blixtmail.se)
Date: Thu, 12 Dec 2019 11:55:04 +0000
Subject: [gdal-dev] extract wtwdis and unlocd with distance marks from
 IENC
In-Reply-To: <20191212095832.GA15107@coulmann.de>
References: <20191212095832.GA15107@coulmann.de>
 <20191123160519.GR29961@coulmann.de>
Message-ID: <a3d0d0169e8d5bd8171c2f1d95779c18@blixtmail.se>

Have tried the inland water profile?  This is how i did it in the past.
This is a config for ogrinfo or ogr2ogr.

--config S57_PROFILE iw

This refers how the attributes are defined differently between normal S57 ENC and the inland water profile in
the csv files

Good luck

/Lars Schylberg


12 december 2019 kl. 10:58, "wulf" <gdal-dev at coulmann.de> skrev:

> Hallo again,
> 
> I found bit more info, so I thing I asked the wrong question.
> what I miss/need is
> wtwdis
> on some points
> unlocd
> 
> is this possible with ogr2ogr?
> Or where can I get further hints.
> 
> If I check the details from Points I like to extract in opencpn I get
> 
> or points without unlocd
> distance mark (dismar)
> 52 13.7280 N, 011 40.0977 E
> CATGEO POINT
> CATDIS distance mark not physically installed(1)
> hunits kilometers(3)
> wtwdis 319.9 m
> unlocd DEQWS031010000003199
> 
> or points without unlocd
> 
> distance mark (dismar)
> 52 13.6335 N, 011 40.1771 E
> CATGEO POINT
> CATDIS distance mark not physically installed(1)
> hunits kilometers
> wtwdis 310.1
> 
> old post at the End
> Best Wulf
> 
>> I like to extract distance marks from S57 IENC
>> 
>> if I run:
>> ogr2ogr -skipfailures -f CSV x.csv 1W7ML310.000 -lco GEOMETRY=AS_XY
>> 
>> I get:
>> X,Y,RCID,PRIM,GRUP,OBJL,RVER,AGEN,FIDN,FIDS,LNAM,LNAM_REFS,FFPT_RIND,catdis,DATEND,DATSTA,NOBJNM,OBJ
>> AM,INFORM,NINFOM,NTXTDS,PICREP,SCAMIN,TXTDSC,updmsg,SORDAT,SORIND
>> 11.5270611,52.2419757,"291","1","2","17004","1","7984","1526304445","36",1F305AF98EBD0024,,,"1",,,,
>> , ,,,,"8000",,,,
>> 
>> I miss the value of the distanc mark (maybe OBJNAM or NOBJNM). If I open the data source with an
>> editor I
>> find something like
>> ¨B310.1^_µBDENQB031010000003101^_ÏB3^_"
>> 
>> where 310.1 refers to "km 310.1" and 031010000003101 is a combination
>> of an waterwaynumber "031010000" and the distanz as intager "3101"
>> so information is present.
>> 
>> How to get it extracted with every row?
>> 
>> you find the S57 data here:
>> http://gpl.coulmann.de/tmp/1W7ML310.000
>> which is original extracted from
>> (provided by german inland waterway administration)
>> https://www.elwis.de/DE/dynamisch/IENC/download_commit.php?file=WW41_2018-06-22_0_318
>> 
>> Thanks for the effort
>> Wulf
>> 
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

From even.rouault at spatialys.com  Thu Dec 12 04:17:21 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 12 Dec 2019 13:17:21 +0100
Subject: [gdal-dev] ogr2ogr can work purely with java bindings
In-Reply-To: <16ef9de7056.124e697cb28230.903104465477346368@zohocorp.com>
References: <16ef9de7056.124e697cb28230.903104465477346368@zohocorp.com>
Message-ID: <46361982.diZlAv9u2e@even-i700>

On jeudi 12 décembre 2019 16:58:54 CET Wuyyuru Ravi Teja Krishna wrote:
> Hello,
> Iam using ogr2ogr with java bindings for file conversion. The conversion
> process is successful in the installed system but upon using the generated
> jars and library files in another system for conversion (same os
> configuration) it was not able to succeed since it needs proj installation.
> I would like to request you to suggest about any way so that i can generate
> in a single system and use those files for conversion on any no of systems
> with zero installation? the errors have occured in CentOs,Mac and
> linux.(CentOs is my top priority)
> 
> 
> 
> (If it is possible to use the files generated everywhere i mean like iam
> using gdal.jar and libgdalalljni.26.so, libgdal.26.so (in centos). If any
> more files are needed so that i can conversion doesnt cause any issues even
> on doing in a new system with just java installed)

See
https://proj.org/resource_files.html#where-are-proj-resource-files-looked-for
and
https://github.com/OSGeo/gdal/blob/master/gdal/swig/include/osr.i#L1412

Likely something like that in Java:
org.osgeo.gdal.osr.SetPROJSearchPath("path_to_directory_where_proj_db_is")


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From gdal-dev at coulmann.de  Thu Dec 12 11:25:15 2019
From: gdal-dev at coulmann.de (Wulf)
Date: Thu, 12 Dec 2019 20:25:15 +0100
Subject: [gdal-dev] extract wtwdis and unlocd with distance marks from
 IENC
In-Reply-To: <a3d0d0169e8d5bd8171c2f1d95779c18@blixtmail.se>
References: <20191212095832.GA15107@coulmann.de>
 <20191123160519.GR29961@coulmann.de>
 <a3d0d0169e8d5bd8171c2f1d95779c18@blixtmail.se>
Message-ID: <20191212192513.GG28303@coulmann.de>


Hi Lars,

thanks for the hint.

> Have tried the inland water profile?  This is how i did it in the past.
> This is a config for ogrinfo or ogr2ogr.
>
> --config S57_PROFILE iw

I try to find where the docs describe this, but didn't.
I'm sure it's my wrong usage, but I do not know how to figure out.


> Good luck
still there is no wtwdis or unlocd

I run

------
ogrinfo -al --config S57_PROFILE iw 1W7ML310.000 POINT

Warning 6: 'ON#' is an unexpected value for RETURN_PRIMITIVES open option of type boolean.
Warning 6: 'ON#' is an unexpected value for RETURN_LINKAGES open option of type boolean.
Warning 6: driver S57 does not support open option RETURN_TXTDSC
Warning 6: driver S57 does not support open option RETURN_INFORM
Warning 6: driver S57 does not support open option RETURN_NINFORM
Warning 6: driver S57 does not support open option RETURN_NOBJNM
Warning 6: driver S57 does not support open option RETURN_OBJNAM
Warning 6: driver S57 does not support open option RETURN_NTXTDS
INFO: Open of `1W7ML310.000'
      using driver `S57' successful.

Layer name: Point
Geometry: Point
Feature Count: 0
Extent: (11.497309, 52.187832) - (11.647561, 52.275467)
Layer SRS WKT:
GEOGCS["WGS 84",
    DATUM["WGS_1984",
        SPHEROID["WGS 84",6378137,298.257223563,
            AUTHORITY["EPSG","7030"]],
        AUTHORITY["EPSG","6326"]],
    PRIMEM["Greenwich",0,
        AUTHORITY["EPSG","8901"]],
    UNIT["degree",0.0174532925199433,
        AUTHORITY["EPSG","9122"]],
    AUTHORITY["EPSG","4326"]]
RCID: Integer (10.0)
PRIM: Integer (3.0)
GRUP: Integer (3.0)
OBJL: Integer (5.0)
RVER: Integer (3.0)
AGEN: Integer (5.0)
FIDN: Integer (10.0)
FIDS: Integer (5.0)
LNAM: String (16.0)
LNAM_REFS: StringList (16.0)
FFPT_RIND: IntegerList (1.0)
NAME_RCNM: IntegerList (3.0)
NAME_RCID: IntegerList (10.0)
ORNT: IntegerList (1.0)
USAG: IntegerList (1.0)
MASK: IntegerList (3.0)

-------
and
------



ogr2ogr --config S57_PROFILE iw -skipfailures -f CSV x.csv 1W7ML310.000 -nlt POINT

also does not extract the needed values.

Best Wulf


From lars.schylberg at blixtmail.se  Thu Dec 12 15:21:08 2019
From: lars.schylberg at blixtmail.se (Lars Schylberg)
Date: Fri, 13 Dec 2019 00:21:08 +0100
Subject: [gdal-dev] extract wtwdis and unlocd with distance marks from
 IENC
In-Reply-To: <20191212192513.GG28303@coulmann.de>
References: <20191212095832.GA15107@coulmann.de>
 <20191123160519.GR29961@coulmann.de>
 <a3d0d0169e8d5bd8171c2f1d95779c18@blixtmail.se>
 <20191212192513.GG28303@coulmann.de>
Message-ID: <d2ac891c-b133-4243-e9aa-4a33e0bab034@blixtmail.se>

Hi again,

I had a closer look and it seems like the profiles were skipped when 
gdal 2.2 was released.

  All the content from iw and aml profiles was merged in the regular

gdal/data/s57objectclasses.csv  and gdal/data/s57attributes.csv  files.

So this might be a case about what gdal version you are using and using 
profile on older versions.

These files can be found under /usr/share/gdal if remember correctly.

There you can look through all possible objects and attributes.

Normally when I analyze a data set, I try and look thru one obejct class 
at the time.

First I run a "ogrinfo -summary" to see what classes I have, then

look at each class separately with e.g.  ogrinfo 1W7ML310.000 <one class 
at the time from summary>

I was doing some work with aml profile files five years ago, and had to 
go thru this examining

of files.   At that time I had to patch some missing attriubutes in the  
57attributes.csv for aml.

The procedure is to compare the specification and the content of the csv 
file.

But I remember that I played with some IW files from Germany as well and 
those displayed just fine.


Good luck /Lars Schylberg


  Den 2019-12-12 kl. 20:25, skrev Wulf:
> Hi Lars,
>
> thanks for the hint.
>
>> Have tried the inland water profile?  This is how i did it in the past.
>> This is a config for ogrinfo or ogr2ogr.
>>
>> --config S57_PROFILE iw
> I try to find where the docs describe this, but didn't.
> I'm sure it's my wrong usage, but I do not know how to figure out.
>
>
>> Good luck
> still there is no wtwdis or unlocd
>
> I run
>
> ------
> ogrinfo -al --config S57_PROFILE iw 1W7ML310.000 POINT
>
> Warning 6: 'ON#' is an unexpected value for RETURN_PRIMITIVES open option of type boolean.
> Warning 6: 'ON#' is an unexpected value for RETURN_LINKAGES open option of type boolean.
> Warning 6: driver S57 does not support open option RETURN_TXTDSC
> Warning 6: driver S57 does not support open option RETURN_INFORM
> Warning 6: driver S57 does not support open option RETURN_NINFORM
> Warning 6: driver S57 does not support open option RETURN_NOBJNM
> Warning 6: driver S57 does not support open option RETURN_OBJNAM
> Warning 6: driver S57 does not support open option RETURN_NTXTDS
> INFO: Open of `1W7ML310.000'
>        using driver `S57' successful.
>
> Layer name: Point
> Geometry: Point
> Feature Count: 0
> Extent: (11.497309, 52.187832) - (11.647561, 52.275467)
> Layer SRS WKT:
> GEOGCS["WGS 84",
>      DATUM["WGS_1984",
>          SPHEROID["WGS 84",6378137,298.257223563,
>              AUTHORITY["EPSG","7030"]],
>          AUTHORITY["EPSG","6326"]],
>      PRIMEM["Greenwich",0,
>          AUTHORITY["EPSG","8901"]],
>      UNIT["degree",0.0174532925199433,
>          AUTHORITY["EPSG","9122"]],
>      AUTHORITY["EPSG","4326"]]
> RCID: Integer (10.0)
> PRIM: Integer (3.0)
> GRUP: Integer (3.0)
> OBJL: Integer (5.0)
> RVER: Integer (3.0)
> AGEN: Integer (5.0)
> FIDN: Integer (10.0)
> FIDS: Integer (5.0)
> LNAM: String (16.0)
> LNAM_REFS: StringList (16.0)
> FFPT_RIND: IntegerList (1.0)
> NAME_RCNM: IntegerList (3.0)
> NAME_RCID: IntegerList (10.0)
> ORNT: IntegerList (1.0)
> USAG: IntegerList (1.0)
> MASK: IntegerList (3.0)
>
> -------
> and
> ------
>
>
>
> ogr2ogr --config S57_PROFILE iw -skipfailures -f CSV x.csv 1W7ML310.000 -nlt POINT
>
> also does not extract the needed values.
>
> Best Wulf
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

From craig.destigter at koordinates.com  Thu Dec 12 17:36:42 2019
From: craig.destigter at koordinates.com (Craig de Stigter)
Date: Fri, 13 Dec 2019 14:36:42 +1300
Subject: [gdal-dev] VSI CIFS driver
Message-ID: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>

Hey folks!

We have to access some customer data via their CIFS shares on a regular
basis.

To date we have been doing it via a setuid script which mounts and unmounts
the CIFS share locally, then treats the files as local. We're
containerising our workers, and using kernel mounts is no longer possible
(at least, not even slightly securely.)

This means we need a userspace CIFS implementation for a lot of our GDAL
code, and a VSI CIFS driver would seem to be the right thing to do.
Presumably it will be a fairly thin wrapper of libsmb.

1. Has anyone tried that? Any comments?

2. Would it be something GDAL might accept as a core contribution, or
should we expect to maintain it outside of core?

3. We noticed https://github.com/OSGeo/gdal/pull/1289 should allow VSI
plugins to be registered from Python, which means we could possibly
implement this in Python if we decided that was the best approach. Because
we're Python experts and not C++ experts, we're likely to choose this path
if the answer to (2) is "no". Are there any docs on how to actually do
this?


Thanks :)

-- 
Regards,
Craig

Developer
Koordinates

+64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191213/80f7c50d/attachment.html>

From seandarcy2 at gmail.com  Thu Dec 12 19:37:32 2019
From: seandarcy2 at gmail.com (Sean Darcy)
Date: Thu, 12 Dec 2019 22:37:32 -0500
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
Message-ID: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>

Building gdal-2.4.3 on Fedora 31, gcc-9.2.1. This happens even though
configure has --disable-static, which is recognized:

checking whether to build shared libraries... yes
checking whether to build static libraries... no

Any suggestions appreciated.

sean

ar r libiso8211.a ddfmodule.lo ddfutils.lo ddffielddefn.lo
ddfrecord.lo ddffield.lo ddfsubfielddefn.lo
ar: creating libiso8211.a
ranlib libiso8211.a
/bin/sh /builddir/build/BUILD/gdal-2.4.2/libtool --mode=compile
--silent --tag=CXX g++ -I/builddir/build/BUILD/gdal-2.4.2/port
-I/builddir/build/BUILD/gdal-2.4.2/gcore
-I/builddir/build/BUILD/gdal-2.4.2/alg
-I/builddir/build/BUILD/gdal-2.4.2/ogr
-I/builddir/build/BUILD/gdal-2.4.2/ogr/ogrsf_frmts
-I/builddir/build/BUILD/gdal-2.4.2/gnm
-I/builddir/build/BUILD/gdal-2.4.2/apps -DHAVE_AVX_AT_COMPILE_TIME
-DHAVE_SSSE3_AT_COMPILE_TIME -O2 -g -pipe -Wall
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2
-Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong
-grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1
-specs=/usr/lib/rpm/redhat/redhat-annobin-cc1 -m64 -mtune=generic
-fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection
-fpic -I/usr/include/libgeotiff -I/usr/include/tirpc  -Wall -Wextra
-Winit-self -Wunused-parameter -Wformat -Werror=format-security
-Wno-format-nonliteral -Wlogical-op -Wshadow -Werror=vla -Wdate-time
-Wnull-dereference -Wduplicated-cond -Wextra-semi -Wfloat-conversion
-Wmissing-declarations -Wnon-virtual-dtor -Woverloaded-virtual
-fno-operator-names -Wzero-as-null-pointer-constant -Wsuggest-override
-Wimplicit-fallthrough  -I. -I../../port -DGNM_ENABLED
-I/usr/include/libgeotiff -I/usr/include/tirpc
-I/builddir/build/BUILD/gdal-2.4.2/port -I/usr/include/openjpeg-2.3
-I/usr/include -Iexternal/include -I/usr/include/cfitsio
-DGDAL_COMPILATION -DHAVE_XERCES -I/usr/include -I/usr/include/xercesc
-I/usr/include/libgeotiff -I/usr/include/tirpc
-I/builddir/build/BUILD/gdal-2.4.2/port -I/usr/include/openjpeg-2.3
-I/usr/include -Iexternal/include -I/usr/include/cfitsio
-DGDAL_COMPILATION -c -o 8211dump.lo 8211dump.cpp
/bin/sh /builddir/build/BUILD/gdal-2.4.2/libtool --mode=link --silent
g++ -Wl,-z,relro -Wl,--as-needed  -Wl,-z,now
-specs=/usr/lib/rpm/redhat/redhat-hardened-ld 8211dump.lo libiso8211.a
/builddir/build/BUILD/gdal-2.4.2/libgdal.la -o 8211dump
/usr/bin/ld: libiso8211.a: error adding symbols: archive has no index;
run ranlib to add one
collect2: error: ld returned 1 exit status
make: *** [GNUmakefile:33: 8211dump] Error 1

From even.rouault at spatialys.com  Fri Dec 13 01:50:53 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 13 Dec 2019 10:50:53 +0100
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
In-Reply-To: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
References: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
Message-ID: <2765013.5Hsoq9kDmh@even-i700>

On jeudi 12 décembre 2019 22:37:32 CET Sean Darcy wrote:
> Building gdal-2.4.3 on Fedora 31, gcc-9.2.1. This happens even though
> configure has --disable-static, which is recognized:
> 
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> 
> Any suggestions appreciated.

You are doing a manual "make 8211dump" from frmts/iso8211, right ? Well, as 
this is mostly debug stuff not built by default, support for static builds 
might be broken. You may need to tweek the makefile.

Works at least for me for a shared + non-libtool build.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Fri Dec 13 02:38:24 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 13 Dec 2019 11:38:24 +0100
Subject: [gdal-dev] VSI CIFS driver
In-Reply-To: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>
References: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>
Message-ID: <2218351.t4joFbaAaY@even-i700>

Craig,

> We have to access some customer data via their CIFS shares on a regular
> basis.
> 
> To date we have been doing it via a setuid script which mounts and unmounts
> the CIFS share locally, then treats the files as local. We're
> containerising our workers, and using kernel mounts is no longer possible
> (at least, not even slightly securely.)

Is upgrading to Kernel 4.18 an option ?
See https://www.phoronix.com/scan.php?page=news_item&px=Linux-4.18-FUSE

> 
> This means we need a userspace CIFS implementation for a lot of our GDAL
> code, and a VSI CIFS driver would seem to be the right thing to do.
> Presumably it will be a fairly thin wrapper of libsmb.
> 
> 2. Would it be something GDAL might accept as a core contribution, or
> should we expect to maintain it outside of core?

Hard to know where to draw the line. If recent kernels would make this no 
longer needed, then its value in core might be low.

> 3. We noticed https://github.com/OSGeo/gdal/pull/1289 should allow VSI
> plugins to be registered from Python,

It allows VSI plugins to be registered with a C interface. So if you'd want ot 
use that from Python, you'd likely have to play with ctypes or similar 
technology.

> Are there any docs on how to actually do this?

Well, the Doxygen docs of VSIAllocFilesystemPluginCallbacksStruct and 
VSIInstallPluginHandler in cpl_vsi.h . And the tutorial you'll add if you 
proceed that way ;-)


Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From seandarcy2 at gmail.com  Fri Dec 13 06:41:17 2019
From: seandarcy2 at gmail.com (sean darcy)
Date: Fri, 13 Dec 2019 09:41:17 -0500
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
In-Reply-To: <2765013.5Hsoq9kDmh@even-i700>
References: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
 <2765013.5Hsoq9kDmh@even-i700>
Message-ID: <qt07ud$7agt$1@blaine.gmane.org>


On 12/13/19 4:50 AM, Even Rouault wrote:
> On jeudi 12 décembre 2019 22:37:32 CET Sean Darcy wrote:
>> Building gdal-2.4.3 on Fedora 31, gcc-9.2.1. This happens even though
>> configure has --disable-static, which is recognized:
>>
>> checking whether to build shared libraries... yes
>> checking whether to build static libraries... no
>>
>> Any suggestions appreciated.
> 
> You are doing a manual "make 8211dump" from frmts/iso8211, right ? Well, as
> this is mostly debug stuff not built by default, support for static builds
> might be broken. You may need to tweek the makefile.
> 
> Works at least for me for a shared + non-libtool build.
> 
I'm not doing a manual make 8211dump . This is a full ./configure make 
dance, with --disable-static:



+ ./configure --build=x86_64-redhat-linux-gnu 
--host=x86_64-redhat-linux-gnu --program-prefix= 
--disable-dependency-tracking --prefix=/usr --exec-prefix=/usr 
--bindir=/usr/bin --sbindir=/usr/sbin
--sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include 
--libdir=/usr/lib64 --libexecdir=/usr/libexec --localstatedir=/var 
--sharedstatedir=/var/lib --mandir=/usr/share/man 
--infodir=/usr/share/info --disable-static 'LIBS=-lg2c_v1.6.0 -ltirpc' 
--with-autoload=/usr/lib64/gdalplugins --datadir=/usr/share/gdal/ 
--includedir=/usr/include/gdal/ --prefix=/usr --with-armadillo 
--with-curl --with-cfitsio=/usr --with-dods-root=/usr --with-expat 
--with-freexl --with-geos --with-geotiff=external --with-gif --with-gta 
--with-hdf4 --with-hdf5 --with-jasper --with-java --with-jpeg 
--with-libjson-c --without-jpeg12 --with-liblzma --with-libtiff=external 
--with-libz --without-mdb --without-msg --with-mysql --with-netcdf 
--with-odbc --with-ogdi --with-openjpeg --with-pcraster --with-pg 
--with-png --with-poppler --with-proj --with-spatialite --with-sqlite3 
--with-threads --with-webp --with-xerces --enable-shared --with-libkml
configure: WARNING: unrecognized options: --disable-dependency-tracking, 
--with-autoload
checking build system type... x86_64-redhat-linux-gnu
checking host system type... x86_64-redhat-linux-gnu
checking for x86_64-redhat-linux-gnu-gcc... no
checking for gcc... gcc
.............
+ make -j1 POPPLER_0_20_OR_LATER=yes POPPLER_0_23_OR_LATER=yes 
POPPLER_BASE_STREAM_HAS_TWO_ARGS=yes POPPLER_0_58_OR_LATER=yes
(cd port; make)
make[1]: Entering directory '/builddir/build/BUILD/gdal-2.4.2/port'
..........

How would I do a "non-libtool build" ?


From seandarcy2 at gmail.com  Fri Dec 13 07:30:03 2019
From: seandarcy2 at gmail.com (sean darcy)
Date: Fri, 13 Dec 2019 10:30:03 -0500
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
In-Reply-To: <2765013.5Hsoq9kDmh@even-i700>
References: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
 <2765013.5Hsoq9kDmh@even-i700>
Message-ID: <qt0apr$5hu4$1@blaine.gmane.org>

On 12/13/19 4:50 AM, Even Rouault wrote:
> On jeudi 12 décembre 2019 22:37:32 CET Sean Darcy wrote:
>> Building gdal-2.4.3 on Fedora 31, gcc-9.2.1. This happens even though
>> configure has --disable-static, which is recognized:
>>
>> checking whether to build shared libraries... yes
>> checking whether to build static libraries... no
>>
>> Any suggestions appreciated.
> 
> You are doing a manual "make 8211dump" from frmts/iso8211, right ? Well, as
> this is mostly debug stuff not built by default, support for static builds
> might be broken. You may need to tweek the makefile.
> 
> Works at least for me for a shared + non-libtool build.
> 

I'm not doing a manual make 8211dump . This is a full ./configure make 
dance, with --disable-static:



+ ./configure --build=x86_64-redhat-linux-gnu 
--host=x86_64-redhat-linux-gnu --program-prefix= 
--disable-dependency-tracking --prefix=/usr --exec-prefix=/usr 
--bindir=/usr/bin --sbindir=/usr/sbin
--sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include 
--libdir=/usr/lib64 --libexecdir=/usr/libexec --localstatedir=/var 
--sharedstatedir=/var/lib --mandir=/usr/share/man 
--infodir=/usr/share/info --disable-static 'LIBS=-lg2c_v1.6.0 -ltirpc' 
--with-autoload=/usr/lib64/gdalplugins --datadir=/usr/share/gdal/ 
--includedir=/usr/include/gdal/ --prefix=/usr --with-armadillo 
--with-curl --with-cfitsio=/usr --with-dods-root=/usr --with-expat 
--with-freexl --with-geos --with-geotiff=external --with-gif --with-gta 
--with-hdf4 --with-hdf5 --with-jasper --with-java --with-jpeg 
--with-libjson-c --without-jpeg12 --with-liblzma --with-libtiff=external 
--with-libz --without-mdb --without-msg --with-mysql --with-netcdf 
--with-odbc --with-ogdi --with-openjpeg --with-pcraster --with-pg 
--with-png --with-poppler --with-proj --with-spatialite --with-sqlite3 
--with-threads --with-webp --with-xerces --enable-shared --with-libkml
configure: WARNING: unrecognized options: --disable-dependency-tracking, 
--with-autoload
checking build system type... x86_64-redhat-linux-gnu
checking host system type... x86_64-redhat-linux-gnu
checking for x86_64-redhat-linux-gnu-gcc... no
checking for gcc... gcc
.............
+ make -j1 POPPLER_0_20_OR_LATER=yes POPPLER_0_23_OR_LATER=yes 
POPPLER_BASE_STREAM_HAS_TWO_ARGS=yes POPPLER_0_58_OR_LATER=yes
(cd port; make)
make[1]: Entering directory '/builddir/build/BUILD/gdal-2.4.2/port'
..........

How would I do a "non-libtool build" ?


From craig.destigter at koordinates.com  Fri Dec 13 23:42:58 2019
From: craig.destigter at koordinates.com (Craig de Stigter)
Date: Sat, 14 Dec 2019 20:42:58 +1300
Subject: [gdal-dev] VSI CIFS driver
In-Reply-To: <2218351.t4joFbaAaY@even-i700>
References: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>
 <2218351.t4joFbaAaY@even-i700>
Message-ID: <CAF1M8pcxMH8_UOg4WxondRVWrPszPNxEC5==_yVr-AdFqVsaYQ@mail.gmail.com>

Thanks Even

That sounds like a possible path forward, although it works for FUSE
filesystems only, so we'd have to find a good FUSE implementation of CIFS
(currently we're using the kernel provided cifs)

If anyone can recommend a well-maintained FUSE CIFS implementation I'd
gladly look into it. After some googling I don't see much that fills me
with confidence, but I will continue to search at work next week.

I'll keep you updated  on what I discover. Thanks
Craig

On Fri, 13 Dec 2019 at 23:38, Even Rouault <even.rouault at spatialys.com>
wrote:

> Craig,
>
> > We have to access some customer data via their CIFS shares on a regular
> > basis.
> >
> > To date we have been doing it via a setuid script which mounts and
> unmounts
> > the CIFS share locally, then treats the files as local. We're
> > containerising our workers, and using kernel mounts is no longer possible
> > (at least, not even slightly securely.)
>
> Is upgrading to Kernel 4.18 an option ?
> See https://www.phoronix.com/scan.php?page=news_item&px=Linux-4.18-FUSE
>
> >
> > This means we need a userspace CIFS implementation for a lot of our GDAL
> > code, and a VSI CIFS driver would seem to be the right thing to do.
> > Presumably it will be a fairly thin wrapper of libsmb.
> >
> > 2. Would it be something GDAL might accept as a core contribution, or
> > should we expect to maintain it outside of core?
>
> Hard to know where to draw the line. If recent kernels would make this no
> longer needed, then its value in core might be low.
>
> > 3. We noticed https://github.com/OSGeo/gdal/pull/1289 should allow VSI
> > plugins to be registered from Python,
>
> It allows VSI plugins to be registered with a C interface. So if you'd
> want ot
> use that from Python, you'd likely have to play with ctypes or similar
> technology.
>
> > Are there any docs on how to actually do this?
>
> Well, the Doxygen docs of VSIAllocFilesystemPluginCallbacksStruct and
> VSIInstallPluginHandler in cpl_vsi.h . And the tutorial you'll add if you
> proceed that way ;-)
>
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>


-- 
Regards,
Craig

Developer
Koordinates

+64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191214/ba6c8955/attachment.html>

From seandarcy2 at gmail.com  Sun Dec 15 07:15:15 2019
From: seandarcy2 at gmail.com (sean darcy)
Date: Sun, 15 Dec 2019 10:15:15 -0500
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
In-Reply-To: <qt0apr$5hu4$1@blaine.gmane.org>
References: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
 <2765013.5Hsoq9kDmh@even-i700> <qt0apr$5hu4$1@blaine.gmane.org>
Message-ID: <qt5im3$42in$2@blaine.gmane.org>

On 12/13/19 10:30 AM, sean darcy wrote:
> On 12/13/19 4:50 AM, Even Rouault wrote:
>> On jeudi 12 décembre 2019 22:37:32 CET Sean Darcy wrote:
>>> Building gdal-2.4.3 on Fedora 31, gcc-9.2.1. This happens even though
>>> configure has --disable-static, which is recognized:
>>>
>>> checking whether to build shared libraries... yes
>>> checking whether to build static libraries... no
>>>
>>> Any suggestions appreciated.
>>
>> You are doing a manual "make 8211dump" from frmts/iso8211, right ? 
>> Well, as
>> this is mostly debug stuff not built by default, support for static 
>> builds
>> might be broken. You may need to tweek the makefile.
>>
>> Works at least for me for a shared + non-libtool build.
>>
> 
> I'm not doing a manual make 8211dump . This is a full ./configure make 
> dance, with --disable-static:
> 
> 
> 
> + ./configure --build=x86_64-redhat-linux-gnu 
> --host=x86_64-redhat-linux-gnu --program-prefix= 
> --disable-dependency-tracking --prefix=/usr --exec-prefix=/usr 
> --bindir=/usr/bin --sbindir=/usr/sbin
> --sysconfdir=/etc --datadir=/usr/share --includedir=/usr/include 
> --libdir=/usr/lib64 --libexecdir=/usr/libexec --localstatedir=/var 
> --sharedstatedir=/var/lib --mandir=/usr/share/man 
> --infodir=/usr/share/info --disable-static 'LIBS=-lg2c_v1.6.0 -ltirpc' 
> --with-autoload=/usr/lib64/gdalplugins --datadir=/usr/share/gdal/ 
> --includedir=/usr/include/gdal/ --prefix=/usr --with-armadillo 
> --with-curl --with-cfitsio=/usr --with-dods-root=/usr --with-expat 
> --with-freexl --with-geos --with-geotiff=external --with-gif --with-gta 
> --with-hdf4 --with-hdf5 --with-jasper --with-java --with-jpeg 
> --with-libjson-c --without-jpeg12 --with-liblzma --with-libtiff=external 
> --with-libz --without-mdb --without-msg --with-mysql --with-netcdf 
> --with-odbc --with-ogdi --with-openjpeg --with-pcraster --with-pg 
> --with-png --with-poppler --with-proj --with-spatialite --with-sqlite3 
> --with-threads --with-webp --with-xerces --enable-shared --with-libkml
> configure: WARNING: unrecognized options: --disable-dependency-tracking, 
> --with-autoload
> checking build system type... x86_64-redhat-linux-gnu
> checking host system type... x86_64-redhat-linux-gnu
> checking for x86_64-redhat-linux-gnu-gcc... no
> checking for gcc... gcc
> .............
> + make -j1 POPPLER_0_20_OR_LATER=yes POPPLER_0_23_OR_LATER=yes 
> POPPLER_BASE_STREAM_HAS_TWO_ARGS=yes POPPLER_0_58_OR_LATER=yes
> (cd port; make)
> make[1]: Entering directory '/builddir/build/BUILD/gdal-2.4.2/port'
> ..........
> 
> How would I do a "non-libtool build" ?
> 

Maybe a better questions is:

why is gdal trying to build a static library when --disable-static is 
specified? Is there any way to _really_ disable static ?

sen


From even.rouault at spatialys.com  Sun Dec 15 09:02:26 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 15 Dec 2019 18:02:26 +0100
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
In-Reply-To: <qt5im3$42in$2@blaine.gmane.org>
References: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
 <qt0apr$5hu4$1@blaine.gmane.org> <qt5im3$42in$2@blaine.gmane.org>
Message-ID: <1982494.rQWDJs63lD@even-i700>

> > How would I do a "non-libtool build" ?

--without-libtool

> 
> Maybe a better questions is:
> 
> why is gdal trying to build a static library when --disable-static is
> specified? Is there any way to _really_ disable static ?

GDAL build system uses autoconf, but not automake. The makefile are hand 
written, so some of the autoconf options will have no real effect. If you want 
to disable the static lib, the best is to delete manually libgdal.a after 
libgdal.so has been generated.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From craig.destigter at koordinates.com  Sun Dec 15 18:40:21 2019
From: craig.destigter at koordinates.com (Craig de Stigter)
Date: Mon, 16 Dec 2019 15:40:21 +1300
Subject: [gdal-dev] VSI CIFS driver
In-Reply-To: <CAF1M8pcxMH8_UOg4WxondRVWrPszPNxEC5==_yVr-AdFqVsaYQ@mail.gmail.com>
References: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>
 <2218351.t4joFbaAaY@even-i700>
 <CAF1M8pcxMH8_UOg4WxondRVWrPszPNxEC5==_yVr-AdFqVsaYQ@mail.gmail.com>
Message-ID: <CAF1M8pfmWmBF0Mg+jLcTSdKe3zMUcAGzNf6nqNTTKanpHu3MTQ@mail.gmail.com>

I haven't quite exhausted my frustration budget for this yet but here's
what I've found so far:


   - `smbfuse` appears to be abandoned since 2007, though Ubuntu is still
   packaging it through 19.10.
   - I can't really find anything else in this space.
   - To use FUSE at all you need the `fuse` module, which isn't enabled in
   any of the default images I tried.
   - Some systems don't seem to support loading kernel modules, e.g. the
   xhyve VM on Docker for Desktop (well, the Mac version anyway) doesn't seem
   to allow `modprobe`

I think it's probably more straightforward to implement a VSI CIFS than a
FUSE CIFS.



On Sat, 14 Dec 2019 at 20:42, Craig de Stigter <
craig.destigter at koordinates.com> wrote:

> Thanks Even
>
> That sounds like a possible path forward, although it works for FUSE
> filesystems only, so we'd have to find a good FUSE implementation of CIFS
> (currently we're using the kernel provided cifs)
>
> If anyone can recommend a well-maintained FUSE CIFS implementation I'd
> gladly look into it. After some googling I don't see much that fills me
> with confidence, but I will continue to search at work next week.
>
> I'll keep you updated  on what I discover. Thanks
> Craig
>
> On Fri, 13 Dec 2019 at 23:38, Even Rouault <even.rouault at spatialys.com>
> wrote:
>
>> Craig,
>>
>> > We have to access some customer data via their CIFS shares on a regular
>> > basis.
>> >
>> > To date we have been doing it via a setuid script which mounts and
>> unmounts
>> > the CIFS share locally, then treats the files as local. We're
>> > containerising our workers, and using kernel mounts is no longer
>> possible
>> > (at least, not even slightly securely.)
>>
>> Is upgrading to Kernel 4.18 an option ?
>> See https://www.phoronix.com/scan.php?page=news_item&px=Linux-4.18-FUSE
>>
>> >
>> > This means we need a userspace CIFS implementation for a lot of our GDAL
>> > code, and a VSI CIFS driver would seem to be the right thing to do.
>> > Presumably it will be a fairly thin wrapper of libsmb.
>> >
>> > 2. Would it be something GDAL might accept as a core contribution, or
>> > should we expect to maintain it outside of core?
>>
>> Hard to know where to draw the line. If recent kernels would make this no
>> longer needed, then its value in core might be low.
>>
>> > 3. We noticed https://github.com/OSGeo/gdal/pull/1289 should allow VSI
>> > plugins to be registered from Python,
>>
>> It allows VSI plugins to be registered with a C interface. So if you'd
>> want ot
>> use that from Python, you'd likely have to play with ctypes or similar
>> technology.
>>
>> > Are there any docs on how to actually do this?
>>
>> Well, the Doxygen docs of VSIAllocFilesystemPluginCallbacksStruct and
>> VSIInstallPluginHandler in cpl_vsi.h . And the tutorial you'll add if you
>> proceed that way ;-)
>>
>>
>> Even
>>
>> --
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>>
>
>
> --
> Regards,
> Craig
>
> Developer
> Koordinates
>
> +64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
> <https://twitter.com/koordinates>
>


-- 
Regards,
Craig

Developer
Koordinates

+64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191216/3c64f45c/attachment.html>

From craig.destigter at koordinates.com  Sun Dec 15 18:41:09 2019
From: craig.destigter at koordinates.com (Craig de Stigter)
Date: Mon, 16 Dec 2019 15:41:09 +1300
Subject: [gdal-dev] VSI CIFS driver
In-Reply-To: <CAF1M8pfmWmBF0Mg+jLcTSdKe3zMUcAGzNf6nqNTTKanpHu3MTQ@mail.gmail.com>
References: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>
 <2218351.t4joFbaAaY@even-i700>
 <CAF1M8pcxMH8_UOg4WxondRVWrPszPNxEC5==_yVr-AdFqVsaYQ@mail.gmail.com>
 <CAF1M8pfmWmBF0Mg+jLcTSdKe3zMUcAGzNf6nqNTTKanpHu3MTQ@mail.gmail.com>
Message-ID: <CAF1M8pcw4FDvs2XeorP5jNgqn=mZDPHsCsbvTczzDvObd_aVVA@mail.gmail.com>

Sorry, that's `fusesmb`, not `smbfuse`

On Mon, 16 Dec 2019 at 15:40, Craig de Stigter <
craig.destigter at koordinates.com> wrote:

> I haven't quite exhausted my frustration budget for this yet but here's
> what I've found so far:
>
>
>    - `smbfuse` appears to be abandoned since 2007, though Ubuntu is still
>    packaging it through 19.10.
>    - I can't really find anything else in this space.
>    - To use FUSE at all you need the `fuse` module, which isn't enabled
>    in any of the default images I tried.
>    - Some systems don't seem to support loading kernel modules, e.g. the
>    xhyve VM on Docker for Desktop (well, the Mac version anyway) doesn't seem
>    to allow `modprobe`
>
> I think it's probably more straightforward to implement a VSI CIFS than a
> FUSE CIFS.
>
>
>
> On Sat, 14 Dec 2019 at 20:42, Craig de Stigter <
> craig.destigter at koordinates.com> wrote:
>
>> Thanks Even
>>
>> That sounds like a possible path forward, although it works for FUSE
>> filesystems only, so we'd have to find a good FUSE implementation of CIFS
>> (currently we're using the kernel provided cifs)
>>
>> If anyone can recommend a well-maintained FUSE CIFS implementation I'd
>> gladly look into it. After some googling I don't see much that fills me
>> with confidence, but I will continue to search at work next week.
>>
>> I'll keep you updated  on what I discover. Thanks
>> Craig
>>
>> On Fri, 13 Dec 2019 at 23:38, Even Rouault <even.rouault at spatialys.com>
>> wrote:
>>
>>> Craig,
>>>
>>> > We have to access some customer data via their CIFS shares on a regular
>>> > basis.
>>> >
>>> > To date we have been doing it via a setuid script which mounts and
>>> unmounts
>>> > the CIFS share locally, then treats the files as local. We're
>>> > containerising our workers, and using kernel mounts is no longer
>>> possible
>>> > (at least, not even slightly securely.)
>>>
>>> Is upgrading to Kernel 4.18 an option ?
>>> See https://www.phoronix.com/scan.php?page=news_item&px=Linux-4.18-FUSE
>>>
>>> >
>>> > This means we need a userspace CIFS implementation for a lot of our
>>> GDAL
>>> > code, and a VSI CIFS driver would seem to be the right thing to do.
>>> > Presumably it will be a fairly thin wrapper of libsmb.
>>> >
>>> > 2. Would it be something GDAL might accept as a core contribution, or
>>> > should we expect to maintain it outside of core?
>>>
>>> Hard to know where to draw the line. If recent kernels would make this
>>> no
>>> longer needed, then its value in core might be low.
>>>
>>> > 3. We noticed https://github.com/OSGeo/gdal/pull/1289 should allow VSI
>>> > plugins to be registered from Python,
>>>
>>> It allows VSI plugins to be registered with a C interface. So if you'd
>>> want ot
>>> use that from Python, you'd likely have to play with ctypes or similar
>>> technology.
>>>
>>> > Are there any docs on how to actually do this?
>>>
>>> Well, the Doxygen docs of VSIAllocFilesystemPluginCallbacksStruct and
>>> VSIInstallPluginHandler in cpl_vsi.h . And the tutorial you'll add if
>>> you
>>> proceed that way ;-)
>>>
>>>
>>> Even
>>>
>>> --
>>> Spatialys - Geospatial professional services
>>> http://www.spatialys.com
>>>
>>
>>
>> --
>> Regards,
>> Craig
>>
>> Developer
>> Koordinates
>>
>> +64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
>> <https://twitter.com/koordinates>
>>
>
>
> --
> Regards,
> Craig
>
> Developer
> Koordinates
>
> +64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
> <https://twitter.com/koordinates>
>


-- 
Regards,
Craig

Developer
Koordinates

+64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191216/87e869c3/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Mon Dec 16 07:43:37 2019
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Mon, 16 Dec 2019 15:43:37 +0000
Subject: [gdal-dev] OAPIF endpoint and trailing slash
Message-ID: <89dc2672cf734e2c974accd3f31691ab@C119S212VM040.msvyvi.vaha.local>

Hi,

GDAL OAPIF driver, according to the documentation https://gdal.org/drivers/vector/oapif.html, takes the service landing page as URL

"Dataset name syntax
The syntax to open a OGC API - Features datasource is : OAPIF:http://path/to/OAPIF/endpoint
where endpoint is the landing page or a the path to collections/{id}."

In the OGC API Features standard http://docs.opengeospatial.org/is/17-069r3/17-069r3.html#_http_uris the landing page is defined as
"The entry point is a Landing page (path /)"

I read this so that the landing page is "base URL followed by slash" and collections are supposed to locate at "base URL followed by /collections".
The standard seems to say that the landing page must always have a trailing slash and therefore I should use URL like this
ogrinfo OAPIF:https://www.ldproxy.nrw.de/rest/services/kataster/

That request works OK with this server and so does work the next request that ogrinfo generates even if has now two slashes in a row in the middle or the URL
https://www.ldproxy.nrw.de/rest/services/kataster//collections/gebaeudebauwerk/items?limit=10<https://www.ldproxy.nrw.de/rest/services/kataster/collections/gebaeudebauwerk/items?limit=10>

However, with our own server landing page with trailing slash leads to failure because it does not like the double slashes later.
ogrinfo oapif:https://beta-paikkatieto.maanmittauslaitos.fi/geographic-names/wfs3/v1/

generates
https://beta-paikkatieto.maanmittauslaitos.fi/geographic-names/wfs3/v1//collections
and the result is
ERROR 1: HTTP error code : 404 Not Found

I can imagine two alternative ways to fix the issue:

  1.  Document that the URL is the base path and concatenate it with "/" or "/collections" for fetching the landing page or collection reference, respectively.
  2.  Document that landing page must end with slash and make sure that slash will not be duplicated for /collections.
Other suggestions are welcome, including advice to fix our own systems. I have checked many web pages which do not have problems with multiple slashes. Reference to corresponding part of http standard would be appreciated.

I wonder also if I understood right that OAPIF driver does not currently read the landing page at all. However I believe that it is OK that OAPIF server is advertising links which do not use the same base url than the landing page and then the collections would not be found.

Finally I do not understand why using direct URL to a collection work for this server
ogrinfo oapif:https://www.ldproxy.nrw.de/kataster/collections/flurstueck

but not for our server
ogrinfo oapif:https://beta-paikkatieto.maanmittauslaitos.fi/maastotiedot_100k/wfs3/v1/collections/rautatiepiste

The http request looks good but the result is Not Found
HTTP: Fetch(https://beta-paikkatieto.maanmittauslaitos.fi/maastotiedot_100k/wfs3/v1/collections/rautatiepiste)
HTTP: libcurl/7.37.1 OpenSSL/1.0.1h zlib/1.2.3
HTTP: These HTTP headers were set: Accept: application/json
ERROR 1: HTTP error code : 404

-Jukka Rahkonen-



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191216/ce53915a/attachment-0001.html>

From even.rouault at spatialys.com  Mon Dec 16 09:14:08 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 16 Dec 2019 18:14:08 +0100
Subject: [gdal-dev] OAPIF endpoint and trailing slash
In-Reply-To: <89dc2672cf734e2c974accd3f31691ab@C119S212VM040.msvyvi.vaha.local>
References: <89dc2672cf734e2c974accd3f31691ab@C119S212VM040.msvyvi.vaha.local>
Message-ID: <10444267.I8h8MxTIJH@even-i700>

Jukka,

> In the OGC API Features standard
> http://docs.opengeospatial.org/is/17-069r3/17-069r3.html#_http_uris the
> landing page is defined as "The entry point is a Landing page (path /)"
> 
> I read this so that the landing page is "base URL followed by slash"

No, I don't think this must be interpreted as it. Here "path /" is a short way 
of telling the root of the service, but the URL of a OAPIF landing page may or 
may not terminate by slash depending on server implementation tastes.

> That request works OK with this server and so does work the next request
> that ogrinfo generates even if has now two slashes in a row in the middle
> or the URL

OK, I've fixed that. Due to the driver taking shortcut to create the
/collections URL. Normally it should retrieve it from the landing page

> Reference to corresponding part of http standard would be appreciated.

I've no idea what HTTP standard(s) stay about that. Hopefully the above 
mentionned fix should avoid reading them :-)

> Finally I do not understand why using direct URL to a collection work for
> but not for our server
> ogrinfo
> oapif:https://beta-paikkatieto.maanmittauslaitos.fi/maastotiedot_100k/wfs3/
> v1/collections/rautatiepiste
> 

I cannot access at all
oapif:https://beta-paikkatieto.maanmittauslaitos.fi/maastotiedot_100k/wfs3/v1

But tring similarly with
oapif:https://beta-paikkatieto.maanmittauslaitos.fi/geographic-names/wfs3/v1/
collections/placenames

the issue is that the answer returned by the server does not follow the right 
schema.
It returns a "collections" array, whereas it should directly return the item 
contained in this array.

So instead of

{
  "links" : [ {
    "href" : "https://beta-paikkatieto.maanmittauslaitos.fi/geographic-names/
wfs3/v1/collections/placenames",
    "rel" : "self",
    "type" : "application/json",
    "title" : "This document"
  } ],
  "collections" : [ {
    "name" : "placenames",
    "title" : "PlaceNames",
    "description" : "NLS Finland GNR: Place names",
    "links" : [ {
      "href" : "https://beta-paikkatieto.maanmittauslaitos.fi/geographic-names/wfs3/v1/collections/placenames/items",
      "rel" : "item",
      "type" : "application/geo+json"
    } ],
    "crs" : [ "http://www.opengis.net/def/crs/EPSG/0/3067", "http://
www.opengis.net/def/crs/EPSG/0/4258", "http://www.opengis.net/def/crs/OGC/1.3/
CRS84", "http://www.opengis.net/def/crs/EPSG/0/3046", "http://www.opengis.net/
def/crs/EPSG/0/3047", "http://www.opengis.net/def/crs/EPSG/0/3048", "http://
www.opengis.net/def/crs/EPSG/0/3873", "http://www.opengis.net/def/crs/EPSG/
0/3874", "http://www.opengis.net/def/crs/EPSG/0/3875", "http://
www.opengis.net/def/crs/EPSG/0/3876", "http://www.opengis.net/def/crs/EPSG/
0/3877", "http://www.opengis.net/def/crs/EPSG/0/3878", "http://
www.opengis.net/def/crs/EPSG/0/3879", "http://www.opengis.net/def/crs/EPSG/
0/3880", "http://www.opengis.net/def/crs/EPSG/0/3881", "http://
www.opengis.net/def/crs/EPSG/0/3882", "http://www.opengis.net/def/crs/EPSG/
0/3883", "http://www.opengis.net/def/crs/EPSG/0/3884", "http://
www.opengis.net/def/crs/EPSG/0/3885" ]
  } ]

it should returns somelink:

{
    "name" : "placenames",
    "title" : "PlaceNames",
    "description" : "NLS Finland GNR: Place names",
    "links" : [ {
      "href" : "https://beta-paikkatieto.maanmittauslaitos.fi/geographic-names/wfs3/v1/collections/placenames/items",
      "rel" : "item",
      "type" : "application/geo+json"
    } ],
    "crs" : [ "http://www.opengis.net/def/crs/EPSG/0/3067", "http://
www.opengis.net/def/crs/EPSG/0/4258", "http://www.opengis.net/def/crs/OGC/1.3/
CRS84", "http://www.opengis.net/def/crs/EPSG/0/3046", "http://www.opengis.net/
def/crs/EPSG/0/3047", "http://www.opengis.net/def/crs/EPSG/0/3048", "http://
www.opengis.net/def/crs/EPSG/0/3873", "http://www.opengis.net/def/crs/EPSG/
0/3874", "http://www.opengis.net/def/crs/EPSG/0/3875", "http://
www.opengis.net/def/crs/EPSG/0/3876", "http://www.opengis.net/def/crs/EPSG/
0/3877", "http://www.opengis.net/def/crs/EPSG/0/3878", "http://
www.opengis.net/def/crs/EPSG/0/3879", "http://www.opengis.net/def/crs/EPSG/
0/3880", "http://www.opengis.net/def/crs/EPSG/0/3881", "http://
www.opengis.net/def/crs/EPSG/0/3882", "http://www.opengis.net/def/crs/EPSG/
0/3883", "http://www.opengis.net/def/crs/EPSG/0/3884", "http://
www.opengis.net/def/crs/EPSG/0/3885" ]
  }

Note: the "name" member is something from draft. The final spec uses "id" (but 
the driver has still some backward compatibility hacks for that)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From craig.destigter at koordinates.com  Mon Dec 16 14:44:27 2019
From: craig.destigter at koordinates.com (Craig de Stigter)
Date: Tue, 17 Dec 2019 11:44:27 +1300
Subject: [gdal-dev] VSI CIFS driver
In-Reply-To: <CAF1M8pcw4FDvs2XeorP5jNgqn=mZDPHsCsbvTczzDvObd_aVVA@mail.gmail.com>
References: <CAF1M8pdNneW4m2kmQccj7QVeF1eU+4p1108TR3z4+ocj4Vn4fw@mail.gmail.com>
 <2218351.t4joFbaAaY@even-i700>
 <CAF1M8pcxMH8_UOg4WxondRVWrPszPNxEC5==_yVr-AdFqVsaYQ@mail.gmail.com>
 <CAF1M8pfmWmBF0Mg+jLcTSdKe3zMUcAGzNf6nqNTTKanpHu3MTQ@mail.gmail.com>
 <CAF1M8pcw4FDvs2XeorP5jNgqn=mZDPHsCsbvTczzDvObd_aVVA@mail.gmail.com>
Message-ID: <CAF1M8peEy93wLRGZWoUL=gqD6hpjU2JcZtW7wkvG=rV8rQJ3Og@mail.gmail.com>

It was a good idea. We've been trying to make the FUSE thing work, but
there are a lot of hoops to jump through.

   - We did find `smbnetfs`, which is a *slightly* more updated package
   with seemingly more sensible usage information
   - Docker doesn't support it unless you have CAP_SYS_ADMIN:
   https://github.com/docker/for-linux/issues/321 - which defeats the
   purpose; we might as well just use `mount.cifs` at that point.

We're going to switch back to looking into implementing a VSI driver for
wrapping libsmb.

On Mon, 16 Dec 2019 at 15:41, Craig de Stigter <
craig.destigter at koordinates.com> wrote:

> Sorry, that's `fusesmb`, not `smbfuse`
>
> On Mon, 16 Dec 2019 at 15:40, Craig de Stigter <
> craig.destigter at koordinates.com> wrote:
>
>> I haven't quite exhausted my frustration budget for this yet but here's
>> what I've found so far:
>>
>>
>>    - `smbfuse` appears to be abandoned since 2007, though Ubuntu is
>>    still packaging it through 19.10.
>>    - I can't really find anything else in this space.
>>    - To use FUSE at all you need the `fuse` module, which isn't enabled
>>    in any of the default images I tried.
>>    - Some systems don't seem to support loading kernel modules, e.g. the
>>    xhyve VM on Docker for Desktop (well, the Mac version anyway) doesn't seem
>>    to allow `modprobe`
>>
>> I think it's probably more straightforward to implement a VSI CIFS than a
>> FUSE CIFS.
>>
>>
>>
>> On Sat, 14 Dec 2019 at 20:42, Craig de Stigter <
>> craig.destigter at koordinates.com> wrote:
>>
>>> Thanks Even
>>>
>>> That sounds like a possible path forward, although it works for FUSE
>>> filesystems only, so we'd have to find a good FUSE implementation of CIFS
>>> (currently we're using the kernel provided cifs)
>>>
>>> If anyone can recommend a well-maintained FUSE CIFS implementation I'd
>>> gladly look into it. After some googling I don't see much that fills me
>>> with confidence, but I will continue to search at work next week.
>>>
>>> I'll keep you updated  on what I discover. Thanks
>>> Craig
>>>
>>> On Fri, 13 Dec 2019 at 23:38, Even Rouault <even.rouault at spatialys.com>
>>> wrote:
>>>
>>>> Craig,
>>>>
>>>> > We have to access some customer data via their CIFS shares on a
>>>> regular
>>>> > basis.
>>>> >
>>>> > To date we have been doing it via a setuid script which mounts and
>>>> unmounts
>>>> > the CIFS share locally, then treats the files as local. We're
>>>> > containerising our workers, and using kernel mounts is no longer
>>>> possible
>>>> > (at least, not even slightly securely.)
>>>>
>>>> Is upgrading to Kernel 4.18 an option ?
>>>> See https://www.phoronix.com/scan.php?page=news_item&px=Linux-4.18-FUSE
>>>>
>>>> >
>>>> > This means we need a userspace CIFS implementation for a lot of our
>>>> GDAL
>>>> > code, and a VSI CIFS driver would seem to be the right thing to do.
>>>> > Presumably it will be a fairly thin wrapper of libsmb.
>>>> >
>>>> > 2. Would it be something GDAL might accept as a core contribution, or
>>>> > should we expect to maintain it outside of core?
>>>>
>>>> Hard to know where to draw the line. If recent kernels would make this
>>>> no
>>>> longer needed, then its value in core might be low.
>>>>
>>>> > 3. We noticed https://github.com/OSGeo/gdal/pull/1289 should allow
>>>> VSI
>>>> > plugins to be registered from Python,
>>>>
>>>> It allows VSI plugins to be registered with a C interface. So if you'd
>>>> want ot
>>>> use that from Python, you'd likely have to play with ctypes or similar
>>>> technology.
>>>>
>>>> > Are there any docs on how to actually do this?
>>>>
>>>> Well, the Doxygen docs of VSIAllocFilesystemPluginCallbacksStruct and
>>>> VSIInstallPluginHandler in cpl_vsi.h . And the tutorial you'll add if
>>>> you
>>>> proceed that way ;-)
>>>>
>>>>
>>>> Even
>>>>
>>>> --
>>>> Spatialys - Geospatial professional services
>>>> http://www.spatialys.com
>>>>
>>>
>>>
>>> --
>>> Regards,
>>> Craig
>>>
>>> Developer
>>> Koordinates
>>>
>>> +64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
>>> <https://twitter.com/koordinates>
>>>
>>
>>
>> --
>> Regards,
>> Craig
>>
>> Developer
>> Koordinates
>>
>> +64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
>> <https://twitter.com/koordinates>
>>
>
>
> --
> Regards,
> Craig
>
> Developer
> Koordinates
>
> +64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
> <https://twitter.com/koordinates>
>


-- 
Regards,
Craig

Developer
Koordinates

+64 21 256 9488 <+64%2021%20256%209488> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191217/22710381/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Tue Dec 17 08:51:51 2019
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Tue, 17 Dec 2019 16:51:51 +0000
Subject: [gdal-dev] How to change wrong PixelIsArea into correct
	PixelIsPoint?
Message-ID: <8447bc691af845f6b5bb9823307434d2@C119S212VM040.msvyvi.vaha.local>

Hi,

I have some images with wrong metadata. They are tagged as pixel-is-area images and listgeo shows the tag
GTRasterTypeGeoKey (Short,1): RasterPixelIsArea

Actually geotiffs are measurements and they should use RasterPixelIsPoint and images should be shifted be half a pixel on a map.

I was thinking that I can make a clever fix with gdal_edit so I made a copy of "area.tif" as "point.tif" and then I edited it

gdal_edit -mo AREA_OR_POINT=Point point.tif

The key gets edited into RasterPixelIsPoint just as I wished. However, the georeferencing that is stored into tag 33922 gets edited by the same.
Before edit:
ModelTiepointTag (2,3):
         0                 0                 0
         115               33                0
      ModelPixelScaleTag (1,3):
         0.1               0.1               0

After edit:
Tagged_Information:
      ModelTiepointTag (2,3):
         0                 0                 0
         115.05            32.95             0
      ModelPixelScaleTag (1,3):
         0.1               0.1               0

Because the ModelTiepoint gets shifted by half a pixel it compensates the shift caused by image-is-area vs. image-is-point and the image footprint and pixels stay exactly where they used to be. I know I can use gdal_edit again with -a_ullr ulx uly lrx lry for shifting the image but I wonder if there happens to be some trick for just changing raster type into pixel-is-point without touching the tiepoint. Option "swap PixelIsPoint/Area" in gdal_edit would be fine for me if the current behavior with -mo AREA_OR_POINT=Point feels correct.

-Jukka Rahkonen-









-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191217/25ba03b9/attachment.html>

From even.rouault at spatialys.com  Tue Dec 17 09:01:01 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 17 Dec 2019 18:01:01 +0100
Subject: [gdal-dev] How to change wrong PixelIsArea into correct
	PixelIsPoint?
In-Reply-To: <8447bc691af845f6b5bb9823307434d2@C119S212VM040.msvyvi.vaha.local>
References: <8447bc691af845f6b5bb9823307434d2@C119S212VM040.msvyvi.vaha.local>
Message-ID: <2721278.hK9lL8leta@even-i700>

Jukka,

> I was thinking that I can make a clever fix with gdal_edit so I made a copy
> of "area.tif" as "point.tif" and then I edited it
> 
> gdal_edit -mo AREA_OR_POINT=Point point.tif

Just add --config GTIFF_POINT_GEO_IGNORE YES to the above

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Tue Dec 17 10:36:44 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 17 Dec 2019 19:36:44 +0100
Subject: [gdal-dev] Changes in SRS handling w.r.t TOWGS84
Message-ID: <1944309.TuLgCblkfb@even-i700>

Hi,

Following a number of exchanges on the PROJ mailing list, related to PROJ 6 
integration in QGIS, I've prepared a pull request changing a bit how we deal 
with the 'early-binding' TOWGS84 term in
https://github.com/OSGeo/gdal/pull/2113

"""
When importing from EPSG, GDAL 3.0.0 to 3.0.2 followed the scheme used in
GDAL 1.x and GDAL 2.x, that is they tried to attach a TOWGS84 transformation.
While the intent was to have some sort of backward compatibility, this may
be a pain for the future.
So do the following changes:
- importFromEPSG(): no longer attach a TOWGS84 transformation, unless the
  user set the OSR_ADD_TOWGS84_ON_IMPORT_FROM_EPSG=YES configuration option
  Add a OGRSpatialReference::AddGuessedTOWGS84() to attach such a
  transformation, when possible (note: this will do it in a more prudent way
  than GDAL 1.x/2.x, that is only if a transformation is found for the whole
  area of use of the CRS)
- exportToProj4(): if the SRS has no transformation to WGS84,
  attach a +towgs84 if the SRS has a EPSG code and AddGuessedToWGS84()  
  succeeds.
  Can be disabled with the OSR_ADD_TOWGS84_ON_EXPORT_TO_PROJ4 = NO
  configuration option
- exportToWkt() with WKT1 format:
  Add a OSR_ADD_TOWGS84_ON_EXPORT_TO_WKT1 = YES/NO configuration option, which
  defaults to NO. If set to YES, then a transformation to WGS84 using
  AddGuessedToWGS84() logic is researched to add a TOWGS84[] node.
"""

The aim is to avoid the propagation of potentially suboptimal TOWGS84 terms by 
default (except when exporting to PROJ4 string as we don't have a more 
expressive way of encoding datum information), which can be the source of 
later problems (not using grids when available due to this towgs84 being 
strictly honoured).

I've a backport of this for the 3.0 branch ready, to go in the 3.0.3 release.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From seandarcy2 at gmail.com  Tue Dec 17 12:22:45 2019
From: seandarcy2 at gmail.com (sean darcy)
Date: Tue, 17 Dec 2019 15:22:45 -0500
Subject: [gdal-dev] gdal-2.4.3 build dies at libiso8211.a
In-Reply-To: <1982494.rQWDJs63lD@even-i700>
References: <CANMCZfsnDuCYz0bm437jeaPAoxV2zj6sOoO8_ipi1tPuVCroug@mail.gmail.com>
 <qt0apr$5hu4$1@blaine.gmane.org> <qt5im3$42in$2@blaine.gmane.org>
 <1982494.rQWDJs63lD@even-i700>
Message-ID: <qtbdem$3vf7$1@blaine.gmane.org>

On 12/15/19 12:02 PM, Even Rouault wrote:
>>> How would I do a "non-libtool build" ?
> 
> --without-libtool
> 
>>
>> Maybe a better questions is:
>>
>> why is gdal trying to build a static library when --disable-static is
>> specified? Is there any way to _really_ disable static ?
> 
> GDAL build system uses autoconf, but not automake. The makefile are hand
> written, so some of the autoconf options will have no real effect. If you want
> to disable the static lib, the best is to delete manually libgdal.a after
> libgdal.so has been generated.
> 
> Even
> 

So --without-libtool worked. I had to fix some fedora quirks, but it 
built on koji, the fedora build server:

https://koji.fedoraproject.org/koji/taskinfo?taskID=39645827

Thanks for all your work. This program is extremely helpful. I amazed 
how good it is.

sean


From nyall.dawson at gmail.com  Tue Dec 17 13:27:53 2019
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Wed, 18 Dec 2019 07:27:53 +1000
Subject: [gdal-dev] Changes in SRS handling w.r.t TOWGS84
In-Reply-To: <1944309.TuLgCblkfb@even-i700>
References: <1944309.TuLgCblkfb@even-i700>
Message-ID: <CAB28Asj=KuWauqLyYUXr3_PGOjAwjwexkEn-z0rSy6Cr8mUa5A@mail.gmail.com>

On Wed, 18 Dec 2019 at 04:37, Even Rouault <even.rouault at spatialys.com> wrote:
>
> Hi,
>
> Following a number of exchanges on the PROJ mailing list, related to PROJ 6
> integration in QGIS, I've prepared a pull request changing a bit how we deal
> with the 'early-binding' TOWGS84 term in
> https://github.com/OSGeo/gdal/pull/2113
>
> The aim is to avoid the propagation of potentially suboptimal TOWGS84 terms by
> default (except when exporting to PROJ4 string as we don't have a more
> expressive way of encoding datum information), which can be the source of
> later problems (not using grids when available due to this towgs84 being
> strictly honoured).
>
> I've a backport of this for the 3.0 branch ready, to go in the 3.0.3 release.

Even -- I think this is totally the right move (from my (partial!)
understanding of the problem), as it means that downstream clients
like QGIS will be able to grab a lossless representation of the
original dataset's CRS via WKT.

I'd be happy to follow this logic in QGIS too, i.e. if coming from a
WKT definition then a bound CRS != its source CRS, but if coming from
a proj string then a bound crs == its source crs. That'd give much
desired consistency across the different tools.

Thanks for working through this!

Nyall



>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

From m2r42kbear at gmail.com  Tue Dec 17 18:53:03 2019
From: m2r42kbear at gmail.com (=?UTF-8?B?0JDQvdC00YDRltC5INCc0LDRgNGH0LDQug==?=)
Date: Wed, 18 Dec 2019 04:53:03 +0200
Subject: [gdal-dev] An issue when trying to add TIFFTAG_DATETIME to BigTIFF
	raster
Message-ID: <CALPDkRPSruH5=utY7NaYuN6dut3A962rBzHULRVzODV+VB+LDg@mail.gmail.com>

Hi,

I have an issue when trying to add TIFFTAG_DATETIME to BigTIFF raster. Here
the input metadata:
ExifTool` Version Number         : 11.79
File Name                       :
cushing_north_high_high_mosaic_7.45cm_utm14_wgs84_meters_2019-01-17.tif
Directory                       : D:/temp
File Size                       : 3.4 GB
File Modification Date/Time     : 2019:12:17 11:25:48+02:00
File Access Date/Time           : 2019:12:17 19:53:20+02:00
File Creation Date/Time         : 2019:12:14 18:46:14+02:00
File Permissions                : rw-rw-rw-
File Type                       : BTF
File Type Extension             : btf
MIME Type                       :  image/x-tiff-big

I run this code:
<gdal_translate
D:\temp\cushing_north_high_high_mosaic_7.45cm_utm14_wgs84_meters_2019-01-17.tif
D:\temp\cushing_north_high_high_mosaic_7.45cm_utm14_wgs84_meters_2019-01-17_Copy.tif
-mo *TIFFTAG_DATETIME="2019:01:31 09:00:00-07:00"* -co COMPRESS=LZW -co
BIGTIFF=YES>

And I got the following metadata for some reason:
ExifTool Version Number         : 11.79
File Name                       :
cushing_north_high_high_mosaic_7.45cm_utm14_wgs84_meters_2019-01-17_Copy.tif
Directory                       : D:/temp
File Size                       : 2.9 GB
File Modification Date/Time     : 2019:12:17 09:36:11+02:00
File Access Date/Time           : 2019:12:17 10:33:22+02:00
File Creation Date/Time         : 2019:12:17 09:34:43+02:00
File Permissions                : rw-rw-rw-
File Type                       : BTF
File Type Extension             : btf
MIME Type                       : image/x-tiff-big
Image Width                     : 28194
Image Height                    : 38514
Bits Per Sample                 : 8 8 8 8
Compression                     : LZW
Photometric Interpretation      : RGB
Strip Offsets                   : (Binary data 409063 bytes, use -b option
to extract)
Samples Per Pixel               : 4
Rows Per Strip                  : 1
Strip Byte Counts               : (Binary data 231034 bytes, use -b option
to extract)
Planar Configuration            : Chunky
*Modify Date                     : 2019:01:31 09:00:00-07:00*
Predictor                       : None
Extra Samples                   : Unassociated Alpha
Sample Format                   : Unsigned; Unsigned; Unsigned; Unsigned
Pixel Scale                     : 0.0744678000000016 0.0744678000000023 0
Model Tie Point                 : 0 0 0 701489.300385367 3989064.72829922 0
Geo Tiff Directory              : (Binary data 106 bytes, use -b option to
extract)
Geo Tiff Ascii Params           : (Binary data 29 bytes, use -b option to
extract)
GDAL Metadata                   : <GDALMetadata>.  <Item name="UNITTYPE"
sample="0" role="unittype">metre</Item>.  <Item name="UNITTYPE" sample="1"
role="unittype">metre</Item>.  <Item name="UNITTYPE" sample="2"
role="unittype">metre</Item>.  <Item name="UNITTYPE" sample="3"
role="unittype">metre</Item>.</GDALMetadata>.
Image Size                      : 28194x38514
Megapixels                      : 1085.9

I need to add a tag *"Date Time", but not "Modify Date"*. I was doing the
same for a few BigTIFF rasters, but with the same results.

Ideally, I want to add a tag *"Capture Date Time"*, but, I found, that GDAL
can deal with the following baseline TIFF tags as dataset-level metadata:
[https://gdal.org/drivers/raster/gtiff.html#metadata]

Thanks,
Andriy

-- 

Best regards,
Andriy Marchak!
Skype: m2r42k_bear
phone: +38 063 147 95 95 (WhatsApp)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191218/9b473355/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Tue Dec 17 22:58:19 2019
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Wed, 18 Dec 2019 06:58:19 +0000
Subject: [gdal-dev] How to change wrong PixelIsArea into correct
 PixelIsPoint?
Message-ID: <f13047316b4a474186ff869b9e770725@C119S212VM040.msvyvi.vaha.local>

Thanks Even,

I did read about GTIFF_POINT_GEO_IGNORE configuration option from https://trac.osgeo.org/gdal/wiki/rfc33_gtiff_pixelispoint but somehow wrapped my brain to think that not ignoring the difference is the right choice. At least I will remember it now and perhaps it feels also logical.

-Jukka-

-----Alkuperäinen viesti-----
Lähettäjä: Even Rouault <even.rouault at spatialys.com> 
Lähetetty: tiistai 17. joulukuuta 2019 19.01
Vastaanottaja: gdal-dev at lists.osgeo.org
Kopio: Rahkonen Jukka (MML) <jukka.rahkonen at maanmittauslaitos.fi>
Aihe: Re: [gdal-dev] How to change wrong PixelIsArea into correct PixelIsPoint?

Jukka,

> I was thinking that I can make a clever fix with gdal_edit so I made a 
> copy of "area.tif" as "point.tif" and then I edited it
> 
> gdal_edit -mo AREA_OR_POINT=Point point.tif

Just add --config GTIFF_POINT_GEO_IGNORE YES to the above

Even

--
Spatialys - Geospatial professional services http://www.spatialys.com

From jukka.rahkonen at maanmittauslaitos.fi  Wed Dec 18 02:36:23 2019
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Wed, 18 Dec 2019 03:36:23 -0700 (MST)
Subject: [gdal-dev] An issue when trying to add TIFFTAG_DATETIME to
 BigTIFF raster
In-Reply-To: <CALPDkRPSruH5=utY7NaYuN6dut3A962rBzHULRVzODV+VB+LDg@mail.gmail.com>
References: <CALPDkRPSruH5=utY7NaYuN6dut3A962rBzHULRVzODV+VB+LDg@mail.gmail.com>
Message-ID: <1576665383385-0.post@n6.nabble.com>

Hi,

You are looking at EXIF metadata that if read-only for GDAL
https://github.com/OSGeo/gdal/issues/828 but DateTime tag is also a baseline
TIFF tag 306 https://awaresystems.be/imaging/tiff/tifftags/datetime.html.

If I set metadata with
gdal_edit -mo TIFFTAG_DATETIME="2019:01:31 09:00:00-07:00" aaa.tif

I can see with the libtiff utility program "tiffinfo" that the item was
inserted correctly:

tiffinfo aaa.tif
...
 DateTime: 2019:01:31 09:00:00-07:00
...

I get the same result with "tiffset" utility
http://www.simplesystems.org/libtiff/man/tiffset.1.html

tiffset -s 306 "2019:01:31 09:00:00-07:00" aaa.tif

So everything seems to go right according to baseline tiff specification.
The EXIF specification https://www.exiv2.org/Exif2-2.PDF defines that
DateTime is the same tag number 306 and it means "File change date and
time". Finally having a look at EXIFtools documentation
https://exiftool.org/TagNames/EXIF.html reveals what happens: ModifyDate in
EXIFTools is the same tag that is called DateTime by the EXIF spec. There
seems to be no issue at all and you have correctly set the DateTime tag.

-Jukka Rahkonen-













Андрій Марчак wrote
> Hi,
> 
> I have an issue when trying to add TIFFTAG_DATETIME to BigTIFF raster.
> Here
> the input metadata:
> ExifTool` Version Number         : 11.79
> File Name                       :
> cushing_north_high_high_mosaic_7.45cm_utm14_wgs84_meters_2019-01-17.tif
> Directory                       : D:/temp
> File Size                       : 3.4 GB
> File Modification Date/Time     : 2019:12:17 11:25:48+02:00
> File Access Date/Time           : 2019:12:17 19:53:20+02:00
> File Creation Date/Time         : 2019:12:14 18:46:14+02:00





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From nirvn.asia at gmail.com  Thu Dec 19 01:41:08 2019
From: nirvn.asia at gmail.com (Mathieu Pellerin)
Date: Thu, 19 Dec 2019 16:41:08 +0700
Subject: [gdal-dev] Refreshing GDAL's logo
Message-ID: <CAC_qv=oswqMYSdqMHWdjPmx9hrJZzsmYNGwEe3aFRFdwSO-Qxg@mail.gmail.com>

Greetings all,

As some of you might have spotted on GDAL’s github account, I have spent
some time coming up with a refreshed GDAL logo proposal.

The draft’s second iteration can be seen here:
https://github.com/OSGeo/gdal/issues/2117 – thanks to Even’s initial
comment on the first iteration, the second draft looks great! :)

The proposed draft logo is IMHO a nice modernized evolution from GDAL’s
current logo: a simplified representation of earth (the curved green line)
under a simplified satellite (or compass) floating over it.

IMHO, the logo professionalizes GDAL’s first look when someone lands on
www.gdal.org, on wikipedia’s gdal page, etc. As superficial as first
impressions are, it remains important.

On top of the arguably subjective “looking better” argument, it has several
objective benefits:

- It nicely scales down to a 32px icon size quite nicely (see examples
provided in the github issue linked to above)

- Being simple and in vector format, it makes it much easier to come up
with side products, i.e. the “mug test” attached in the gitthub issue ;)
this logo would likely stand well as a round sticker, printed on a shirt,
etc.  which is always useful during hackfests.

Thoughts?

Mathieu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191219/17d79377/attachment.html>

From a.neumann at carto.net  Thu Dec 19 02:26:23 2019
From: a.neumann at carto.net (Andreas Neumann)
Date: Thu, 19 Dec 2019 11:26:23 +0100
Subject: [gdal-dev] Refreshing GDAL's logo
In-Reply-To: <CAC_qv=oswqMYSdqMHWdjPmx9hrJZzsmYNGwEe3aFRFdwSO-Qxg@mail.gmail.com>
References: <CAC_qv=oswqMYSdqMHWdjPmx9hrJZzsmYNGwEe3aFRFdwSO-Qxg@mail.gmail.com>
Message-ID: <19dd34c73e1f9ec36f61f5795cfaaead@carto.net>

Hi Mathieu, 

Thanks for working on this. I added my comment on github. 

I do like the logo a lot - my only problem is that I personally, would
associate this particular logo draft more with "proj" than with "gdal". 

To me it represents a compass (Zirkel in german) - and that was in the
pre-computer age more used to do projections than file formats. 

I guess the earth shape is fine, but maybe the compass could be styled
in a way to make it look more like a satellite? E.g. it could have a
smaller angle/fov than the current version that covers the whole earth? 

Just some thoughts - thanks again for working on it. 

Andreas 

On 2019-12-19 10:41, Mathieu Pellerin wrote:

> Greetings all,
> 
> As some of you might have spotted on GDAL's github account, I have spent some time coming up with a refreshed GDAL logo proposal.
> 
> The draft's second iteration can be seen here: https://github.com/OSGeo/gdal/issues/2117 - thanks to Even's initial comment on the first iteration, the second draft looks great! :)
> 
> The proposed draft logo is IMHO a nice modernized evolution from GDAL's current logo: a simplified representation of earth (the curved green line) under a simplified satellite (or compass) floating over it.
> 
> IMHO, the logo professionalizes GDAL's first look when someone lands on www.gdal.org [1], on wikipedia's gdal page, etc. As superficial as first impressions are, it remains important. 
> 
> On top of the arguably subjective "looking better" argument, it has several objective benefits:
> 
> - It nicely scales down to a 32px icon size quite nicely (see examples provided in the github issue linked to above)
> 
> - Being simple and in vector format, it makes it much easier to come up with side products, i.e. the "mug test" attached in the gitthub issue ;) this logo would likely stand well as a round sticker, printed on a shirt, etc.  which is always useful during hackfests.
> 
> Thoughts? 
> 
> Mathieu
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

 

Links:
------
[1] http://www.gdal.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191219/8ba075c5/attachment.html>

From gdal-dev at coulmann.de  Thu Dec 19 03:46:05 2019
From: gdal-dev at coulmann.de (wulf)
Date: Thu, 19 Dec 2019 12:46:05 +0100
Subject: [gdal-dev] patch: s57objectclasses.csv for distance marks from
 IENC [add wtwdis; unlocd]
Message-ID: <20191219114600.GI12094@coulmann.de>



Hi developers,

attached, there is a patch for

s57objectclasses.csv against git commit 94431c2


191c191
< 17004,Distance mark,dismar,catdis;wtwdis;unlocd;DATEND;DATSTA;NOBJNM;OBJNAM;,INFORM;NINFOM;NTXTDS;PICREP;SCAMIN;TXTDSC;updmsg;,SORDAT;SORIND;,G,Point;
---
> 17004,Distance mark,dismar,catdis;DATEND;DATSTA;NOBJNM;OBJNAM;,INFORM;NINFOM;NTXTDS;PICREP;SCAMIN;TXTDSC;updmsg;,SORDAT;SORIND;,G,Point;

I'm not competent if this is a correct solution, but with that version
I'm able to extract the needed values.

many thanks to Lars for his hints, so my problem is solved.

  ogr2ogr -skipfailures -f CSV flusskilometer.csv 1W7ML310.000  dismar

from the result I have to filter values with "catdis=1", thats it

> If I check the details from Points I like to extract in opencpn I get
>
> or points without unlocd
> distance mark (dismar)
> 52 13.7280 N, 011 40.0977 E
> CATGEO POINT
> CATDIS distance mark not physically installed(1)
> hunits kilometers(3)
> wtwdis 319.9 m
> unlocd DEQWS031010000003199


thanks for the effort
-------------- next part --------------
A non-text attachment was scrubbed...
Name: s57objectclasses.csv.diff
Type: text/x-diff
Size: 304 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191219/54078ca7/attachment.diff>

From even.rouault at spatialys.com  Thu Dec 19 04:06:56 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 19 Dec 2019 13:06:56 +0100
Subject: [gdal-dev] patch: s57objectclasses.csv for distance marks from
	IENC [add wtwdis; unlocd]
In-Reply-To: <20191219114600.GI12094@coulmann.de>
References: <20191219114600.GI12094@coulmann.de>
Message-ID: <3767224.kJ4TKKBEzS@even-i700>

On jeudi 19 décembre 2019 12:46:05 CET wulf wrote:
> Hi developers,
> 
> attached, there is a patch for
> 
> s57objectclasses.csv against git commit 94431c2
> 
> 
> 191c191
> < 17004,Distance
> mark,dismar,catdis;wtwdis;unlocd;DATEND;DATSTA;NOBJNM;OBJNAM;,INFORM;NINFOM
> ;NTXTDS;PICREP;SCAMIN;TXTDSC;updmsg;,SORDAT;SORIND;,G,Point; ---
> 
> > 17004,Distance
> > mark,dismar,catdis;DATEND;DATSTA;NOBJNM;OBJNAM;,INFORM;NINFOM;NTXTDS;PICR
> > EP;SCAMIN;TXTDSC;updmsg;,SORDAT;SORIND;,G,Point;
> I'm not competent if this is a correct solution, but with that version
> I'm able to extract the needed values.

Can you submit this as a pull request by editing
https://github.com/OSGeo/gdal/blob/master/gdal/data/s57objectclasses.csv
(possibly directly from github UI ?)

So you've added
;wtwdis;unlocd

Is that right ?
Where does this come from ? I can't see that on http://www.s-57.com/ . Or are 
they specific to the particular profile of S57 you use ?

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From gdal-dev at coulmann.de  Thu Dec 19 05:49:55 2019
From: gdal-dev at coulmann.de (wulf)
Date: Thu, 19 Dec 2019 14:49:55 +0100
Subject: [gdal-dev] patch: s57objectclasses.csv for distance marks from
 IENC [add wtwdis; unlocd]
In-Reply-To: <20191123160519.GR29961@coulmann.de>
Message-ID: <20191219134952.GA30050@coulmann.de>

Hi Even,

> Can you submit this as a pull request by editing
done
  https://github.com/OSGeo/gdal/pull/2123

> So you've added
> ;wtwdis;unlocd

> Is that right ?
yes

> Where does this come from ? I can't see that on http://www.s-57.com/ . Or are 
> they specific to the particular profile of S57 you use ?

I also searched at http://www.s-57.com/ without success.

I found the values by inspecting the object with opencpn as chart-viewer

The s57 data are the official inland waterway maps from the german waterway
administration. They are provided free of charge. (I'm a professional
inland waterway skipper, we must use this data by low for ECDIS (chart
display of AIS data) on all vessels longer than 20 m)

e.g. Mittellandkanal https://en.wikipedia.org/wiki/Mittelland_Canal
  https://www.elwis.de/DE/dynamisch/IENC/download_commit.php?file=WW41_2018-06-22_0_318

or an overview at:
  https://www.elwis.de/DE/Service/Inland-ENC-der-WSV/Inland-ENC-der-WSV-node.html

or an example without the hassel of extracting
  http://gpl.coulmann.de/tmp/1W7ML310.000

The chart holds river kilometers with not physically installed distance
marks. I like to use this for personal interest for locking up the
nearest river kilometer if I have an AIS gps position of a vessel.

With the patch I can export this data

See also this thread:
  (sorry, with my last post I killed the In-Reply-To:)
   [gdal-dev] no OBJNAM/NOBJNM after extract distance marks from IENC
   └─>Re: [gdal-dev] extract wtwdis and unlocd with distance marks from IENC
     └─>
       └─>
         └─>


Best Wulf

From ao at t-kartor.se  Thu Dec 19 06:23:13 2019
From: ao at t-kartor.se (Andreas Oxenstierna)
Date: Thu, 19 Dec 2019 15:23:13 +0100
Subject: [gdal-dev] patch: s57objectclasses.csv for distance marks from
 IENC [add wtwdis; unlocd]
In-Reply-To: <20191219134952.GA30050@coulmann.de>
References: <20191219134952.GA30050@coulmann.de>
Message-ID: <eebb9e28-9047-f72b-03ee-6336dd0c488b@t-kartor.se>

Hi list

see 
http://www.unece.org/fileadmin/DAM/trans/doc/finaldocs/sc3/TRANS-SC3-156s2apAe.pdf
for the Inland water S-57 profile, doc from 2001

I have not compared it against the GDAL S57 iw files or checked if there 
is a newer version

> Hi Even,
>
>> Can you submit this as a pull request by editing
> done
>    https://github.com/OSGeo/gdal/pull/2123
>
>> So you've added
>> ;wtwdis;unlocd
>> Is that right ?
> yes
>
>> Where does this come from ? I can't see that on http://www.s-57.com/ . Or are
>> they specific to the particular profile of S57 you use ?
> I also searched at http://www.s-57.com/ without success.
>
> I found the values by inspecting the object with opencpn as chart-viewer
>
> The s57 data are the official inland waterway maps from the german waterway
> administration. They are provided free of charge. (I'm a professional
> inland waterway skipper, we must use this data by low for ECDIS (chart
> display of AIS data) on all vessels longer than 20 m)
>
> e.g. Mittellandkanal https://en.wikipedia.org/wiki/Mittelland_Canal
>    https://www.elwis.de/DE/dynamisch/IENC/download_commit.php?file=WW41_2018-06-22_0_318
>
> or an overview at:
>    https://www.elwis.de/DE/Service/Inland-ENC-der-WSV/Inland-ENC-der-WSV-node.html
>
> or an example without the hassel of extracting
>    http://gpl.coulmann.de/tmp/1W7ML310.000
>
> The chart holds river kilometers with not physically installed distance
> marks. I like to use this for personal interest for locking up the
> nearest river kilometer if I have an AIS gps position of a vessel.
>
> With the patch I can export this data
>
> See also this thread:
>    (sorry, with my last post I killed the In-Reply-To:)
>     [gdal-dev] no OBJNAM/NOBJNM after extract distance marks from IENC
>     └─>Re: [gdal-dev] extract wtwdis and unlocd with distance marks from IENC
>       └─>
>         └─>
>           └─>
>
>
> Best Wulf
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


-- 
Hälsningar

Andreas Oxenstierna
T-Kartor Geospatial AB
Olof Mohlins väg 12 Kristianstad
mobile: +46 733 206831
mailto: ao at t-kartor.se
http://www.t-kartor.com


From kusala9 at googlemail.com  Thu Dec 19 15:16:57 2019
From: kusala9 at googlemail.com (kusala nine)
Date: Thu, 19 Dec 2019 23:16:57 +0000
Subject: [gdal-dev] patch: s57objectclasses.csv for distance marks from
 IENC [add wtwdis; unlocd]
In-Reply-To: <3767224.kJ4TKKBEzS@even-i700>
References: <20191219114600.GI12094@coulmann.de> <3767224.kJ4TKKBEzS@even-i700>
Message-ID: <CAOn9mqduXKMPu_DQFwXbLfYJ9wBbo-6+Xk4Z8hD2L36Q=W1ygA@mail.gmail.com>

These are features and attributes from the Inland ENC catalogue which is an
S-57 product specification similar to ENC - basically ENCs for inland
waterways. unlocd is UN Location Code, the unique identifier of a port and
wtwdis is "waterway distance" - both from the IENC product specification.
The clue is lower case - ENC features and attributes are always upper case,
INFORM, OBJNAM, LNDARE etc etc... So, I think it's fine to add these as the
S-57 driver needs to understand the different object ids and what they
represent. In the next version of the product specification the feature
catalogue will be embedded into the header of the iso8211 file (IHO S-101
which will replace S-57 in time). If anyone's interested in doing the
iso8211 parser for it (it uses concatenated data structures and like AML,
can't be read natively by existing GDAL drivers) I'm happy to help out -
the C++ is a tad beyond me right now but I'm aware the IHO momentum behind
S-101 particularly is picking up speed so it would be worth thinking about
at some point :-)

cheers,

JP

On Thu, 19 Dec 2019 at 12:07, Even Rouault <even.rouault at spatialys.com>
wrote:

> On jeudi 19 décembre 2019 12:46:05 CET wulf wrote:
> > Hi developers,
> >
> > attached, there is a patch for
> >
> > s57objectclasses.csv against git commit 94431c2
> >
> >
> > 191c191
> > < 17004,Distance
> >
> mark,dismar,catdis;wtwdis;unlocd;DATEND;DATSTA;NOBJNM;OBJNAM;,INFORM;NINFOM
> > ;NTXTDS;PICREP;SCAMIN;TXTDSC;updmsg;,SORDAT;SORIND;,G,Point; ---
> >
> > > 17004,Distance
> > >
> mark,dismar,catdis;DATEND;DATSTA;NOBJNM;OBJNAM;,INFORM;NINFOM;NTXTDS;PICR
> > > EP;SCAMIN;TXTDSC;updmsg;,SORDAT;SORIND;,G,Point;
> > I'm not competent if this is a correct solution, but with that version
> > I'm able to extract the needed values.
>
> Can you submit this as a pull request by editing
> https://github.com/OSGeo/gdal/blob/master/gdal/data/s57objectclasses.csv
> (possibly directly from github UI ?)
>
> So you've added
> ;wtwdis;unlocd
>
> Is that right ?
> Where does this come from ? I can't see that on http://www.s-57.com/ . Or
> are
> they specific to the particular profile of S57 you use ?
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191219/4b8a2c82/attachment.html>

From kusala9 at googlemail.com  Thu Dec 19 15:18:49 2019
From: kusala9 at googlemail.com (kusala nine)
Date: Thu, 19 Dec 2019 23:18:49 +0000
Subject: [gdal-dev] patch: s57objectclasses.csv for distance marks from
 IENC [add wtwdis; unlocd]
In-Reply-To: <eebb9e28-9047-f72b-03ee-6336dd0c488b@t-kartor.se>
References: <20191219134952.GA30050@coulmann.de>
 <eebb9e28-9047-f72b-03ee-6336dd0c488b@t-kartor.se>
Message-ID: <CAOn9mqfe5s=u2FHLh50Jx86rdekwg4tAqONjReaGZXVZWR+7Sg@mail.gmail.com>

http://s100.iho.int/S100/productspecs

this will become IHO S-401 in time when revised but the features/attributes
will probably stay the same in name...

JP

On Thu, 19 Dec 2019 at 14:23, Andreas Oxenstierna <ao at t-kartor.se> wrote:

> Hi list
>
> see
>
> http://www.unece.org/fileadmin/DAM/trans/doc/finaldocs/sc3/TRANS-SC3-156s2apAe.pdf
> for the Inland water S-57 profile, doc from 2001
>
> I have not compared it against the GDAL S57 iw files or checked if there
> is a newer version
>
> > Hi Even,
> >
> >> Can you submit this as a pull request by editing
> > done
> >    https://github.com/OSGeo/gdal/pull/2123
> >
> >> So you've added
> >> ;wtwdis;unlocd
> >> Is that right ?
> > yes
> >
> >> Where does this come from ? I can't see that on http://www.s-57.com/ .
> Or are
> >> they specific to the particular profile of S57 you use ?
> > I also searched at http://www.s-57.com/ without success.
> >
> > I found the values by inspecting the object with opencpn as chart-viewer
> >
> > The s57 data are the official inland waterway maps from the german
> waterway
> > administration. They are provided free of charge. (I'm a professional
> > inland waterway skipper, we must use this data by low for ECDIS (chart
> > display of AIS data) on all vessels longer than 20 m)
> >
> > e.g. Mittellandkanal https://en.wikipedia.org/wiki/Mittelland_Canal
> >
> https://www.elwis.de/DE/dynamisch/IENC/download_commit.php?file=WW41_2018-06-22_0_318
> >
> > or an overview at:
> >
> https://www.elwis.de/DE/Service/Inland-ENC-der-WSV/Inland-ENC-der-WSV-node.html
> >
> > or an example without the hassel of extracting
> >    http://gpl.coulmann.de/tmp/1W7ML310.000
> >
> > The chart holds river kilometers with not physically installed distance
> > marks. I like to use this for personal interest for locking up the
> > nearest river kilometer if I have an AIS gps position of a vessel.
> >
> > With the patch I can export this data
> >
> > See also this thread:
> >    (sorry, with my last post I killed the In-Reply-To:)
> >     [gdal-dev] no OBJNAM/NOBJNM after extract distance marks from IENC
> >     └─>Re: [gdal-dev] extract wtwdis and unlocd with distance marks from
> IENC
> >       └─>
> >         └─>
> >           └─>
> >
> >
> > Best Wulf
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> --
> Hälsningar
>
> Andreas Oxenstierna
> T-Kartor Geospatial AB
> Olof Mohlins väg 12 Kristianstad
> mobile: +46 733 206831
> mailto: ao at t-kartor.se
> http://www.t-kartor.com
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191219/b37632a2/attachment.html>

From even.rouault at spatialys.com  Mon Dec 23 10:52:49 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 23 Dec 2019 19:52:49 +0100
Subject: [gdal-dev] Fwd: Re: [Projects] OSGeo Budget 2020
Message-ID: <2167492.BTN8mzmtpH@even-i700>

Hi,

I had apparently missed the initial email for this request to ask for a 2020 
budget. Do we have specific needs ?

After short discussion with the OSGeo treasurer, it appears that the cost for 
the extended Travis-CI support that were covered through GDAL budget in 2018 
and 2019 will go to a general OSGeo budget line in 2020 (infrastructure or 
so), as they are shared with other projects like PROJ.

Even

----------  Forwarded Message  ----------

Subject: Re: [Projects] OSGeo Budget 2020
Date: lundi 23 décembre 2019, 20:35:20 CET
From: Angelos Tzotsos <gcpp.kalxas at gmail.com>
To: projects at lists.osgeo.org
CC: OSGeo Discussions <discuss at lists.osgeo.org>, OSGeo Board 
<board at lists.osgeo.org>

Hi all,

Please submit your budget requests by Dec 30th so we can start drafting 
the 2020 budget.

Happy holidays,
Angelos

On 12/9/19 9:38 PM, Angelos Tzotsos wrote:
> Dear OSGeo project members and committees,
>
> Over the previous years, OSGeo has been proud to support a growing 
> number of project events, such as code sprints, developer meetings, 
> and user conferences.
>
> OSGeo is reaching out to all committees, including project steering 
> committees, to help plan our budget for 2020.
>
> As in last year, the board is discussing about assigning a starting 
> budget of 2000$ to all graduated projects who have reported to the 
> board the last 12 months (e.g. during the AGM or directly to a board 
> meeting).
>
> For projects with more of a plan (to pursue a specific goal) projects 
> are welcome to send a more detailed request for approval (see detailed 
> budget requests from 2019 e.g. 
> https://wiki.osgeo.org/wiki/GvSIG_Budget_2019)
>
> A good idea is to focus on OSGeo participation, for example attending 
> the AGM or OSGeo code sprint. Also keep in mind OSGeo goals as an 
> organization, (e.g. interoperability goal: CITE compliance or 
> participation developing new standards)
>
> We would like to ask you to help us with budget proposals to assist 
> your project. This will help us set aside a realistic amount of funding.
>
> Please add your project info to the budget draft at:
>
> https://wiki.osgeo.org/wiki/OSGeo_Budget_2020
>
> ideally by Dec 30 ahead of our next board meeting.
>
> When making a budget request please keep in mind the vision and goals 
> of our foundation, along with any obligations you wish to meet.
>
> Thank you.
>
> On behalf of the OSGeo Board,
>
> Angelos
>
>


-- 
Angelos Tzotsos, PhD
Charter Member
Open Source Geospatial Foundation
http://users.ntua.gr/tzotsos

_______________________________________________
Projects mailing list
Projects at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/projects

-----------------------------------------
-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From evert.etienne at sitemark.com  Thu Dec 26 06:26:01 2019
From: evert.etienne at sitemark.com (Evert Etienne (SITEMARK))
Date: Thu, 26 Dec 2019 14:26:01 +0000
Subject: [gdal-dev] GDAL python bindings memory usage
Message-ID: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>

Hi all,

I have a question about memory usage of the python gdal bindings. For some GDAL calls (python or not), we try to optimise the gdal cache. Doing this, I’ve noticed the free RAM decreasing after doing gdal operations. I have been able to narrow it down to the python bindings. Using `memory_profiler` (https://pypi.org/project/memory-profiler/) I get the following:

The first column represents the line number of the code that has been profiled, the second column (Mem usage) the memory usage of the Python interpreter after that line has been executed. The third column (Increment) represents the difference in memory of the current line with respect to the last one. The last column (Line Contents) prints the code that has been profiled.

```
101     65.4 MiB      0.0 MiB               logging.debug(kwargs)
102    203.9 MiB    138.4 MiB               gdal.Warp(temp.name, input_path, **kwargs)
```

It does seem related to the cache because of the following tests, but only partially. I would expect since every file is on disk that these calls do not have any lasting effect on memory usage.

```
98     65.4 MiB      0.0 MiB               gdal.SetCacheMax(0)
99     87.8 MiB     22.4 MiB               gdal.Warp(temp.name, input_path, **kwargs)
```

temp.name is a `tempfile.NamedTemporaryFile('w+’)` (`/var/folders/3t/_j9hh3_907g646cgt8pkkjch0000gn/T/tmpumywovz7`. The passed kwargs are ` {'dstSRS': 'EPSG:3857', 'resampleAlg': 2, 'format': 'gtiff', 'multithread': True, 'warpOptions': ['NUM_THREADS=ALL_CPUS'], 'creationOptions': ['BIGTIFF=YES', 'NUM_THREADS=ALL_CPUS’]}`. The input file is 84.5 MB.

Assigning and deleting the result does not affect the results. They grow bigger but also decrease after deletion. I assume this is the dataset size.

```
    96     65.4 MiB      0.0 MiB               logging.debug(kwargs)
    97    249.8 MiB    184.4 MiB               ds = gdal.Warp(temp.name, input_path, **kwargs)
    98    193.8 MiB      0.0 MiB               del ds
```

Am I overlooking any cause for this memory increase or is there a possibility to clear this?
Am I correct to assume the usage of the gdal python bindings in this way (All files are on disk) should have barely any effect on script memory usage?

Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191226/3d82125a/attachment.html>

From evert.etienne at sitemark.com  Thu Dec 26 06:30:35 2019
From: evert.etienne at sitemark.com (Evert Etienne (SITEMARK))
Date: Thu, 26 Dec 2019 14:30:35 +0000
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
Message-ID: <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>

Using a bigger file (8GB) and a machine with 64GB Ram we can see the increase being higher. For both gdal.Warp and gdal.Translate

```

    97    112.2 MiB      0.0 MiB               logging.debug(kwargs)
    98    691.5 MiB    579.3 MiB               gdal.Warp(temp.name, input_path, **kwargs)
    99    691.5 MiB      0.0 MiB               logging.debug('Compressing image...')
   100   3943.1 MiB   3251.6 MiB               gdal.Translate(output_path, temp.name, creationOptions=copts, callback=progress_logging('Compressing image', one_is_max=True))

 97    112.2 MiB      0.0 MiB               logging.debug(kwargs)
 98    691.5 MiB    579.3 MiB               gdal.Warp(temp.name, input_path, **kwargs)
100   3943.1 MiB   3251.6 MiB               gdal.Translate(output_path, temp.name, creationOptions=copts)

```

On 26 Dec 2019, at 15:26, Evert Etienne (SITEMARK) <evert.etienne at sitemark.com<mailto:evert.etienne at sitemark.com>> wrote:

Hi all,

I have a question about memory usage of the python gdal bindings. For some GDAL calls (python or not), we try to optimise the gdal cache. Doing this, I’ve noticed the free RAM decreasing after doing gdal operations. I have been able to narrow it down to the python bindings. Using `memory_profiler` (https://pypi.org/project/memory-profiler/<https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fpypi.org%2Fproject%2Fmemory-profiler%2F&data=01%7C01%7Cevert.etienne%40sitemark.com%7C341fa1258c3c4f700a4e08d78a0f8e45%7Cfc89adff07ac47008853b7b7e906068e%7C0&sdata=PxqBDpBlLOr8eiUQXw9fSdSfCH8lKnUeLLCbciVMO5E%3D&reserved=0>) I get the following:

The first column represents the line number of the code that has been profiled, the second column (Mem usage) the memory usage of the Python interpreter after that line has been executed. The third column (Increment) represents the difference in memory of the current line with respect to the last one. The last column (Line Contents) prints the code that has been profiled.

```
101     65.4 MiB      0.0 MiB               logging.debug(kwargs)
102    203.9 MiB    138.4 MiB               gdal.Warp(temp.name, input_path, **kwargs)
```

It does seem related to the cache because of the following tests, but only partially. I would expect since every file is on disk that these calls do not have any lasting effect on memory usage.

```
98     65.4 MiB      0.0 MiB               gdal.SetCacheMax(0)
99     87.8 MiB     22.4 MiB               gdal.Warp(temp.name, input_path, **kwargs)
```

temp.name is a `tempfile.NamedTemporaryFile('w+’)` (`/var/folders/3t/_j9hh3_907g646cgt8pkkjch0000gn/T/tmpumywovz7`. The passed kwargs are ` {'dstSRS': 'EPSG:3857', 'resampleAlg': 2, 'format': 'gtiff', 'multithread': True, 'warpOptions': ['NUM_THREADS=ALL_CPUS'], 'creationOptions': ['BIGTIFF=YES', 'NUM_THREADS=ALL_CPUS’]}`. The input file is 84.5 MB.

Assigning and deleting the result does not affect the results. They grow bigger but also decrease after deletion. I assume this is the dataset size.

```
    96     65.4 MiB      0.0 MiB               logging.debug(kwargs)
    97    249.8 MiB    184.4 MiB               ds = gdal.Warp(temp.name, input_path, **kwargs)
    98    193.8 MiB      0.0 MiB               del ds
```

Am I overlooking any cause for this memory increase or is there a possibility to clear this?
Am I correct to assume the usage of the gdal python bindings in this way (All files are on disk) should have barely any effect on script memory usage?

Thanks in advance.
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
https://eur03.safelinks.protection.outlook.com/?url=https%3A%2F%2Flists.osgeo.org%2Fmailman%2Flistinfo%2Fgdal-dev&amp;data=01%7C01%7Cevert.etienne%40sitemark.com%7C341fa1258c3c4f700a4e08d78a0f8e45%7Cfc89adff07ac47008853b7b7e906068e%7C0&amp;sdata=swgZAj2FYOzIEkzJo6%2FlDaeusFh7xslQnAyQnQT1mNU%3D&amp;reserved=0

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191226/e5089e19/attachment-0001.html>

From even.rouault at spatialys.com  Thu Dec 26 07:07:24 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 26 Dec 2019 16:07:24 +0100
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
Message-ID: <3055092.IQcZlfvos9@even-i700>

On jeudi 26 décembre 2019 14:30:35 CET Evert Etienne (SITEMARK) wrote:
> Using a bigger file (8GB) and a machine with 64GB Ram we can see the
> increase being higher. For both gdal.Warp and gdal.Translate

GDAL may use up to GDAL_CACHEMAX memory, plus some other smaller caches. I'm 
not sure how memory_profile monitors memory consumption, but it is possible 
that the apparent virtual memory is not returned to the OS. But if you run 
those commands several times in the same procss, you should hopefully observe 
some ceiling in memory consumption.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From evert.etienne at sitemark.com  Thu Dec 26 10:05:38 2019
From: evert.etienne at sitemark.com (Evert Etienne (SITEMARK))
Date: Thu, 26 Dec 2019 18:05:38 +0000
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <3055092.IQcZlfvos9@even-i700>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
 <3055092.IQcZlfvos9@even-i700>
Message-ID: <8D384E84-7B0B-4651-818B-8D1AC5A20BD4@sitemark.com>

The smaller caches might indeed explain the difference. Also the ceiling is indeed observed.

Do you have any idea why setting `gdal.SetCacheMax(0)` does not clear the memory?
Setting it to 0 should explicitly clear the cache according to https://github.com/OSGeo/gdal/blob/master/gdal/gcore/gdalrasterblock.cpp#L167 but `GetCacheUsed` already reports 0 right after the python call finishes.

Some more extracts of our logfile:
```
Setting GDAL CacheMax to 31111.349609375 MB
…
95 9702.1 MiB 9593.9 MiB gdal.Warp(temp.name, input_path, **kwargs)
97 40839.7 MiB 31137.6 MiB gdal.Translate(output_path, temp.name, creationOptions=copts)
```
We set the CacheMax using the python bindings and we can see the Translate call reaches the maximum amount. Afterwards gdal reports `gdal cache: 0.0/31111.349609375` (Used/max) but the memory usage stays the same.
To explain why this is a problem for us. Afterwards we run gdal2tiles with GDAL_CACHEMAX set to 50% of the free RAM which is very low because the cache from the calls before is seen as not-free or is not freed.

Thanks already for helping me look into this.

Evert

On 26 Dec 2019, at 16:07, Even Rouault <even.rouault at spatialys.com<mailto:even.rouault at spatialys.com>> wrote:

On jeudi 26 décembre 2019 14:30:35 CET Evert Etienne (SITEMARK) wrote:
Using a bigger file (8GB) and a machine with 64GB Ram we can see the
increase being higher. For both gdal.Warp and gdal.Translate

GDAL may use up to GDAL_CACHEMAX memory, plus some other smaller caches. I'm
not sure how memory_profile monitors memory consumption, but it is possible
that the apparent virtual memory is not returned to the OS. But if you run
those commands several times in the same procss, you should hopefully observe
some ceiling in memory consumption.

Even

--
Spatialys - Geospatial professional services
https://eur03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.spatialys.com&amp;data=01%7C01%7Cevert.etienne%40sitemark.com%7Cb0c5f46254fc4bad08ac08d78a15516c%7Cfc89adff07ac47008853b7b7e906068e%7C0&amp;sdata=St%2FX27v2p7nYw2IP2RwKMnH3ghGSJFj8Jfld5%2F%2B%2BYNY%3D&amp;reserved=0

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191226/9801c5b2/attachment.html>

From andrew at aitchison.me.uk  Thu Dec 26 11:21:16 2019
From: andrew at aitchison.me.uk (Andrew C Aitchison)
Date: Thu, 26 Dec 2019 19:21:16 +0000 (GMT)
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <8D384E84-7B0B-4651-818B-8D1AC5A20BD4@sitemark.com>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
 <3055092.IQcZlfvos9@even-i700>
 <8D384E84-7B0B-4651-818B-8D1AC5A20BD4@sitemark.com>
Message-ID: <alpine.DEB.2.21.99999.351.1912261911140.25477@warden.aitchison.me.uk>

On Thu, 26 Dec 2019, Evert Etienne (SITEMARK) wrote:

> The smaller caches might indeed explain the difference. Also the ceiling is indeed observed.
>
> Do you have any idea why setting `gdal.SetCacheMax(0)` does not clear the memory?
> Setting it to 0 should explicitly clear the cache according to
> https://github.com/OSGeo/gdal/blob/master/gdal/gcore/gdalrasterblock.cpp#L167
> but `GetCacheUsed` already reports 0 right after the python call
> finishes.
>
> Some more extracts of our logfile:
> ```
> Setting GDAL CacheMax to 31111.349609375 MB
> â?Š
> 95 9702.1 MiB 9593.9 MiB gdal.Warp(temp.name, input_path, **kwargs)
> 97 40839.7 MiB 31137.6 MiB gdal.Translate(output_path, temp.name, creationOptions=copts)
> ```
> We set the CacheMax using the python bindings and we can see the
> Translate call reaches the maximum amount. Afterwards gdal reports
> `gdal cache: 0.0/31111.349609375` (Used/max) but the memory usage
> stays the same.
> To explain why this is a problem for us. Afterwards we run
> gdal2tiles with GDAL_CACHEMAX set to 50% of the free RAM which is
> very low because the cache from the calls before is seen as not-free
> or is not freed.

How are you measuring free RAM at this point ?

The GDAL cache will be included in the the memory use reported by the
python interpreter, but at least on Linux the system command "free"
also reports the memory used by the file-system cache, which will contain
(the read parts of) the file, until the system decides to use that RAM for something else.
Your tempfile is likely being stored in the filesystem cache.

-- 
Andrew C. Aitchison					Kendal, UK
 			andrew at aitchison.me.uk

From evert.etienne at sitemark.com  Thu Dec 26 13:07:12 2019
From: evert.etienne at sitemark.com (Evert Etienne (SITEMARK))
Date: Thu, 26 Dec 2019 21:07:12 +0000
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <alpine.DEB.2.21.99999.351.1912261911140.25477@warden.aitchison.me.uk>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
 <3055092.IQcZlfvos9@even-i700>
 <8D384E84-7B0B-4651-818B-8D1AC5A20BD4@sitemark.com>
 <alpine.DEB.2.21.99999.351.1912261911140.25477@warden.aitchison.me.uk>
Message-ID: <E33D0CB4-E9AF-41D5-B03F-8347AC74743F@sitemark.com>

I am measuring memory usage using psutil:
Process: `psutil.Process().memory_info().rss` and `psutil.Process().memory_percent()`
General: `psutil.virtual_memory().available`

I do tests both on MacOS and linux.

Any idea about how to investigate the file cache or how to use psutil to check the difference between this file-system cache and other memory usage?
By the way, instead of using a real tempfile but removing it and using `input + ’.tmp’` as output file yields the same behavior.

When calling the gdal calls in a Process, the issues do not appear (3 different approaches)

```
    74    109.5 MiB      0.0 MiB           ctx = multiprocessing.get_context('spawn')
    75    109.5 MiB      0.0 MiB           p = ctx.Process(target=gdalwarp_wrapper, args=(output_path, input_path), kwargs=kwargs)
    76    109.7 MiB      0.1 MiB           p.start()
    77    105.5 MiB      0.0 MiB           p.join()
    78    105.5 MiB      0.0 MiB           ctx = multiprocessing.get_context('fork')
    79    105.5 MiB      0.0 MiB           p = ctx.Process(target=gdalwarp_wrapper, args=(output_path, input_path), kwargs=kwargs)
    80    105.5 MiB      0.0 MiB           p.start()
    81    105.5 MiB      0.0 MiB           p.join()
    82   3750.6 MiB   3645.0 MiB           gdalwarp_wrapper(output_path, input_path, **kwargs)
```

Thanks!

On 26 Dec 2019, at 20:21, Andrew C Aitchison <andrew at aitchison.me.uk<mailto:andrew at aitchison.me.uk>> wrote:

How are you measuring free RAM at this point ?

The GDAL cache will be included in the the memory use reported by the
python interpreter, but at least on Linux the system command "free"
also reports the memory used by the file-system cache, which will contain
(the read parts of) the file, until the system decides to use that RAM for something else.
Your tempfile is likely being stored in the filesystem cache.

--
Andrew C. Aitchison Kendal, UK
andrew at aitchison.me.uk<mailto:andrew at aitchison.me.uk>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191226/4ed75fae/attachment.html>

From info at jakobmiksch.eu  Fri Dec 27 10:22:01 2019
From: info at jakobmiksch.eu (Jakob Miksch)
Date: Fri, 27 Dec 2019 19:22:01 +0100
Subject: [gdal-dev] ogr2ogr: new layer called "SELECT" after SQLITE query
Message-ID: <db4c8802-d61d-8581-d34f-bc7aa791105e@jakobmiksch.eu>

Dear list,

I found a unexpected behavior of the SQLITE dialect. See this example 
where I access ten features of a remote GeoJSON:

ogr2ogr \
   -dialect SQLITE \
   -sql "SELECT * FROM chapters LIMIT 10" \
   -f GPKG output.gpkg \
https://raw.githubusercontent.com/maptime/maptime.github.io/master/_data/chapters.json

The resulting layername with SQLITE dialect is "SELECT". In contrast, 
with OGRSQL dialect, the resulting layername is "chapters" - which is 
more logical to me.

Any ideas why this behavior is different between SQLITE and OGRSQL dialect?

Thanks in advance and best wishes,
Jakob

-- 
Jakob Miksch
www.jakobmiksch.eu

From evert.etienne at sitemark.com  Fri Dec 27 11:15:20 2019
From: evert.etienne at sitemark.com (Evert Etienne (SITEMARK))
Date: Fri, 27 Dec 2019 19:15:20 +0000
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <alpine.DEB.2.21.99999.351.1912271853400.13078@warden.aitchison.me.uk>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
 <3055092.IQcZlfvos9@even-i700>
 <8D384E84-7B0B-4651-818B-8D1AC5A20BD4@sitemark.com>
 <alpine.DEB.2.21.99999.351.1912261911140.25477@warden.aitchison.me.uk>
 <E33D0CB4-E9AF-41D5-B03F-8347AC74743F@sitemark.com>,
 <alpine.DEB.2.21.99999.351.1912271853400.13078@warden.aitchison.me.uk>
Message-ID: <4870c08f-9227-45c7-a82a-9f9e55189621@email.android.com>

The issue is also visible on process level. Do you know if this cache exists in process level and if so, if free can show this as well?

On Dec 27, 2019 20:08, Andrew C Aitchison <andrew at aitchison.me.uk> wrote:
On Thu, 26 Dec 2019, Evert Etienne (SITEMARK) wrote:

> I am measuring memory usage using psutil: Process:
> `psutil.Process().memory_info().rss` and
> `psutil.Process().memory_percent()` General:
> `psutil.virtual_memory().available`
>
> I do tests both on MacOS and linux.
>
> Any idea about how to investigate the file cache or how to use
> psutil to check the difference between this file-system cache and
> other memory usage?

I'm afraid I don't know enough python to help.

On Linux (not sure about MacOS) the command "free" shows this filesystem
cache as "buff/cache".


> By the way, instead of using a real tempfile but removing it and
> using `input + â??.tmpâ??` as output file yields the same behavior.
>
> When calling the gdal calls in a Process, the issues do not appear (3 different approaches)
>
> ```
>    74    109.5 MiB      0.0 MiB           ctx = multiprocessing.get_context('spawn')
>    75    109.5 MiB      0.0 MiB           p = ctx.Process(target=gdalwarp_wrapper, args=(output_path, input_path), kwargs=kwargs)
>    76    109.7 MiB      0.1 MiB           p.start()
>    77    105.5 MiB      0.0 MiB           p.join()
>    78    105.5 MiB      0.0 MiB           ctx = multiprocessing.get_context('fork')
>    79    105.5 MiB      0.0 MiB           p = ctx.Process(target=gdalwarp_wrapper, args=(output_path, input_path), kwargs=kwargs)
>    80    105.5 MiB      0.0 MiB           p.start()
>    81    105.5 MiB      0.0 MiB           p.join()
>    82   3750.6 MiB   3645.0 MiB           gdalwarp_wrapper(output_path, input_path, **kwargs)
> ```
>
> Thanks!
>
> On 26 Dec 2019, at 20:21, Andrew C Aitchison <andrew at aitchison.me.uk<mailto:andrew at aitchison.me.uk>> wrote:
>
> How are you measuring free RAM at this point ?
>
> The GDAL cache will be included in the the memory use reported by
> the python interpreter, but at least on Linux the system command
> "free" also reports the memory used by the file-system cache, which
> will contain (the read parts of) the file, until the system decides
> to use that RAM for something else.  Your tempfile is likely being
> stored in the filesystem cache.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191227/5a3a5dca/attachment-0001.html>

From even.rouault at spatialys.com  Fri Dec 27 11:18:46 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 27 Dec 2019 20:18:46 +0100
Subject: [gdal-dev] ogr2ogr: new layer called "SELECT" after SQLITE query
In-Reply-To: <db4c8802-d61d-8581-d34f-bc7aa791105e@jakobmiksch.eu>
References: <db4c8802-d61d-8581-d34f-bc7aa791105e@jakobmiksch.eu>
Message-ID: <5210266.pMKSOQHXgm@even-i700>

On vendredi 27 décembre 2019 19:22:01 CET Jakob Miksch wrote:
> Dear list,
> 
> I found a unexpected behavior of the SQLITE dialect. See this example
> where I access ten features of a remote GeoJSON:
> 
> ogr2ogr \
>    -dialect SQLITE \
>    -sql "SELECT * FROM chapters LIMIT 10" \
>    -f GPKG output.gpkg \
> https://raw.githubusercontent.com/maptime/maptime.github.io/master/_data/cha
> pters.json
> 
> The resulting layername with SQLITE dialect is "SELECT". In contrast,
> with OGRSQL dialect, the resulting layername is "chapters" - which is
> more logical to me.
> 
> Any ideas why this behavior is different between SQLITE and OGRSQL dialect?

OGRSQL parses the SQL, so it knows the SQL is about selecting in a given 
layer.
In the SQLite case, the SQL is mostly forwarded to SQLite and we don't really 
try if we select from a single layer, or do something more complicated like a 
join etc

Adding "-nln chapers" will make it work as you expect.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From andrew at aitchison.me.uk  Fri Dec 27 11:08:31 2019
From: andrew at aitchison.me.uk (Andrew C Aitchison)
Date: Fri, 27 Dec 2019 19:08:31 +0000 (GMT)
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <E33D0CB4-E9AF-41D5-B03F-8347AC74743F@sitemark.com>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <39E49B8A-A644-4218-AF41-DAF94DD4D9CB@sitemark.com>
 <3055092.IQcZlfvos9@even-i700>
 <8D384E84-7B0B-4651-818B-8D1AC5A20BD4@sitemark.com>
 <alpine.DEB.2.21.99999.351.1912261911140.25477@warden.aitchison.me.uk>
 <E33D0CB4-E9AF-41D5-B03F-8347AC74743F@sitemark.com>
Message-ID: <alpine.DEB.2.21.99999.351.1912271853400.13078@warden.aitchison.me.uk>

On Thu, 26 Dec 2019, Evert Etienne (SITEMARK) wrote:

> I am measuring memory usage using psutil: Process: 
> `psutil.Process().memory_info().rss` and 
> `psutil.Process().memory_percent()` General: 
> `psutil.virtual_memory().available`
>
> I do tests both on MacOS and linux.
>
> Any idea about how to investigate the file cache or how to use
> psutil to check the difference between this file-system cache and
> other memory usage?

I'm afraid I don't know enough python to help.

On Linux (not sure about MacOS) the command "free" shows this filesystem
cache as "buff/cache".


> By the way, instead of using a real tempfile but removing it and
> using `input + â??.tmpâ??` as output file yields the same behavior.
>
> When calling the gdal calls in a Process, the issues do not appear (3 different approaches)
>
> ```
>    74    109.5 MiB      0.0 MiB           ctx = multiprocessing.get_context('spawn')
>    75    109.5 MiB      0.0 MiB           p = ctx.Process(target=gdalwarp_wrapper, args=(output_path, input_path), kwargs=kwargs)
>    76    109.7 MiB      0.1 MiB           p.start()
>    77    105.5 MiB      0.0 MiB           p.join()
>    78    105.5 MiB      0.0 MiB           ctx = multiprocessing.get_context('fork')
>    79    105.5 MiB      0.0 MiB           p = ctx.Process(target=gdalwarp_wrapper, args=(output_path, input_path), kwargs=kwargs)
>    80    105.5 MiB      0.0 MiB           p.start()
>    81    105.5 MiB      0.0 MiB           p.join()
>    82   3750.6 MiB   3645.0 MiB           gdalwarp_wrapper(output_path, input_path, **kwargs)
> ```
>
> Thanks!
>
> On 26 Dec 2019, at 20:21, Andrew C Aitchison <andrew at aitchison.me.uk<mailto:andrew at aitchison.me.uk>> wrote:
>
> How are you measuring free RAM at this point ?
>
> The GDAL cache will be included in the the memory use reported by
> the python interpreter, but at least on Linux the system command
> "free" also reports the memory used by the file-system cache, which
> will contain (the read parts of) the file, until the system decides
> to use that RAM for something else.  Your tempfile is likely being
> stored in the filesystem cache.

From even.rouault at spatialys.com  Fri Dec 27 12:45:05 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 27 Dec 2019 21:45:05 +0100
Subject: [gdal-dev] GDAL python bindings memory usage
In-Reply-To: <4870c08f-9227-45c7-a82a-9f9e55189621@email.android.com>
References: <EB31B19E-1886-4CFB-9290-C081B5E785DE@sitemark.com>
 <alpine.DEB.2.21.99999.351.1912271853400.13078@warden.aitchison.me.uk>
 <4870c08f-9227-45c7-a82a-9f9e55189621@email.android.com>
Message-ID: <6660112.JM74GmeJTS@even-i700>

I question the reliability of memory_profiler

See

Line #    Mem usage    Increment   Line Contents
================================================
    27  112.125 MiB  112.125 MiB   @profile
    28                             def test2():
    29  112.676 MiB    0.551 MiB       gdal.SetCacheMax(1000 * 1024 * 1024)
    30 1101.855 MiB  989.180 MiB       gdal.Translate('/tmp/out.tif', 'byte.tif', options = '-co TILED=YES -outsize 100000 10000')
    31 1101.855 MiB    0.000 MiB       dummy = 1

vs

Line #    Mem usage    Increment   Line Contents
================================================
    28  109.336 MiB  109.336 MiB   @profile
    29                             def test2():
    30  109.336 MiB    0.000 MiB       gdal.SetCacheMax(1000 * 1024 * 1024)
    31 1098.309 MiB  988.973 MiB       gdal.Translate('/tmp/out.tif', 'byte.tif', options = '-co TILED=YES -outsize 100000 10000')
    32 1098.309 MiB    0.000 MiB       h = ctypes.cdll.LoadLibrary(None)
    33 1098.309 MiB    0.000 MiB       h.malloc.argtypes = [ctypes.c_size_t]
    34 1098.309 MiB    0.000 MiB       h.malloc.restype = ctypes.c_void_p
    35 1098.309 MiB    0.000 MiB       h.free.argtypes = [ctypes.c_void_p]
    36 1098.309 MiB    0.000 MiB       h.free.restype = None
    37 1098.309 MiB    0.000 MiB       size = 1024 * 1024
    38 1098.309 MiB    0.000 MiB       x = h.malloc(size)
    39  117.422 MiB    0.000 MiB       h.free(x)
    40  117.422 MiB    0.000 MiB       dummy = 1

vs

Line #    Mem usage    Increment   Line Contents
================================================
    28  111.305 MiB  111.305 MiB   @profile
    29                             def test2():
    30  111.852 MiB    0.547 MiB       gdal.SetCacheMax(1000 * 1024 * 1024)
    31  188.504 MiB   76.652 MiB       gdal.Translate('/tmp/out.tif', 'byte.tif', options = '-co TILED=YES -outsize 100000 10000')
    32  188.504 MiB    0.000 MiB       h = ctypes.cdll.LoadLibrary(None)
    33  188.504 MiB    0.000 MiB       h.free.argtypes = [ctypes.c_void_p]
    34  188.504 MiB    0.000 MiB       h.free.restype = None
    35  188.504 MiB    0.000 MiB       h.free(None)
    36  188.504 MiB    0.000 MiB       dummy = 1

vs

Line #    Mem usage    Increment   Line Contents
================================================
    28  112.164 MiB  112.164 MiB   @profile
    29                             def test2():
    30  112.164 MiB    0.000 MiB       gdal.SetCacheMax(1000 * 1024 * 1024)
    31  112.770 MiB    0.605 MiB       h = ctypes.cdll.LoadLibrary(None)
    32  112.770 MiB    0.000 MiB       h.free.argtypes = [ctypes.c_void_p]
    33  112.770 MiB    0.000 MiB       h.free.restype = None
    34 1101.918 MiB  989.148 MiB       gdal.Translate('/tmp/out.tif', 'byte.tif', options = '-co TILED=YES -outsize 100000 10000')
    35 1101.918 MiB    0.000 MiB       h.free(None)
    36 1101.918 MiB    0.000 MiB       dummy = 1

That doesn't make much sense to me.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From rlelamer at hotmail.fr  Sun Dec 29 07:47:02 2019
From: rlelamer at hotmail.fr (LE LAMER Romain)
Date: Sun, 29 Dec 2019 15:47:02 +0000
Subject: [gdal-dev] How to convert png color to png/tiff black and white
Message-ID: <VI1P193MB0509DBE334047D264B28721DB6240@VI1P193MB0509.EURP193.PROD.OUTLOOK.COM>

Hi,

I need to convert 524 288 color png tiles to black and white png.

=> The lands always have the 2 colors RGB (RGBA?) 59,89,95,255 and / or 60,89,96,255.
=> The sea always has the colors RGB 109,178,200,255 / 138,193,212,255 and 161,205,220,255.

Some tiles contain only land, others only sea and still others contain land and at least 1 color of the sea ...

I use gdal_translate to georeference and assign a projection to each tile (via script) with the following command (and it works perfectly):
gdal_translate -a_srs EPSG: 4326 -a_ullr <ulx> <uly> <lrx> <lry> input.png output.tiff

I have read and reread, in every way, the gdal_translate help with the args -b and -mask and I don't understand how to use it ...

I need all the sea colors to always be Black and all the lands colors to be White.
(I polygonize each tile afterwards)

How can I do this via gdal_translate or other gdal program?

Thanks for your help


PS:
What gdalinfo gives me for a random tile (original png)
gdalinfo map_11_0_309.png
Driver: PNG/Portable Network Graphics
Files: map_11_0_309.png
Size is 256, 256
Coordinate System is `'
Corner Coordinates:
Upper Left  (    0.0,    0.0)
Lower Left  (    0.0,  256.0)
Upper Right (  256.0,    0.0)
Lower Right (  256.0,  256.0)
Center      (  128.0,  128.0)
Band 1 Block=256x1 Type=Byte, ColorInterp=Palette
  Image Structure Metadata:
    NBITS=2
  Color Table (RGB with 4 entries)
    0: 60,89,96,255
    1: 109,178,200,255
    2: 138,193,212,255
    3: 161,205,220,255

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191229/47c55bde/attachment.html>

From momtchil at momtchev.com  Sun Dec 29 10:13:02 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 19:13:02 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL 2.1.2
	vs 3.x
Message-ID: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>


     Hello,


     Hopefully the attached file will pass through.


     I was stunned to discover a difference in the values of a GeoTIFF 
file when read with GDAL 2.1.2 (official Debian stretch build) and GDAL 
3.1.0 (official Docker image). It happens through the API and it happens 
with gdallocationinfo.

     Most of the values are identical except a few. The 2.1.2 result is 
the one I expected.

     I concede that the GeoTIFF is less than then ideal with the 
projection being random as I don't use it, but this happens when reading 
it as a raster image:

Docker 3.1.0:

root at d13c4572b671:# gdallocationinfo 2.tiff 9 0
Report:
   Location: (9P,0L)
   Band 1:
     Value: 24
   Band 2:
     Value: 255
root at d13c4572b671:# gdallocationinfo 2.tiff 10 0
Report:
   Location: (10P,0L)
   Band 1:
     Value: 31
   Band 2:
     Value: 163


GDAL 2.1.2 Debian build:

mmom at sokol$ gdallocationinfo 2.tiff 9 0
Report:
   Location: (9P,0L)
   Band 1:
     Value: 16
   Band 2:
     Value: 130
mmom at sokol:$ gdallocationinfo 2.tiff 10 0
Report:
   Location: (10P,0L)
   Band 1:
     Value: 14
   Band 2:
     Value: 163


-- 
Momtchil Momtchev <momtchil at momtchev.com>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2.tiff
Type: image/tiff
Size: 4395 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20191229/9ca48149/attachment.tiff>

From even.rouault at spatialys.com  Sun Dec 29 10:27:43 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 29 Dec 2019 19:27:43 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
	2.1.2 vs 3.x
In-Reply-To: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
Message-ID: <1687596.WVjxI0qyp9@even-i700>

>      I was stunned to discover a difference in the values of a GeoTIFF
> file when read with GDAL 2.1.2 (official Debian stretch build) and GDAL
> 3.1.0 (official Docker image)

Which Docker image exactly ? With the ones of
https://github.com/OSGeo/gdal/tree/master/gdal/docker , I get the same result 
as with 2.1.2:

$ docker run --rm -v /home:/home osgeo/gdal gdalinfo --version
GDAL 3.1.0dev-7652d752281951e989687c0270ce1c2d9b4219dd, released 2019/12/29

$ docker run --rm -v /home:/home osgeo/gdal gdallocationinfo $PWD/2.tiff 9 0
Report:
  Location: (9P,0L)
  Band 1:
    Value: 16
  Band 2:
    Value: 130


$ docker run --rm -v /home:/home osgeo/gdal gdallocationinfo $PWD/2.tiff 10 0
Report:
  Location: (10P,0L)
  Band 1:
    Value: 14
  Band 2:
    Value: 163

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From momtchil at momtchev.com  Sun Dec 29 11:59:52 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 20:59:52 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <1687596.WVjxI0qyp9@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <1687596.WVjxI0qyp9@even-i700>
Message-ID: <11aeb089-ad47-a408-f6e5-526b32564e48@momtchev.com>


     I get incorrect results with both of these images on 2 different 
machines both with AMD CPUs:

osgeo/gdal          latest                 7e049ed0255b        18 hours 
ago        1.15GB
osgeo/gdal          alpine-normal-v2.4.1   8ab6c3ea733b        8 months 
ago        154MB


     Those same docker images give correct results on an Intel CPU.

     I also tried GDAL 2.4.2 on OS X which is of course an Intel CPU and 
I get correct results, too.

     Is it possible that this is a compiler issue? Anyone else that can 
test this on an AMD CPU? Mine are old Phenom II X4 965s.

     2.1.2 is correct on both CPUs.


On 29/12/2019 19:27, Even Rouault wrote:
>>       I was stunned to discover a difference in the values of a GeoTIFF
>> file when read with GDAL 2.1.2 (official Debian stretch build) and GDAL
>> 3.1.0 (official Docker image)
> Which Docker image exactly ? With the ones of
> https://github.com/OSGeo/gdal/tree/master/gdal/docker , I get the same result
> as with 2.1.2:
>
> $ docker run --rm -v /home:/home osgeo/gdal gdalinfo --version
> GDAL 3.1.0dev-7652d752281951e989687c0270ce1c2d9b4219dd, released 2019/12/29
>
> $ docker run --rm -v /home:/home osgeo/gdal gdallocationinfo $PWD/2.tiff 9 0
> Report:
>    Location: (9P,0L)
>    Band 1:
>      Value: 16
>    Band 2:
>      Value: 130
>
>
> $ docker run --rm -v /home:/home osgeo/gdal gdallocationinfo $PWD/2.tiff 10 0
> Report:
>    Location: (10P,0L)
>    Band 1:
>      Value: 14
>    Band 2:
>      Value: 163
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From even.rouault at spatialys.com  Sun Dec 29 12:51:08 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 29 Dec 2019 21:51:08 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
	2.1.2 vs 3.x
In-Reply-To: <11aeb089-ad47-a408-f6e5-526b32564e48@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <1687596.WVjxI0qyp9@even-i700>
 <11aeb089-ad47-a408-f6e5-526b32564e48@momtchev.com>
Message-ID: <13391595.3zFs62ujMU@even-i700>

>      Is it possible that this is a compiler issue? Anyone else that can
> test this on an AMD CPU? Mine are old Phenom II X4 965s.

Perhaps rather a runtime issue. I suspect this is related to a SSSE3 
optimization that has been added in GDAL 2.2 that is used in this use case 
(unpacking of byte buffer with a 2 byte stride to packed buffer)

>From what I found on the net, I think this CPU doesn't support the SSSE3 
instruction set (SSSE3 with three S, not to be confused with SSE3...)
Can you check the following ?
cat /proc/cpuinfo | grep ssse3

What is strange is that GDAL does have a runtime check to detect if SSSE3 is 
available, so I'm not sure why you would get that issue. Unless that Docker 
would wrongly expose SSSE3, but Docker is not a VM technology so it shouldn't 
mess up with CPU capability discoveries. This is weird.

Can you try the following ?

docker run --rm osgeo/gdal su -c "apt install -y cpuid; cpuid" | grep SSSE3

In a DEBUG build of GDAL, you could disable at runtime the SSSE3 optimization 
by defining the environment variable/configuration option GDAL_USE_SSSE3 to 
NO, but this will not work on the release builds available on Docker.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From momtchil at momtchev.com  Sun Dec 29 13:04:23 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 22:04:23 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <13391595.3zFs62ujMU@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <1687596.WVjxI0qyp9@even-i700>
 <11aeb089-ad47-a408-f6e5-526b32564e48@momtchev.com>
 <13391595.3zFs62ujMU@even-i700>
Message-ID: <c9bfee51-f33f-9b5c-1cd6-65f4372788cd@momtchev.com>


     That was my first idea too so I rebuilt without SSE, SSE3 and AVX 
and it is still the same. I haven't rebuilt libgeotiff tho.

Here is the output of cpuid

mmom at mmom-workstation:~$ docker run --rm osgeo/gdal su -c "apt install 
-y cpuid; cpuid" | grep SSSE3
       SSSE3 extensions                        = false
       SSSE3/SSE5 opcode set disable = false
       SSSE3 extensions                        = false
       SSSE3/SSE5 opcode set disable = false
       SSSE3 extensions                        = false
       SSSE3/SSE5 opcode set disable = false
       SSSE3 extensions                        = false
       SSSE3/SSE5 opcode set disable = false

And here are my cpu flags from cpuinfo

flags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca 
cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt 
pdpe1gb rdtscp lm 3dnowext 3dnow constant_tsc rep_good nopl nonstop_tsc 
cpuid extd_apicid pni monitor cx16 popcnt lahf_lm cmp_legacy svm extapic 
cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt 
hw_pstate vmmcall npt lbrv svm_lock nrip_save

No SSE3 on Phenom X4, only SSE/SSE2.


On 29/12/2019 21:51, Even Rouault wrote:
>>       Is it possible that this is a compiler issue? Anyone else that can
>> test this on an AMD CPU? Mine are old Phenom II X4 965s.
> Perhaps rather a runtime issue. I suspect this is related to a SSSE3
> optimization that has been added in GDAL 2.2 that is used in this use case
> (unpacking of byte buffer with a 2 byte stride to packed buffer)
>
>  From what I found on the net, I think this CPU doesn't support the SSSE3
> instruction set (SSSE3 with three S, not to be confused with SSE3...)
> Can you check the following ?
> cat /proc/cpuinfo | grep ssse3
>
> What is strange is that GDAL does have a runtime check to detect if SSSE3 is
> available, so I'm not sure why you would get that issue. Unless that Docker
> would wrongly expose SSSE3, but Docker is not a VM technology so it shouldn't
> mess up with CPU capability discoveries. This is weird.
>
> Can you try the following ?
>
> docker run --rm osgeo/gdal su -c "apt install -y cpuid; cpuid" | grep SSSE3
>
> In a DEBUG build of GDAL, you could disable at runtime the SSSE3 optimization
> by defining the environment variable/configuration option GDAL_USE_SSSE3 to
> NO, but this will not work on the release builds available on Docker.
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From momtchil at momtchev.com  Sun Dec 29 13:15:02 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 22:15:02 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <13391595.3zFs62ujMU@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <1687596.WVjxI0qyp9@even-i700>
 <11aeb089-ad47-a408-f6e5-526b32564e48@momtchev.com>
 <13391595.3zFs62ujMU@even-i700>
Message-ID: <d509c389-3023-d545-0d5f-069af7a0f04f@momtchev.com>


     I get the same wrong results with and without Docker, with and 
without the SSE/SSE3/AVX when using the configure script. I also tried 
removing -O2. Is the SSE3 unpacking in GDAL or in libgeotiff?

On 29/12/2019 21:51, Even Rouault wrote:
>>       Is it possible that this is a compiler issue? Anyone else that can
>> test this on an AMD CPU? Mine are old Phenom II X4 965s.
> Perhaps rather a runtime issue. I suspect this is related to a SSSE3
> optimization that has been added in GDAL 2.2 that is used in this use case
> (unpacking of byte buffer with a 2 byte stride to packed buffer)
>
>  From what I found on the net, I think this CPU doesn't support the SSSE3
> instruction set (SSSE3 with three S, not to be confused with SSE3...)
> Can you check the following ?
> cat /proc/cpuinfo | grep ssse3
>
> What is strange is that GDAL does have a runtime check to detect if SSSE3 is
> available, so I'm not sure why you would get that issue. Unless that Docker
> would wrongly expose SSSE3, but Docker is not a VM technology so it shouldn't
> mess up with CPU capability discoveries. This is weird.
>
> Can you try the following ?
>
> docker run --rm osgeo/gdal su -c "apt install -y cpuid; cpuid" | grep SSSE3
>
> In a DEBUG build of GDAL, you could disable at runtime the SSSE3 optimization
> by defining the environment variable/configuration option GDAL_USE_SSSE3 to
> NO, but this will not work on the release builds available on Docker.
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From even.rouault at spatialys.com  Sun Dec 29 13:18:08 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 29 Dec 2019 22:18:08 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
	2.1.2 vs 3.x
In-Reply-To: <c9bfee51-f33f-9b5c-1cd6-65f4372788cd@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <13391595.3zFs62ujMU@even-i700>
 <c9bfee51-f33f-9b5c-1cd6-65f4372788cd@momtchev.com>
Message-ID: <2054717.MMUpikYRpk@even-i700>

On dimanche 29 décembre 2019 22:04:23 CET Momtchil Momtchev wrote:
>      That was my first idea too so I rebuilt without SSE,

--without-sse will have no effect on a 64-bit build on the part of the code 
I'm suspecting (it only affects gdal_grid). As all Intel/AMD CPUs supporting 
64-bit have SSE and SSE2, SSE2 optimizations are unconditionally enabled.

In gcore/rasterio.cpp, can you change line 2869

#if (defined(__x86_64) || defined(_M_X64)) &&  !(defined(__GNUC__) && __GNUC__ 
< 4)

to

#if 0

to remove any SSE2 (and SSSE3) optimization ?

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From momtchil at momtchev.com  Sun Dec 29 13:36:24 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 22:36:24 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <2054717.MMUpikYRpk@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <13391595.3zFs62ujMU@even-i700>
 <c9bfee51-f33f-9b5c-1cd6-65f4372788cd@momtchev.com>
 <2054717.MMUpikYRpk@even-i700>
Message-ID: <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>


     Disabling HAVE_SSSE3_AT_COMPILE_TIME had no effect, but after 
short-circuiting the #ifdef I got a correct result.

On 29/12/2019 22:18, Even Rouault wrote:
> On dimanche 29 décembre 2019 22:04:23 CET Momtchil Momtchev wrote:
>>       That was my first idea too so I rebuilt without SSE,
> --without-sse will have no effect on a 64-bit build on the part of the code
> I'm suspecting (it only affects gdal_grid). As all Intel/AMD CPUs supporting
> 64-bit have SSE and SSE2, SSE2 optimizations are unconditionally enabled.
>
> In gcore/rasterio.cpp, can you change line 2869
>
> #if (defined(__x86_64) || defined(_M_X64)) &&  !(defined(__GNUC__) && __GNUC__
> < 4)
>
> to
>
> #if 0
>
> to remove any SSE2 (and SSSE3) optimization ?
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From even.rouault at spatialys.com  Sun Dec 29 13:57:29 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 29 Dec 2019 22:57:29 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
	2.1.2 vs 3.x
In-Reply-To: <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <2054717.MMUpikYRpk@even-i700>
 <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>
Message-ID: <4689281.9M2WixvCNZ@even-i700>

On dimanche 29 décembre 2019 22:36:24 CET Momtchil Momtchev wrote:
>      Disabling HAVE_SSSE3_AT_COMPILE_TIME had no effect,

Make sure you run "make clean" after running ./configure

> but after
> short-circuiting the #ifdef I got a correct result.

Hum so it seems that the SSSE3 detection doesn't work properly. 

Can you :

1. undo your code changes

2. modify port/cpl_cpu_features.cpp at line 98 to replace the code of the 
CPLDetectSSE3() function by

static inline bool CPLDetectSSE3()
{
    int cpuinfo[4] = { 0, 0, 0, 0 };
    CPL_CPUID(0, cpuinfo);
    if( cpuinfo[REG_EAX] <= 0 )
        return false;
    CPL_CPUID(1, cpuinfo);
    return (cpuinfo[REG_ECX] & (1 << CPUID_SSSE3_ECX_BIT)) != 0;
}

(note: this function should really be called CPLDetectSSSE3 ... missing S... 
but that doesn't matter)

3. modify port/cpl_cpu_features.h to add just after line 47 "#if __SSSE3__" a 
new line with "dummy" as content. Normally this shouldn't be compiled... but 
this is just to make sure the compiler doesn't define SSSE3 as available 
unconditionnally at runtime.

4. run configure again *without* disabling ssse3
5. make clean
6. make (possibly with -j something)


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From momtchil at momtchev.com  Sun Dec 29 14:22:16 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 23:22:16 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <4689281.9M2WixvCNZ@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <2054717.MMUpikYRpk@even-i700>
 <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>
 <4689281.9M2WixvCNZ@even-i700>
Message-ID: <820917a8-f99a-aa89-653c-f876ed2e6718@momtchev.com>


     I did make distclean after each configure change.


     I found some other reports about SSE problems on Phenom II 9xx.

     This is the exact part number: HDZ965FBK4DGM

http://www.cpu-world.com/CPUs/K10/AMD-Phenom%20II%20X4%20965%20Black%20Edition%20-%20HDZ965FBK4DGM%20(HDZ965FBGMBOX).html

     It is a CPU that claims SSE3 support but Linux does not recognize 
it as such.

     Both the machines that give incorrect results have exactly this 
part number.


     Let me me modify the SSE3 detection code.


On 29/12/2019 22:57, Even Rouault wrote:
> On dimanche 29 décembre 2019 22:36:24 CET Momtchil Momtchev wrote:
>>       Disabling HAVE_SSSE3_AT_COMPILE_TIME had no effect,
> Make sure you run "make clean" after running ./configure
>
>> but after
>> short-circuiting the #ifdef I got a correct result.
> Hum so it seems that the SSSE3 detection doesn't work properly.
>
> Can you :
>
> 1. undo your code changes
>
> 2. modify port/cpl_cpu_features.cpp at line 98 to replace the code of the
> CPLDetectSSE3() function by
>
> static inline bool CPLDetectSSE3()
> {
>      int cpuinfo[4] = { 0, 0, 0, 0 };
>      CPL_CPUID(0, cpuinfo);
>      if( cpuinfo[REG_EAX] <= 0 )
>          return false;
>      CPL_CPUID(1, cpuinfo);
>      return (cpuinfo[REG_ECX] & (1 << CPUID_SSSE3_ECX_BIT)) != 0;
> }
>
> (note: this function should really be called CPLDetectSSSE3 ... missing S...
> but that doesn't matter)
>
> 3. modify port/cpl_cpu_features.h to add just after line 47 "#if __SSSE3__" a
> new line with "dummy" as content. Normally this shouldn't be compiled... but
> this is just to make sure the compiler doesn't define SSSE3 as available
> unconditionnally at runtime.
>
> 4. run configure again *without* disabling ssse3
> 5. make clean
> 6. make (possibly with -j something)
>
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From momtchil at momtchev.com  Sun Dec 29 14:30:01 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 23:30:01 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <4689281.9M2WixvCNZ@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <2054717.MMUpikYRpk@even-i700>
 <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>
 <4689281.9M2WixvCNZ@even-i700>
Message-ID: <92986e63-881d-a6f9-985d-b35ebafcd009@momtchev.com>


     Yes, in fact, this is exactly on of those CPUs that have SSE3 but 
not SSSE3.


On 29/12/2019 22:57, Even Rouault wrote:
>
> (note: this function should really be called CPLDetectSSSE3 ... missing S...
> but that doesn't matter)
>
>
> Momtchil Momtchev <momtchil at momtchev.com>

From momtchil at momtchev.com  Sun Dec 29 14:53:14 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 23:53:14 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <d509c389-3023-d545-0d5f-069af7a0f04f@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <1687596.WVjxI0qyp9@even-i700>
 <11aeb089-ad47-a408-f6e5-526b32564e48@momtchev.com>
 <13391595.3zFs62ujMU@even-i700>
 <d509c389-3023-d545-0d5f-069af7a0f04f@momtchev.com>
Message-ID: <c32b0bf1-0566-76ea-79f3-91ddbfb23257@momtchev.com>


     I recompiled with the modified CPU detection, the SSE3 syntax error 
and with the default configure options (after a distclean) and I get the 
_incorrect_ result.


On 29/12/2019 22:15, Momtchil Momtchev wrote:
>
>     I get the same wrong results with and without Docker, with and 
> without the SSE/SSE3/AVX when using the configure script. I also tried 
> removing -O2. Is the SSE3 unpacking in GDAL or in libgeotiff?
>
> On 29/12/2019 21:51, Even Rouault wrote:
>>>       Is it possible that this is a compiler issue? Anyone else that 
>>> can
>>> test this on an AMD CPU? Mine are old Phenom II X4 965s.
>> Perhaps rather a runtime issue. I suspect this is related to a SSSE3
>> optimization that has been added in GDAL 2.2 that is used in this use 
>> case
>> (unpacking of byte buffer with a 2 byte stride to packed buffer)
>>
>>  From what I found on the net, I think this CPU doesn't support the 
>> SSSE3
>> instruction set (SSSE3 with three S, not to be confused with SSE3...)
>> Can you check the following ?
>> cat /proc/cpuinfo | grep ssse3
>>
>> What is strange is that GDAL does have a runtime check to detect if 
>> SSSE3 is
>> available, so I'm not sure why you would get that issue. Unless that 
>> Docker
>> would wrongly expose SSSE3, but Docker is not a VM technology so it 
>> shouldn't
>> mess up with CPU capability discoveries. This is weird.
>>
>> Can you try the following ?
>>
>> docker run --rm osgeo/gdal su -c "apt install -y cpuid; cpuid" | grep 
>> SSSE3
>>
>> In a DEBUG build of GDAL, you could disable at runtime the SSSE3 
>> optimization
>> by defining the environment variable/configuration option 
>> GDAL_USE_SSSE3 to
>> NO, but this will not work on the release builds available on Docker.
>>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From momtchil at momtchev.com  Sun Dec 29 14:59:12 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Sun, 29 Dec 2019 23:59:12 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <4689281.9M2WixvCNZ@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <2054717.MMUpikYRpk@even-i700>
 <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>
 <4689281.9M2WixvCNZ@even-i700>
Message-ID: <a9302f71-acf5-4349-256b-2d7d04ef028e@momtchev.com>


     Here is the cpuid output


On 29/12/2019 22:57, Even Rouault wrote:
> On dimanche 29 décembre 2019 22:36:24 CET Momtchil Momtchev wrote:
>>       Disabling HAVE_SSSE3_AT_COMPILE_TIME had no effect,
> Make sure you run "make clean" after running ./configure
>
>> but after
>> short-circuiting the #ifdef I got a correct result.
> Hum so it seems that the SSSE3 detection doesn't work properly.
>
> Can you :
>
> 1. undo your code changes
>
> 2. modify port/cpl_cpu_features.cpp at line 98 to replace the code of the
> CPLDetectSSE3() function by
>
> static inline bool CPLDetectSSE3()
> {
>      int cpuinfo[4] = { 0, 0, 0, 0 };
>      CPL_CPUID(0, cpuinfo);
>      if( cpuinfo[REG_EAX] <= 0 )
>          return false;
>      CPL_CPUID(1, cpuinfo);
>      return (cpuinfo[REG_ECX] & (1 << CPUID_SSSE3_ECX_BIT)) != 0;
> }
>
> (note: this function should really be called CPLDetectSSSE3 ... missing S...
> but that doesn't matter)
>
> 3. modify port/cpl_cpu_features.h to add just after line 47 "#if __SSSE3__" a
> new line with "dummy" as content. Normally this shouldn't be compiled... but
> this is just to make sure the compiler doesn't define SSSE3 as available
> unconditionnally at runtime.
>
> 4. run configure again *without* disabling ssse3
> 5. make clean
> 6. make (possibly with -j something)
>
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>

-------------- next part --------------
CPU 0:
   vendor_id = "AuthenticAMD"
   version information (1/eax):
      processor type  = primary processor (0)
      family          = Intel Pentium 4/Pentium D/Pentium Extreme Edition/Celeron/Xeon/Xeon MP/Itanium2, AMD Athlon 64/Athlon XP-M/Opteron/Sempron/Turion (15)
      model           = 0x4 (4)
      stepping id     = 0x3 (3)
      extended family = 0x1 (1)
      extended model  = 0x0 (0)
      (simple synth)  = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   miscellaneous (1/ebx):
      process local APIC physical ID = 0x0 (0)
      cpu count                      = 0x4 (4)
      CLFLUSH line size              = 0x8 (8)
      brand index                    = 0x0 (0)
   brand id = 0x00 (0): unknown
   feature information (1/edx):
      x87 FPU on chip                        = true
      VME: virtual-8086 mode enhancement     = true
      DE: debugging extensions               = true
      PSE: page size extensions              = true
      TSC: time stamp counter                = true
      RDMSR and WRMSR support                = true
      PAE: physical address extensions       = true
      MCE: machine check exception           = true
      CMPXCHG8B inst.                        = true
      APIC on chip                           = true
      SYSENTER and SYSEXIT                   = true
      MTRR: memory type range registers      = true
      PTE global bit                         = true
      MCA: machine check architecture        = true
      CMOV: conditional move/compare instr   = true
      PAT: page attribute table              = true
      PSE-36: page size extension            = true
      PSN: processor serial number           = false
      CLFLUSH instruction                    = true
      DS: debug store                        = false
      ACPI: thermal monitor and clock ctrl   = false
      MMX Technology                         = true
      FXSAVE/FXRSTOR                         = true
      SSE extensions                         = true
      SSE2 extensions                        = true
      SS: self snoop                         = false
      hyper-threading / multi-core supported = true
      TM: therm. monitor                     = false
      IA64                                   = false
      PBE: pending break event               = false
   feature information (1/ecx):
      PNI/SSE3: Prescott New Instructions     = true
      PCLMULDQ instruction                    = false
      DTES64: 64-bit debug store              = false
      MONITOR/MWAIT                           = true
      CPL-qualified debug store               = false
      VMX: virtual machine extensions         = false
      SMX: safer mode extensions              = false
      Enhanced Intel SpeedStep Technology     = false
      TM2: thermal monitor 2                  = false
      SSSE3 extensions                        = false
      context ID: adaptive or shared L1 data  = false
      SDBG: IA32_DEBUG_INTERFACE              = false
      FMA instruction                         = false
      CMPXCHG16B instruction                  = true
      xTPR disable                            = false
      PDCM: perfmon and debug                 = false
      PCID: process context identifiers       = false
      DCA: direct cache access                = false
      SSE4.1 extensions                       = false
      SSE4.2 extensions                       = false
      x2APIC: extended xAPIC support          = false
      MOVBE instruction                       = false
      POPCNT instruction                      = true
      time stamp counter deadline             = false
      AES instruction                         = false
      XSAVE/XSTOR states                      = false
      OS-enabled XSAVE/XSTOR                  = false
      AVX: advanced vector extensions         = false
      F16C half-precision convert instruction = false
      RDRAND instruction                      = false
      hypervisor guest status                 = false
   cache and TLB information (2):
   processor serial number: 0010-0F43-0000-0000-0000-0000
   MONITOR/MWAIT (5):
      smallest monitor-line size (bytes)       = 0x40 (64)
      largest monitor-line size (bytes)        = 0x40 (64)
      enum of Monitor-MWAIT exts supported     = true
      supports intrs as break-event for MWAIT  = true
      number of C0 sub C-states using MWAIT    = 0x0 (0)
      number of C1 sub C-states using MWAIT    = 0x0 (0)
      number of C2 sub C-states using MWAIT    = 0x0 (0)
      number of C3 sub C-states using MWAIT    = 0x0 (0)
      number of C4 sub C-states using MWAIT    = 0x0 (0)
      number of C5 sub C-states using MWAIT    = 0x0 (0)
      number of C6 sub C-states using MWAIT    = 0x0 (0)
      number of C7 sub C-states using MWAIT    = 0x0 (0)
   extended processor signature (0x80000001/eax):
      family/generation = AMD Athlon 64/Opteron/Sempron/Turion (15)
      model             = 0x4 (4)
      stepping id       = 0x3 (3)
      extended family   = 0x1 (1)
      extended model    = 0x0 (0)
      (simple synth) = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   extended feature flags (0x80000001/edx):
      x87 FPU on chip                       = true
      virtual-8086 mode enhancement         = true
      debugging extensions                  = true
      page size extensions                  = true
      time stamp counter                    = true
      RDMSR and WRMSR support               = true
      physical address extensions           = true
      machine check exception               = true
      CMPXCHG8B inst.                       = true
      APIC on chip                          = true
      SYSCALL and SYSRET instructions       = true
      memory type range registers           = true
      global paging extension               = true
      machine check architecture            = true
      conditional move/compare instruction  = true
      page attribute table                  = true
      page size extension                   = true
      multiprocessing capable               = false
      no-execute page protection            = true
      AMD multimedia instruction extensions = true
      MMX Technology                        = true
      FXSAVE/FXRSTOR                        = true
      SSE extensions                        = true
      1-GB large page support               = true
      RDTSCP                                = true
      long mode (AA-64)                     = true
      3DNow! instruction extensions         = true
      3DNow! instructions                   = true
   extended brand id (0x80000001/ebx):
      raw          = 0x10001c16 (268442646)
      BrandId      = 0x1c16 (7190)
      str1         = 0x3 (3)
      str2         = 0x6 (6)
      PartialModel = 0x41 (65)
      PG           = 0x0 (0)
      PkgType      = 0x1 (1)
   AMD feature flags (0x80000001/ecx):
      LAHF/SAHF supported in 64-bit mode     = true
      CMP Legacy                             = true
      SVM: secure virtual machine            = true
      extended APIC space                    = true
      AltMovCr8                              = true
      LZCNT advanced bit manipulation        = true
      SSE4A support                          = true
      misaligned SSE mode                    = true
      3DNow! PREFETCH/PREFETCHW instructions = true
      OS visible workaround                  = true
      instruction based sampling             = true
      XOP support                            = false
      SKINIT/STGI support                    = true
      watchdog timer support                 = true
      lightweight profiling support          = false
      4-operand FMA instruction              = false
      TCE: translation cache extension       = false
      NodeId MSR C001100C                    = false
      TBM support                            = false
      topology extensions                    = false
      core performance counter extensions    = false
      data breakpoint extension              = false
      performance time-stamp counter support = false
      performance counter extensions         = false
      MWAITX/MONITORX supported              = false
   brand = "AMD Phenom(tm) II X4 965 Processor"
   L1 TLB/cache information: 2M/4M pages & L1 TLB (0x80000005/eax):
      instruction # entries     = 0x10 (16)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 TLB/cache information: 4K pages & L1 TLB (0x80000005/ebx):
      instruction # entries     = 0x20 (32)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 data cache information (0x80000005/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L1 instruction cache information (0x80000005/edx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L2 TLB/cache information: 2M/4M pages & L2 TLB (0x80000006/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x80 (128)
      data associativity        = 2-way (2)
   L2 TLB/cache information: 4K pages & L2 TLB (0x80000006/ebx):
      instruction # entries     = 0x200 (512)
      instruction associativity = 4-way (4)
      data # entries            = 0x200 (512)
      data associativity        = 4-way (4)
   L2 unified cache information (0x80000006/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 16-way (8)
      size (KB)         = 0x200 (512)
   L3 cache information (0x80000006/edx):
      line size (bytes)     = 0x40 (64)
      lines per tag         = 0x1 (1)
      associativity         = 48-way (11)
      size (in 512KB units) = 0xc (12)
   RAS Capability (0x80000007/ebx):
      MCA overflow recovery support = false
      SUCCOR support                = false
      HWA: hardware assert support  = false
      scalable MCA support          = false
   Advanced Power Management Features (0x80000007/ecx):
      CmpUnitPwrSampleTimeRatio = 0x0 (0)
   Advanced Power Management Features (0x80000007/edx):
      TS: temperature sensing diode           = true
      FID: frequency ID control               = false
      VID: voltage ID control                 = false
      TTP: thermal trip                       = true
      TM: thermal monitor                     = true
      STC: software thermal control           = true
      100 MHz multiplier control              = true
      hardware P-State control                = true
      TscInvariant                            = true
      CPB: core performance boost             = false
      read-only effective frequency interface = false
      processor feedback interface            = false
      APM power reporting                     = false
      connected standby                       = false
      RAPL: running average power limit       = false
   Physical Address and Linear Address Size (0x80000008/eax):
      maximum physical address bits         = 0x30 (48)
      maximum linear (virtual) address bits = 0x30 (48)
      maximum guest physical address bits   = 0x0 (0)
   Extended Feature Extensions ID (0x80000008/ebx):
      CLZERO instruction                 = false
      instructions retired count support = false
      always save/restore error pointers = false
   Logical CPU cores (0x80000008/ecx):
      number of CPU cores - 1 = 0x3 (3)
      ApicIdCoreIdSize        = 0x2 (2)
   SVM Secure Virtual Machine (0x8000000a/eax):
      SvmRev: SVM revision = 0x1 (1)
   SVM Secure Virtual Machine (0x8000000a/edx):
      nested paging                          = true
      LBR virtualization                     = true
      SVM lock                               = true
      NRIP save                              = true
      MSR based TSC rate control             = false
      VMCB clean bits support                = false
      flush by ASID                          = false
      decode assists                         = false
      SSSE3/SSE5 opcode set disable          = false
      pause intercept filter                 = false
      pause filter threshold                 = false
      AVIC: AMD virtual interrupt controller = false
      virtualized VMLOAD/VMSAVE              = false
      virtualized GIF                        = false
   NASID: number of address space identifiers = 0x40 (64):
   L1 TLB information: 1G pages (0x80000019/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x30 (48)
      data associativity        = full (15)
   L2 TLB information: 1G pages (0x80000019/ebx):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x10 (16)
      data associativity        = 8-way (6)
   SVM Secure Virtual Machine (0x8000001a/eax):
      128-bit SSE executed full-width = true
      MOVU* better than MOVL*/MOVH*   = true
      256-bit SSE executed full-width = false
   Instruction Based Sampling Identifiers (0x8000001b/eax):
      IBS feature flags valid                  = true
      IBS fetch sampling                       = true
      IBS execution sampling                   = true
      read write of op counter                 = true
      op counting mode                         = true
      branch target address reporting          = false
      IbsOpCurCnt and IbsOpMaxCnt extend 7     = false
      invalid RIP indication support           = false
      fused branch micro-op indication support = false
      IBS fetch control extended MSR support   = false
      IBS op data 4 MSR support                = false
   (instruction supported synth):
      CMPXCHG8B                = true
      conditional move/compare = true
      PREFETCH/PREFETCHW       = true
   (multi-processing synth): multi-core (c=4)
   (multi-processing method): AMD
   (APIC widths synth): CORE_width=2 SMT_width=0
   (APIC synth): PKG_ID=0 CORE_ID=0 SMT_ID=0
   (synth) = AMD Phenom II X4 (Deneb RB-C3) [K10], 45nm 965 Processor
CPU 1:
   vendor_id = "AuthenticAMD"
   version information (1/eax):
      processor type  = primary processor (0)
      family          = Intel Pentium 4/Pentium D/Pentium Extreme Edition/Celeron/Xeon/Xeon MP/Itanium2, AMD Athlon 64/Athlon XP-M/Opteron/Sempron/Turion (15)
      model           = 0x4 (4)
      stepping id     = 0x3 (3)
      extended family = 0x1 (1)
      extended model  = 0x0 (0)
      (simple synth)  = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   miscellaneous (1/ebx):
      process local APIC physical ID = 0x1 (1)
      cpu count                      = 0x4 (4)
      CLFLUSH line size              = 0x8 (8)
      brand index                    = 0x0 (0)
   brand id = 0x00 (0): unknown
   feature information (1/edx):
      x87 FPU on chip                        = true
      VME: virtual-8086 mode enhancement     = true
      DE: debugging extensions               = true
      PSE: page size extensions              = true
      TSC: time stamp counter                = true
      RDMSR and WRMSR support                = true
      PAE: physical address extensions       = true
      MCE: machine check exception           = true
      CMPXCHG8B inst.                        = true
      APIC on chip                           = true
      SYSENTER and SYSEXIT                   = true
      MTRR: memory type range registers      = true
      PTE global bit                         = true
      MCA: machine check architecture        = true
      CMOV: conditional move/compare instr   = true
      PAT: page attribute table              = true
      PSE-36: page size extension            = true
      PSN: processor serial number           = false
      CLFLUSH instruction                    = true
      DS: debug store                        = false
      ACPI: thermal monitor and clock ctrl   = false
      MMX Technology                         = true
      FXSAVE/FXRSTOR                         = true
      SSE extensions                         = true
      SSE2 extensions                        = true
      SS: self snoop                         = false
      hyper-threading / multi-core supported = true
      TM: therm. monitor                     = false
      IA64                                   = false
      PBE: pending break event               = false
   feature information (1/ecx):
      PNI/SSE3: Prescott New Instructions     = true
      PCLMULDQ instruction                    = false
      DTES64: 64-bit debug store              = false
      MONITOR/MWAIT                           = true
      CPL-qualified debug store               = false
      VMX: virtual machine extensions         = false
      SMX: safer mode extensions              = false
      Enhanced Intel SpeedStep Technology     = false
      TM2: thermal monitor 2                  = false
      SSSE3 extensions                        = false
      context ID: adaptive or shared L1 data  = false
      SDBG: IA32_DEBUG_INTERFACE              = false
      FMA instruction                         = false
      CMPXCHG16B instruction                  = true
      xTPR disable                            = false
      PDCM: perfmon and debug                 = false
      PCID: process context identifiers       = false
      DCA: direct cache access                = false
      SSE4.1 extensions                       = false
      SSE4.2 extensions                       = false
      x2APIC: extended xAPIC support          = false
      MOVBE instruction                       = false
      POPCNT instruction                      = true
      time stamp counter deadline             = false
      AES instruction                         = false
      XSAVE/XSTOR states                      = false
      OS-enabled XSAVE/XSTOR                  = false
      AVX: advanced vector extensions         = false
      F16C half-precision convert instruction = false
      RDRAND instruction                      = false
      hypervisor guest status                 = false
   cache and TLB information (2):
   processor serial number: 0010-0F43-0000-0000-0000-0000
   MONITOR/MWAIT (5):
      smallest monitor-line size (bytes)       = 0x40 (64)
      largest monitor-line size (bytes)        = 0x40 (64)
      enum of Monitor-MWAIT exts supported     = true
      supports intrs as break-event for MWAIT  = true
      number of C0 sub C-states using MWAIT    = 0x0 (0)
      number of C1 sub C-states using MWAIT    = 0x0 (0)
      number of C2 sub C-states using MWAIT    = 0x0 (0)
      number of C3 sub C-states using MWAIT    = 0x0 (0)
      number of C4 sub C-states using MWAIT    = 0x0 (0)
      number of C5 sub C-states using MWAIT    = 0x0 (0)
      number of C6 sub C-states using MWAIT    = 0x0 (0)
      number of C7 sub C-states using MWAIT    = 0x0 (0)
   extended processor signature (0x80000001/eax):
      family/generation = AMD Athlon 64/Opteron/Sempron/Turion (15)
      model             = 0x4 (4)
      stepping id       = 0x3 (3)
      extended family   = 0x1 (1)
      extended model    = 0x0 (0)
      (simple synth) = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   extended feature flags (0x80000001/edx):
      x87 FPU on chip                       = true
      virtual-8086 mode enhancement         = true
      debugging extensions                  = true
      page size extensions                  = true
      time stamp counter                    = true
      RDMSR and WRMSR support               = true
      physical address extensions           = true
      machine check exception               = true
      CMPXCHG8B inst.                       = true
      APIC on chip                          = true
      SYSCALL and SYSRET instructions       = true
      memory type range registers           = true
      global paging extension               = true
      machine check architecture            = true
      conditional move/compare instruction  = true
      page attribute table                  = true
      page size extension                   = true
      multiprocessing capable               = false
      no-execute page protection            = true
      AMD multimedia instruction extensions = true
      MMX Technology                        = true
      FXSAVE/FXRSTOR                        = true
      SSE extensions                        = true
      1-GB large page support               = true
      RDTSCP                                = true
      long mode (AA-64)                     = true
      3DNow! instruction extensions         = true
      3DNow! instructions                   = true
   extended brand id (0x80000001/ebx):
      raw          = 0x10001c16 (268442646)
      BrandId      = 0x1c16 (7190)
      str1         = 0x3 (3)
      str2         = 0x6 (6)
      PartialModel = 0x41 (65)
      PG           = 0x0 (0)
      PkgType      = 0x1 (1)
   AMD feature flags (0x80000001/ecx):
      LAHF/SAHF supported in 64-bit mode     = true
      CMP Legacy                             = true
      SVM: secure virtual machine            = true
      extended APIC space                    = true
      AltMovCr8                              = true
      LZCNT advanced bit manipulation        = true
      SSE4A support                          = true
      misaligned SSE mode                    = true
      3DNow! PREFETCH/PREFETCHW instructions = true
      OS visible workaround                  = true
      instruction based sampling             = true
      XOP support                            = false
      SKINIT/STGI support                    = true
      watchdog timer support                 = true
      lightweight profiling support          = false
      4-operand FMA instruction              = false
      TCE: translation cache extension       = false
      NodeId MSR C001100C                    = false
      TBM support                            = false
      topology extensions                    = false
      core performance counter extensions    = false
      data breakpoint extension              = false
      performance time-stamp counter support = false
      performance counter extensions         = false
      MWAITX/MONITORX supported              = false
   brand = "AMD Phenom(tm) II X4 965 Processor"
   L1 TLB/cache information: 2M/4M pages & L1 TLB (0x80000005/eax):
      instruction # entries     = 0x10 (16)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 TLB/cache information: 4K pages & L1 TLB (0x80000005/ebx):
      instruction # entries     = 0x20 (32)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 data cache information (0x80000005/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L1 instruction cache information (0x80000005/edx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L2 TLB/cache information: 2M/4M pages & L2 TLB (0x80000006/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x80 (128)
      data associativity        = 2-way (2)
   L2 TLB/cache information: 4K pages & L2 TLB (0x80000006/ebx):
      instruction # entries     = 0x200 (512)
      instruction associativity = 4-way (4)
      data # entries            = 0x200 (512)
      data associativity        = 4-way (4)
   L2 unified cache information (0x80000006/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 16-way (8)
      size (KB)         = 0x200 (512)
   L3 cache information (0x80000006/edx):
      line size (bytes)     = 0x40 (64)
      lines per tag         = 0x1 (1)
      associativity         = 48-way (11)
      size (in 512KB units) = 0xc (12)
   RAS Capability (0x80000007/ebx):
      MCA overflow recovery support = false
      SUCCOR support                = false
      HWA: hardware assert support  = false
      scalable MCA support          = false
   Advanced Power Management Features (0x80000007/ecx):
      CmpUnitPwrSampleTimeRatio = 0x0 (0)
   Advanced Power Management Features (0x80000007/edx):
      TS: temperature sensing diode           = true
      FID: frequency ID control               = false
      VID: voltage ID control                 = false
      TTP: thermal trip                       = true
      TM: thermal monitor                     = true
      STC: software thermal control           = true
      100 MHz multiplier control              = true
      hardware P-State control                = true
      TscInvariant                            = true
      CPB: core performance boost             = false
      read-only effective frequency interface = false
      processor feedback interface            = false
      APM power reporting                     = false
      connected standby                       = false
      RAPL: running average power limit       = false
   Physical Address and Linear Address Size (0x80000008/eax):
      maximum physical address bits         = 0x30 (48)
      maximum linear (virtual) address bits = 0x30 (48)
      maximum guest physical address bits   = 0x0 (0)
   Extended Feature Extensions ID (0x80000008/ebx):
      CLZERO instruction                 = false
      instructions retired count support = false
      always save/restore error pointers = false
   Logical CPU cores (0x80000008/ecx):
      number of CPU cores - 1 = 0x3 (3)
      ApicIdCoreIdSize        = 0x2 (2)
   SVM Secure Virtual Machine (0x8000000a/eax):
      SvmRev: SVM revision = 0x1 (1)
   SVM Secure Virtual Machine (0x8000000a/edx):
      nested paging                          = true
      LBR virtualization                     = true
      SVM lock                               = true
      NRIP save                              = true
      MSR based TSC rate control             = false
      VMCB clean bits support                = false
      flush by ASID                          = false
      decode assists                         = false
      SSSE3/SSE5 opcode set disable          = false
      pause intercept filter                 = false
      pause filter threshold                 = false
      AVIC: AMD virtual interrupt controller = false
      virtualized VMLOAD/VMSAVE              = false
      virtualized GIF                        = false
   NASID: number of address space identifiers = 0x40 (64):
   L1 TLB information: 1G pages (0x80000019/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x30 (48)
      data associativity        = full (15)
   L2 TLB information: 1G pages (0x80000019/ebx):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x10 (16)
      data associativity        = 8-way (6)
   SVM Secure Virtual Machine (0x8000001a/eax):
      128-bit SSE executed full-width = true
      MOVU* better than MOVL*/MOVH*   = true
      256-bit SSE executed full-width = false
   Instruction Based Sampling Identifiers (0x8000001b/eax):
      IBS feature flags valid                  = true
      IBS fetch sampling                       = true
      IBS execution sampling                   = true
      read write of op counter                 = true
      op counting mode                         = true
      branch target address reporting          = false
      IbsOpCurCnt and IbsOpMaxCnt extend 7     = false
      invalid RIP indication support           = false
      fused branch micro-op indication support = false
      IBS fetch control extended MSR support   = false
      IBS op data 4 MSR support                = false
   (instruction supported synth):
      CMPXCHG8B                = true
      conditional move/compare = true
      PREFETCH/PREFETCHW       = true
   (multi-processing synth): multi-core (c=4)
   (multi-processing method): AMD
   (APIC widths synth): CORE_width=2 SMT_width=0
   (APIC synth): PKG_ID=0 CORE_ID=1 SMT_ID=0
   (synth) = AMD Phenom II X4 (Deneb RB-C3) [K10], 45nm 965 Processor
CPU 2:
   vendor_id = "AuthenticAMD"
   version information (1/eax):
      processor type  = primary processor (0)
      family          = Intel Pentium 4/Pentium D/Pentium Extreme Edition/Celeron/Xeon/Xeon MP/Itanium2, AMD Athlon 64/Athlon XP-M/Opteron/Sempron/Turion (15)
      model           = 0x4 (4)
      stepping id     = 0x3 (3)
      extended family = 0x1 (1)
      extended model  = 0x0 (0)
      (simple synth)  = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   miscellaneous (1/ebx):
      process local APIC physical ID = 0x2 (2)
      cpu count                      = 0x4 (4)
      CLFLUSH line size              = 0x8 (8)
      brand index                    = 0x0 (0)
   brand id = 0x00 (0): unknown
   feature information (1/edx):
      x87 FPU on chip                        = true
      VME: virtual-8086 mode enhancement     = true
      DE: debugging extensions               = true
      PSE: page size extensions              = true
      TSC: time stamp counter                = true
      RDMSR and WRMSR support                = true
      PAE: physical address extensions       = true
      MCE: machine check exception           = true
      CMPXCHG8B inst.                        = true
      APIC on chip                           = true
      SYSENTER and SYSEXIT                   = true
      MTRR: memory type range registers      = true
      PTE global bit                         = true
      MCA: machine check architecture        = true
      CMOV: conditional move/compare instr   = true
      PAT: page attribute table              = true
      PSE-36: page size extension            = true
      PSN: processor serial number           = false
      CLFLUSH instruction                    = true
      DS: debug store                        = false
      ACPI: thermal monitor and clock ctrl   = false
      MMX Technology                         = true
      FXSAVE/FXRSTOR                         = true
      SSE extensions                         = true
      SSE2 extensions                        = true
      SS: self snoop                         = false
      hyper-threading / multi-core supported = true
      TM: therm. monitor                     = false
      IA64                                   = false
      PBE: pending break event               = false
   feature information (1/ecx):
      PNI/SSE3: Prescott New Instructions     = true
      PCLMULDQ instruction                    = false
      DTES64: 64-bit debug store              = false
      MONITOR/MWAIT                           = true
      CPL-qualified debug store               = false
      VMX: virtual machine extensions         = false
      SMX: safer mode extensions              = false
      Enhanced Intel SpeedStep Technology     = false
      TM2: thermal monitor 2                  = false
      SSSE3 extensions                        = false
      context ID: adaptive or shared L1 data  = false
      SDBG: IA32_DEBUG_INTERFACE              = false
      FMA instruction                         = false
      CMPXCHG16B instruction                  = true
      xTPR disable                            = false
      PDCM: perfmon and debug                 = false
      PCID: process context identifiers       = false
      DCA: direct cache access                = false
      SSE4.1 extensions                       = false
      SSE4.2 extensions                       = false
      x2APIC: extended xAPIC support          = false
      MOVBE instruction                       = false
      POPCNT instruction                      = true
      time stamp counter deadline             = false
      AES instruction                         = false
      XSAVE/XSTOR states                      = false
      OS-enabled XSAVE/XSTOR                  = false
      AVX: advanced vector extensions         = false
      F16C half-precision convert instruction = false
      RDRAND instruction                      = false
      hypervisor guest status                 = false
   cache and TLB information (2):
   processor serial number: 0010-0F43-0000-0000-0000-0000
   MONITOR/MWAIT (5):
      smallest monitor-line size (bytes)       = 0x40 (64)
      largest monitor-line size (bytes)        = 0x40 (64)
      enum of Monitor-MWAIT exts supported     = true
      supports intrs as break-event for MWAIT  = true
      number of C0 sub C-states using MWAIT    = 0x0 (0)
      number of C1 sub C-states using MWAIT    = 0x0 (0)
      number of C2 sub C-states using MWAIT    = 0x0 (0)
      number of C3 sub C-states using MWAIT    = 0x0 (0)
      number of C4 sub C-states using MWAIT    = 0x0 (0)
      number of C5 sub C-states using MWAIT    = 0x0 (0)
      number of C6 sub C-states using MWAIT    = 0x0 (0)
      number of C7 sub C-states using MWAIT    = 0x0 (0)
   extended processor signature (0x80000001/eax):
      family/generation = AMD Athlon 64/Opteron/Sempron/Turion (15)
      model             = 0x4 (4)
      stepping id       = 0x3 (3)
      extended family   = 0x1 (1)
      extended model    = 0x0 (0)
      (simple synth) = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   extended feature flags (0x80000001/edx):
      x87 FPU on chip                       = true
      virtual-8086 mode enhancement         = true
      debugging extensions                  = true
      page size extensions                  = true
      time stamp counter                    = true
      RDMSR and WRMSR support               = true
      physical address extensions           = true
      machine check exception               = true
      CMPXCHG8B inst.                       = true
      APIC on chip                          = true
      SYSCALL and SYSRET instructions       = true
      memory type range registers           = true
      global paging extension               = true
      machine check architecture            = true
      conditional move/compare instruction  = true
      page attribute table                  = true
      page size extension                   = true
      multiprocessing capable               = false
      no-execute page protection            = true
      AMD multimedia instruction extensions = true
      MMX Technology                        = true
      FXSAVE/FXRSTOR                        = true
      SSE extensions                        = true
      1-GB large page support               = true
      RDTSCP                                = true
      long mode (AA-64)                     = true
      3DNow! instruction extensions         = true
      3DNow! instructions                   = true
   extended brand id (0x80000001/ebx):
      raw          = 0x10001c16 (268442646)
      BrandId      = 0x1c16 (7190)
      str1         = 0x3 (3)
      str2         = 0x6 (6)
      PartialModel = 0x41 (65)
      PG           = 0x0 (0)
      PkgType      = 0x1 (1)
   AMD feature flags (0x80000001/ecx):
      LAHF/SAHF supported in 64-bit mode     = true
      CMP Legacy                             = true
      SVM: secure virtual machine            = true
      extended APIC space                    = true
      AltMovCr8                              = true
      LZCNT advanced bit manipulation        = true
      SSE4A support                          = true
      misaligned SSE mode                    = true
      3DNow! PREFETCH/PREFETCHW instructions = true
      OS visible workaround                  = true
      instruction based sampling             = true
      XOP support                            = false
      SKINIT/STGI support                    = true
      watchdog timer support                 = true
      lightweight profiling support          = false
      4-operand FMA instruction              = false
      TCE: translation cache extension       = false
      NodeId MSR C001100C                    = false
      TBM support                            = false
      topology extensions                    = false
      core performance counter extensions    = false
      data breakpoint extension              = false
      performance time-stamp counter support = false
      performance counter extensions         = false
      MWAITX/MONITORX supported              = false
   brand = "AMD Phenom(tm) II X4 965 Processor"
   L1 TLB/cache information: 2M/4M pages & L1 TLB (0x80000005/eax):
      instruction # entries     = 0x10 (16)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 TLB/cache information: 4K pages & L1 TLB (0x80000005/ebx):
      instruction # entries     = 0x20 (32)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 data cache information (0x80000005/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L1 instruction cache information (0x80000005/edx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L2 TLB/cache information: 2M/4M pages & L2 TLB (0x80000006/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x80 (128)
      data associativity        = 2-way (2)
   L2 TLB/cache information: 4K pages & L2 TLB (0x80000006/ebx):
      instruction # entries     = 0x200 (512)
      instruction associativity = 4-way (4)
      data # entries            = 0x200 (512)
      data associativity        = 4-way (4)
   L2 unified cache information (0x80000006/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 16-way (8)
      size (KB)         = 0x200 (512)
   L3 cache information (0x80000006/edx):
      line size (bytes)     = 0x40 (64)
      lines per tag         = 0x1 (1)
      associativity         = 48-way (11)
      size (in 512KB units) = 0xc (12)
   RAS Capability (0x80000007/ebx):
      MCA overflow recovery support = false
      SUCCOR support                = false
      HWA: hardware assert support  = false
      scalable MCA support          = false
   Advanced Power Management Features (0x80000007/ecx):
      CmpUnitPwrSampleTimeRatio = 0x0 (0)
   Advanced Power Management Features (0x80000007/edx):
      TS: temperature sensing diode           = true
      FID: frequency ID control               = false
      VID: voltage ID control                 = false
      TTP: thermal trip                       = true
      TM: thermal monitor                     = true
      STC: software thermal control           = true
      100 MHz multiplier control              = true
      hardware P-State control                = true
      TscInvariant                            = true
      CPB: core performance boost             = false
      read-only effective frequency interface = false
      processor feedback interface            = false
      APM power reporting                     = false
      connected standby                       = false
      RAPL: running average power limit       = false
   Physical Address and Linear Address Size (0x80000008/eax):
      maximum physical address bits         = 0x30 (48)
      maximum linear (virtual) address bits = 0x30 (48)
      maximum guest physical address bits   = 0x0 (0)
   Extended Feature Extensions ID (0x80000008/ebx):
      CLZERO instruction                 = false
      instructions retired count support = false
      always save/restore error pointers = false
   Logical CPU cores (0x80000008/ecx):
      number of CPU cores - 1 = 0x3 (3)
      ApicIdCoreIdSize        = 0x2 (2)
   SVM Secure Virtual Machine (0x8000000a/eax):
      SvmRev: SVM revision = 0x1 (1)
   SVM Secure Virtual Machine (0x8000000a/edx):
      nested paging                          = true
      LBR virtualization                     = true
      SVM lock                               = true
      NRIP save                              = true
      MSR based TSC rate control             = false
      VMCB clean bits support                = false
      flush by ASID                          = false
      decode assists                         = false
      SSSE3/SSE5 opcode set disable          = false
      pause intercept filter                 = false
      pause filter threshold                 = false
      AVIC: AMD virtual interrupt controller = false
      virtualized VMLOAD/VMSAVE              = false
      virtualized GIF                        = false
   NASID: number of address space identifiers = 0x40 (64):
   L1 TLB information: 1G pages (0x80000019/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x30 (48)
      data associativity        = full (15)
   L2 TLB information: 1G pages (0x80000019/ebx):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x10 (16)
      data associativity        = 8-way (6)
   SVM Secure Virtual Machine (0x8000001a/eax):
      128-bit SSE executed full-width = true
      MOVU* better than MOVL*/MOVH*   = true
      256-bit SSE executed full-width = false
   Instruction Based Sampling Identifiers (0x8000001b/eax):
      IBS feature flags valid                  = true
      IBS fetch sampling                       = true
      IBS execution sampling                   = true
      read write of op counter                 = true
      op counting mode                         = true
      branch target address reporting          = false
      IbsOpCurCnt and IbsOpMaxCnt extend 7     = false
      invalid RIP indication support           = false
      fused branch micro-op indication support = false
      IBS fetch control extended MSR support   = false
      IBS op data 4 MSR support                = false
   (instruction supported synth):
      CMPXCHG8B                = true
      conditional move/compare = true
      PREFETCH/PREFETCHW       = true
   (multi-processing synth): multi-core (c=4)
   (multi-processing method): AMD
   (APIC widths synth): CORE_width=2 SMT_width=0
   (APIC synth): PKG_ID=0 CORE_ID=2 SMT_ID=0
   (synth) = AMD Phenom II X4 (Deneb RB-C3) [K10], 45nm 965 Processor
CPU 3:
   vendor_id = "AuthenticAMD"
   version information (1/eax):
      processor type  = primary processor (0)
      family          = Intel Pentium 4/Pentium D/Pentium Extreme Edition/Celeron/Xeon/Xeon MP/Itanium2, AMD Athlon 64/Athlon XP-M/Opteron/Sempron/Turion (15)
      model           = 0x4 (4)
      stepping id     = 0x3 (3)
      extended family = 0x1 (1)
      extended model  = 0x0 (0)
      (simple synth)  = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   miscellaneous (1/ebx):
      process local APIC physical ID = 0x3 (3)
      cpu count                      = 0x4 (4)
      CLFLUSH line size              = 0x8 (8)
      brand index                    = 0x0 (0)
   brand id = 0x00 (0): unknown
   feature information (1/edx):
      x87 FPU on chip                        = true
      VME: virtual-8086 mode enhancement     = true
      DE: debugging extensions               = true
      PSE: page size extensions              = true
      TSC: time stamp counter                = true
      RDMSR and WRMSR support                = true
      PAE: physical address extensions       = true
      MCE: machine check exception           = true
      CMPXCHG8B inst.                        = true
      APIC on chip                           = true
      SYSENTER and SYSEXIT                   = true
      MTRR: memory type range registers      = true
      PTE global bit                         = true
      MCA: machine check architecture        = true
      CMOV: conditional move/compare instr   = true
      PAT: page attribute table              = true
      PSE-36: page size extension            = true
      PSN: processor serial number           = false
      CLFLUSH instruction                    = true
      DS: debug store                        = false
      ACPI: thermal monitor and clock ctrl   = false
      MMX Technology                         = true
      FXSAVE/FXRSTOR                         = true
      SSE extensions                         = true
      SSE2 extensions                        = true
      SS: self snoop                         = false
      hyper-threading / multi-core supported = true
      TM: therm. monitor                     = false
      IA64                                   = false
      PBE: pending break event               = false
   feature information (1/ecx):
      PNI/SSE3: Prescott New Instructions     = true
      PCLMULDQ instruction                    = false
      DTES64: 64-bit debug store              = false
      MONITOR/MWAIT                           = true
      CPL-qualified debug store               = false
      VMX: virtual machine extensions         = false
      SMX: safer mode extensions              = false
      Enhanced Intel SpeedStep Technology     = false
      TM2: thermal monitor 2                  = false
      SSSE3 extensions                        = false
      context ID: adaptive or shared L1 data  = false
      SDBG: IA32_DEBUG_INTERFACE              = false
      FMA instruction                         = false
      CMPXCHG16B instruction                  = true
      xTPR disable                            = false
      PDCM: perfmon and debug                 = false
      PCID: process context identifiers       = false
      DCA: direct cache access                = false
      SSE4.1 extensions                       = false
      SSE4.2 extensions                       = false
      x2APIC: extended xAPIC support          = false
      MOVBE instruction                       = false
      POPCNT instruction                      = true
      time stamp counter deadline             = false
      AES instruction                         = false
      XSAVE/XSTOR states                      = false
      OS-enabled XSAVE/XSTOR                  = false
      AVX: advanced vector extensions         = false
      F16C half-precision convert instruction = false
      RDRAND instruction                      = false
      hypervisor guest status                 = false
   cache and TLB information (2):
   processor serial number: 0010-0F43-0000-0000-0000-0000
   MONITOR/MWAIT (5):
      smallest monitor-line size (bytes)       = 0x40 (64)
      largest monitor-line size (bytes)        = 0x40 (64)
      enum of Monitor-MWAIT exts supported     = true
      supports intrs as break-event for MWAIT  = true
      number of C0 sub C-states using MWAIT    = 0x0 (0)
      number of C1 sub C-states using MWAIT    = 0x0 (0)
      number of C2 sub C-states using MWAIT    = 0x0 (0)
      number of C3 sub C-states using MWAIT    = 0x0 (0)
      number of C4 sub C-states using MWAIT    = 0x0 (0)
      number of C5 sub C-states using MWAIT    = 0x0 (0)
      number of C6 sub C-states using MWAIT    = 0x0 (0)
      number of C7 sub C-states using MWAIT    = 0x0 (0)
   extended processor signature (0x80000001/eax):
      family/generation = AMD Athlon 64/Opteron/Sempron/Turion (15)
      model             = 0x4 (4)
      stepping id       = 0x3 (3)
      extended family   = 0x1 (1)
      extended model    = 0x0 (0)
      (simple synth) = AMD Phenom II (Callisto / Heka / Deneb RB-C3) [K10], 45nm
   extended feature flags (0x80000001/edx):
      x87 FPU on chip                       = true
      virtual-8086 mode enhancement         = true
      debugging extensions                  = true
      page size extensions                  = true
      time stamp counter                    = true
      RDMSR and WRMSR support               = true
      physical address extensions           = true
      machine check exception               = true
      CMPXCHG8B inst.                       = true
      APIC on chip                          = true
      SYSCALL and SYSRET instructions       = true
      memory type range registers           = true
      global paging extension               = true
      machine check architecture            = true
      conditional move/compare instruction  = true
      page attribute table                  = true
      page size extension                   = true
      multiprocessing capable               = false
      no-execute page protection            = true
      AMD multimedia instruction extensions = true
      MMX Technology                        = true
      FXSAVE/FXRSTOR                        = true
      SSE extensions                        = true
      1-GB large page support               = true
      RDTSCP                                = true
      long mode (AA-64)                     = true
      3DNow! instruction extensions         = true
      3DNow! instructions                   = true
   extended brand id (0x80000001/ebx):
      raw          = 0x10001c16 (268442646)
      BrandId      = 0x1c16 (7190)
      str1         = 0x3 (3)
      str2         = 0x6 (6)
      PartialModel = 0x41 (65)
      PG           = 0x0 (0)
      PkgType      = 0x1 (1)
   AMD feature flags (0x80000001/ecx):
      LAHF/SAHF supported in 64-bit mode     = true
      CMP Legacy                             = true
      SVM: secure virtual machine            = true
      extended APIC space                    = true
      AltMovCr8                              = true
      LZCNT advanced bit manipulation        = true
      SSE4A support                          = true
      misaligned SSE mode                    = true
      3DNow! PREFETCH/PREFETCHW instructions = true
      OS visible workaround                  = true
      instruction based sampling             = true
      XOP support                            = false
      SKINIT/STGI support                    = true
      watchdog timer support                 = true
      lightweight profiling support          = false
      4-operand FMA instruction              = false
      TCE: translation cache extension       = false
      NodeId MSR C001100C                    = false
      TBM support                            = false
      topology extensions                    = false
      core performance counter extensions    = false
      data breakpoint extension              = false
      performance time-stamp counter support = false
      performance counter extensions         = false
      MWAITX/MONITORX supported              = false
   brand = "AMD Phenom(tm) II X4 965 Processor"
   L1 TLB/cache information: 2M/4M pages & L1 TLB (0x80000005/eax):
      instruction # entries     = 0x10 (16)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 TLB/cache information: 4K pages & L1 TLB (0x80000005/ebx):
      instruction # entries     = 0x20 (32)
      instruction associativity = 0xff (255)
      data # entries            = 0x30 (48)
      data associativity        = 0xff (255)
   L1 data cache information (0x80000005/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L1 instruction cache information (0x80000005/edx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 0x2 (2)
      size (KB)         = 0x40 (64)
   L2 TLB/cache information: 2M/4M pages & L2 TLB (0x80000006/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x80 (128)
      data associativity        = 2-way (2)
   L2 TLB/cache information: 4K pages & L2 TLB (0x80000006/ebx):
      instruction # entries     = 0x200 (512)
      instruction associativity = 4-way (4)
      data # entries            = 0x200 (512)
      data associativity        = 4-way (4)
   L2 unified cache information (0x80000006/ecx):
      line size (bytes) = 0x40 (64)
      lines per tag     = 0x1 (1)
      associativity     = 16-way (8)
      size (KB)         = 0x200 (512)
   L3 cache information (0x80000006/edx):
      line size (bytes)     = 0x40 (64)
      lines per tag         = 0x1 (1)
      associativity         = 48-way (11)
      size (in 512KB units) = 0xc (12)
   RAS Capability (0x80000007/ebx):
      MCA overflow recovery support = false
      SUCCOR support                = false
      HWA: hardware assert support  = false
      scalable MCA support          = false
   Advanced Power Management Features (0x80000007/ecx):
      CmpUnitPwrSampleTimeRatio = 0x0 (0)
   Advanced Power Management Features (0x80000007/edx):
      TS: temperature sensing diode           = true
      FID: frequency ID control               = false
      VID: voltage ID control                 = false
      TTP: thermal trip                       = true
      TM: thermal monitor                     = true
      STC: software thermal control           = true
      100 MHz multiplier control              = true
      hardware P-State control                = true
      TscInvariant                            = true
      CPB: core performance boost             = false
      read-only effective frequency interface = false
      processor feedback interface            = false
      APM power reporting                     = false
      connected standby                       = false
      RAPL: running average power limit       = false
   Physical Address and Linear Address Size (0x80000008/eax):
      maximum physical address bits         = 0x30 (48)
      maximum linear (virtual) address bits = 0x30 (48)
      maximum guest physical address bits   = 0x0 (0)
   Extended Feature Extensions ID (0x80000008/ebx):
      CLZERO instruction                 = false
      instructions retired count support = false
      always save/restore error pointers = false
   Logical CPU cores (0x80000008/ecx):
      number of CPU cores - 1 = 0x3 (3)
      ApicIdCoreIdSize        = 0x2 (2)
   SVM Secure Virtual Machine (0x8000000a/eax):
      SvmRev: SVM revision = 0x1 (1)
   SVM Secure Virtual Machine (0x8000000a/edx):
      nested paging                          = true
      LBR virtualization                     = true
      SVM lock                               = true
      NRIP save                              = true
      MSR based TSC rate control             = false
      VMCB clean bits support                = false
      flush by ASID                          = false
      decode assists                         = false
      SSSE3/SSE5 opcode set disable          = false
      pause intercept filter                 = false
      pause filter threshold                 = false
      AVIC: AMD virtual interrupt controller = false
      virtualized VMLOAD/VMSAVE              = false
      virtualized GIF                        = false
   NASID: number of address space identifiers = 0x40 (64):
   L1 TLB information: 1G pages (0x80000019/eax):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x30 (48)
      data associativity        = full (15)
   L2 TLB information: 1G pages (0x80000019/ebx):
      instruction # entries     = 0x0 (0)
      instruction associativity = L2 off (0)
      data # entries            = 0x10 (16)
      data associativity        = 8-way (6)
   SVM Secure Virtual Machine (0x8000001a/eax):
      128-bit SSE executed full-width = true
      MOVU* better than MOVL*/MOVH*   = true
      256-bit SSE executed full-width = false
   Instruction Based Sampling Identifiers (0x8000001b/eax):
      IBS feature flags valid                  = true
      IBS fetch sampling                       = true
      IBS execution sampling                   = true
      read write of op counter                 = true
      op counting mode                         = true
      branch target address reporting          = false
      IbsOpCurCnt and IbsOpMaxCnt extend 7     = false
      invalid RIP indication support           = false
      fused branch micro-op indication support = false
      IBS fetch control extended MSR support   = false
      IBS op data 4 MSR support                = false
   (instruction supported synth):
      CMPXCHG8B                = true
      conditional move/compare = true
      PREFETCH/PREFETCHW       = true
   (multi-processing synth): multi-core (c=4)
   (multi-processing method): AMD
   (APIC widths synth): CORE_width=2 SMT_width=0
   (APIC synth): PKG_ID=0 CORE_ID=3 SMT_ID=0
   (synth) = AMD Phenom II X4 (Deneb RB-C3) [K10], 45nm 965 Processor

From momtchil at momtchev.com  Sun Dec 29 15:03:09 2019
From: momtchil at momtchev.com (Momtchil Momtchev)
Date: Mon, 30 Dec 2019 00:03:09 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
 2.1.2 vs 3.x
In-Reply-To: <4689281.9M2WixvCNZ@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <2054717.MMUpikYRpk@even-i700>
 <74850b8c-37de-e9f2-8a6d-2dac5b49d66c@momtchev.com>
 <4689281.9M2WixvCNZ@even-i700>
Message-ID: <9ca1b243-2716-1d72-735c-2b4bd9bddd07@momtchev.com>


     In fact EAX is negative (0x80000001/eax) in the extended status, 
not the basic one?

     Let me test it.


On 29/12/2019 22:57, Even Rouault wrote:
> On dimanche 29 décembre 2019 22:36:24 CET Momtchil Momtchev wrote:
>>       Disabling HAVE_SSSE3_AT_COMPILE_TIME had no effect,
> Make sure you run "make clean" after running ./configure
>
>> but after
>> short-circuiting the #ifdef I got a correct result.
> Hum so it seems that the SSSE3 detection doesn't work properly.
>
> Can you :
>
> 1. undo your code changes
>
> 2. modify port/cpl_cpu_features.cpp at line 98 to replace the code of the
> CPLDetectSSE3() function by
>
> static inline bool CPLDetectSSE3()
> {
>      int cpuinfo[4] = { 0, 0, 0, 0 };
>      CPL_CPUID(0, cpuinfo);
>      if( cpuinfo[REG_EAX] <= 0 )
>          return false;
>      CPL_CPUID(1, cpuinfo);
>      return (cpuinfo[REG_ECX] & (1 << CPUID_SSSE3_ECX_BIT)) != 0;
> }
>
> (note: this function should really be called CPLDetectSSSE3 ... missing S...
> but that doesn't matter)
>
> 3. modify port/cpl_cpu_features.h to add just after line 47 "#if __SSSE3__" a
> new line with "dummy" as content. Normally this shouldn't be compiled... but
> this is just to make sure the compiler doesn't define SSSE3 as available
> unconditionnally at runtime.
>
> 4. run configure again *without* disabling ssse3
> 5. make clean
> 6. make (possibly with -j something)
>
>
-- 
Momtchil Momtchev <momtchil at momtchev.com>


From even.rouault at spatialys.com  Sun Dec 29 15:22:49 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 30 Dec 2019 00:22:49 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
	2.1.2 vs 3.x
In-Reply-To: <c32b0bf1-0566-76ea-79f3-91ddbfb23257@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <d509c389-3023-d545-0d5f-069af7a0f04f@momtchev.com>
 <c32b0bf1-0566-76ea-79f3-91ddbfb23257@momtchev.com>
Message-ID: <5952717.yBNBJcHe4D@even-i700>

On dimanche 29 décembre 2019 23:53:14 CET Momtchil Momtchev wrote:
>      I recompiled with the modified CPU detection, the SSE3 syntax error
> and with the default configure options (after a distclean) and I get the
> _incorrect_ result.

Hum, what about the following ?

static inline bool CPLDetectSSE3()
{
    int cpuinfo[4] = { 0, 0, 0, 0 };
    CPL_CPUID(0, cpuinfo);
    if( cpuinfo[REG_EAX] <= 2 )
        return false;
    CPL_CPUID(0x80000000, cpuinfo);
    if( static_cast<unsigned>(cpuinfo[REG_EAX]) <= 1 )
        return false;
    CPL_CPUID(1, cpuinfo);
    fprintf(stderr, "ECX = 0x%X\n", cpuinfo[REG_ECX]);
    return (cpuinfo[REG_ECX] & (1 << CPUID_SSSE3_ECX_BIT)) != 0;
}

> 
> On 29/12/2019 22:15, Momtchil Momtchev wrote:
> >     I get the same wrong results with and without Docker, with and
> > without the SSE/SSE3/AVX when using the configure script. I also tried
> > removing -O2. Is the SSE3 unpacking in GDAL or in libgeotiff?
> > 
> > On 29/12/2019 21:51, Even Rouault wrote:
> >>>       Is it possible that this is a compiler issue? Anyone else that
> >>> can
> >>> test this on an AMD CPU? Mine are old Phenom II X4 965s.
> >> 
> >> Perhaps rather a runtime issue. I suspect this is related to a SSSE3
> >> optimization that has been added in GDAL 2.2 that is used in this use
> >> case
> >> (unpacking of byte buffer with a 2 byte stride to packed buffer)
> >> 
> >>  From what I found on the net, I think this CPU doesn't support the
> >> SSSE3
> >> instruction set (SSSE3 with three S, not to be confused with SSE3...)
> >> Can you check the following ?
> >> cat /proc/cpuinfo | grep ssse3
> >> 
> >> What is strange is that GDAL does have a runtime check to detect if
> >> SSSE3 is
> >> available, so I'm not sure why you would get that issue. Unless that
> >> Docker
> >> would wrongly expose SSSE3, but Docker is not a VM technology so it
> >> shouldn't
> >> mess up with CPU capability discoveries. This is weird.
> >> 
> >> Can you try the following ?
> >> 
> >> docker run --rm osgeo/gdal su -c "apt install -y cpuid; cpuid" | grep
> >> SSSE3
> >> 
> >> In a DEBUG build of GDAL, you could disable at runtime the SSSE3
> >> optimization
> >> by defining the environment variable/configuration option
> >> GDAL_USE_SSSE3 to
> >> NO, but this will not work on the release builds available on Docker.


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Sun Dec 29 16:10:15 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 30 Dec 2019 01:10:15 +0100
Subject: [gdal-dev] Different results when reading a GeoTIFF with GDAL
	2.1.2 vs 3.x
In-Reply-To: <5952717.yBNBJcHe4D@even-i700>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
 <c32b0bf1-0566-76ea-79f3-91ddbfb23257@momtchev.com>
 <5952717.yBNBJcHe4D@even-i700>
Message-ID: <1938625.JvzVcN0PSK@even-i700>

(removing the list to avoid "spamming" them while we're in debug mode)

Actually that should be

static inline bool CPLDetectSSE3()
{
    int cpuinfo[4] = { 0, 0, 0, 0 };
    CPL_CPUID(0, cpuinfo);
    if( cpuinfo[REG_EAX] <= 2 )
        return false;
    CPL_CPUID(0x80000000, cpuinfo);
    if( static_cast<unsigned>(cpuinfo[REG_EAX]) < 1 )
        return false;
    CPL_CPUID(1, cpuinfo);
    fprintf(stderr, "ECX = 0x%X\n", cpuinfo[REG_ECX]);
    return (cpuinfo[REG_ECX] & (1 << CPUID_SSSE3_ECX_BIT)) != 0;
}

The static_cast<unsigned>(cpuinfo[REG_EAX]) <= 1 has been changed to < 1
I don't think that would make a difference. Your CPU does support extended 
status, but my assumption is that CPL_CPUID(0x80000000, cpuinfo) must be 
called before CPL_CPUID(1, cpuinfo) so the later gets correct results (not 
super confident that it will change anything...)

If that still doesn't work, I'm a bit short of idea and would need to be able 
to test locally if you can provide ssh access.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Mon Dec 30 02:31:14 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 30 Dec 2019 11:31:14 +0100
Subject: [gdal-dev] [SOLVED] Re: Different results when reading a GeoTIFF
	with GDAL 2.1.2 vs 3.x
In-Reply-To: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
References: <f1ed7da8-90e3-8861-1e93-2fe5ffa32bf6@momtchev.com>
Message-ID: <4465888.NarQhtWHyl@even-i700>

Hi,

so after investigation this was not an issue with the detection of SSSE3, but 
a bug in the SSE2-only optimization that was then used when SSSE3 is missing.
Affected GeoTIFF files with 2 bands of type=Byte and pixel-interleaving layout 
(PlanarConfiguration=Contig)

Fixed by https://github.com/OSGeo/gdal/pull/2143 and backported to 3.0 and 2.4 
branches

(the interesting thing is that this code path was unit tested, but with data 
with a specific bit pattern that hid the bug, a bit like someone writting
let addition(a,b) = a | b and believing it works correctly if testing 
addition(2,4), addition(5,24) etc. )

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

