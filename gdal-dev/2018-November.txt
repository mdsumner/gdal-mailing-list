From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov  1 00:10:43 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Thu, 1 Nov 2018 00:10:43 -0700 (MST)
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
Message-ID: <1541056243969-0.post@n6.nabble.com>

koji higuchi wrote
> Hi
> I am extracting .osm.pbf file into .gpkg; but the writing rate is very
> slow.
> When I write into .shp, rate is faster but its limit is 4gb.
> So, what other format is better for larger than 4gb requirement?
> Thanks for your ideas.
> Koji

Hi,

Show the exact command that you are using so we can see if it could be made
faster. For example if you happen to use -skipfailures for handling the
invalid geometries of the OSM data then you will make GDAL to do a new
transaction for each row and that certainly is slow. But let's have a look
at your command first.

-Jukka Rahkonen-



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From koji51guchi at gmail.com  Thu Nov  1 01:24:54 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 17:24:54 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <1541056243969-0.post@n6.nabble.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
Message-ID: <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>

Hi, following is the code I used:

Import os, osmium, fiona

fi = 'europe-latest.osm.pbf'
fo = 'europe-latest.dpkg'

drv = 'DPKG'

crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
'longlat'}

 schema = {'geometry': 'LineString',
                   'properties': {'id': 'float', 'name' : 'str', 'kind' :
'str'}}

outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)

geomfab = osmium.geom.GeoJSONFactory()

class ShapeConverter(osmium.SimpleHandler):
      def way(self, w):
           if 'place' in w.tags:
               rec = {'geometry' : eval(geomfab.create_linestring(w)),
                      'properties' : {'id' : float(w.id),
                                     'name' : w.tags.get('name'),
                                       'kind' : w.tags['place']}}
               outfile.write(rec)

ShapeConverter().apply_file(fi, locations=True)

On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
jukka.rahkonen at maanmittauslaitos.fi> wrote:

> koji higuchi wrote
> > Hi
> > I am extracting .osm.pbf file into .gpkg; but the writing rate is very
> > slow.
> > When I write into .shp, rate is faster but its limit is 4gb.
> > So, what other format is better for larger than 4gb requirement?
> > Thanks for your ideas.
> > Koji
>
> Hi,
>
> Show the exact command that you are using so we can see if it could be made
> faster. For example if you happen to use -skipfailures for handling the
> invalid geometries of the OSM data then you will make GDAL to do a new
> transaction for each row and that certainly is slow. But let's have a look
> at your command first.
>
> -Jukka Rahkonen-
>
>
>
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/66e137e5/attachment.html>

From mfathin at csysint.com  Thu Nov  1 02:31:45 2018
From: mfathin at csysint.com (Athin)
Date: Thu, 1 Nov 2018 02:31:45 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1540950114674-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
Message-ID: <1541064705634-0.post@n6.nabble.com>

Hai All, 

My target just know want to try to display raster map, but i still stuck in
this starting point. The code I run below will display an error

error c4700 uninitialized local variable 'pszFilename' used

can someone help me regarding this and what i need to with the file i
download from this link:https://trac.osgeo.org/gdal/wiki/DownloadSource

where i need to add on VS2012?

Thank you and best regards

#include "gdal_priv.h"
#include "cpl_conv.h" // for CPLMalloc()
#include "stdafx.h"
#include "gdal.h"


int main()
{
	class GDALDataset;
	const char *pszFilename;
	

    GDALDataset *poDataset;
	void CPL_DLL CPL_STDCALL GDALAllRegister(void);

    poDataset = (GDALDataset *) GDALOpen(pszFilename, GA_ReadOnly );
    if( poDataset == NULL )
	{}

}



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Thu Nov  1 02:45:53 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 01 Nov 2018 10:45:53 +0100
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
Message-ID: <1633761.8QadCDHqCS@even-i700>

You are perhaps using a too old version of Fiona. Recent versions insert 
features within OGR transactions. Should be fine with latest Fiona 1.8.0
See https://github.com/Toblerity/Fiona/issues/476

> Hi, following is the code I used:
> 
> Import os, osmium, fiona
> 
> fi = 'europe-latest.osm.pbf'
> fo = 'europe-latest.dpkg'
> 
> drv = 'DPKG'
> 
> crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
> 'longlat'}
> 
>  schema = {'geometry': 'LineString',
>                    'properties': {'id': 'float', 'name' : 'str', 'kind' :
> 'str'}}
> 
> outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)
> 
> geomfab = osmium.geom.GeoJSONFactory()
> 
> class ShapeConverter(osmium.SimpleHandler):
>       def way(self, w):
>            if 'place' in w.tags:
>                rec = {'geometry' : eval(geomfab.create_linestring(w)),
>                       'properties' : {'id' : float(w.id),
>                                      'name' : w.tags.get('name'),
>                                        'kind' : w.tags['place']}}
>                outfile.write(rec)
> 
> ShapeConverter().apply_file(fi, locations=True)
> 
> On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
> 
> jukka.rahkonen at maanmittauslaitos.fi> wrote:
> > koji higuchi wrote
> > 
> > > Hi
> > > I am extracting .osm.pbf file into .gpkg; but the writing rate is very
> > > slow.
> > > When I write into .shp, rate is faster but its limit is 4gb.
> > > So, what other format is better for larger than 4gb requirement?
> > > Thanks for your ideas.
> > > Koji
> > 
> > Hi,
> > 
> > Show the exact command that you are using so we can see if it could be
> > made
> > faster. For example if you happen to use -skipfailures for handling the
> > invalid geometries of the OSM data then you will make GDAL to do a new
> > transaction for each row and that certainly is slow. But let's have a look
> > at your command first.
> > 
> > -Jukka Rahkonen-
> > 
> > 
> > 
> > --
> > Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > https://lists.osgeo.org/mailman/listinfo/gdal-dev


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov  1 02:55:44 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Thu, 1 Nov 2018 02:55:44 -0700 (MST)
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
Message-ID: <1541066144898-0.post@n6.nabble.com>

koji higuchi wrote
> Hi, following is the code I used:
> 
> Import os, osmium, fiona
> 
> fi = 'europe-latest.osm.pbf'
> fo = 'europe-latest.dpkg'
> 
> drv = 'DPKG'

Hi,

I am not able to evaluate if your code is effective or not. However, I can
give you some numbers for comparison.

Test data http://download.geofabrik.de/europe/finland-latest.osm.pbf
- 322 MB as .pbf
- 770725 points
- 1778917 lines
- 3128 multilinestrings
- 2087911 multipolygons
- 6985 other relations

Command:
ogr2ogr -f gpkg finland.gpkg finland-latest.osm.pbf

Execution time on Windows laptop:
2 minutes and 20 seconds

If you experience some slower performance it is probably not because of
SQLite/GeoPackage as a format is slow but because something is not done in a
way that is not optimal for the format. Could you also define your source
data and the performance that you have measured?

-Jukka Rahkonen-





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From koji51guchi at gmail.com  Thu Nov  1 03:02:56 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 19:02:56 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <1541066144898-0.post@n6.nabble.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1541066144898-0.post@n6.nabble.com>
Message-ID: <CADHxCLKhzjKZfdDAr4tYck9sdVyQ1yn-+Z2K26f5aWmHKwLpLA@mail.gmail.com>

Hi, my source file is too big, around 19gb (europe-latest.osm.pbf)
I also tried ogr2ogr for clipping into region as follows.
ogr2ogr -f,  gpkg,  -clipdst, str(ulx), str(lry), str(lrx), str(uly), fo, fi
but it was also very slow.


On Thu, Nov 1, 2018 at 6:55 PM jratike80 <
jukka.rahkonen at maanmittauslaitos.fi> wrote:

> koji higuchi wrote
> > Hi, following is the code I used:
> >
> > Import os, osmium, fiona
> >
> > fi = 'europe-latest.osm.pbf'
> > fo = 'europe-latest.dpkg'
> >
> > drv = 'DPKG'
>
> Hi,
>
> I am not able to evaluate if your code is effective or not. However, I can
> give you some numbers for comparison.
>
> Test data http://download.geofabrik.de/europe/finland-latest.osm.pbf
> - 322 MB as .pbf
> - 770725 points
> - 1778917 lines
> - 3128 multilinestrings
> - 2087911 multipolygons
> - 6985 other relations
>
> Command:
> ogr2ogr -f gpkg finland.gpkg finland-latest.osm.pbf
>
> Execution time on Windows laptop:
> 2 minutes and 20 seconds
>
> If you experience some slower performance it is probably not because of
> SQLite/GeoPackage as a format is slow but because something is not done in
> a
> way that is not optimal for the format. Could you also define your source
> data and the performance that you have measured?
>
> -Jukka Rahkonen-
>
>
>
>
>
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/30200ad3/attachment-0001.html>

From koji51guchi at gmail.com  Thu Nov  1 03:05:57 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 19:05:57 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <1633761.8QadCDHqCS@even-i700>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
Message-ID: <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>

Hi Even

I am trying to replace using fiona by pure ogr.
but having difficult to collapse the code with class and objects.
If i could extract geom and tags in a ogr pythonic way, then it be better


On Thu, Nov 1, 2018 at 6:45 PM Even Rouault <even.rouault at spatialys.com>
wrote:

> You are perhaps using a too old version of Fiona. Recent versions insert
> features within OGR transactions. Should be fine with latest Fiona 1.8.0
> See https://github.com/Toblerity/Fiona/issues/476
>
> > Hi, following is the code I used:
> >
> > Import os, osmium, fiona
> >
> > fi = 'europe-latest.osm.pbf'
> > fo = 'europe-latest.dpkg'
> >
> > drv = 'DPKG'
> >
> > crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
> > 'longlat'}
> >
> >  schema = {'geometry': 'LineString',
> >                    'properties': {'id': 'float', 'name' : 'str', 'kind' :
> > 'str'}}
> >
> > outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)
> >
> > geomfab = osmium.geom.GeoJSONFactory()
> >
> > class ShapeConverter(osmium.SimpleHandler):
> >       def way(self, w):
> >            if 'place' in w.tags:
> >                rec = {'geometry' : eval(geomfab.create_linestring(w)),
> >                       'properties' : {'id' : float(w.id),
> >                                      'name' : w.tags.get('name'),
> >                                        'kind' : w.tags['place']}}
> >                outfile.write(rec)
> >
> > ShapeConverter().apply_file(fi, locations=True)
> >
> > On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
> >
> > jukka.rahkonen at maanmittauslaitos.fi> wrote:
> > > koji higuchi wrote
> > >
> > > > Hi
> > > > I am extracting .osm.pbf file into .gpkg; but the writing rate is
> very
> > > > slow.
> > > > When I write into .shp, rate is faster but its limit is 4gb.
> > > > So, what other format is better for larger than 4gb requirement?
> > > > Thanks for your ideas.
> > > > Koji
> > >
> > > Hi,
> > >
> > > Show the exact command that you are using so we can see if it could be
> > > made
> > > faster. For example if you happen to use -skipfailures for handling the
> > > invalid geometries of the OSM data then you will make GDAL to do a new
> > > transaction for each row and that certainly is slow. But let's have a
> look
> > > at your command first.
> > >
> > > -Jukka Rahkonen-
> > >
> > >
> > >
> > > --
> > > Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> > > _______________________________________________
> > > gdal-dev mailing list
> > > gdal-dev at lists.osgeo.org
> > > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/2a24ab69/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov  1 03:13:39 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Thu, 1 Nov 2018 03:13:39 -0700 (MST)
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLKhzjKZfdDAr4tYck9sdVyQ1yn-+Z2K26f5aWmHKwLpLA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1541066144898-0.post@n6.nabble.com>
 <CADHxCLKhzjKZfdDAr4tYck9sdVyQ1yn-+Z2K26f5aWmHKwLpLA@mail.gmail.com>
Message-ID: <1541067219690-0.post@n6.nabble.com>

Hi,

That is probably another problem, OSM pbf format does not support effective
selection by region so selecting a subarea from europe-latest.osm.pbf may be
almost as slow as processing the whole dataset. I would try if
osmium-extract https://docs.osmcode.org/osmium/latest/osmium-extract.html
could do the clipping  faster.

-Jukka Rahkonen-


koji higuchi wrote
> Hi, my source file is too big, around 19gb (europe-latest.osm.pbf)
> I also tried ogr2ogr for clipping into region as follows.
> ogr2ogr -f,  gpkg,  -clipdst, str(ulx), str(lry), str(lrx), str(uly), fo,
> fi
> but it was also very slow.
> 
> 
> On Thu, Nov 1, 2018 at 6:55 PM jratike80 <

> jukka.rahkonen@

>> wrote:
> 
>> koji higuchi wrote
>> > Hi, following is the code I used:
>> >
>> > Import os, osmium, fiona
>> >
>> > fi = 'europe-latest.osm.pbf'
>> > fo = 'europe-latest.dpkg'
>> >
>> > drv = 'DPKG'
>>
>> Hi,
>>
>> I am not able to evaluate if your code is effective or not. However, I
>> can
>> give you some numbers for comparison.
>>
>> Test data http://download.geofabrik.de/europe/finland-latest.osm.pbf
>> - 322 MB as .pbf
>> - 770725 points
>> - 1778917 lines
>> - 3128 multilinestrings
>> - 2087911 multipolygons
>> - 6985 other relations
>>
>> Command:
>> ogr2ogr -f gpkg finland.gpkg finland-latest.osm.pbf
>>
>> Execution time on Windows laptop:
>> 2 minutes and 20 seconds
>>
>> If you experience some slower performance it is probably not because of
>> SQLite/GeoPackage as a format is slow but because something is not done
>> in
>> a
>> way that is not optimal for the format. Could you also define your source
>> data and the performance that you have measured?
>>
>> -Jukka Rahkonen-
>>





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From koji51guchi at gmail.com  Thu Nov  1 03:16:00 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 19:16:00 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <1541067219690-0.post@n6.nabble.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1541066144898-0.post@n6.nabble.com>
 <CADHxCLKhzjKZfdDAr4tYck9sdVyQ1yn-+Z2K26f5aWmHKwLpLA@mail.gmail.com>
 <1541067219690-0.post@n6.nabble.com>
Message-ID: <CADHxCLK=_v6QKRDqwvKKLYW-VGJQ8EVYkpMzVBXMtmR7CcFtMA@mail.gmail.com>

Hi Jukka

Is osmium-extract available in pyosmium?
i'm using windows; and seems difficult to use osmium in windows

On Thu, Nov 1, 2018 at 7:13 PM jratike80 <
jukka.rahkonen at maanmittauslaitos.fi> wrote:

> Hi,
>
> That is probably another problem, OSM pbf format does not support effective
> selection by region so selecting a subarea from europe-latest.osm.pbf may
> be
> almost as slow as processing the whole dataset. I would try if
> osmium-extract https://docs.osmcode.org/osmium/latest/osmium-extract.html
> could do the clipping  faster.
>
> -Jukka Rahkonen-
>
>
> koji higuchi wrote
> > Hi, my source file is too big, around 19gb (europe-latest.osm.pbf)
> > I also tried ogr2ogr for clipping into region as follows.
> > ogr2ogr -f,  gpkg,  -clipdst, str(ulx), str(lry), str(lrx), str(uly), fo,
> > fi
> > but it was also very slow.
> >
> >
> > On Thu, Nov 1, 2018 at 6:55 PM jratike80 <
>
> > jukka.rahkonen@
>
> >> wrote:
> >
> >> koji higuchi wrote
> >> > Hi, following is the code I used:
> >> >
> >> > Import os, osmium, fiona
> >> >
> >> > fi = 'europe-latest.osm.pbf'
> >> > fo = 'europe-latest.dpkg'
> >> >
> >> > drv = 'DPKG'
> >>
> >> Hi,
> >>
> >> I am not able to evaluate if your code is effective or not. However, I
> >> can
> >> give you some numbers for comparison.
> >>
> >> Test data http://download.geofabrik.de/europe/finland-latest.osm.pbf
> >> - 322 MB as .pbf
> >> - 770725 points
> >> - 1778917 lines
> >> - 3128 multilinestrings
> >> - 2087911 multipolygons
> >> - 6985 other relations
> >>
> >> Command:
> >> ogr2ogr -f gpkg finland.gpkg finland-latest.osm.pbf
> >>
> >> Execution time on Windows laptop:
> >> 2 minutes and 20 seconds
> >>
> >> If you experience some slower performance it is probably not because of
> >> SQLite/GeoPackage as a format is slow but because something is not done
> >> in
> >> a
> >> way that is not optimal for the format. Could you also define your
> source
> >> data and the performance that you have measured?
> >>
> >> -Jukka Rahkonen-
> >>
>
>
>
>
>
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/c8c7b9b1/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov  1 03:38:37 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Thu, 1 Nov 2018 03:38:37 -0700 (MST)
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLK=_v6QKRDqwvKKLYW-VGJQ8EVYkpMzVBXMtmR7CcFtMA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1541066144898-0.post@n6.nabble.com>
 <CADHxCLKhzjKZfdDAr4tYck9sdVyQ1yn-+Z2K26f5aWmHKwLpLA@mail.gmail.com>
 <1541067219690-0.post@n6.nabble.com>
 <CADHxCLK=_v6QKRDqwvKKLYW-VGJQ8EVYkpMzVBXMtmR7CcFtMA@mail.gmail.com>
Message-ID: <1541068717787-0.post@n6.nabble.com>

Hi,

Unfortunately I have never used osmium-extract myself but I was remembering
that I had been reading something about doing spatial selection from OSM
pbf. I did even find the thread
https://lists.openstreetmap.org/pipermail/dev/2018-October/030400.html

-Jukka-



koji higuchi wrote
> Hi Jukka
> 
> Is osmium-extract available in pyosmium?
> i'm using windows; and seems difficult to use osmium in windows
> 
> On Thu, Nov 1, 2018 at 7:13 PM jratike80 <

> jukka.rahkonen@

>> wrote:
> 
>> Hi,
>>
>> That is probably another problem, OSM pbf format does not support
>> effective
>> selection by region so selecting a subarea from europe-latest.osm.pbf may
>> be
>> almost as slow as processing the whole dataset. I would try if
>> osmium-extract https://docs.osmcode.org/osmium/latest/osmium-extract.html
>> could do the clipping  faster.
>>
>> -Jukka Rahkonen-
>>
>>
>> koji higuchi wrote
>> > Hi, my source file is too big, around 19gb (europe-latest.osm.pbf)
>> > I also tried ogr2ogr for clipping into region as follows.
>> > ogr2ogr -f,  gpkg,  -clipdst, str(ulx), str(lry), str(lrx), str(uly),
>> fo,
>> > fi
>> > but it was also very slow.
>> >
>> >
>> > On Thu, Nov 1, 2018 at 6:55 PM jratike80 <
>>
>> > jukka.rahkonen@
>>
>> >> wrote:
>> >
>> >> koji higuchi wrote
>> >> > Hi, following is the code I used:
>> >> >
>> >> > Import os, osmium, fiona
>> >> >
>> >> > fi = 'europe-latest.osm.pbf'
>> >> > fo = 'europe-latest.dpkg'
>> >> >
>> >> > drv = 'DPKG'
>> >>
>> >> Hi,
>> >>
>> >> I am not able to evaluate if your code is effective or not. However, I
>> >> can
>> >> give you some numbers for comparison.
>> >>
>> >> Test data http://download.geofabrik.de/europe/finland-latest.osm.pbf
>> >> - 322 MB as .pbf
>> >> - 770725 points
>> >> - 1778917 lines
>> >> - 3128 multilinestrings
>> >> - 2087911 multipolygons
>> >> - 6985 other relations
>> >>
>> >> Command:
>> >> ogr2ogr -f gpkg finland.gpkg finland-latest.osm.pbf
>> >>
>> >> Execution time on Windows laptop:
>> >> 2 minutes and 20 seconds
>> >>
>> >> If you experience some slower performance it is probably not because
>> of
>> >> SQLite/GeoPackage as a format is slow but because something is not
>> done
>> >> in
>> >> a
>> >> way that is not optimal for the format. Could you also define your
>> source
>> >> data and the performance that you have measured?
>> >>
>> >> -Jukka Rahkonen-
>> >>
>>
>>
>>
>>
>>
>> --
>> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>> _______________________________________________
>> gdal-dev mailing list
>> 

> gdal-dev at .osgeo

>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
> 
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From ivan.lucena at outlook.com  Thu Nov  1 04:03:10 2018
From: ivan.lucena at outlook.com (Ivan Lucena)
Date: Thu, 1 Nov 2018 11:03:10 +0000
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541064705634-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
Message-ID: <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>

Athin,

If this is your target, GDAL might not be the right choice for you.
    
    My target just know want to try to display raster map, but i still stuck in
    this starting point. The code I run below will display an error

The GDAL API doesn't support display capabilities. If you go ahead and solve the problems that you are facing you will end up with a buffer of pixels in memory, in order to get that as an image/map into a desktop window you need to write your own code (against Microsoft APIs probably) or call some other library that have that capability.
    
    can someone help me regarding this and what i need to with the file i
    download from this link:https://trac.osgeo.org/gdal/wiki/DownloadSource

You don't need to download the GDAL source code and compile it to follow the GDAL tutorial. You can get the binary distribution from GISInternals [https://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries]
    
    where i need to add on VS2012?
    error c4700 uninitialized local variable 'pszFilename' used

I would advise you to take some VS and C++ tutorials/exercises to get familiar with the language itself, error messages and the programming environment.

Good luck,

Ivan


From bradh at frogmouth.net  Thu Nov  1 03:50:29 2018
From: bradh at frogmouth.net (bradh at frogmouth.net)
Date: Thu, 1 Nov 2018 21:50:29 +1100
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541064705634-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
Message-ID: <008d01d471d0$b5788de0$2069a9a0$@frogmouth.net>

The problem below is nothing to do with GDAL, you just need to initialise the variable (probably by some kind of command line argument - argv[1] if nothing else). If that doesn't make sense, is there another programming language that you are more comfortable with?

Brad

-----Original Message-----
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Athin
Sent: Thursday, 1 November 2018 8:32 PM
To: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++

Hai All, 

My target just know want to try to display raster map, but i still stuck in this starting point. The code I run below will display an error

error c4700 uninitialized local variable 'pszFilename' used

can someone help me regarding this and what i need to with the file i download from this link:https://trac.osgeo.org/gdal/wiki/DownloadSource

where i need to add on VS2012?

Thank you and best regards

#include "gdal_priv.h"
#include "cpl_conv.h" // for CPLMalloc() #include "stdafx.h"
#include "gdal.h"


int main()
{
	class GDALDataset;
	const char *pszFilename;
	

    GDALDataset *poDataset;
	void CPL_DLL CPL_STDCALL GDALAllRegister(void);

    poDataset = (GDALDataset *) GDALOpen(pszFilename, GA_ReadOnly );
    if( poDataset == NULL )
	{}

}



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/gdal-dev


From koji51guchi at gmail.com  Thu Nov  1 04:10:22 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 20:10:22 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
 <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>
Message-ID: <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>

Hi Even
I managed to write gpkg without ogr without fiona using class
ShapeConverter(osmium.SimpleHandler).
still, speed seems slow.
Any idea to increase it up.

On Thu, Nov 1, 2018 at 7:05 PM koji higuchi <koji51guchi at gmail.com> wrote:

> Hi Even
>
> I am trying to replace using fiona by pure ogr.
> but having difficult to collapse the code with class and objects.
> If i could extract geom and tags in a ogr pythonic way, then it be better
>
>
> On Thu, Nov 1, 2018 at 6:45 PM Even Rouault <even.rouault at spatialys.com>
> wrote:
>
>> You are perhaps using a too old version of Fiona. Recent versions insert
>> features within OGR transactions. Should be fine with latest Fiona 1.8.0
>> See https://github.com/Toblerity/Fiona/issues/476
>>
>> > Hi, following is the code I used:
>> >
>> > Import os, osmium, fiona
>> >
>> > fi = 'europe-latest.osm.pbf'
>> > fo = 'europe-latest.dpkg'
>> >
>> > drv = 'DPKG'
>> >
>> > crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
>> > 'longlat'}
>> >
>> >  schema = {'geometry': 'LineString',
>> >                    'properties': {'id': 'float', 'name' : 'str', 'kind'
>> :
>> > 'str'}}
>> >
>> > outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)
>> >
>> > geomfab = osmium.geom.GeoJSONFactory()
>> >
>> > class ShapeConverter(osmium.SimpleHandler):
>> >       def way(self, w):
>> >            if 'place' in w.tags:
>> >                rec = {'geometry' : eval(geomfab.create_linestring(w)),
>> >                       'properties' : {'id' : float(w.id),
>> >                                      'name' : w.tags.get('name'),
>> >                                        'kind' : w.tags['place']}}
>> >                outfile.write(rec)
>> >
>> > ShapeConverter().apply_file(fi, locations=True)
>> >
>> > On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
>> >
>> > jukka.rahkonen at maanmittauslaitos.fi> wrote:
>> > > koji higuchi wrote
>> > >
>> > > > Hi
>> > > > I am extracting .osm.pbf file into .gpkg; but the writing rate is
>> very
>> > > > slow.
>> > > > When I write into .shp, rate is faster but its limit is 4gb.
>> > > > So, what other format is better for larger than 4gb requirement?
>> > > > Thanks for your ideas.
>> > > > Koji
>> > >
>> > > Hi,
>> > >
>> > > Show the exact command that you are using so we can see if it could be
>> > > made
>> > > faster. For example if you happen to use -skipfailures for handling
>> the
>> > > invalid geometries of the OSM data then you will make GDAL to do a new
>> > > transaction for each row and that certainly is slow. But let's have a
>> look
>> > > at your command first.
>> > >
>> > > -Jukka Rahkonen-
>> > >
>> > >
>> > >
>> > > --
>> > > Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>> > > _______________________________________________
>> > > gdal-dev mailing list
>> > > gdal-dev at lists.osgeo.org
>> > > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>>
>> --
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/69322f59/attachment.html>

From a.neumann at carto.net  Thu Nov  1 04:27:23 2018
From: a.neumann at carto.net (Andreas Neumann)
Date: Thu, 1 Nov 2018 12:27:23 +0100
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
 <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>
 <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>
Message-ID: <99724d16-cbe9-70ea-f370-c3e9e25f72e6@carto.net>

Hi,

Just a quick stupid question: are you writing to a local file system or 
to a network filesystem. The latter can be substantially slower than the 
former, esp. with Geopackage.

Andreas

Am 01.11.18 um 12:10 schrieb koji higuchi:
> Hi Even
> I managed to write gpkg without ogr without fiona using class 
> ShapeConverter(osmium.SimpleHandler).
> still, speed seems slow.
> Any idea to increase it up.
>
> On Thu, Nov 1, 2018 at 7:05 PM koji higuchi <koji51guchi at gmail.com 
> <mailto:koji51guchi at gmail.com>> wrote:
>
>     Hi Even
>
>     I am trying to replace using fiona by pure ogr.
>     but having difficult to collapse the code with class and objects.
>     If i could extract geom and tags in a ogr pythonic way, then it be
>     better
>
>
>     On Thu, Nov 1, 2018 at 6:45 PM Even Rouault
>     <even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>>
>     wrote:
>
>         You are perhaps using a too old version of Fiona. Recent
>         versions insert
>         features within OGR transactions. Should be fine with latest
>         Fiona 1.8.0
>         See https://github.com/Toblerity/Fiona/issues/476
>
>         > Hi, following is the code I used:
>         >
>         > Import os, osmium, fiona
>         >
>         > fi = 'europe-latest.osm.pbf'
>         > fo = 'europe-latest.dpkg'
>         >
>         > drv = 'DPKG'
>         >
>         > crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84',
>         'proj':
>         > 'longlat'}
>         >
>         >  schema = {'geometry': 'LineString',
>         >                    'properties': {'id': 'float', 'name' :
>         'str', 'kind' :
>         > 'str'}}
>         >
>         > outfile = fiona.open(fo, 'w', driver=drv, crs=crs,
>         schema=schema)
>         >
>         > geomfab = osmium.geom.GeoJSONFactory()
>         >
>         > class ShapeConverter(osmium.SimpleHandler):
>         >       def way(self, w):
>         >            if 'place' in w.tags:
>         >                rec = {'geometry' :
>         eval(geomfab.create_linestring(w)),
>         >                       'properties' : {'id' : float(w.id
>         <http://w.id>),
>         >                                      'name' :
>         w.tags.get('name'),
>         >                                        'kind' :
>         w.tags['place']}}
>         >                outfile.write(rec)
>         >
>         > ShapeConverter().apply_file(fi, locations=True)
>         >
>         > On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
>         >
>         > jukka.rahkonen at maanmittauslaitos.fi
>         <mailto:jukka.rahkonen at maanmittauslaitos.fi>> wrote:
>         > > koji higuchi wrote
>         > >
>         > > > Hi
>         > > > I am extracting .osm.pbf file into .gpkg; but the
>         writing rate is very
>         > > > slow.
>         > > > When I write into .shp, rate is faster but its limit is 4gb.
>         > > > So, what other format is better for larger than 4gb
>         requirement?
>         > > > Thanks for your ideas.
>         > > > Koji
>         > >
>         > > Hi,
>         > >
>         > > Show the exact command that you are using so we can see if
>         it could be
>         > > made
>         > > faster. For example if you happen to use -skipfailures for
>         handling the
>         > > invalid geometries of the OSM data then you will make GDAL
>         to do a new
>         > > transaction for each row and that certainly is slow. But
>         let's have a look
>         > > at your command first.
>         > >
>         > > -Jukka Rahkonen-
>         > >
>         > >
>         > >
>         > > --
>         > > Sent from:
>         http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>         > > _______________________________________________
>         > > gdal-dev mailing list
>         > > gdal-dev at lists.osgeo.org <mailto:gdal-dev at lists.osgeo.org>
>         > > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
>         -- 
>         Spatialys - Geospatial professional services
>         http://www.spatialys.com
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/ea8f8a5b/attachment-0001.html>

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov  1 04:33:14 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Thu, 1 Nov 2018 04:33:14 -0700 (MST)
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
 <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>
 <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>
Message-ID: <1541071994919-0.post@n6.nabble.com>

koji higuchi wrote
> Hi Even
> I managed to write gpkg without ogr without fiona using class
> ShapeConverter(osmium.SimpleHandler).
> still, speed seems slow.
> Any idea to increase it up.

Hi,

Have you realised the importance of making big transactions? You can read
background information from https://sqlite.org/atomiccommit.html. Every
transaction has quite heavy initial cost and if your code is saving only one
row per transaction it will be slow.

If your code with ShapeConverter(osmium.SimpleHandler) is slow I suggest to
study what kind of transactions it is generating.

-Jukka-



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From koji51guchi at gmail.com  Thu Nov  1 04:34:47 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 20:34:47 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <99724d16-cbe9-70ea-f370-c3e9e25f72e6@carto.net>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
 <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>
 <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>
 <99724d16-cbe9-70ea-f370-c3e9e25f72e6@carto.net>
Message-ID: <CADHxCLJnUx8goUMU4z5Ai8nUXPPocKr+K=8JAYu_9tmbYgKadA@mail.gmail.com>

Hi  Andreas
I'm writing to a file into my PC disk.

On Thu, Nov 1, 2018 at 8:32 PM Andreas Neumann <a.neumann at carto.net> wrote:

> Hi,
>
> Just a quick stupid question: are you writing to a local file system or to
> a network filesystem. The latter can be substantially slower than the
> former, esp. with Geopackage.
>
> Andreas
> Am 01.11.18 um 12:10 schrieb koji higuchi:
>
> Hi Even
> I managed to write gpkg without ogr without fiona using class
> ShapeConverter(osmium.SimpleHandler).
> still, speed seems slow.
> Any idea to increase it up.
>
> On Thu, Nov 1, 2018 at 7:05 PM koji higuchi <koji51guchi at gmail.com> wrote:
>
>> Hi Even
>>
>> I am trying to replace using fiona by pure ogr.
>> but having difficult to collapse the code with class and objects.
>> If i could extract geom and tags in a ogr pythonic way, then it be better
>>
>>
>> On Thu, Nov 1, 2018 at 6:45 PM Even Rouault <even.rouault at spatialys.com>
>> wrote:
>>
>>> You are perhaps using a too old version of Fiona. Recent versions insert
>>> features within OGR transactions. Should be fine with latest Fiona 1.8.0
>>> See https://github.com/Toblerity/Fiona/issues/476
>>>
>>> > Hi, following is the code I used:
>>> >
>>> > Import os, osmium, fiona
>>> >
>>> > fi = 'europe-latest.osm.pbf'
>>> > fo = 'europe-latest.dpkg'
>>> >
>>> > drv = 'DPKG'
>>> >
>>> > crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
>>> > 'longlat'}
>>> >
>>> >  schema = {'geometry': 'LineString',
>>> >                    'properties': {'id': 'float', 'name' : 'str',
>>> 'kind' :
>>> > 'str'}}
>>> >
>>> > outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)
>>> >
>>> > geomfab = osmium.geom.GeoJSONFactory()
>>> >
>>> > class ShapeConverter(osmium.SimpleHandler):
>>> >       def way(self, w):
>>> >            if 'place' in w.tags:
>>> >                rec = {'geometry' : eval(geomfab.create_linestring(w)),
>>> >                       'properties' : {'id' : float(w.id),
>>> >                                      'name' : w.tags.get('name'),
>>> >                                        'kind' : w.tags['place']}}
>>> >                outfile.write(rec)
>>> >
>>> > ShapeConverter().apply_file(fi, locations=True)
>>> >
>>> > On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
>>> >
>>> > jukka.rahkonen at maanmittauslaitos.fi> wrote:
>>> > > koji higuchi wrote
>>> > >
>>> > > > Hi
>>> > > > I am extracting .osm.pbf file into .gpkg; but the writing rate is
>>> very
>>> > > > slow.
>>> > > > When I write into .shp, rate is faster but its limit is 4gb.
>>> > > > So, what other format is better for larger than 4gb requirement?
>>> > > > Thanks for your ideas.
>>> > > > Koji
>>> > >
>>> > > Hi,
>>> > >
>>> > > Show the exact command that you are using so we can see if it could
>>> be
>>> > > made
>>> > > faster. For example if you happen to use -skipfailures for handling
>>> the
>>> > > invalid geometries of the OSM data then you will make GDAL to do a
>>> new
>>> > > transaction for each row and that certainly is slow. But let's have
>>> a look
>>> > > at your command first.
>>> > >
>>> > > -Jukka Rahkonen-
>>> > >
>>> > >
>>> > >
>>> > > --
>>> > > Sent from:
>>> http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>>> > > _______________________________________________
>>> > > gdal-dev mailing list
>>> > > gdal-dev at lists.osgeo.org
>>> > > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>>>
>>>
>>> --
>>> Spatialys - Geospatial professional services
>>> http://www.spatialys.com
>>>
>>
> _______________________________________________
> gdal-dev mailing listgdal-dev at lists.osgeo.orghttps://lists.osgeo.org/mailman/listinfo/gdal-dev
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/c14603d9/attachment.html>

From koji51guchi at gmail.com  Thu Nov  1 04:40:35 2018
From: koji51guchi at gmail.com (koji higuchi)
Date: Thu, 1 Nov 2018 20:40:35 +0900
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <CADHxCLJnUx8goUMU4z5Ai8nUXPPocKr+K=8JAYu_9tmbYgKadA@mail.gmail.com>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
 <CADHxCLKfgnpsz--epH_MQmU9adukTzmeVwzGnAsR=Ywe+dygcw@mail.gmail.com>
 <CADHxCLJTz0LYieyA923vXpMkpxMc9KkM4OdsPR3W7pD462jZuA@mail.gmail.com>
 <99724d16-cbe9-70ea-f370-c3e9e25f72e6@carto.net>
 <CADHxCLJnUx8goUMU4z5Ai8nUXPPocKr+K=8JAYu_9tmbYgKadA@mail.gmail.com>
Message-ID: <CADHxCL+r0FCzLZwx761VVh0UOw2a1kt4W=JWhCT4Nurbs+JJPw@mail.gmail.com>

I'm writing file using class ShapeConverter(osmium.SimpleHandler)  and ogr
(not fiona)
But, do not know whether transaction are all written instantaneously and
simultaneously or not...

On Thu, Nov 1, 2018 at 8:34 PM koji higuchi <koji51guchi at gmail.com> wrote:

> Hi  Andreas
> I'm writing to a file into my PC disk.
>
> On Thu, Nov 1, 2018 at 8:32 PM Andreas Neumann <a.neumann at carto.net>
> wrote:
>
>> Hi,
>>
>> Just a quick stupid question: are you writing to a local file system or
>> to a network filesystem. The latter can be substantially slower than the
>> former, esp. with Geopackage.
>>
>> Andreas
>> Am 01.11.18 um 12:10 schrieb koji higuchi:
>>
>> Hi Even
>> I managed to write gpkg without ogr without fiona using class
>> ShapeConverter(osmium.SimpleHandler).
>> still, speed seems slow.
>> Any idea to increase it up.
>>
>> On Thu, Nov 1, 2018 at 7:05 PM koji higuchi <koji51guchi at gmail.com>
>> wrote:
>>
>>> Hi Even
>>>
>>> I am trying to replace using fiona by pure ogr.
>>> but having difficult to collapse the code with class and objects.
>>> If i could extract geom and tags in a ogr pythonic way, then it be better
>>>
>>>
>>> On Thu, Nov 1, 2018 at 6:45 PM Even Rouault <even.rouault at spatialys.com>
>>> wrote:
>>>
>>>> You are perhaps using a too old version of Fiona. Recent versions
>>>> insert
>>>> features within OGR transactions. Should be fine with latest Fiona 1.8.0
>>>> See https://github.com/Toblerity/Fiona/issues/476
>>>>
>>>> > Hi, following is the code I used:
>>>> >
>>>> > Import os, osmium, fiona
>>>> >
>>>> > fi = 'europe-latest.osm.pbf'
>>>> > fo = 'europe-latest.dpkg'
>>>> >
>>>> > drv = 'DPKG'
>>>> >
>>>> > crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
>>>> > 'longlat'}
>>>> >
>>>> >  schema = {'geometry': 'LineString',
>>>> >                    'properties': {'id': 'float', 'name' : 'str',
>>>> 'kind' :
>>>> > 'str'}}
>>>> >
>>>> > outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)
>>>> >
>>>> > geomfab = osmium.geom.GeoJSONFactory()
>>>> >
>>>> > class ShapeConverter(osmium.SimpleHandler):
>>>> >       def way(self, w):
>>>> >            if 'place' in w.tags:
>>>> >                rec = {'geometry' : eval(geomfab.create_linestring(w)),
>>>> >                       'properties' : {'id' : float(w.id),
>>>> >                                      'name' : w.tags.get('name'),
>>>> >                                        'kind' : w.tags['place']}}
>>>> >                outfile.write(rec)
>>>> >
>>>> > ShapeConverter().apply_file(fi, locations=True)
>>>> >
>>>> > On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
>>>> >
>>>> > jukka.rahkonen at maanmittauslaitos.fi> wrote:
>>>> > > koji higuchi wrote
>>>> > >
>>>> > > > Hi
>>>> > > > I am extracting .osm.pbf file into .gpkg; but the writing rate is
>>>> very
>>>> > > > slow.
>>>> > > > When I write into .shp, rate is faster but its limit is 4gb.
>>>> > > > So, what other format is better for larger than 4gb requirement?
>>>> > > > Thanks for your ideas.
>>>> > > > Koji
>>>> > >
>>>> > > Hi,
>>>> > >
>>>> > > Show the exact command that you are using so we can see if it could
>>>> be
>>>> > > made
>>>> > > faster. For example if you happen to use -skipfailures for handling
>>>> the
>>>> > > invalid geometries of the OSM data then you will make GDAL to do a
>>>> new
>>>> > > transaction for each row and that certainly is slow. But let's have
>>>> a look
>>>> > > at your command first.
>>>> > >
>>>> > > -Jukka Rahkonen-
>>>> > >
>>>> > >
>>>> > >
>>>> > > --
>>>> > > Sent from:
>>>> http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>>>> > > _______________________________________________
>>>> > > gdal-dev mailing list
>>>> > > gdal-dev at lists.osgeo.org
>>>> > > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>>>>
>>>>
>>>> --
>>>> Spatialys - Geospatial professional services
>>>> http://www.spatialys.com
>>>>
>>>
>> _______________________________________________
>> gdal-dev mailing listgdal-dev at lists.osgeo.orghttps://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/ff15c71e/attachment-0001.html>

From sean at mapbox.com  Thu Nov  1 07:35:47 2018
From: sean at mapbox.com (Sean Gillies)
Date: Thu, 1 Nov 2018 08:35:47 -0600
Subject: [gdal-dev] Alternative to GPKG format
In-Reply-To: <1633761.8QadCDHqCS@even-i700>
References: <CADHxCLKNJJCHS6+K383SUEp_7wsnx=pqCeXb6wvNrbyCvSH_+Q@mail.gmail.com>
 <1541056243969-0.post@n6.nabble.com>
 <CADHxCL+hyHUS5pXpZr_hhtKUcWkd0v4UN7sAk+dr47du1p1FrA@mail.gmail.com>
 <1633761.8QadCDHqCS@even-i700>
Message-ID: <CADPhZXw8A5=RfKntAuFvdsLco6EhWH+0MCysBwxJgcfByu4_aA@mail.gmail.com>

Hi all,

Upgrading to Fiona 1.8.0 won't help the code below because every
outfile.write() call entails a transaction of size 1. The user needs to
pass a sequence or iterator of many records to outfile.writerecords() if
they want to benefit from larger transactions.

On Thu, Nov 1, 2018 at 3:46 AM Even Rouault <even.rouault at spatialys.com>
wrote:

> You are perhaps using a too old version of Fiona. Recent versions insert
> features within OGR transactions. Should be fine with latest Fiona 1.8.0
> See https://github.com/Toblerity/Fiona/issues/476
>
> > Hi, following is the code I used:
> >
> > Import os, osmium, fiona
> >
> > fi = 'europe-latest.osm.pbf'
> > fo = 'europe-latest.dpkg'
> >
> > drv = 'DPKG'
> >
> > crs = {'no_defs': True, 'ellps': 'WGS84', 'datum': 'WGS84', 'proj':
> > 'longlat'}
> >
> >  schema = {'geometry': 'LineString',
> >                    'properties': {'id': 'float', 'name' : 'str', 'kind' :
> > 'str'}}
> >
> > outfile = fiona.open(fo, 'w', driver=drv, crs=crs, schema=schema)
> >
> > geomfab = osmium.geom.GeoJSONFactory()
> >
> > class ShapeConverter(osmium.SimpleHandler):
> >       def way(self, w):
> >            if 'place' in w.tags:
> >                rec = {'geometry' : eval(geomfab.create_linestring(w)),
> >                       'properties' : {'id' : float(w.id),
> >                                      'name' : w.tags.get('name'),
> >                                        'kind' : w.tags['place']}}
> >                outfile.write(rec)
> >
> > ShapeConverter().apply_file(fi, locations=True)
> >
> > On Thu, Nov 1, 2018 at 4:10 PM jratike80 <
> >
> > jukka.rahkonen at maanmittauslaitos.fi> wrote:
> > > koji higuchi wrote
> > >
> > > > Hi
> > > > I am extracting .osm.pbf file into .gpkg; but the writing rate is
> very
> > > > slow.
> > > > When I write into .shp, rate is faster but its limit is 4gb.
> > > > So, what other format is better for larger than 4gb requirement?
> > > > Thanks for your ideas.
> > > > Koji
> > >
> > > Hi,
> > >
> > > Show the exact command that you are using so we can see if it could be
> > > made
> > > faster. For example if you happen to use -skipfailures for handling the
> > > invalid geometries of the OSM data then you will make GDAL to do a new
> > > transaction for each row and that certainly is slow. But let's have a
> look
> > > at your command first.
> > >
> > > -Jukka Rahkonen-
> > >
> > >
> > >
> > > --
> > > Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> > > _______________________________________________
> > > gdal-dev mailing list
> > > gdal-dev at lists.osgeo.org
> > > https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Sean Gillies
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181101/17b6b980/attachment.html>

From mfathin at csysint.com  Thu Nov  1 17:43:35 2018
From: mfathin at csysint.com (Athin)
Date: Thu, 1 Nov 2018 17:43:35 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <008d01d471d0$b5788de0$2069a9a0$@frogmouth.net>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <008d01d471d0$b5788de0$2069a9a0$@frogmouth.net>
Message-ID: <1541119415586-0.post@n6.nabble.com>

Hai Bradh,

Sorry I not use to C++, I only familiar with C#. I need to use C++ because
Gdal support it and i need to combine it to the Visual Studio C# (Wpf).

Thank you and best regards.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From mfathin at csysint.com  Thu Nov  1 17:48:16 2018
From: mfathin at csysint.com (Athin)
Date: Thu, 1 Nov 2018 17:48:16 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
Message-ID: <1541119696181-0.post@n6.nabble.com>

Hai Ivan,

Yeah I will take the C++ tutorials/exercise. But I need to try a bit the
Gdal capability. I just want to try it first hand by follow the tutorial,
but it seem there is not many example that allow to see the running of
complete code. Did you have any GDAL sample that can share with me?

Thank you and best regards





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bradh at frogmouth.net  Thu Nov  1 21:57:49 2018
From: bradh at frogmouth.net (bradh at frogmouth.net)
Date: Fri, 2 Nov 2018 15:57:49 +1100
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541119415586-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <008d01d471d0$b5788de0$2069a9a0$@frogmouth.net>
 <1541119415586-0.post@n6.nabble.com>
Message-ID: <002501d47268$9ae2ff40$d0a8fdc0$@frogmouth.net>

There are C# bindings for GDAL: https://trac.osgeo.org/gdal/wiki/GdalOgrInCsharp
Examples are at https://trac.osgeo.org/gdal/browser/trunk/gdal/swig/csharp/apps

You may also find Nuget packages, however I haven' tried that.

Brad

-----Original Message-----
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Athin
Sent: Friday, 2 November 2018 11:44 AM
To: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++

Hai Bradh,

Sorry I not use to C++, I only familiar with C#. I need to use C++ because Gdal support it and i need to combine it to the Visual Studio C# (Wpf).

Thank you and best regards.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/gdal-dev


From c.lockenkoetter at web.de  Fri Nov  2 03:16:52 2018
From: c.lockenkoetter at web.de (Carsten L)
Date: Fri, 2 Nov 2018 03:16:52 -0700 (MST)
Subject: [gdal-dev] GTiff split to smaller tiles,
 GDALTranslateOptions: Unknown option name -srcwin
Message-ID: <1541153812435-0.post@n6.nabble.com>

Hi,

i created an issue on github for my problem / question, but maybe it is
better to write it here to you.

https://github.com/OSGeo/gdal/issues/1066
I think, there is a good description for my problem.
Is it a bug or am I doing something wrong?

Or is there another way to split huge geotiff files to smaller tiles (e.g.
5000 x 5000 pixel), without using python?

Thanks in advance,
Carsten




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From ivan.lucena at outlook.com  Fri Nov  2 07:18:01 2018
From: ivan.lucena at outlook.com (Ivan Lucena)
Date: Fri, 2 Nov 2018 14:18:01 +0000
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541119696181-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
Message-ID: <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>

Hi Athin,

I think we have some problem with the GDAL tutorials. The first example in C and C++ have the same error as your code, pszFilename is not initialized [https://www.gdal.org/gdal_tutorial.html]. It is not supposed to be a full source code sample, but anyway...

    Yeah I will take the C++ tutorials/exercise. But I need to try a bit the
    Gdal capability. I just want to try it first hand by follow the tutorial,
    but it seem there is not many example that allow to see the running of
    complete code. Did you have any GDAL sample that can share with me?

The code that I wrote for GDAL is for format-drivers (BYN, RST, GEORASTER, INGR) and GDAL driver code are usually too complex and not good example, if what you want is to developer application based on the GDAL public API.

But we do have some good code sample in other programming language that might be of you interest:

https://github.com/OSGeo/gdal/tree/master/gdal/swig/csharp/apps

https://github.com/OSGeo/gdal/tree/master/gdal/swig/java/apps

https://github.com/OSGeo/gdal/tree/master/gdal/swig/python/samples

Best regards,

Ivan








From tobias.wendorff at tu-dortmund.de  Fri Nov  2 09:33:07 2018
From: tobias.wendorff at tu-dortmund.de (Tobias Wendorff)
Date: Fri, 2 Nov 2018 17:33:07 +0100
Subject: [gdal-dev] GeoTIFF: embedd JPEG without recompression
Message-ID: <099fcd1bb548a3c9612afbed220ae294.squirrel@webmail.tu-dortmund.de>

Hi there,

can "gdal_translate" embedd a JPEG file in TIFF without recompression?

Best regards,
Tobias


From even.rouault at spatialys.com  Fri Nov  2 10:40:59 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 02 Nov 2018 18:40:59 +0100
Subject: [gdal-dev] GeoTIFF: embedd JPEG without recompression
In-Reply-To: <099fcd1bb548a3c9612afbed220ae294.squirrel@webmail.tu-dortmund.de>
References: <099fcd1bb548a3c9612afbed220ae294.squirrel@webmail.tu-dortmund.de>
Message-ID: <2494518.52kTumCfkN@even-i700>

On vendredi 2 novembre 2018 17:33:07 CET Tobias Wendorff wrote:
> Hi there,
> 
> can "gdal_translate" embedd a JPEG file in TIFF without recompression?

Yes, this is limited to a single JPEG file as a source (not a VRT of several 
JPEG files for example), and if you use -co COMPRESS=JPEG without an explicit 
-co QUALITY setting. -co TILED=YES is supported.

If you add "--debug GTiff", you'll see a "GTiff: Using special copy mode from 
a JPEG dataset" debug message when this direct mode is used.

$ gdal_translatenin.jpg out.tif -co compress=jpeg --debug GTiff
Input file size is 50, 50
GTiff: Using special copy mode from a JPEG dataset

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From andrew.bell.ia at gmail.com  Fri Nov  2 13:32:29 2018
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Fri, 2 Nov 2018 16:32:29 -0400
Subject: [gdal-dev] Linking proj statically/dynamically
Message-ID: <CACJ51z1846WBQQYigta4eJ+jHXMS=4irEUGqrnn9qFcTRSJwUQ@mail.gmail.com>

Hi,

I'm trying to figure out what might be going on with setting things up for
proj with GDAL.  If I set
--with-proj=/directory/to/where/proj/is/installed, I end up with
PROJ_STATIC set to true, even though I have no static proj library built (I
only have libproj.so, no libproj.a in the install directory).  Looking at
configure.ac, I'm not seeing anything that would explicitly check for a
static library at all, just a bunch of checks for a proj library of various
incarnations in various directories relative to the one I set in
--with-proj.

At the conclusion of configuration, GDALmake.opt sets LIBS includes the
proper information to link:

LIBS = ... -L/directory/to/where/proj/is/installed/lib -lproj ...

But no rpath is entered to support locating the proj library when linking
another project with GDAL, which means that I get errors at link time
asking for me to add --rpath-link to my link line.

What, exactly, is --with-proj supposed to do and how does it interact with
static linking of proj, assuming I have libproj.a somewhere?

Thanks,

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181102/a9a19104/attachment.html>

From even.rouault at spatialys.com  Fri Nov  2 13:45:54 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 02 Nov 2018 21:45:54 +0100
Subject: [gdal-dev] Linking proj statically/dynamically
In-Reply-To: <CACJ51z1846WBQQYigta4eJ+jHXMS=4irEUGqrnn9qFcTRSJwUQ@mail.gmail.com>
References: <CACJ51z1846WBQQYigta4eJ+jHXMS=4irEUGqrnn9qFcTRSJwUQ@mail.gmail.com>
Message-ID: <2093063.opnpedNmCf@even-i700>

On vendredi 2 novembre 2018 16:32:29 CET Andrew Bell wrote:
> Hi,
> 
> I'm trying to figure out what might be going on with setting things up for
> proj with GDAL.  If I set
> --with-proj=/directory/to/where/proj/is/installed, I end up with
> PROJ_STATIC set to true, even though I have no static proj library built (I
> only have libproj.so, no libproj.a in the install directory).  Looking at
> configure.ac, I'm not seeing anything that would explicitly check for a
> static library at all, just a bunch of checks for a proj library of various
> incarnations in various directories relative to the one I set in
> --with-proj.
> 

The 'static' here is not to be understood as linking against a static library, 
but linking at build time against a .a or .so. To be opposed to the default 
mode which uses dlopen()

> At the conclusion of configuration, GDALmake.opt sets LIBS includes the
> proper information to link:
> 
> LIBS = ... -L/directory/to/where/proj/is/installed/lib -lproj ...
> 
> But no rpath is entered to support locating the proj library when linking
> another project with GDAL, which means that I get errors at link time
> asking for me to add --rpath-link to my link line.

AFAIK GDAL never sets rpath

> 
> What, exactly, is --with-proj supposed to do and how does it interact with
> static linking of proj, assuming I have libproj.a somewhere?

--with-proj should behave similarly to linking against other libraries if 
you've only .so, only .a or both (in later case, not sure which one will be 
choosen, but that will be whatever the linker does in those cases)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tobias.wendorff at tu-dortmund.de  Fri Nov  2 13:50:41 2018
From: tobias.wendorff at tu-dortmund.de (Tobias Wendorff)
Date: Fri, 2 Nov 2018 21:50:41 +0100
Subject: [gdal-dev] GeoTIFF: embedd JPEG without recompression
In-Reply-To: <2494518.52kTumCfkN@even-i700>
References: <099fcd1bb548a3c9612afbed220ae294.squirrel@webmail.tu-dortmund.de>
 <2494518.52kTumCfkN@even-i700>
Message-ID: <8c242e24b6601c3cb5e6cf4b2fc7ef68.squirrel@webmail.tu-dortmund.de>

Am Fr, 2.11.2018, 18:40 schrieb Even Rouault:
>
> Yes, this is limited to a single JPEG file as a source (not a VRT of
> several JPEG files for example), and if you use -co COMPRESS=JPEG
> without an explicit -co QUALITY setting. -co TILED=YES is supported.

Yeeks, it also gets "jpeg:sampling-factor" correctly! Good work.
It's even doing it better than ImageMagick!

I now can use GDAL to create TIFFs for printing images on canvas.
JPEG can't handle dimensions (millimeters and DPI) correctly, while
TIFF can. Add this to GDAL's use-cases, please :-)

Thanks, good work!


From andrew.bell.ia at gmail.com  Fri Nov  2 15:49:27 2018
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Fri, 2 Nov 2018 18:49:27 -0400
Subject: [gdal-dev] Linking proj statically/dynamically
In-Reply-To: <2093063.opnpedNmCf@even-i700>
References: <CACJ51z1846WBQQYigta4eJ+jHXMS=4irEUGqrnn9qFcTRSJwUQ@mail.gmail.com>
 <2093063.opnpedNmCf@even-i700>
Message-ID: <CACJ51z1hXVCMZBd9H-FgwE_qQxYotHsfz2VaffAjqi2-i3qjjQ@mail.gmail.com>

On Fri, Nov 2, 2018 at 4:45 PM Even Rouault <even.rouault at spatialys.com>
wrote:

> On vendredi 2 novembre 2018 16:32:29 CET Andrew Bell wrote:
> > Hi,
> >
> > I'm trying to figure out what might be going on with setting things up
> for
> > proj with GDAL.  If I set
> > --with-proj=/directory/to/where/proj/is/installed, I end up with
> > PROJ_STATIC set to true, even though I have no static proj library built
> (I
> > only have libproj.so, no libproj.a in the install directory).  Looking at
> > configure.ac, I'm not seeing anything that would explicitly check for a
> > static library at all, just a bunch of checks for a proj library of
> various
> > incarnations in various directories relative to the one I set in
> > --with-proj.
> >
>
> The 'static' here is not to be understood as linking against a static
> library,
> but linking at build time against a .a or .so. To be opposed to the
> default
> mode which uses dlopen().
>

This is confuing.  Perhaps changing the name of the macro would be
helpful.  I could do this if nobody minds.


> > At the conclusion of configuration, GDALmake.opt sets LIBS includes the
> > proper information to link:
> >
> > LIBS = ... -L/directory/to/where/proj/is/installed/lib -lproj ...
> >
> > But no rpath is entered to support locating the proj library when linking
> > another project with GDAL, which means that I get errors at link time
> > asking for me to add --rpath-link to my link line.
>
> AFAIK GDAL never sets rpath
>

In this case, since you're providing a SPECIFIC library path at
configuration, it would seem reasonable to store that information in the
created GDAL library.  Otherwise, I'm not sure what the point is, since you
can provide a library search path at link time through the environment.

> What, exactly, is --with-proj supposed to do and how does it interact with
> > static linking of proj, assuming I have libproj.a somewhere?
>
> --with-proj should behave similarly to linking against other libraries if
> you've only .so, only .a or both (in later case, not sure which one will
> be
> choosen, but that will be whatever the linker does in those cases)
>

Why is proj special?  Why is it not always linked to the GDAL library like
so many other things?  Why would one want to dlopen() proj instead of
having it located as other libraries are located at link/runtime?  I'm sure
there's a reason ;)

Thanks,

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181102/17f727ae/attachment.html>

From even.rouault at spatialys.com  Sat Nov  3 00:30:27 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 03 Nov 2018 08:30:27 +0100
Subject: [gdal-dev] Linking proj statically/dynamically
In-Reply-To: <CACJ51z1hXVCMZBd9H-FgwE_qQxYotHsfz2VaffAjqi2-i3qjjQ@mail.gmail.com>
References: <CACJ51z1846WBQQYigta4eJ+jHXMS=4irEUGqrnn9qFcTRSJwUQ@mail.gmail.com>
 <2093063.opnpedNmCf@even-i700>
 <CACJ51z1hXVCMZBd9H-FgwE_qQxYotHsfz2VaffAjqi2-i3qjjQ@mail.gmail.com>
Message-ID: <37595709.p7izePgCv3@even-i700>

> 
> This is confuing.  Perhaps changing the name of the macro would be
> helpful.  I could do this if nobody minds.
> 

Feel free to do so

> In this case, since you're providing a SPECIFIC library path at
> configuration, it would seem reasonable to store that information in the
> created GDAL library.  Otherwise, I'm not sure what the point is, since you
> can provide a library search path at link time through the environment.

I see that there's an explicit --with-jvm-lib-add-rpath switch

> 
> Why is proj special?  Why is it not always linked to the GDAL library like
> so many other things?  Why would one want to dlopen() proj instead of
> having it located as other libraries are located at link/runtime?  I'm sure
> there's a reason ;)

I believe initially it was envisionned that PROJ could be replaced by another 
projection engine, and dlopen() would have figured which one was available. 
This never happened. Anyway the dlopen() thing will go away when I'm going to 
integrate the PROJ 6/master into GDAL, which will become anyway a required 
dependency of GDAL.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nicolas.cadieux at archeotec.ca  Mon Nov  5 09:22:29 2018
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Mon, 5 Nov 2018 12:22:29 -0500
Subject: [gdal-dev] Introduction to the python API
Message-ID: <21d921f3-1f19-c3f1-01d1-08f3b63af1d7@archeotec.ca>

Hi,

I am a self-taught python programmer trying to get a handle on the 
latest Python GDAL api.  I use the Cookbook 
(https://pcjericks.github.io/py-gdalogr-cookbook/index.html) but I am 
not sure it's up to date (version 1x???).  What books, sites or 
cookbooks do you recommend that would help me out? I have been googling 
for a while but keep on hitting outdated information and courses.

Thanks,

Nicolas


From junt0015 at umn.edu  Mon Nov  5 11:21:14 2018
From: junt0015 at umn.edu (Thomas Juntunen)
Date: Mon, 5 Nov 2018 13:21:14 -0600
Subject: [gdal-dev] Introduction to the python API
In-Reply-To: <21d921f3-1f19-c3f1-01d1-08f3b63af1d7@archeotec.ca>
References: <21d921f3-1f19-c3f1-01d1-08f3b63af1d7@archeotec.ca>
Message-ID: <CAF028HWTjCEiboDg7_qiJ5gNtYLxuKVDLmVe45ROAP1VaFbu-A@mail.gmail.com>

This resource was linked to very recently on this mailing list. I've found
it quite informative:
https://github.com/OSGeo/gdal/tree/master/gdal/swig/python/samples

Thomas

On Mon, Nov 5, 2018 at 11:22 AM, Nicolas Cadieux <
nicolas.cadieux at archeotec.ca> wrote:

> Hi,
>
> I am a self-taught python programmer trying to get a handle on the latest
> Python GDAL api.  I use the Cookbook (https://pcjericks.github.io/p
> y-gdalogr-cookbook/index.html) but I am not sure it's up to date (version
> 1x???).  What books, sites or cookbooks do you recommend that would help me
> out? I have been googling for a while but keep on hitting outdated
> information and courses.
>
> Thanks,
>
> Nicolas
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev




-- 
*The right coordinate system can turn an impossible problem into two really
hard problems. -- Charlie Pellerin*

Thomas Juntunen
GIS Specialist
Polar Geospatial Center
R280 Learning and Environmental Science
1954 Buford Ave
University of Minnesota
St. Paul, MN 55108
612-626-0505
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181105/94d1d156/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Mon Nov  5 14:25:16 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Mon, 5 Nov 2018 15:25:16 -0700 (MST)
Subject: [gdal-dev] GTiff split to smaller tiles,
 GDALTranslateOptions: Unknown option name -srcwin
In-Reply-To: <1541153812435-0.post@n6.nabble.com>
References: <1541153812435-0.post@n6.nabble.com>
Message-ID: <1541456716254-0.post@n6.nabble.com>

Carsten L wrote
> Hi,
> 
> i created an issue on github for my problem / question, but maybe it is
> better to write it here to you.
> 
> https://github.com/OSGeo/gdal/issues/1066
> I think, there is a good description for my problem.
> Is it a bug or am I doing something wrong?
> 
> Or is there another way to split huge geotiff files to smaller tiles (e.g.
> 5000 x 5000 pixel), without using python?
> 
> Thanks in advance,
> Carsten


Hi,

Unfortunately there does not seem to be many users who are familiar with
GDAL.NET nuget package and using C# bindings. Perhaps adding a bit more
about your problem into the mail could help. People are sometimes lazy in
following links.

Other options probably include a little bit of scripting about
gdal_translate, and using C++. And as far as I know QGIS has a special
splitting tool for that purpose.

-Jukka Rahkonen-




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From neteler at osgeo.org  Mon Nov  5 21:09:46 2018
From: neteler at osgeo.org (Markus Neteler)
Date: Tue, 6 Nov 2018 06:09:46 +0100
Subject: [gdal-dev] GTiff split to smaller tiles,
 GDALTranslateOptions: Unknown option name -srcwin
In-Reply-To: <1541456716254-0.post@n6.nabble.com>
References: <1541153812435-0.post@n6.nabble.com>
 <1541456716254-0.post@n6.nabble.com>
Message-ID: <CALFmHhtVWJ=dzo0+GEo-1X6R59Wg3rPtZQgeTCrSLw_FeZf2bw@mail.gmail.com>

Am Mo., 5. Nov. 2018, 23:25 hat jratike80 <
jukka.rahkonen at maanmittauslaitos.fi> geschrieben:

> Carsten L wrote
>
...

> >
> > Or is there another way to split huge geotiff files to smaller tiles
> (e.g.
> > 5000 x 5000 pixel), without using python?



You can do that easily with GRASS GIS, using

https://grass.osgeo.org/grass74/manuals/r.tile.html

Best
Markus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181106/868cd4b1/attachment.html>

From parthivpradeep at gmail.com  Tue Nov  6 02:08:14 2018
From: parthivpradeep at gmail.com (Pradeep kumar)
Date: Tue, 6 Nov 2018 11:08:14 +0100
Subject: [gdal-dev] gdaladdo taking very long time to build overviews for
	large extent mosaic.
Message-ID: <CAL9U1WuT8X-U8FWievL_xkG2atMUa6eAgtppOncsumO1jBbBvg@mail.gmail.com>

Dear gdal-dev team,

we have to build a mosaic for 350 aerial images. These images are gray
images and have an alpha band. The avg size of  each images is 24000x24000.
The size of final mosaic would be  1676843x1441203. The coordinate system
of input images and final mosaic is EPSG:25832

First approach: virtual mosaic, gdal_translate, gdaladdo
first built a virtual mosaic for all input images with the command
```gdalbuildvrt virtualmosaic.vrt ./*.tif```
This process was fast

``` gdal_translate virtualmosaic.vrt mosaic.tif -ot Byte -of GTiff -co
TILED=YES -co COMPRESS=JPEG  -co BIGTIFF=YES -a_srs EPSG:25832```
This process took almost one and a half days

```gdaladdo -r average --config COMPRESS_OVERVIEW JPEG --config
PHOTOMETRIC_OVERVIEW MINISBLACK --config INTERLEAVE_OVERVIEW PIXEL --config
GDAL_TIFF_OVER_BLOCKSIZE 256 --config BIGTIFF_OVERVIEW YES mosaic.tif 2 4 8
16 32 64 128 256 512 1024 2048 4096 8192```
This was taking way too much time. After three weeks of processing, it did
not even showed any progress on terminal. The mosaic image size is
increasing very slowly (it increased 40 kb in three weeks). We checked
htop. It was using less than 2 percent of cpu processing. Most of the time
the process status id D in red color.
[image: image.png]

This process was taking too much time so we tried the second approach.

Second approach: The idea is to build a mosaic with gdalwarp and build the
overviews with gdaladdo
mosaic command
```gdalwarp -of GTiff -co COMPRESS=JPEG -co TILED=YES -co BIGTIFF=YES
images_path/*.tif image_path/mosaic.tif```
This process was too slow. It was taking around 30 hours to merge one
image. So we thought it would take a long time merge 350 images and build
overviews so we stopped there.

Third approach: We divided all images into 8 sets. First we mosaiced
neighborhood sets using gdalwarp. This process was fast. We followed same
way for next 4 sets. Finally we mosaiced all images with gdalwarp in a few
days. Then we started building overviews with gdaladdo. Again building
overviews was very slow.

We tried with -multi option, increasing the cache memory --config
GDAL_CACHEMAX xxx and -WM xxx but nothing helped us.

Our first and second approach worked well when we mosaiced a few images or
the mosaic extent was small but it is taking too much time to create mosaic
of a large extent.

We have a quite powerful processing machine available which has 20
processing cores and 120 GB RAM.

Finally our questions are:

1) Is there any flaw in our approach to build overviews?
2) If our approach is fine then why it is taking too much time to process
and how we can increase the processing speed?
3) How can we run gdal commands using effectively multiple cores?


Best Regards,
Pradeep Gulla
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181106/bd8d8048/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 55801 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181106/bd8d8048/attachment-0001.png>

From even.rouault at spatialys.com  Tue Nov  6 02:31:07 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 06 Nov 2018 11:31:07 +0100
Subject: [gdal-dev] gdaladdo taking very long time to build overviews
	for large extent mosaic.
In-Reply-To: <CAL9U1WuT8X-U8FWievL_xkG2atMUa6eAgtppOncsumO1jBbBvg@mail.gmail.com>
References: <CAL9U1WuT8X-U8FWievL_xkG2atMUa6eAgtppOncsumO1jBbBvg@mail.gmail.com>
Message-ID: <308304781.jEyKFYfJS9@even-i700>

On mardi 6 novembre 2018 11:08:14 CET Pradeep kumar wrote:
> Dear gdal-dev team,
> 
> we have to build a mosaic for 350 aerial images. These images are gray
> images and have an alpha band. The avg size of  each images is 24000x24000.
> The size of final mosaic would be  1676843x1441203. The coordinate system
> of input images and final mosaic is EPSG:25832
> 
> First approach: virtual mosaic, gdal_translate, gdaladdo
> first built a virtual mosaic for all input images with the command
> ```gdalbuildvrt virtualmosaic.vrt ./*.tif```
> This process was fast
> 
> ``` gdal_translate virtualmosaic.vrt mosaic.tif -ot Byte -of GTiff -co
> TILED=YES -co COMPRESS=JPEG  -co BIGTIFF=YES -a_srs EPSG:25832```
> This process took almost one and a half days
> 
> ```gdaladdo -r average --config COMPRESS_OVERVIEW JPEG --config
> PHOTOMETRIC_OVERVIEW MINISBLACK --config INTERLEAVE_OVERVIEW PIXEL --config
> GDAL_TIFF_OVER_BLOCKSIZE 256 --config BIGTIFF_OVERVIEW YES mosaic.tif 2 4 8
> 16 32 64 128 256 512 1024 2048 4096 8192```
> This was taking way too much time. After three weeks of processing, it did
> not even showed any progress on terminal. The mosaic image size is
> increasing very slowly (it increased 40 kb in three weeks). We checked
> htop. It was using less than 2 percent of cpu processing. Most of the time
> the process status id D in red color.

Yes, this is a well known issue due to costly 'context switching' in the 
libtiff library. A solution is to create external overviews, and one level at 
a time, and repeat the creation of a new level on the .ovr of the previous 
level.

So:
gdaladdo -ro [options here] mosaic.tif 2 (actually you can do it on the .vrt 
file directly to, and rename the .vrt.ovr as mosaic.tif.ovr)
gdaladdo -ro [options here] mosaic.tif.ovr 2
gdaladdo -ro [options here] mosaic.tif.ovr.ovr 2
gdaladdo -ro [options here] mosaic.tif.ovr.ovr.ovr 2
etc

If you want a single file at the end, you then do:

gdal_translate mosaic.tif final.tif -co COPY_SRC_OVERVIEWS=YES [other options]

In that case, you'd better drop the JPEG compression in the first 
gdal_translate and gdaladdo steps, and only apply it in the final stage.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nik at nikosalexandris.net  Tue Nov  6 02:53:10 2018
From: nik at nikosalexandris.net (Nikos Alexandris)
Date: Tue, 6 Nov 2018 11:53:10 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
Message-ID: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>

Dear list,

the projection "Bertin 1953" was recently added in Proj4 [0]

[0] https://github.com/OSGeo/proj.4/blob/master/src/PJ_bertin1953.c

What would be the fastest way to try this out, except of compiling all
Proj4 and GDAL from source, then re-compile whatever tool uses GDAL
again?

Thank you, Nikos


From even.rouault at spatialys.com  Tue Nov  6 03:07:18 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 06 Nov 2018 12:07:18 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
Message-ID: <3348551.Gf7FvRyFPS@even-i700>

On mardi 6 novembre 2018 11:53:10 CET Nikos Alexandris wrote:
> Dear list,
> 
> the projection "Bertin 1953" was recently added in Proj4 [0]
> 
> [0] https://github.com/OSGeo/proj.4/blob/master/src/PJ_bertin1953.c
> 
> What would be the fastest way to try this out, except of compiling all
> Proj4 and GDAL from source, then re-compile whatever tool uses GDAL
> again?

You just need to recompile PROJ.
You can then use it in your existing GDAL (providing it links to the 
recompiled PROJ) with
"+proj=bertin1953 +wktext"
(the key is to add +wktext to the PROJ string)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From astewart at terragotech.com  Tue Nov  6 13:16:04 2018
From: astewart at terragotech.com (Alan Stewart)
Date: Tue, 6 Nov 2018 21:16:04 +0000
Subject: [gdal-dev] adding a new method to OGRFieldDefn & gdalautotest
Message-ID: <BN3PR15MB085035E93E84FC9FB87A153EC4CB0@BN3PR15MB0850.namprd15.prod.outlook.com>

I'm working in Windows 7 with VS 2017 and Python 2.7.15.

I've added a new method to this class,  and wish to add tests for it to gdalautotest. I found and added the new method to swig/python/osgeo/ogr.py. Is there anything else I need to do to add python support for my new class method?

The current errors I get when calling it from my new test seems to indicate I need to do something further to get swig to recognize it, though after rebuilding the new method does appear in my python's Lib/site-packages/GDAL-2.3.0-py2.7-win32.egg/osgeo/ogr.py.

The test (so far):

def ogr_fgdb_26():

    try:
        shutil.rmtree('tmp/aliasname.gdb')
    except OSError:
        pass
    gdaltest.unzip('tmp', 'data/aliasname.gdb.zip')
    if not os.path.exists('data/aliasname.gdb'):
        gdaltest.post_reason('failure to unzip archive')
        return 'fail'

    ds = ogr.Open('data/aliasname.gdb')
    if not ds:
        gdaltest.post_reason('failure to open dataset')
        return 'fail'

    ## retrieve and test table
    table00 = ds.GetLayerByName('table00')
    layerDefn = table00.GetLayerDefn()
    fieldDfn = layerDefn.GetFieldDefn(layerDefn.GetFieldIndex('has_alias'))
    name = fieldDfn.GetName()
    alias = fieldDfn.GetAliasName()
    print('name: {0} alias: {1}'.format(name, alias))

The runtime error:

Traceback (most recent call last):
  File "../pymod\gdaltest_python2.py", line 43, in run_func
    result = func()
  File "C:\devel\GitHub\gdal\autotest\ogr\ogr_fgdb.py", line 2626, in ogr_fgdb_26
    alias = fieldDfn.GetAliasName()
  File "C:\Python27\lib\site-packages\gdal-2.3.0-py2.7-win32.egg\osgeo\ogr.py", line 5415, in <lambda>
    __getattr__ = lambda self, name: _swig_getattr(self, FieldDefn, name)
  File "C:\Python27\lib\site-packages\gdal-2.3.0-py2.7-win32.egg\osgeo\ogr.py", line 74, in _swig_getattr
    return _swig_getattr_nondynamic(self, class_type, name, 0)
  File "C:\Python27\lib\site-packages\gdal-2.3.0-py2.7-win32.egg\osgeo\ogr.py", line 69, in _swig_getattr_nondynamic
    return object.__getattr__(self, name)
AttributeError: type object 'object' has no attribute '__getattr__'


Alan Stewart
Senior Software Engineer
TerraGo Technologies
3200 Windy Hill Road, Suite 1550W
Atlanta, GA 30339 USA
O.  +1 678.391.9615

www.terragotech.com<applewebdata://B24C0762-C7C9-4431-8518-ACC915448B89/www.terragotech.com>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181106/982b0efd/attachment.html>

From even.rouault at spatialys.com  Tue Nov  6 13:26:22 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 06 Nov 2018 22:26:22 +0100
Subject: [gdal-dev] adding a new method to OGRFieldDefn & gdalautotest
In-Reply-To: <BN3PR15MB085035E93E84FC9FB87A153EC4CB0@BN3PR15MB0850.namprd15.prod.outlook.com>
References: <BN3PR15MB085035E93E84FC9FB87A153EC4CB0@BN3PR15MB0850.namprd15.prod.outlook.com>
Message-ID: <1993811.dzJz356KHc@even-i700>

On mardi 6 novembre 2018 21:16:04 CET Alan Stewart wrote:
> I'm working in Windows 7 with VS 2017 and Python 2.7.15.
> 
> I've added a new method to this class,  and wish to add tests for it to
> gdalautotest. I found and added the new method to swig/python/osgeo/ogr.py.
> Is there anything else I need to do to add python support for my new class
> method?

As the header of this file warns it, this is a generated file that you 
shouldn't edit. Adding new methods in it is not sufficient. Code must also be 
added swig/python/extensions/ogr_wrap.cpp.
So edit swig/include/ogr.i to define your new method there, and run "make 
generate" in swig/python (you need SWIG to be available) (or "nmake /f 
makefile.vc python" from swig/ on Windows)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From mohdfathin3293 at gmail.com  Tue Nov  6 17:33:50 2018
From: mohdfathin3293 at gmail.com (Athin)
Date: Tue, 6 Nov 2018 18:33:50 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
Message-ID: <1541554430069-0.post@n6.nabble.com>

Hai Ivan,

May i know the function of the swig(c#) that you share to me? 

Thank you and best regards



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From nik at nikosalexandris.net  Tue Nov  6 22:49:48 2018
From: nik at nikosalexandris.net (Nikos Alexandris)
Date: Wed, 7 Nov 2018 07:49:48 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <3348551.Gf7FvRyFPS@even-i700>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
 <3348551.Gf7FvRyFPS@even-i700>
Message-ID: <20181107064948.bqi77r2qg54fc33u@imap.dreamhost.com>

Nikos wrote:

>> the projection "Bertin 1953" was recently added in Proj4 [0]
>>
>> [0] https://github.com/OSGeo/proj.4/blob/master/src/PJ_bertin1953.c
>>
>> What would be the fastest way to try this out, except of compiling all
>> Proj4 and GDAL from source, then re-compile whatever tool uses GDAL
>> again?

Even:

>You just need to recompile PROJ.
>You can then use it in your existing GDAL (providing it links to the
>recompiled PROJ) with
>"+proj=bertin1953 +wktext"
>(the key is to add +wktext to the PROJ string)

Merci Even,

I compiled Proj.4 sourced from https://github.com/OSGeo/proj.4.git
(including wget
https://github.com/OSGeo/proj-datumgrid/archive/1.8.tar.gz in a
subdirectory, placed under the root directory of the above, named 'nad')

Confirming I do use "my" proj version (also, I removed the one available
in "my" distro's repository):
```
whereis proj
proj: /usr/local/bin/proj /usr/share/proj
```

and
```
proj --version
Rel. 6.0.0, March 1st, 2019
<proj>:
invalid option: --
program abnormally terminated
```

I can then list it:
```
proj -lp |grep bertin
bertin1953 : Bertin 1953
```

And query further:
```
proj -l=bertin1953
bertin1953 : Bertin 1953
        Misc Sph no inv.
```

Then some tests to confirm(?) the definition is usable:
```
echo 12 55 0 0 | cct "+proj=bertin1953 +wktext"
 -242763.3626   1451842.4684        0.0000        0.0000
```

and
```
echo 12 55 0 0 | proj "+proj=bertin1953 +wktext"
Rel. 6.0.0, March 1st, 2019
<proj>:
projection initialization failure
cause: unknown projection id
program abnormally terminated
```

or using the following map
```
file TM_WORLD_BORDERS_SIMPL-0.3.shp
TM_WORLD_BORDERS_SIMPL-0.3.shp: ESRI Shapefile version 1000 length 224094 type Polygon
```
`ogr2ogr` segfaults:
```
ogr2ogr -t_srs "+proj=bertin1953 +wktext" TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp TM_WORLD_BORDERS_SIMPL-0.3.shp
ERROR 6: Failed to initialize PROJ.4 with `+proj=bertin1953 +wktext'.
Segmentation fault
```

Thank you, Nikos

--
Note, in https://trac.osgeo.org/gdal/wiki/FAQCoordinateSystemsAndProjections#WhatareWellKnownTextprojectionsandhowdoIusethem
there is a broken link (to): https://www.gdal.org/ogr/osr_tutorial.html

From even.rouault at spatialys.com  Wed Nov  7 03:10:19 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 07 Nov 2018 12:10:19 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <20181107064948.bqi77r2qg54fc33u@imap.dreamhost.com>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
 <3348551.Gf7FvRyFPS@even-i700>
 <20181107064948.bqi77r2qg54fc33u@imap.dreamhost.com>
Message-ID: <2929579.Dc3uFIaxCl@even-i700>

> ```
> echo 12 55 0 0 | proj "+proj=bertin1953 +wktext"
> Rel. 6.0.0, March 1st, 2019
> <proj>:
> projection initialization failure
> cause: unknown projection id
> program abnormally terminated
> ```

'proj' syntax is without quoting. And you only need +wktext for GDAL, not for 
PROJ utilities

> 
> or using the following map
> ```
> file TM_WORLD_BORDERS_SIMPL-0.3.shp
> TM_WORLD_BORDERS_SIMPL-0.3.shp: ESRI Shapefile version 1000 length 224094
> type Polygon ```
> `ogr2ogr` segfaults:
> ```
> ogr2ogr -t_srs "+proj=bertin1953 +wktext"
> TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp TM_WORLD_BORDERS_SIMPL-0.3.shp
> ERROR 6: Failed to initialize PROJ.4 with `+proj=bertin1953 +wktext'.
> Segmentation fault
> ```
> 

It is likely you have an issue with GDAL linking also against your system 
PROJ. Has it been compiled --with-static-proj / --with-proj or not ? Check 
with ldd which libproj libgdal links against. You may need to adjust your 
LD_LIBRARY_PATH and potentially create a symbolic link from the new 
libproj.so.xxxx to the name of the old libproj.so.yyyyy so that GDAL sees one 
and one single libproj.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jsalerno at westongeo.com  Wed Nov  7 05:06:00 2018
From: jsalerno at westongeo.com (Jeremy Salerno)
Date: Wed, 7 Nov 2018 08:06:00 -0500
Subject: [gdal-dev] gdal_merge.py not executing or found
Message-ID: <CAELRdYOFjRwAjkuEssz9NDC3B+RVyFhL_hbyMJyA2YcXvfWT9w@mail.gmail.com>

Hi All,

When I type gdal_merge.py into Terminal, the output is -bash:
gdal_merge.py: command not found.

I installed 3.4.0 Madeira [from this link] for macOS 10.13 (
https://www.qgis.org/en/site/forusers/download), which came with a gdal
installer.

I cannot even find the gdal_merge.py file in
/Library/Frameworks/GDAL.framework/Versions/Current/Programs/ or anywhere
else in the gdal framework directory. I looked to see if I could install
the .py file separately but can't find any installation options on the GDAL
website.


Thanks!

Jeremy

--

Jeremy A. Salerno

Weston Geophysical Corp.
181 Bedford St. Suite #1
Lexington, MA. 02420
jsalerno at westongeo.com



*www.westongeophysical.com* <http://www.westongeophysical.com>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181107/98cb0af8/attachment-0001.html>

From ivan.lucena at outlook.com  Wed Nov  7 05:44:07 2018
From: ivan.lucena at outlook.com (Ivan Lucena)
Date: Wed, 7 Nov 2018 13:44:07 +0000
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541554430069-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
 <1541554430069-0.post@n6.nabble.com>
Message-ID: <BBC87CB3-8662-453C-9945-795033939615@outlook.com>

Hi Athin,

Here it goes again:

https://github.com/OSGeo/gdal/tree/master/gdal/swig/csharp/apps

For more information on GDAL's C# API:

https://trac.osgeo.org/gdal/wiki/GdalOgrInCsharp

Regards,

Ivan

﻿On 11/6/18, 8:34 PM, "gdal-dev on behalf of Athin" <gdal-dev-bounces at lists.osgeo.org on behalf of mohdfathin3293 at gmail.com> wrote:

    Hai Ivan,
    
    May i know the function of the swig(c#) that you share to me? 
    
    Thank you and best regards
    
    
    
    --
    Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
    _______________________________________________
    gdal-dev mailing list
    gdal-dev at lists.osgeo.org
    https://lists.osgeo.org/mailman/listinfo/gdal-dev


From even.rouault at spatialys.com  Wed Nov  7 06:28:00 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 07 Nov 2018 15:28:00 +0100
Subject: [gdal-dev] gdal_merge.py not executing or found
In-Reply-To: <CAELRdYOFjRwAjkuEssz9NDC3B+RVyFhL_hbyMJyA2YcXvfWT9w@mail.gmail.com>
References: <CAELRdYOFjRwAjkuEssz9NDC3B+RVyFhL_hbyMJyA2YcXvfWT9w@mail.gmail.com>
Message-ID: <2902109.XeBJcctUVO@even-i700>

Jeremy,

> I cannot even find the gdal_merge.py file in
> /Library/Frameworks/GDAL.framework/Versions/Current/Programs/ or anywhere
> else in the gdal framework directory.

Should be reported to the creator of the package. I believe this is
William Kyngesburye (CC'ed) but I'm not completely sure.


> I looked to see if I could install
> the .py file separately but can't find any installation options on the GDAL
> website.

You can always download the script from
https://github.com/OSGeo/gdal/blob/master/gdal/swig/python/scripts/gdal_merge.py

(assuming that the GDAL Python bindings are installed)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jsalerno at westongeo.com  Wed Nov  7 06:55:28 2018
From: jsalerno at westongeo.com (Jeremy Salerno)
Date: Wed, 7 Nov 2018 09:55:28 -0500
Subject: [gdal-dev] gdal_merge.py not executing or found
In-Reply-To: <2902109.XeBJcctUVO@even-i700>
References: <CAELRdYOFjRwAjkuEssz9NDC3B+RVyFhL_hbyMJyA2YcXvfWT9w@mail.gmail.com>
 <2902109.XeBJcctUVO@even-i700>
Message-ID: <CAELRdYPakS9s0CXYhwadWYS2LBtyzY9VZ0G3rWr_MAe-NCmRHA@mail.gmail.com>

Thanks for the help Even.

Is there a simple way to check if the python bindings are installed? I
installed GDAL through the QGIS installer. I tried running gdal_merge.py
after downloading the file from github and have had no success.

--

Jeremy A. Salerno

Weston Geophysical Corp.
181 Bedford St. Suite #1
Lexington, MA. 02420
jsalerno at westongeo.com



*www.westongeophysical.com* <http://www.westongeophysical.com>



On Wed, Nov 7, 2018 at 9:28 AM Even Rouault <even.rouault at spatialys.com>
wrote:

> Jeremy,
>
> > I cannot even find the gdal_merge.py file in
> > /Library/Frameworks/GDAL.framework/Versions/Current/Programs/ or anywhere
> > else in the gdal framework directory.
>
> Should be reported to the creator of the package. I believe this is
> William Kyngesburye (CC'ed) but I'm not completely sure.
>
>
> > I looked to see if I could install
> > the .py file separately but can't find any installation options on the
> GDAL
> > website.
>
> You can always download the script from
>
> https://github.com/OSGeo/gdal/blob/master/gdal/swig/python/scripts/gdal_merge.py
>
> (assuming that the GDAL Python bindings are installed)
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181107/95d456c6/attachment.html>

From bishop.dev at gmail.com  Wed Nov  7 07:14:29 2018
From: bishop.dev at gmail.com (Dmitry Baryshnikov)
Date: Wed, 7 Nov 2018 18:14:29 +0300
Subject: [gdal-dev] gdal_merge.py not executing or found
In-Reply-To: <CAELRdYPakS9s0CXYhwadWYS2LBtyzY9VZ0G3rWr_MAe-NCmRHA@mail.gmail.com>
References: <CAELRdYOFjRwAjkuEssz9NDC3B+RVyFhL_hbyMJyA2YcXvfWT9w@mail.gmail.com>
 <2902109.XeBJcctUVO@even-i700>
 <CAELRdYPakS9s0CXYhwadWYS2LBtyzY9VZ0G3rWr_MAe-NCmRHA@mail.gmail.com>
Message-ID: <ba94f57e-be72-d6ab-342d-4410760c91e2@gmail.com>

Hi Jeremy,

You can install QGIS with GDAL and python bindings using alternative 
installer by NextGIS (http://nextgis.com/nextgis-qgis/).

GDAL python bindings working, gdal_merge also included.

This is previous QGIS LTR release 2.18.25, but with fresh GDAL 2.3.2 and 
other libraries. This installation should not affect you current QGIS 
install, but I'm not sure about the opposite.

Best regards,
     Dmitry

07.11.2018 17:55, Jeremy Salerno пишет:
> Thanks for the help Even.
>
> Is there a simple way to check if the python bindings are installed? I
> installed GDAL through the QGIS installer. I tried running gdal_merge.py
> after downloading the file from github and have had no success.
>
> --
>
> Jeremy A. Salerno
>
> Weston Geophysical Corp.
> 181 Bedford St. Suite #1
> Lexington, MA. 02420
> jsalerno at westongeo.com
>
>
>
> *www.westongeophysical.com* <http://www.westongeophysical.com>
>
>
>
> On Wed, Nov 7, 2018 at 9:28 AM Even Rouault <even.rouault at spatialys.com>
> wrote:
>
>> Jeremy,
>>
>>> I cannot even find the gdal_merge.py file in
>>> /Library/Frameworks/GDAL.framework/Versions/Current/Programs/ or anywhere
>>> else in the gdal framework directory.
>> Should be reported to the creator of the package. I believe this is
>> William Kyngesburye (CC'ed) but I'm not completely sure.
>>
>>
>>> I looked to see if I could install
>>> the .py file separately but can't find any installation options on the
>> GDAL
>>> website.
>> You can always download the script from
>>
>> https://github.com/OSGeo/gdal/blob/master/gdal/swig/python/scripts/gdal_merge.py
>>
>> (assuming that the GDAL Python bindings are installed)
>>
>> Even
>>
>> --
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181107/c6c498c1/attachment.html>

From szekerest at gmail.com  Wed Nov  7 11:59:04 2018
From: szekerest at gmail.com (Tamas Szekeres)
Date: Wed, 7 Nov 2018 20:59:04 +0100
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <BBC87CB3-8662-453C-9945-795033939615@outlook.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
 <1541554430069-0.post@n6.nabble.com>
 <BBC87CB3-8662-453C-9945-795033939615@outlook.com>
Message-ID: <CACALY+SMNAa_W1v4YGWn9VJk149t9XpbpdCo6phqyupSywoCBQ@mail.gmail.com>

Packages for GDAL have also been submitted to nuget.org  (GDAL, GDAL.Native
and GDAL.Plugins) which could be referenced in your Visual Studio project
easily.


Best regards,

Tamas

Ivan Lucena <ivan.lucena at outlook.com> ezt írta (időpont: 2018. nov. 7.,
Sze, 14:44):

> Hi Athin,
>
> Here it goes again:
>
> https://github.com/OSGeo/gdal/tree/master/gdal/swig/csharp/apps
>
> For more information on GDAL's C# API:
>
> https://trac.osgeo.org/gdal/wiki/GdalOgrInCsharp
>
> Regards,
>
> Ivan
>
> ﻿On 11/6/18, 8:34 PM, "gdal-dev on behalf of Athin" <
> gdal-dev-bounces at lists.osgeo.org on behalf of mohdfathin3293 at gmail.com>
> wrote:
>
>     Hai Ivan,
>
>     May i know the function of the swig(c#) that you share to me?
>
>     Thank you and best regards
>
>
>
>     --
>     Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
>     _______________________________________________
>     gdal-dev mailing list
>     gdal-dev at lists.osgeo.org
>     https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181107/4cd953d6/attachment-0001.html>

From even.rouault at spatialys.com  Wed Nov  7 12:19:34 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 07 Nov 2018 21:19:34 +0100
Subject: [gdal-dev] adding a new method to OGRFieldDefn & gdalautotest
In-Reply-To: <BN3PR15MB08501BA4D885C8C9CA5F63A9C4C40@BN3PR15MB0850.namprd15.prod.outlook.com>
References: <BN3PR15MB085035E93E84FC9FB87A153EC4CB0@BN3PR15MB0850.namprd15.prod.outlook.com>
 <1993811.dzJz356KHc@even-i700>
 <BN3PR15MB08501BA4D885C8C9CA5F63A9C4C40@BN3PR15MB0850.namprd15.prod.outlook.com>
Message-ID: <2980467.v53Z9dSQJi@even-i700>

On mercredi 7 novembre 2018 19:56:10 CET Alan Stewart wrote:
> Thanks, Even, I certainly didn't read the file header. After making all your
> suggested changes the compiler is erroring on
> swig/python/extensions/gdal_wrap.cpp, which I have not touched.
> 
> I notice it is using " Visual C++ for Python", version 9.0. Is that the
> correct compiler to use?

In theory, yes, but in practice you can force the use of your current MSVC 
version and it happens to work just fine, by setting the following env 
variables

set DISTUTILS_USE_SDK=1
set MSSdk=1

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From gigas002 at yandex.ru  Wed Nov  7 13:05:53 2018
From: gigas002 at yandex.ru (=?utf-8?B?0Jo=?=)
Date: Thu, 08 Nov 2018 00:05:53 +0300
Subject: [gdal-dev] Question: build gdal2tiles.py as exe
Message-ID: <5763661541624753@sas1-adb97d30497b.qloud-c.yandex.net>

Hello! 
I'm trying to bulild gdal2tiles.py as standalone executable by using PyInstaller to use it as process from c# code (because gdal2tiles is'nt exist in bindings).
I tried with both Python 3.7.1 and Python 2.7.15, but the output binary is unable to run or lacks some functionality. For Python3 it runs OK, but throws an exception if i try to use "--processes" parameter.  For Python2 it can't run and says, that it's unable to find 'osgeo' package.
In both cases I used the following command line: pyinstaller D:\gdal\bin\gdal\python\scripts\gdal2tiles.py -D -p "D:\gdal\bin"
To build this version I used Gdal 2.3.2 stable daily release from GisInternals, build with x64 binaries and python on win10 x64.
It'd be great if you would advice me, how to build it as executable or a better way to use gdal2tiles in c# code (with no need to install python on target computer).
Thanks in advance for your reply!

From mohdfathin3293 at gmail.com  Wed Nov  7 16:50:12 2018
From: mohdfathin3293 at gmail.com (Athin)
Date: Wed, 7 Nov 2018 17:50:12 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <CACALY+SMNAa_W1v4YGWn9VJk149t9XpbpdCo6phqyupSywoCBQ@mail.gmail.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
 <1541554430069-0.post@n6.nabble.com>
 <BBC87CB3-8662-453C-9945-795033939615@outlook.com>
 <CACALY+SMNAa_W1v4YGWn9VJk149t9XpbpdCo6phqyupSywoCBQ@mail.gmail.com>
Message-ID: <1541638212107-0.post@n6.nabble.com>

Hai Tamas,

May i know what the package for GDAL at nuget.org (GDAL, GDAL.Native and
GDAL.Plugins) cover? It can fully C# or  i still need ti use C++ then make
extension to C# so that it can use VS Wpf.

Thank you and best regards.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From anna.maria.klimkowska at gmail.com  Wed Nov  7 22:59:48 2018
From: anna.maria.klimkowska at gmail.com (Anna Klimkowska)
Date: Thu, 8 Nov 2018 15:59:48 +0900
Subject: [gdal-dev] GDAL image mosaicing
Message-ID: <CADoyY1w-D878-VM=3y=R+_jHdT5HQLdZ1d1gc_pjY8SBVsw07g@mail.gmail.com>

Hi All,

I am working on blending two georeferenced images. My idea was to open them
in Python using GDAL library , finding the overlapping area and then do
some more work.
I found this book about Geoprocessing with Python where they talk about
convertingpixel coordinates to another image. Unfortunately I stuck at the
beginning. The beggigning of the code looks like this:

def get_extent(fn):
    #Returns min_x, max_y, max_x, min_y
    ds = gdal.Open(fn)
    gt = ds.GetGeoTransform()
    return (gt[0], gt[3], gt[0] + gt[1] * ds.RasterXSize, gt[3] + gt[5] *
ds.RasterYSize)

os.chdir(r'Path_to_images'')
in_files = glob.glob('O*.png')

min_x, max_y, max_x, min_y = get_extent(in_files[0])
# calculate output extent from all inputs
for fn in in_files[1:]:
    minx, maxy, maxx, miny = get_extent(fn)
    min_x = min(min_x, minx)
    max_y = max(max_y, maxy)
    max_x = max(max_x, maxx)
    min_y = min(min_y, miny)

in_ds = gdal.Open(in_files[0])
gt = in_ds.GetGeoTransform()

When I run this code, I receive error:
 min_x, max_y, max_x, min_y = get_extent(in_files[0])

IndexError: list index out of range

My* in_files* are empty.

When I change the way of loading data to:

in_files = [cv2.imread(file) for file in glob.glob('D:/_work(z
pulpitu)/mosaicing/GDAL_test/data/*png')]

My in_files type is a list with two attributes (nuppy_arrays) byt I get the
error:
return _gdal.Open(*args)

RuntimeError: not a string

Can anyone help me with solving this problem?

Thanks,
Ania
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181108/b935510a/attachment.html>

From gigas002 at yandex.ru  Thu Nov  8 13:32:29 2018
From: gigas002 at yandex.ru (Gigas002)
Date: Thu, 8 Nov 2018 14:32:29 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541638212107-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
 <1541554430069-0.post@n6.nabble.com>
 <BBC87CB3-8662-453C-9945-795033939615@outlook.com>
 <CACALY+SMNAa_W1v4YGWn9VJk149t9XpbpdCo6phqyupSywoCBQ@mail.gmail.com>
 <1541638212107-0.post@n6.nabble.com>
Message-ID: <1541712749720-0.post@n6.nabble.com>

Hi Athin,
Not exactly an answer to your question, but there is a good nuget package
for using in c#, called GDAL.NET:
https://www.nuget.org/packages/GDAL.NET/
It contains bindings, automatically added to your project after build gdal's
binary files and GdalConfiguration class that will automatically setup
GDAL/OGR environment variables and paths after you call ConfigureGdal().
About covering of .net gdal, I suppose bindings have been a bit forgotten in
community, and there some really outdated classes, that have only pre-2.0
funcs (take a look at this issue for example):
https://github.com/OSGeo/gdal/issues/918
As for me, I personally use GDAL.NET bindings as a replacement for gdal
utilities (gdal_translate, gdalwarp, gdalbuildvrt etc.), I just prefer to
call them as methods from code, not as process.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From thomas.bonfort at gmail.com  Fri Nov  9 03:47:17 2018
From: thomas.bonfort at gmail.com (thomas bonfort)
Date: Fri, 9 Nov 2018 12:47:17 +0100
Subject: [gdal-dev] Projection error messages when warping from worldwide to
	local projection
Message-ID: <CAOM3y2i+hSrqOF+_DQPD_oAON1P=CabeV1HrR0R3YhjvZeD_Fg@mail.gmail.com>

Hi,
I'm trying to warp an extract of a epsg:3857 tiled layer to a local
transverse mercator projection.

osm.xml:

<GDAL_WMS>
<Service name="TMS">
<ServerUrl>https://a.tile.openstreetmap.org/${z}/${x}/${y}.png</ServerUrl>
</Service>
<DataWindow>
<UpperLeftX>-20037508.34</UpperLeftX>
<UpperLeftY>20037508.34</UpperLeftY>
<LowerRightX>20037508.34</LowerRightX>
<LowerRightY>-20037508.34</LowerRightY>
<TileLevel>18</TileLevel>
<TileCountX>1</TileCountX>
<TileCountY>1</TileCountY>
<YOrigin>top</YOrigin>
</DataWindow>
<Projection>EPSG:3857</Projection>
<BlockSizeX>256</BlockSizeX>
<BlockSizeY>256</BlockSizeY>
<BandsCount>3</BandsCount>
<MaxConnections>5</MaxConnections>
<Cache/>
</GDAL_WMS>

I then run an extract over a 200 meter square:

gdalwarp -r bilinear -t_srs "+proj=tmerc +lon_0=1.45 +ellps=WGS84 +units=m"
-tr 0.5 0.5 -te -100 4826000 100 4826200  osm.xml osm.tif
Creating output file that is 400P x 400L.
Processing osm.xml [1/1] : 0ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: latitude or longitude exceeded limits
ERROR 1: Reprojection failed, err = -14, further errors will be suppressed
on the transform object.
...10...20...30...40...50...60...70...80...90...100 - done.

The generated file at the end is correct, however is there a way to get rid
of these errors/warnings?

Best regards,
Thomas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181109/e7de6e64/attachment.html>

From even.rouault at spatialys.com  Fri Nov  9 06:27:16 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 09 Nov 2018 15:27:16 +0100
Subject: [gdal-dev] Projection error messages when warping from
	worldwide to local projection
In-Reply-To: <CAOM3y2i+hSrqOF+_DQPD_oAON1P=CabeV1HrR0R3YhjvZeD_Fg@mail.gmail.com>
References: <CAOM3y2i+hSrqOF+_DQPD_oAON1P=CabeV1HrR0R3YhjvZeD_Fg@mail.gmail.com>
Message-ID: <3348774.VD6jkmc1Y2@even-i700>

Salut Thomas,

I don't get any warning with GDAL 2.3.2 and PROJ 5.1.0. While investigating, I 
found this is due to the use of the PROJ 5 transformation API that doesn't 
emit an error when an out of domain situation happens when transforming a 
single point (wheras PROJ 4 did), but just returning a HUGE_VAL value.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From thomas.bonfort at gmail.com  Fri Nov  9 06:50:19 2018
From: thomas.bonfort at gmail.com (thomas bonfort)
Date: Fri, 9 Nov 2018 15:50:19 +0100
Subject: [gdal-dev] Projection error messages when warping from
 worldwide to local projection
In-Reply-To: <3348774.VD6jkmc1Y2@even-i700>
References: <CAOM3y2i+hSrqOF+_DQPD_oAON1P=CabeV1HrR0R3YhjvZeD_Fg@mail.gmail.com>
 <3348774.VD6jkmc1Y2@even-i700>
Message-ID: <CAOM3y2gERFX4rZ8UD5txCE+i+ahfHCqLxZm5p2g1xo17WkWz=g@mail.gmail.com>

Salut Even,
Thanks for the quick answer. Sorry I forgot to mention I was using gdal
2.3.2 and proj 4.9.3. I'll upgrade to 5.1.0!

Regards,
Thomas

On Fri, Nov 9, 2018 at 3:27 PM Even Rouault <even.rouault at spatialys.com>
wrote:

> Salut Thomas,
>
> I don't get any warning with GDAL 2.3.2 and PROJ 5.1.0. While
> investigating, I
> found this is due to the use of the PROJ 5 transformation API that doesn't
> emit an error when an out of domain situation happens when transforming a
> single point (wheras PROJ 4 did), but just returning a HUGE_VAL value.
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181109/8c69b843/attachment.html>

From even.rouault at spatialys.com  Fri Nov  9 06:56:05 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 09 Nov 2018 15:56:05 +0100
Subject: [gdal-dev] Projection error messages when warping from
	worldwide to local projection
In-Reply-To: <CAOM3y2gERFX4rZ8UD5txCE+i+ahfHCqLxZm5p2g1xo17WkWz=g@mail.gmail.com>
References: <CAOM3y2i+hSrqOF+_DQPD_oAON1P=CabeV1HrR0R3YhjvZeD_Fg@mail.gmail.com>
 <3348774.VD6jkmc1Y2@even-i700>
 <CAOM3y2gERFX4rZ8UD5txCE+i+ahfHCqLxZm5p2g1xo17WkWz=g@mail.gmail.com>
Message-ID: <4868007.QNj01Ocebd@even-i700>

On vendredi 9 novembre 2018 15:50:19 CET thomas bonfort wrote:
> Salut Even,
> Thanks for the quick answer. Sorry I forgot to mention I was using gdal
> 2.3.2 and proj 4.9.3. I'll upgrade to 5.1.0!

Use 5.2.0 while your are it

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From TimBodin at comcast.net  Fri Nov  9 19:29:26 2018
From: TimBodin at comcast.net (Tim Bodin)
Date: Fri, 9 Nov 2018 21:29:26 -0600
Subject: [gdal-dev] C++ / GDAL - reading raster, exception, access violation,
	help please!
Message-ID: <000001d478a5$954f82e0$bfee88a0$@comcast.net>

I sure hope someone can give me some advice.  I'm modestly experienced with
GIS and spatial stuff, but I'm trying to do rasters in C++ for the first
time.  I've been cobbling experiments together, generally successfully, but
have not consistently been able to get a raster read working, and I don't
know C++ or GDAL deeply enough to understand what to do.

 

Code is snapshotted below.  Using Windows, Visual Studio 2017.  If I enable
the 5 lines in the inner loop near the bottom, I get an Exception/Access
Violation on the "inDS->GetRasterBand(etc)" statement.  If I disable that
section, and specifically that line, it runs to completion without problem.
Can anyone suggest what I might try?  Thanks for helping!

 

*************************

 

#include "stdafx.h"

#include <iostream>

#include <gdal.h>

#include <gdal_priv.h>

#include "cpl_conv.h"

 

using namespace std;

 

int main()

{

       GDALDataset  *inDS;

       GDALAllRegister();

       const char *input = "D:/Imagery/CDLClipped.tif";

       inDS = (GDALDataset*) GDALOpen(input, GA_ReadOnly);

       if (inDS == NULL)

       {

             cout << "unable to open input" << endl;

       }

       int nRows, nCols;

       double transform[6];

       double noData;

       nRows = inDS->GetRasterBand(1)->GetYSize();

       nCols = inDS->GetRasterBand(1)->GetXSize();

       noData = inDS->GetRasterBand(1)->GetNoDataValue();

       inDS->GetGeoTransform(transform);

       cout << "nRows, nCols, noData = " << nRows << ", " << nCols << ", "
<< noData << endl;

       float *inDSRow = (float*)CPLMalloc(sizeof(float)*nCols);

       for (int i = 0; i < 5; i++)

       {

             inDS->GetRasterBand(1)->RasterIO(GF_Read, 0, i, nCols, 1,
inDSRow, nCols, 1, GDT_CFloat32, 0, 0);

             for (int j = 0; j < 5 ; j++)

             {

                    cout << inDSRow[j] << endl;

             }

       }

       cin.ignore();

}

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181109/9159620e/attachment.html>

From even.rouault at spatialys.com  Sat Nov 10 00:33:19 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 10 Nov 2018 09:33:19 +0100
Subject: [gdal-dev] C++ / GDAL - reading raster, exception,
	access violation, help please!
In-Reply-To: <000001d478a5$954f82e0$bfee88a0$@comcast.net>
References: <000001d478a5$954f82e0$bfee88a0$@comcast.net>
Message-ID: <2172912.zmdGfnnKiK@even-i700>

[...]
> 
>        float *inDSRow = (float*)CPLMalloc(sizeof(float)*nCols);
[...]
>              inDS->GetRasterBand(1)->RasterIO(GF_Read, 0, i, nCols, 1,
> inDSRow, nCols, 1, GDT_CFloat32, 0, 0);

The memory allocation and requested datatypes aren't consistent:
- either you really want complex Float32, and then you need 2 floats per 
sample. That is CPLMalloc(2 * sizeof(float) * nCols)
- or you want non-complex Float32, and request GDT_Float32 instead

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Sat Nov 10 07:13:09 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 10 Nov 2018 16:13:09 +0100
Subject: [gdal-dev] Fwd: Re: [Tiff] Libtiff will be released soon
Message-ID: <18143925.OLitUtTB1u@even-i700>

Hi all,

Due to Adobe no longer assigning TIFF tags / tags value, and someone mentionning that
the previously values use for COMPRESSION_ZSTD and COMPRESSION_WEBP were already taken,
those have been just changed:

https://gitlab.com/libtiff/libtiff/commit/126a949736fe8d2684525706e9047b39e2a095a6

I'll resynchronize the internal GDAL copy with that, which means that if you have
existing TIFF file using ZStd / WebP compression, they will no longer be recognized.
I imagine we could come with a hack to still recognize the old values, but I don't
plan to go to that complication unless really needed.

Even

----------  Forwarded Message  ----------

Subject: Re: [Tiff] Libtiff will be released soon
Date: samedi 10 novembre 2018, 09:00:18 CET
From: Bob Friesenhahn <bfriesen at simple.dallas.tx.us>
To: Roger Leigh <rleigh at codelibre.net>
CC: tiff at lists.maptools.org

On Fri, 9 Nov 2018, Roger Leigh wrote:
>
> We could potentially do the same.  Assuming the tags are allocated in a
> linear order, if we jumped all the way to e.g. 50000 we would avoid
> clashes with Adobe tag registration for some time to come.  Or if Adobe
> could grant us a chunk of e.g. 1000 tags, we could manage their usage
> and standardisation ourselves.

I just submitted a changeset such that COMPRESSION_ZSTD is changed to 
50000 and COMPRESSION_WEBP is changed to 50001.

Bob
-- 
Bob Friesenhahn
bfriesen at simple.dallas.tx.us, http://www.simplesystems.org/users/bfriesen/
GraphicsMagick Maintainer,    http://www.GraphicsMagick.org/
_______________________________________________
Tiff mailing list: Tiff at lists.maptools.org
http://lists.maptools.org/mailman/listinfo/tiff
http://www.remotesensing.org/libtiff/

-----------------------------------------
-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tobias.wendorff at tu-dortmund.de  Sat Nov 10 07:21:45 2018
From: tobias.wendorff at tu-dortmund.de (Tobias Wendorff)
Date: Sat, 10 Nov 2018 16:21:45 +0100
Subject: [gdal-dev] Fwd: Re: [Tiff] Libtiff will be released soon
In-Reply-To: <18143925.OLitUtTB1u@even-i700>
References: <18143925.OLitUtTB1u@even-i700>
Message-ID: <409653b8f0008c8c4b1cdac5effd9c11.squirrel@webmail.tu-dortmund.de>

Am Sa, 10.11.2018, 16:13 schrieb Even Rouault:
> I imagine we could come with a hack to still recognize the old values,
> but I don't plan to go to that complication unless really needed.

Not knowing the full topic: can't users with a problem just patch the
magic byte in the header to port them to the new values?


From even.rouault at spatialys.com  Sat Nov 10 07:57:56 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 10 Nov 2018 16:57:56 +0100
Subject: [gdal-dev] Fwd: Re: [Tiff] Libtiff will be released soon
In-Reply-To: <409653b8f0008c8c4b1cdac5effd9c11.squirrel@webmail.tu-dortmund.de>
References: <18143925.OLitUtTB1u@even-i700>
 <409653b8f0008c8c4b1cdac5effd9c11.squirrel@webmail.tu-dortmund.de>
Message-ID: <1859796.BcGLjr3ZCn@even-i700>

On samedi 10 novembre 2018 16:21:45 CET Tobias Wendorff wrote:
> Am Sa, 10.11.2018, 16:13 schrieb Even Rouault:
> > I imagine we could come with a hack to still recognize the old values,
> > but I don't plan to go to that complication unless really needed.
> 
> Not knowing the full topic: can't users with a problem just patch the
> magic byte in the header to port them to the new values?

Sure. That's just what I've done with the few golden files in GDAL autotest.

You can use the following Python script to do the patching.

{{{
#!/usr/bin/env python
import os
import struct
import sys

def patch(filename):
    with open(filename, "rb+") as f:
        magic = f.read(4)
        if magic == b'\x49\x49\x2A\x00':
            # Classic TIFF little endian
            while True:
                dir_offset = struct.unpack('<I', f.read(4))[0]
                if dir_offset == 0:
                    break
                f.seek(dir_offset, os.SEEK_SET)
                num_tags = struct.unpack('<H', f.read(2))[0]
                for i in range(num_tags):
                    tag_name = struct.unpack('<H', f.read(2))[0]
                    f.read(2 + 4) # skip type and count
                    tag_value = struct.unpack('<I', f.read(4))[0]
                    if tag_name == 259: # TIFFTAG_COMPRESSION
                        if tag_value == 34926:
                            print('Patching COMPRESSION_ZSTD to new value')
                            f.seek(-4, os.SEEK_CUR)
                            f.write(struct.pack('<I', (50000)))
                            f.seek(0, os.SEEK_CUR)
                        elif tag_value == 34927:
                            print('Patching COMPRESSION_WEBP to new value')
                            f.seek(-4, os.SEEK_CUR)
                            f.write(struct.pack('<I', (50001)))
                            f.seek(0, os.SEEK_CUR)

        elif magic == b'\x49\x49\x2B\x00':
            # BigTIFF little endian
            f.read(4) # skip
            while True:
                dir_offset = struct.unpack('<Q', f.read(8))[0]
                if dir_offset == 0:
                    break
                f.seek(dir_offset, os.SEEK_SET)
                num_tags = struct.unpack('<Q', f.read(8))[0]
                for i in range(num_tags):
                    tag_name = struct.unpack('<H', f.read(2))[0]
                    f.read(2 + 8) # skip type and count
                    tag_value = struct.unpack('<Q', f.read(8))[0]
                    if tag_name == 259: # TIFFTAG_COMPRESSION
                        if tag_value == 34926:
                            print('Patching COMPRESSION_ZSTD to new value')
                            f.seek(-8, os.SEEK_CUR)
                            f.write(struct.pack('<Q', (50000)))
                            f.seek(0, os.SEEK_CUR)
                        elif tag_value == 34927:
                            print('Patching COMPRESSION_WEBP to new value')
                            f.seek(-8, os.SEEK_CUR)
                            f.write(struct.pack('<Q', (50001)))
                            f.seek(0, os.SEEK_CUR)

        else:
            print('Unrecognized file type')

if __name__ == '__main__':
    patch(sys.argv[1])

}}}



-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From TimBodin at comcast.net  Sat Nov 10 08:09:47 2018
From: TimBodin at comcast.net (timbo1711)
Date: Sat, 10 Nov 2018 09:09:47 -0700 (MST)
Subject: [gdal-dev] C++ / GDAL - reading raster, exception,
 access violation, help please!
In-Reply-To: <2172912.zmdGfnnKiK@even-i700>
References: <000001d478a5$954f82e0$bfee88a0$@comcast.net>
 <2172912.zmdGfnnKiK@even-i700>
Message-ID: <1541866187854-0.post@n6.nabble.com>

Thanks Even!  After a bunch of hours of manipulation last night, I got into
same area of code, and got it running to completion, but data handling /
conversion still needs sorting out.  Your comments are very helpful and
clarifying.  I’m continuing, thx again.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Sun Nov 11 23:57:48 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 12 Nov 2018 08:57:48 +0100
Subject: [gdal-dev] Fwd: Re: [Tiff] Libtiff will be released soon
In-Reply-To: <18143925.OLitUtTB1u@even-i700>
References: <18143925.OLitUtTB1u@even-i700>
Message-ID: <3223589.R8XTpUpJkP@even-i700>

On samedi 10 novembre 2018 16:13:09 CET Even Rouault wrote:
> Hi all,
> 
> Due to Adobe no longer assigning TIFF tags / tags value, and someone
> mentionning that the previously values use for COMPRESSION_ZSTD and
> COMPRESSION_WEBP were already taken, those have been just changed:
> 
> https://gitlab.com/libtiff/libtiff/commit/126a949736fe8d2684525706e9047b39e2
> a095a6
> 
> I'll resynchronize the internal GDAL copy with that, which means that if you
> have existing TIFF file using ZStd / WebP compression, they will no longer
> be recognized.

Not completely sure what to do with GDAL 2.3 branch, as it already had ZStd 
(if using its internal libtiff copy). I feel it is probably wise to also 
update the modified value of COMPRESSION_ZSTD there to avoid the risk of 
people creating files with the now obsolete tag value ?


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From DeDuikertjes at xs4all.nl  Mon Nov 12 00:48:03 2018
From: DeDuikertjes at xs4all.nl (deduikertjes)
Date: Mon, 12 Nov 2018 01:48:03 -0700 (MST)
Subject: [gdal-dev] OGR drivers written in Python
In-Reply-To: <6079142.z3hTm2DpqI@even-i700>
References: <6079142.z3hTm2DpqI@even-i700>
Message-ID: <1542012483764-0.post@n6.nabble.com>


I'd love to have the possibility to add drivers to GDAl using Python.

Use case for me is all those services/ datasets containing useful geo
data but adhere to no standard. Being able to create a driver quickly to get
it in QGIS or an ETL proces is
really useful.

Did this proposal ever make it to GDAL? I couldn't find it in any
changelogs.
If not, do you expect it to make it some day?

MArco



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From robert.coup at koordinates.com  Mon Nov 12 00:48:59 2018
From: robert.coup at koordinates.com (Robert Coup)
Date: Mon, 12 Nov 2018 08:48:59 +0000
Subject: [gdal-dev] Fwd: Re: [Tiff] Libtiff will be released soon
In-Reply-To: <3223589.R8XTpUpJkP@even-i700>
References: <18143925.OLitUtTB1u@even-i700> <3223589.R8XTpUpJkP@even-i700>
Message-ID: <CAFLLRpL4s7GGvFy649r4UDycudE03YAn7Mp3cf-gsqYfxAbb8A@mail.gmail.com>

Hi Even,

On Mon, 12 Nov 2018 at 07:57, Even Rouault <even.rouault at spatialys.com>
wrote:

>
> Not completely sure what to do with GDAL 2.3 branch, as it already had
> ZStd
> (if using its internal libtiff copy). I feel it is probably wise to also
> update the modified value of COMPRESSION_ZSTD there to avoid the risk of
> people creating files with the now obsolete tag value ?
>

How about:

1. Read both values as enabling ZSTD
2. Output a warning when the old value is encountered
3. Always write the new value

Rob :)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181112/b9d17af5/attachment.html>

From even.rouault at spatialys.com  Mon Nov 12 01:10:57 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 12 Nov 2018 10:10:57 +0100
Subject: [gdal-dev] OGR drivers written in Python
In-Reply-To: <1542012483764-0.post@n6.nabble.com>
References: <6079142.z3hTm2DpqI@even-i700> <1542012483764-0.post@n6.nabble.com>
Message-ID: <2302446.9XRpRAaDrS@even-i700>

On lundi 12 novembre 2018 01:48:03 CET deduikertjes wrote:
> I'd love to have the possibility to add drivers to GDAl using Python.
> 
> Use case for me is all those services/ datasets containing useful geo
> data but adhere to no standard. Being able to create a driver quickly to get
> it in QGIS or an ETL proces is
> really useful.
> 
> Did this proposal ever make it to GDAL? I couldn't find it in any
> changelogs.

No, it has remained a toy experiment.

> If not, do you expect it to make it some day?

I won't risk myself at predicting the future. All I can say is I haven't any 
immediate plan for it.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Mon Nov 12 01:39:54 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 12 Nov 2018 10:39:54 +0100
Subject: [gdal-dev] Fwd: Re: [Tiff] Libtiff will be released soon
In-Reply-To: <CAFLLRpL4s7GGvFy649r4UDycudE03YAn7Mp3cf-gsqYfxAbb8A@mail.gmail.com>
References: <18143925.OLitUtTB1u@even-i700> <3223589.R8XTpUpJkP@even-i700>
 <CAFLLRpL4s7GGvFy649r4UDycudE03YAn7Mp3cf-gsqYfxAbb8A@mail.gmail.com>
Message-ID: <3051824.NbHCi85yxq@even-i700>

On lundi 12 novembre 2018 08:48:59 CET Robert Coup wrote:
> Hi Even,
> 
> On Mon, 12 Nov 2018 at 07:57, Even Rouault <even.rouault at spatialys.com>
> 
> wrote:
> > Not completely sure what to do with GDAL 2.3 branch, as it already had
> > ZStd
> > (if using its internal libtiff copy). I feel it is probably wise to also
> > update the modified value of COMPRESSION_ZSTD there to avoid the risk of
> > people creating files with the now obsolete tag value ?
> 
> How about:
> 
> 1. Read both values as enabling ZSTD
> 2. Output a warning when the old value is encountered
> 3. Always write the new value

Yeah, that's just what I have done. But only in 2.3 branch, not in master, as 
I patched the internal libtiff copy for that, and don't intend to upstream 
that hack or make the internal libtiff in master diverge from official 
libtiff.

$ gdalinfo ../autotest/gcore/data/byte_zstd.tif
Warning 1: TIFFInitZSTD:Value of Compression Tag is 34926, which is the 
deprecated value for ZStd. Please use the new value of 50000 by recreating/
patching this file. Next GDAL releases won't recognize this file.
Driver: GTiff/GeoTIFF
Files: ../autotest/gcore/data/byte_zstd.tif
[...]

Note: if you build GDAL 2.3 with the shiny new libtiff 4.0.10 as external 
libtiff, those files with 34926 won't be recognized.

Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From DeDuikertjes at xs4all.nl  Mon Nov 12 01:46:44 2018
From: DeDuikertjes at xs4all.nl (deduikertjes)
Date: Mon, 12 Nov 2018 02:46:44 -0700 (MST)
Subject: [gdal-dev] OGR drivers written in Python
In-Reply-To: <2302446.9XRpRAaDrS@even-i700>
References: <6079142.z3hTm2DpqI@even-i700>
 <1542012483764-0.post@n6.nabble.com> <2302446.9XRpRAaDrS@even-i700>
Message-ID: <1542016004989-0.post@n6.nabble.com>

Even,

I think your 'toy' is a real gem which deserves to live (if only as
something flagged 'experimental').

AFAIK this would be the only option for GDAL users to extend GDAL on run
time.
Confining this technique to run time only extensions IMHO addresses the main
concerns in the discussion. 

Marco



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From gigas002 at yandex.ru  Mon Nov 12 08:33:48 2018
From: gigas002 at yandex.ru (Gigas002)
Date: Mon, 12 Nov 2018 09:33:48 -0700 (MST)
Subject: [gdal-dev] Dataset's ReadRaster/WriteRaster throws exception on c#
Message-ID: <1542040428626-0.post@n6.nabble.com>

Hi all.
I've rewritten some python code from gdal2tiles.py on c#, using GDAL.NET
nuget package (ver. 2.3.1). Here you can see the working python code:

def create_overview_tiles(input_file, output_file):
	tile_driver = 'PNG'
	tile_size = 256
	tilebands = 4
	resampling = 'bilinear'

	mem_driver = gdal.GetDriverByName('MEM')
	out_driver = gdal.GetDriverByName(tile_driver)

	dsquery = mem_driver.Create('', 2 * tile_size, 2 * tile_size, tilebands)
	dstile = mem_driver.Create('', tile_size, tile_size, tilebands)
	dsquerytile = gdal.Open(input_file, gdal.GA_ReadOnly)

	dsquery.WriteRaster(0, 0, tile_size, tile_size, dsquerytile.ReadRaster(0,
0, tile_size, tile_size), band_list=list(range(1, tilebands + 1)))
	scale_query_to_tile(dsquery, dstile, resampling)
	out_driver.CreateCopy(output_file, dstile, strict=0)


def scale_query_to_tile(dsquery, dstile, resampling):
    querysize = dsquery.RasterXSize
    tilesize = dstile.RasterXSize

    if resampling == 'near':
        gdal_resampling = gdal.GRA_NearestNeighbour
	
    elif resampling == 'bilinear':
		gdal_resampling = gdal.GRA_Bilinear

    elif resampling == 'cubic':
        gdal_resampling = gdal.GRA_Cubic

    elif resampling == 'cubicspline':
        gdal_resampling = gdal.GRA_CubicSpline

    dsquery.SetGeoTransform((0.0, tilesize / float(querysize), 0.0, 0.0,
0.0, tilesize / float(querysize)))
    dstile.SetGeoTransform((0.0, 1.0, 0.0, 0.0, 0.0, 1.0))

    gdal.ReprojectImage(dsquery, dstile, None, None, gdal_resampling)


And here's rewritten code on c#:

        private static void BuildOverview(string inputFile, string
outputFile)
        {
            const string tileDriver = "PNG";
            const int tileSize = 256;
            const int tileBands = 4;
            const string resampling = "bilinear";

            Driver memDriver = Gdal.GetDriverByName("MEM");
            Driver outDriver = Gdal.GetDriverByName(tileDriver);

            Dataset dsQuery = memDriver.Create("", 2 * tileSize, 2 *
tileSize, tileBands, DataType.GDT_Byte, null);
            Dataset dsTile = memDriver.Create("", tileSize, tileSize,
tileBands, DataType.GDT_Byte, null);
            Dataset dsQueryTile = Gdal.Open(inputFile, Access.GA_ReadOnly);

            byte[] readRaster = new byte[tileSize * tileSize];
            dsQueryTile.ReadRaster(0, 0, tileSize, tileSize, readRaster,
tileSize, tileSize,
                tileBands, Enumerable.Range(1, tileBands + 1).ToArray(), 0,
0, 0);
            dsQuery.WriteRaster(0, 0, tileSize, tileSize, readRaster,
tileSize, tileSize,
                tileBands, Enumerable.Range(1, tileBands + 1).ToArray(), 0,
0, 0);

            ScaleQueryToTile(dsQuery, dsTile, resampling);
            outDriver.CreateCopy(outputFile, dsTile, 0, null, null, null);
        }

        private static void ScaleQueryToTile(Dataset dsQuery, Dataset
dsTile, string resampling)
        {
            int querySize = dsQuery.RasterXSize;
            int tileSize = dsTile.RasterXSize;

            ResampleAlg gdalResampling;
            switch (resampling)
            {
                case "near":
                    gdalResampling = ResampleAlg.GRA_NearestNeighbour;
                    break;
                case "bilinear":
                    gdalResampling = ResampleAlg.GRA_Bilinear;
                    break;
                case "cubicspline":
                    gdalResampling = ResampleAlg.GRA_CubicSpline;
                    break;
                default:
                    gdalResampling = ResampleAlg.GRA_Cubic;
                    break;
            }

            dsQuery.SetGeoTransform(new[] {0.0, tileSize / (float)
querySize, 0, 0, 0, tileSize / (float) querySize});
            dsTile.SetGeoTransform(new[] { 0.0, 1.0, 0.0, 0.0, 0.0, 1.0 });

            Gdal.ReprojectImage(dsQuery, dsTile, null, null, gdalResampling,
0, 0, null, null, null);
        }


I use these methods to create upper tile (in my case create 10 lvl tile from
11 lvl tile). Python version works without problem, but c#'s throws
"System.AccessViolationException" (Additional information on exception from
VS: Attempted to read or write protected memory. This is often an indication
that other memory is corrupt) on "dsQueryTile.ReadRaster(..." line in
runtime. 
I suppose the exception is thrown because ReadRaster try to create pointer
to byte[] and somehow fails. 

I uploaded the 11 lvl png tile, named "z_x_y.png", and good 10 lvl tile,
done by python. I'm using VS2017, Win10x64 and writing on .net framework
4.7.2.
Hope anyone knows how to fix it!

11_2200_1621.png
<http://osgeo-org.1560.x6.nabble.com/file/t384059/11_2200_1621.png>  
10_1100_810.png
<http://osgeo-org.1560.x6.nabble.com/file/t384059/10_1100_810.png>  



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From szekerest at gmail.com  Mon Nov 12 10:05:05 2018
From: szekerest at gmail.com (Tamas Szekeres)
Date: Mon, 12 Nov 2018 19:05:05 +0100
Subject: [gdal-dev] Dataset's ReadRaster/WriteRaster throws exception on
	c#
In-Reply-To: <1542040428626-0.post@n6.nabble.com>
References: <1542040428626-0.post@n6.nabble.com>
Message-ID: <CACALY+T90f7buPsB+0A9Unmxi-hnrqfEA=a7aum+DGR26-=vPw@mail.gmail.com>

You did not count the band size when allocating memory for the buffer.
That should be:

byte[] readRaster = new byte[tileSize * tileSize * 4];

Or alternatively use Band.ReadRaster to read just a specific band.

Best regards,

Tamas




Gigas002 <gigas002 at yandex.ru> ezt írta (időpont: 2018. nov. 12., H, 17:34):

> Hi all.
> I've rewritten some python code from gdal2tiles.py on c#, using GDAL.NET
> nuget package (ver. 2.3.1). Here you can see the working python code:
>
> def create_overview_tiles(input_file, output_file):
>         tile_driver = 'PNG'
>         tile_size = 256
>         tilebands = 4
>         resampling = 'bilinear'
>
>         mem_driver = gdal.GetDriverByName('MEM')
>         out_driver = gdal.GetDriverByName(tile_driver)
>
>         dsquery = mem_driver.Create('', 2 * tile_size, 2 * tile_size,
> tilebands)
>         dstile = mem_driver.Create('', tile_size, tile_size, tilebands)
>         dsquerytile = gdal.Open(input_file, gdal.GA_ReadOnly)
>
>         dsquery.WriteRaster(0, 0, tile_size, tile_size,
> dsquerytile.ReadRaster(0,
> 0, tile_size, tile_size), band_list=list(range(1, tilebands + 1)))
>         scale_query_to_tile(dsquery, dstile, resampling)
>         out_driver.CreateCopy(output_file, dstile, strict=0)
>
>
> def scale_query_to_tile(dsquery, dstile, resampling):
>     querysize = dsquery.RasterXSize
>     tilesize = dstile.RasterXSize
>
>     if resampling == 'near':
>         gdal_resampling = gdal.GRA_NearestNeighbour
>
>     elif resampling == 'bilinear':
>                 gdal_resampling = gdal.GRA_Bilinear
>
>     elif resampling == 'cubic':
>         gdal_resampling = gdal.GRA_Cubic
>
>     elif resampling == 'cubicspline':
>         gdal_resampling = gdal.GRA_CubicSpline
>
>     dsquery.SetGeoTransform((0.0, tilesize / float(querysize), 0.0, 0.0,
> 0.0, tilesize / float(querysize)))
>     dstile.SetGeoTransform((0.0, 1.0, 0.0, 0.0, 0.0, 1.0))
>
>     gdal.ReprojectImage(dsquery, dstile, None, None, gdal_resampling)
>
>
> And here's rewritten code on c#:
>
>         private static void BuildOverview(string inputFile, string
> outputFile)
>         {
>             const string tileDriver = "PNG";
>             const int tileSize = 256;
>             const int tileBands = 4;
>             const string resampling = "bilinear";
>
>             Driver memDriver = Gdal.GetDriverByName("MEM");
>             Driver outDriver = Gdal.GetDriverByName(tileDriver);
>
>             Dataset dsQuery = memDriver.Create("", 2 * tileSize, 2 *
> tileSize, tileBands, DataType.GDT_Byte, null);
>             Dataset dsTile = memDriver.Create("", tileSize, tileSize,
> tileBands, DataType.GDT_Byte, null);
>             Dataset dsQueryTile = Gdal.Open(inputFile, Access.GA_ReadOnly);
>
>             byte[] readRaster = new byte[tileSize * tileSize];
>             dsQueryTile.ReadRaster(0, 0, tileSize, tileSize, readRaster,
> tileSize, tileSize,
>                 tileBands, Enumerable.Range(1, tileBands + 1).ToArray(), 0,
> 0, 0);
>             dsQuery.WriteRaster(0, 0, tileSize, tileSize, readRaster,
> tileSize, tileSize,
>                 tileBands, Enumerable.Range(1, tileBands + 1).ToArray(), 0,
> 0, 0);
>
>             ScaleQueryToTile(dsQuery, dsTile, resampling);
>             outDriver.CreateCopy(outputFile, dsTile, 0, null, null, null);
>         }
>
>         private static void ScaleQueryToTile(Dataset dsQuery, Dataset
> dsTile, string resampling)
>         {
>             int querySize = dsQuery.RasterXSize;
>             int tileSize = dsTile.RasterXSize;
>
>             ResampleAlg gdalResampling;
>             switch (resampling)
>             {
>                 case "near":
>                     gdalResampling = ResampleAlg.GRA_NearestNeighbour;
>                     break;
>                 case "bilinear":
>                     gdalResampling = ResampleAlg.GRA_Bilinear;
>                     break;
>                 case "cubicspline":
>                     gdalResampling = ResampleAlg.GRA_CubicSpline;
>                     break;
>                 default:
>                     gdalResampling = ResampleAlg.GRA_Cubic;
>                     break;
>             }
>
>             dsQuery.SetGeoTransform(new[] {0.0, tileSize / (float)
> querySize, 0, 0, 0, tileSize / (float) querySize});
>             dsTile.SetGeoTransform(new[] { 0.0, 1.0, 0.0, 0.0, 0.0, 1.0 });
>
>             Gdal.ReprojectImage(dsQuery, dsTile, null, null,
> gdalResampling,
> 0, 0, null, null, null);
>         }
>
>
> I use these methods to create upper tile (in my case create 10 lvl tile
> from
> 11 lvl tile). Python version works without problem, but c#'s throws
> "System.AccessViolationException" (Additional information on exception from
> VS: Attempted to read or write protected memory. This is often an
> indication
> that other memory is corrupt) on "dsQueryTile.ReadRaster(..." line in
> runtime.
> I suppose the exception is thrown because ReadRaster try to create pointer
> to byte[] and somehow fails.
>
> I uploaded the 11 lvl png tile, named "z_x_y.png", and good 10 lvl tile,
> done by python. I'm using VS2017, Win10x64 and writing on .net framework
> 4.7.2.
> Hope anyone knows how to fix it!
>
> 11_2200_1621.png
> <http://osgeo-org.1560.x6.nabble.com/file/t384059/11_2200_1621.png>
> 10_1100_810.png
> <http://osgeo-org.1560.x6.nabble.com/file/t384059/10_1100_810.png>
>
>
>
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181112/23ef3ada/attachment-0001.html>

From Peter.Marlow at scisys.co.uk  Tue Nov 13 06:05:18 2018
From: Peter.Marlow at scisys.co.uk (Peter Marlow)
Date: Tue, 13 Nov 2018 14:05:18 +0000
Subject: [gdal-dev] ogr2ogr clip operation very slow compared to QGIS
Message-ID: <AA48096CDCDA4745B245B6A21526D99840101B97@CITCH-MXEXCH1.scisys.co.uk>

Hi,

I'm trying to clip some GML data via a fairly complex ShapeFile boundary using standard ogr2ogr and it is taking roughly 5 minutes before completing successfully. This same operation takes less than a second using the Clip operation in QGIS with exactly the same data. I was lead to believe that QGIS is using OGR under the hood to perform the clip operation, so my question is: why is my ogr2ogr clip command taking so much longer?

The command I'm running is:

ogr2ogr -f GML output_file input_file.gz -clipsrc clip_boundary.shp -clipsrclayer clip_boundary

Thanks,
Pete



SCISYS UK Limited. Registered in England and Wales No. 4373530.
Registered Office: Methuen Park, Chippenham, Wiltshire SN14 0GB, UK.
 
Before printing, please think about the environment.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181113/d496e3c5/attachment.html>

From even.rouault at spatialys.com  Tue Nov 13 07:02:57 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 13 Nov 2018 16:02:57 +0100
Subject: [gdal-dev] ogr2ogr clip operation very slow compared to QGIS
In-Reply-To: <AA48096CDCDA4745B245B6A21526D99840101B97@CITCH-MXEXCH1.scisys.co.uk>
References: <AA48096CDCDA4745B245B6A21526D99840101B97@CITCH-MXEXCH1.scisys.co.uk>
Message-ID: <257024592.pHlUPbFmid@even-i700>

Peter,

> 
> I'm trying to clip some GML data via a fairly complex ShapeFile boundary
> using standard ogr2ogr and it is taking roughly 5 minutes before completing
> successfully.

Does your input dataset (input_file.gz) has many features ? (let's say ~1000)

> This same operation takes less than a second using the Clip
> operation in QGIS with exactly the same data. I was lead to believe that
> QGIS is using OGR under the hood to perform the clip operation, 

I don't think so. From what I can see, qgsalgorithmclip.cpp in QGIS uses the 
same geometry library as OGR, namely GEOS, but doesn't use OGR itself.

> so my
> question is: why is my ogr2ogr clip command taking so much longer?

Looking at QGIS code, it uses GEOS prepared geometry mechanism with the clip 
geometry, so as to speed up intersection operations on it. Whereas ogr2ogr -
clipsrc uses the 'naive' intersection function. I guess this is the reason for 
the speed difference. QGIS also checks for the result of contains() and 
intersects() predicates before calculating the intersection geometry. Not sure 
how much that speed-up things. So I bet ogr2ogr could be improved to have 
similar performance as QGIS clipping.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sean at mapbox.com  Tue Nov 13 13:13:27 2018
From: sean at mapbox.com (Sean Gillies)
Date: Tue, 13 Nov 2018 14:13:27 -0700
Subject: [gdal-dev] Confusing error behavior of OGR_L_GetSpatialRef
Message-ID: <CADPhZXxt9=wZGLGVs-ku=X6962e-t5Cvo+JjSfG-wOEABqZJ0Q@mail.gmail.com>

Hi,

While debugging a problem with my Fiona project I realized that if
GDAL_DATA is not known, OGR_L_GetSpatialRef() (master branch and also
2.3.2) can return a not-NULL spatial reference while also putting a
CE_Failure error on the error stack. Is this intended or is the error code
perhaps one level too high in this case? Are application using GDAL
supposed to continue working if the EPSG support files aren't found? Might
this be changed to a warning instead?

I see that ogr2ogr does continue while also printing the following to the
terminal:

ERROR 4: Unable to open EPSG support file gcs.csv.  Try setting the
GDAL_DATA environment variable to point to the directory containing EPSG
csv files.

Will OGR_L_GetSpatialRef() always return NULL if there is a error condition
that an application can't or shouldn't continue from? Or do applications
need to check the error stack to see how bad the situation is?

Thanks,

-- 
Sean Gillies
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181113/71b7d63a/attachment.html>

From even.rouault at spatialys.com  Tue Nov 13 13:55:05 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 13 Nov 2018 22:55:05 +0100
Subject: [gdal-dev] Confusing error behavior of OGR_L_GetSpatialRef
In-Reply-To: <CADPhZXxt9=wZGLGVs-ku=X6962e-t5Cvo+JjSfG-wOEABqZJ0Q@mail.gmail.com>
References: <CADPhZXxt9=wZGLGVs-ku=X6962e-t5Cvo+JjSfG-wOEABqZJ0Q@mail.gmail.com>
Message-ID: <29661018.LAqUjdLoVq@even-i700>

On mardi 13 novembre 2018 14:13:27 CET Sean Gillies wrote:
> Hi,
> 
> While debugging a problem with my Fiona project I realized that if
> GDAL_DATA is not known, OGR_L_GetSpatialRef() (master branch and also
> 2.3.2) can return a not-NULL spatial reference while also putting a
> CE_Failure error on the error stack.

This is driver specific behaviour. How can we reproduce ?
Is the SRS returned still meaningful or somewhat dummy ?

> Is this intended or is the error code
> perhaps one level too high in this case? Are application using GDAL
> supposed to continue working if the EPSG support files aren't found? Might
> this be changed to a warning instead?

Well GDAL_DATA not defined or not set correctly is something supposed not to 
happen in correctly setup environment.

Returning an error or a warning depends on the context (if importing a EPSG 
code as a user requested action and no GDAL_DATA, then it is an error. But if 
it is some attempt of a driver to identify a SRS against a well-known CRS in 
the database, then it would be more a warning), but at the point where the 
error is detected, this is too level for the code to known.

Anyway soon that will be PROJ_LIB that you will have to define correctly ;-)


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From matthias at opengis.ch  Tue Nov 13 14:04:51 2018
From: matthias at opengis.ch (Matthias Kuhn)
Date: Tue, 13 Nov 2018 23:04:51 +0100
Subject: [gdal-dev] Non-standard field types in OGR
Message-ID: <3a6ddb00-d237-d1ca-521a-86df19a5bf47@opengis.ch>

Hi,

I'm looking for a way to load a geopackage layer with a type affinity
set to a custom type and to detect this type.

I.e. what I have is a table with a field called myJson, the type of
which is JSON.

Looking at the debug output of QGIS, I currently get this message which
seems to be generated by OGR:

Warning 1: Field format 'JSON' not supported

Warning 1: geometry column 'myJson' of type 'JSON' ignored

Is it currently possible to load such a field via OGR?

What I was hoping is to load this field (with fallback as string) and
detect that it's of type JSON. I think even if I was able to load the
field, it would only be possible to detect which of the types in
OGRFieldType it is and not get the raw name of the type on the
underlying data source.

Am I missing something and this is already possible? If not, would it be
acceptable to patch ogr to support this? Or is the idea to have a custom
type name for JSON in a GeoPackage/SQLite container flawed in itself?

Thanks a lot

Matthias

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181113/84ba0da1/attachment.html>

From even.rouault at spatialys.com  Tue Nov 13 14:22:00 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 13 Nov 2018 23:22:00 +0100
Subject: [gdal-dev] Non-standard field types in OGR
In-Reply-To: <3a6ddb00-d237-d1ca-521a-86df19a5bf47@opengis.ch>
References: <3a6ddb00-d237-d1ca-521a-86df19a5bf47@opengis.ch>
Message-ID: <2049651.vlyWzdfDEi@even-i700>

Hi Matthias,

> 
> I'm looking for a way to load a geopackage layer with a type affinity
> set to a custom type and to detect this type.

This would likely be illegal for core GeoPackage spec since data types are 
standardized per http://www.geopackage.org/spec/#r5 . But could be made an 
extension

> 
> I.e. what I have is a table with a field called myJson, the type of
> which is JSON.
> 
> Looking at the debug output of QGIS, I currently get this message which
> seems to be generated by OGR:
> 
> Warning 1: Field format 'JSON' not supported
> 
> Warning 1: geometry column 'myJson' of type 'JSON' ignored
> 
> Is it currently possible to load such a field via OGR?

Nope, not by the GPKG driver in its current state

> 
> What I was hoping is to load this field (with fallback as string) and
> detect that it's of type JSON. I think even if I was able to load the
> field, it would only be possible to detect which of the types in
> OGRFieldType it is and not get the raw name of the type on the
> underlying data source.

Yes, you would get it as a OFTString. That said we could potentially extend 
the OGRFieldSubType enumeration to have a OFSTJSon value that would be valid 
for OFTString type. A number of drivers could use that (like Postgres)

> 
> Am I missing something and this is already possible? If not, would it be
> acceptable to patch ogr to support this? 

The driver could be made more robust not to consider columns with unknown data 
types as potential geometry column as it does currently, but try to handle 
them as attributes with fallback to OFTString. Emitting a warning could still 
be appropriate, unless the GeoPackage also contains in gpkg_extensions a 
declaration of the fact that the table has custom data types (extension to 
create for that purpose)

It would help SQLite to use 'TEXT_JSON' for correct detection as text affinity 
(see §3.1 of https://www.sqlite.org/datatype3.html)

~~~~~~

Hum actually another option, likely a better one, would be to use the already 
standardized 'schema' extension (unimplemented by the OGR driver):
http://www.geopackage.org/spec/#extension_schema
And set 'application/json' in gpkg_data_columns as the 'mime_type'
The column in the table layer would then be declared as standard TEXT, so 
consumers unaware of the extension would be able to still read it correctly.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nyall.dawson at gmail.com  Tue Nov 13 15:17:17 2018
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Wed, 14 Nov 2018 09:17:17 +1000
Subject: [gdal-dev] ogr2ogr clip operation very slow compared to QGIS
In-Reply-To: <257024592.pHlUPbFmid@even-i700>
References: <AA48096CDCDA4745B245B6A21526D99840101B97@CITCH-MXEXCH1.scisys.co.uk>
 <257024592.pHlUPbFmid@even-i700>
Message-ID: <CAB28AshqN-RCKLboF5KBsAduwy=tDRhPEvgsdt3ZLT3gD+SYoA@mail.gmail.com>

On Wed, 14 Nov 2018 at 01:03, Even Rouault <even.rouault at spatialys.com> wrote:

> Looking at QGIS code, it uses GEOS prepared geometry mechanism with the clip
> geometry, so as to speed up intersection operations on it. Whereas ogr2ogr -
> clipsrc uses the 'naive' intersection function. I guess this is the reason for
> the speed difference.

This is the big difference -- using the prepared methods results in
orders of magnitude speed boosts.

> QGIS also checks for the result of contains() and
> intersects() predicates before calculating the intersection geometry. Not sure
> how much that speed-up things.

Significantly (sorry no actual figures available). What's happening
here is the GEOS intersection method doesn't utilise prepared
geometries, yet the tests like contains and intersects do. The raw
intersection method is slow, even if there's no actual intersection or
if the geometry will be returned unchanged (i.e. it's within the clip
mask). So by taking advantage of the fast within/intersects tests on
the prepared geometry we potentially skip a bunch of unnecessary slow
intersection calculations.

Nyall

From nik at nikosalexandris.net  Tue Nov 13 17:27:29 2018
From: nik at nikosalexandris.net (Nikos Alexandris)
Date: Wed, 14 Nov 2018 02:27:29 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <2929579.Dc3uFIaxCl@even-i700>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
 <3348551.Gf7FvRyFPS@even-i700>
 <20181107064948.bqi77r2qg54fc33u@imap.dreamhost.com>
 <2929579.Dc3uFIaxCl@even-i700>
Message-ID: <20181114012729.elna2dcwjl3gr3rr@imap.dreamhost.com>

* Even Rouault <even.rouault at spatialys.com> [2018-11-07 12:10:19 +0100]:

>> ```
>> echo 12 55 0 0 | proj "+proj=bertin1953 +wktext"
>> Rel. 6.0.0, March 1st, 2019
>> <proj>:
>> projection initialization failure
>> cause: unknown projection id
>> program abnormally terminated
>> ```
>
>'proj' syntax is without quoting. And you only need +wktext for GDAL, not for
>PROJ utilities
>
>>
>> or using the following map
>> ```
>> file TM_WORLD_BORDERS_SIMPL-0.3.shp
>> TM_WORLD_BORDERS_SIMPL-0.3.shp: ESRI Shapefile version 1000 length 224094
>> type Polygon ```
>> `ogr2ogr` segfaults:
>> ```
>> ogr2ogr -t_srs "+proj=bertin1953 +wktext"
>> TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp TM_WORLD_BORDERS_SIMPL-0.3.shp
>> ERROR 6: Failed to initialize PROJ.4 with `+proj=bertin1953 +wktext'.
>> Segmentation fault
>> ```
>>
>
>It is likely you have an issue with GDAL linking also against your system
>PROJ. Has it been compiled --with-static-proj / --with-proj or not ? Check
>with ldd which libproj libgdal links against. You may need to adjust your
>LD_LIBRARY_PATH and potentially create a symbolic link from the new
>libproj.so.xxxx to the name of the old libproj.so.yyyyy so that GDAL sees one
>and one single libproj.

By the way, are there any notes on LD_LIBRARY_PATH?  I mean, with respect to
GDAL/OGR and Proj4.

Nikos

From _kfj at yahoo.com  Wed Nov 14 00:34:33 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Wed, 14 Nov 2018 09:34:33 +0100
Subject: [gdal-dev] clipping linestrings with ogr2ogr may create points
Message-ID: <8a861610-2e07-7ef9-210b-307f8e35d7e1@yahoo.com>

Hi all!

I have a file with contour lines 'contour.shp' (made with gdal_contour) 
which I want to clip with a rectangle. I was using this command to 
obtain 'clipped.shp'

ogr2ogr -clipsrc 460000 5105000 465000 5110000 clipped.shp contour.shp

But whatever I tried, I got an error:

ERROR 1: Attempt to write non-linestring (GEOMETRYCOLLECTION) geometry 
to ARC type shapefile.
ERROR 1: Unable to write feature 84 from layer contour.
ERROR 1: Terminating translation prematurely after failed

I took a good while to realize that the clipping actually produced a 
single point, where one of the contours left the clipping rectangle, 
came back to coincide with the clipping rectangle on this point and went 
further out again.

The geometry looks like this:

           / <- linestring
      *   /
     / \ /
---*---*----  <- top of clipping rectangle
   /    ^
  /     | yields single point to the GEOMETRYCOLLECTION

So technically the result is correct. The single point is inside the 
clipping rectangle, and therefore part of the output, which can't be 
stored in the output shapefile because that already has linestrings in it.

I managed to avoid the problem by changing the clipping rectangle ever 
so slightly:

ogr2ogr -clipsrc 460000.0001 5105000.0001 464999.9999 5109999.9999 \
         clipped.shp contour.shp

And I can also save to other formats which can take several geometries, 
like KML.

But I'm not quite happy with either of the solutions so I'd like to 
discuss this issue. Are there maybe additional parameters to limit the 
geometries resulting from clipping to linestrings, or to exclude 
resulting isolated points from the output? If ogr2ogr were to output 
linestrings an points separately instead of putting them in a 
GEOMETRYCOLLECTION, I could use -skipfailures, but since the clipped 
linestring is inside the GEOMETRYCOLLECTION, when using -skipfailures, 
it is removed from the output as well - and missing contour lines on a 
hillside stick out like a sore thumb.

So my issue is not strictly speaking a bug report, it's more about what 
a user would expect when clipping a bunch of linestrings, namely to 
receive back a bunch of linestrings, never mind geometrical correctness.

With regards
Kay









From Peter.Marlow at scisys.co.uk  Wed Nov 14 01:10:37 2018
From: Peter.Marlow at scisys.co.uk (Peter Marlow)
Date: Wed, 14 Nov 2018 09:10:37 +0000
Subject: [gdal-dev] ogr2ogr clip operation very slow compared to QGIS
In-Reply-To: <257024592.pHlUPbFmid@even-i700>
References: <AA48096CDCDA4745B245B6A21526D99840101B97@CITCH-MXEXCH1.scisys.co.uk>
 <257024592.pHlUPbFmid@even-i700>
Message-ID: <AA48096CDCDA4745B245B6A21526D99840101C5A@CITCH-MXEXCH1.scisys.co.uk>

Hi Even,

Thanks for the reply. That makes sense then, I didn't realise QGIS was doing lots of additional optimisation. It looks like there are Python bindings for GEOS so I will try to use the clip mechanism that resides there instead of ogr2ogr.

Making ogr2ogr use the same performance enhancements as GEOS would be a great improvement :) (suspect it's not that straight-forward though)

Thanks,
Pete

-----Original Message-----
From: Even Rouault <even.rouault at spatialys.com> 
Sent: 13 November 2018 15:03
To: gdal-dev at lists.osgeo.org
Cc: Peter Marlow <Peter.Marlow at scisys.co.uk>
Subject: Re: [gdal-dev] ogr2ogr clip operation very slow compared to QGIS

Peter,

> 
> I'm trying to clip some GML data via a fairly complex ShapeFile 
> boundary using standard ogr2ogr and it is taking roughly 5 minutes 
> before completing successfully.

Does your input dataset (input_file.gz) has many features ? (let's say ~1000)

> This same operation takes less than a second using the Clip operation 
> in QGIS with exactly the same data. I was lead to believe that QGIS is 
> using OGR under the hood to perform the clip operation,

I don't think so. From what I can see, qgsalgorithmclip.cpp in QGIS uses the same geometry library as OGR, namely GEOS, but doesn't use OGR itself.

> so my
> question is: why is my ogr2ogr clip command taking so much longer?

Looking at QGIS code, it uses GEOS prepared geometry mechanism with the clip geometry, so as to speed up intersection operations on it. Whereas ogr2ogr - clipsrc uses the 'naive' intersection function. I guess this is the reason for the speed difference. QGIS also checks for the result of contains() and
intersects() predicates before calculating the intersection geometry. Not sure how much that speed-up things. So I bet ogr2ogr could be improved to have similar performance as QGIS clipping.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com



SCISYS UK Limited. Registered in England and Wales No. 4373530.
Registered Office: Methuen Park, Chippenham, Wiltshire SN14 0GB, UK.
 
Before printing, please think about the environment.


From jukka.rahkonen at maanmittauslaitos.fi  Wed Nov 14 02:11:14 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Wed, 14 Nov 2018 03:11:14 -0700 (MST)
Subject: [gdal-dev] clipping linestrings with ogr2ogr may create points
In-Reply-To: <8a861610-2e07-7ef9-210b-307f8e35d7e1@yahoo.com>
References: <8a861610-2e07-7ef9-210b-307f8e35d7e1@yahoo.com>
Message-ID: <1542190274088-0.post@n6.nabble.com>

Hi,

I understand that it does not feel intuitive but the result is the same when
you compute an intersection for example with PostGIS

SELECT ST_AsText(ST_Intersection(ST_GeomFromText('LINESTRING ( 0 3, 3 8,
3.975762579723482 6, 6 9 )'),ST_GeomFromText('POLYGON (( 1 2, 1 6, 6 6, 6 2,
1 2 ))')));

Result:
GEOMETRYCOLLECTION(POINT(3.97576257972348 6),LINESTRING(1
4.66666666666667,1.8 6))

Geometrycollection is the only possibility if one input geometry must yield
one output geometry.  Ogr2ogr has already rather many options and your use
case may not be common enough for having its own switch.

If I had just to have the job done I would perhaps save the result first
into GeoPackage by using general geometries (-nlt geometry), re-run ogr2ogr
with -explodecollections into a new layer, and finally filter that by
geometrytype by using either the OGR SQL dialect or the SQLite dialect.

-Jukka Rahkonen-


kfj wrote
> Hi all!
> 
> I have a file with contour lines 'contour.shp' (made with gdal_contour) 
> which I want to clip with a rectangle. I was using this command to 
> obtain 'clipped.shp'
> 
> ogr2ogr -clipsrc 460000 5105000 465000 5110000 clipped.shp contour.shp
> 
> But whatever I tried, I got an error:
> 
> ERROR 1: Attempt to write non-linestring (GEOMETRYCOLLECTION) geometry 
> to ARC type shapefile.
> ERROR 1: Unable to write feature 84 from layer contour.
> ERROR 1: Terminating translation prematurely after failed
> 
> I took a good while to realize that the clipping actually produced a 
> single point, where one of the contours left the clipping rectangle, 
> came back to coincide with the clipping rectangle on this point and went 
> further out again.
> 
> The geometry looks like this:
> 
>            / <- linestring
>       *   /
>      / \ /
> ---*---*----  <- top of clipping rectangle
>    /    ^
>   /     | yields single point to the GEOMETRYCOLLECTION
> 
> So technically the result is correct. The single point is inside the 
> clipping rectangle, and therefore part of the output, which can't be 
> stored in the output shapefile because that already has linestrings in it.
> 
> I managed to avoid the problem by changing the clipping rectangle ever 
> so slightly:
> 
> ogr2ogr -clipsrc 460000.0001 5105000.0001 464999.9999 5109999.9999 \
>          clipped.shp contour.shp
> 
> And I can also save to other formats which can take several geometries, 
> like KML.
> 
> But I'm not quite happy with either of the solutions so I'd like to 
> discuss this issue. Are there maybe additional parameters to limit the 
> geometries resulting from clipping to linestrings, or to exclude 
> resulting isolated points from the output? If ogr2ogr were to output 
> linestrings an points separately instead of putting them in a 
> GEOMETRYCOLLECTION, I could use -skipfailures, but since the clipped 
> linestring is inside the GEOMETRYCOLLECTION, when using -skipfailures, 
> it is removed from the output as well - and missing contour lines on a 
> hillside stick out like a sore thumb.
> 
> So my issue is not strictly speaking a bug report, it's more about what 
> a user would expect when clipping a bunch of linestrings, namely to 
> receive back a bunch of linestrings, never mind geometrical correctness.
> 
> With regards
> Kay
> 
> 
> 
> 
> 
> 
> 
> 
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From nik at nikosalexandris.net  Wed Nov 14 02:52:36 2018
From: nik at nikosalexandris.net (Nikos Alexandris)
Date: Wed, 14 Nov 2018 11:52:36 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <20181114012729.elna2dcwjl3gr3rr@imap.dreamhost.com>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
 <3348551.Gf7FvRyFPS@even-i700>
 <20181107064948.bqi77r2qg54fc33u@imap.dreamhost.com>
 <2929579.Dc3uFIaxCl@even-i700>
 <20181114012729.elna2dcwjl3gr3rr@imap.dreamhost.com>
Message-ID: <20181114105236.tm3zj6yp2ba2de7r@imap.dreamhost.com>

* Nikos Alexandris <nik at nikosalexandris.net> [2018-11-14 02:27:29 +0100]:

>* Even Rouault <even.rouault at spatialys.com> [2018-11-07 12:10:19 +0100]:
>
>>>```
>>>echo 12 55 0 0 | proj "+proj=bertin1953 +wktext"
>>>Rel. 6.0.0, March 1st, 2019
>>><proj>:
>>>projection initialization failure
>>>cause: unknown projection id
>>>program abnormally terminated
>>>```
>>
>>'proj' syntax is without quoting. And you only need +wktext for GDAL, not for
>>PROJ utilities
>>
>>>
>>>or using the following map
>>>```
>>>file TM_WORLD_BORDERS_SIMPL-0.3.shp
>>>TM_WORLD_BORDERS_SIMPL-0.3.shp: ESRI Shapefile version 1000 length 224094
>>>type Polygon ```
>>>`ogr2ogr` segfaults:
>>>```
>>>ogr2ogr -t_srs "+proj=bertin1953 +wktext"
>>>TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp TM_WORLD_BORDERS_SIMPL-0.3.shp
>>>ERROR 6: Failed to initialize PROJ.4 with `+proj=bertin1953 +wktext'.
>>>Segmentation fault
>>>```
>>>
>>
>>It is likely you have an issue with GDAL linking also against your system
>>PROJ. Has it been compiled --with-static-proj / --with-proj or not ? Check
>>with ldd which libproj libgdal links against. You may need to adjust your
>>LD_LIBRARY_PATH and potentially create a symbolic link from the new
>>libproj.so.xxxx to the name of the old libproj.so.yyyyy so that GDAL sees one
>>and one single libproj.
>
>By the way, are there any notes on LD_LIBRARY_PATH?  I mean, with respect to
>GDAL/OGR and Proj4.

I still can't make sense of it. While I also posted about this (and some
related stuff) on the forums of the Linux distribution I use [0],
here some overview:

Paths:
```
export LD_LIBRARY_PATH=/lib:/usr/lib:/usr/local/lib
ldconfig
echo $LD_LIBRARY_PATH
/lib:/usr/lib:/usr/local/lib
```

PROJ is there:
```
ldd /usr/local/bin/proj
      linux-vdso.so.1 (0x00007ffcf57da000)
      libproj.so.13 => /usr/local/lib/libproj.so.13 (0x00007f2f0e5c0000)
      libpthread.so.0 => /lib/libpthread.so.0 (0x00007f2f0e3a0000)
      libm.so.6 => /lib/libm.so.6 (0x00007f2f0e05e000)
      libc.so.6 => /lib/libc.so.6 (0x00007f2f0dc9a000)
      /lib64/ld-linux-x86-64.so.2 (0x00007f2f0e836000)
```

Berting is there:
```
proj -l=bertin1953
bertin1953 : Bertin 1953
        Misc Sph no inv.

proj -lp |grep bertin
bertin1953 : Bertin 1953
```

OGR sees nothing:
```
ldd /usr/bin/ogrinfo  |grep proj
```

So, `ogr2ogr` fails to pick up "Bertin 1953":
```
ogr2ogr -t_srs +proj=bertin1953 TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp TM_WORLD_BORDERS_SIMPL-0.3.shp
ERROR 1: Failed to process SRS definition: +proj=bertin1953
```

How to do you say "hey GDAL/OGR, pick this libproj.so up"? Is this
https://trac.osgeo.org/gdal/wiki/ConfigOptions#PROJSO relevant at
run-time?

I tried to set PROJSO to point to `/usr/local/lib64/libproj.so` but does
not help.

(
I wonder if this wouldn't be just easier to solve with a docker image.
)

Nikos


[0] https://forums.funtoo.org/topic/1844-using-latest-proj-from-its-source-and-some-generic-questions-on-build-logs/?page=0#comment-8757


From even.rouault at spatialys.com  Wed Nov 14 03:13:50 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 14 Nov 2018 12:13:50 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <20181114105236.tm3zj6yp2ba2de7r@imap.dreamhost.com>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
 <20181114012729.elna2dcwjl3gr3rr@imap.dreamhost.com>
 <20181114105236.tm3zj6yp2ba2de7r@imap.dreamhost.com>
Message-ID: <2158265.uYhzpff2mm@even-i700>

> So, `ogr2ogr` fails to pick up "Bertin 1953":
> ```
> ogr2ogr -t_srs +proj=bertin1953 TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp
> TM_WORLD_BORDERS_SIMPL-0.3.shp ERROR 1: Failed to process SRS definition:
> +proj=bertin1953
> ```

You need to add the +wktext parameter for use in GDAL:
	  -t_srs "+proj=bertin1953 +wktext"


> 
> How to do you say "hey GDAL/OGR, pick this libproj.so up"? Is this
> https://trac.osgeo.org/gdal/wiki/ConfigOptions#PROJSO relevant at
> run-time?

Only if you don't compile --with-proj (compiling --with-proj is recommended 
since the dlopen'ing can be confusing)


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nik at nikosalexandris.net  Wed Nov 14 07:26:39 2018
From: nik at nikosalexandris.net (Nikos Alexandris)
Date: Wed, 14 Nov 2018 16:26:39 +0100
Subject: [gdal-dev] The "Bertin 1953" projection
In-Reply-To: <2158265.uYhzpff2mm@even-i700>
References: <20181106105310.67zfzh57b2kboy2i@imap.dreamhost.com>
 <20181114012729.elna2dcwjl3gr3rr@imap.dreamhost.com>
 <20181114105236.tm3zj6yp2ba2de7r@imap.dreamhost.com>
 <2158265.uYhzpff2mm@even-i700>
Message-ID: <20181114152639.zzv23i5o7b4zzqqp@imap.dreamhost.com>

* Even Rouault <even.rouault at spatialys.com> [2018-11-14 12:13:50 +0100]:

>> So, `ogr2ogr` fails to pick up "Bertin 1953":
>> ```
>> ogr2ogr -t_srs +proj=bertin1953 TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.shp
>> TM_WORLD_BORDERS_SIMPL-0.3.shp ERROR 1: Failed to process SRS definition:
>> +proj=bertin1953
>> ```
>
>You need to add the +wktext parameter for use in GDAL:
>	  -t_srs "+proj=bertin1953 +wktext"

It works:

```
ogr2ogr -t_srs "+proj=bertin1953 +wktext" -f GPKG TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.gpkg TM_WORLD_BO
RDERS_SIMPL-0.3.shp
Warning 1: A geometry of type MULTIPOLYGON is inserted into layer TM_WORLD_BORDERS_SIMPL-0.3 of geometry t
ype POLYGON, which is not allowed. This warning will no longer be emitted for this combination of layer an
d feature geometry type.
```

and
```
ogrinfo TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.gpkg -al -so
INFO: Open of `TM_WORLD_BORDERS_SIMPL-0.3_Bertin1953.gpkg'
      using driver `GPKG' successful.

Layer name: TM_WORLD_BORDERS_SIMPL-0.3
Metadata:
  DBF_DATE_LAST_UPDATE=2008-07-30
Geometry: Polygon
Feature Count: 246
Extent: (-14385600.000000, -8557200.000000) - (16159500.000000, 8556070.000000)
Layer SRS WKT:
PROJCS["unnamed",
    GEOGCS["WGS 84",
        DATUM["unknown",
            SPHEROID["WGS84",6378137,298.257223563]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4326"]],
    PROJECTION["custom_proj4"],
    EXTENSION["PROJ4","+proj=bertin1953 +wktext"]]
FID Column = fid
Geometry Column = geom
FIPS: String (2.0)
ISO2: String (2.0)
ISO3: String (3.0)
UN: Integer (0.0)
NAME: String (50.0)
AREA: Integer (0.0)
POP2005: Integer64 (0.0)
REGION: Integer (0.0)
SUBREGION: Integer (0.0)
LON: Real (0.0)
LAT: Real (0.0)
```

Merci Even!

Next would be to make this usable through GRASS GIS or QGIS, for
example.  I'll write in grass-user next for that matter.

Nikos

From even.rouault at spatialys.com  Wed Nov 14 09:54:54 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 14 Nov 2018 18:54:54 +0100
Subject: [gdal-dev] Confusing error behavior of OGR_L_GetSpatialRef
In-Reply-To: <CADPhZXz4CsW8oVZyPCB7CwezCdsxHOXDwa9_D6e=i0b49xK8nw@mail.gmail.com>
References: <CADPhZXxt9=wZGLGVs-ku=X6962e-t5Cvo+JjSfG-wOEABqZJ0Q@mail.gmail.com>
 <29661018.LAqUjdLoVq@even-i700>
 <CADPhZXz4CsW8oVZyPCB7CwezCdsxHOXDwa9_D6e=i0b49xK8nw@mail.gmail.com>
Message-ID: <4621782.8YOWsefx8n@even-i700>

Hi Sean,

(re adding the list)

> > This is driver specific behaviour. How can we reproduce ?
> 
> I see it with this shapefile:
> 
> https://github.com/Toblerity/Fiona/tree/master/tests/data/coutwildrnp.shp
> 
> The .prj file contains
> 
> GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137,298.257
> 223563]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]]
> 
> Strictly speaking, it's not OGR_L_GetSpatialRef() that puts the error on
> the stack, but importFromEPSGAInternal() in ogr_fromepsg.cpp.

OK, yes, that's when the driver tries to identify the ESRI WKT with a CRS in 
the EPSG database.

> 
> > Is the SRS returned still meaningful or somewhat dummy ?
> 
> I'm not sure.

Yes, it is meaningful in that case even in the absence of GDAL_DATA

> 
> If I try to reproject the shapefile without any GDAL_DATA, ogr2ogr writes
> an empty file.
> 
> $ GDAL_DATA=/foo/bar ogr2ogr -f GeoJSON -t_srs epsg:26913 /tmp/foo.json
> tests/data/coutwildrnp.shp
> ERROR 4: Unable to open EPSG support file gcs.csv.  Try setting the
> GDAL_DATA environment variable to point to the directory containing EPSG
> csv files.
> ERROR 1: Failed to process SRS definition: epsg:26913

Yes, that's expected, you need a valid GDAL_DATA to resolve EPSG:26913 from 
the .csv files.

> 
> Though reprojection does seem to work if I pass -t_srs "+init=epsg:26913"
> instead, which is confusing.

Yes, because this syntax goes to PROJ, and read its 'epsg' file instead. 
Hopefully after my current work, both syntax will end up resolving into the 
new proj.db database

> 
> Well, yes, but in my experience unset GDAL_DATA is one of the first gotchas
> for new users who are installing GDAL in new ways (using Anaconda, for
> example). I'm including the GDAL and PROJ support files in my Fiona and
> Rasterio wheels and have it *mostly* foolproof, but not quite.

Is this is an issue with Windows build ? Unix builds should normally not need 
GDAL_DATA and PROJ_LIB and use instead the installation prefix.

> > Anyway soon that will be PROJ_LIB that you will have to define correctly
> > ;-)
> 
> I'm looking forward to having a configuration option for PROJ_LIB. I don't
> like the way I'm patching os.environ in Fiona and Rasterio now.

PROJ doesn't have the equivalent of configuration options, but we could indeed 
have a PROJ C function to set this path.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From _kfj at yahoo.com  Thu Nov 15 03:06:36 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Thu, 15 Nov 2018 12:06:36 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
Message-ID: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>

Hi all!

I have a very detailed GeoTIFF DEM of part of my target area (2m 
resolution). The remainder of the area is covered in 5m. So I'd like to 
downsample the moore detailed data to have everything in 5m for further 
processing. The nearest thing to what I have in mind is using -r 
average, but from signal processing theory I know that using a simple 
average over a block of data is not a good approximation for a low-pass 
filter. Also, since some of the source pixels are fully inside the 
target pixels and some are only partly (5 doesn't divide by 2), An 
average over all participating source pixels seems wrong. What would you 
advise?

With regards
Kay

From deduikertjes at xs4all.nl  Thu Nov 15 03:59:54 2018
From: deduikertjes at xs4all.nl (Marco)
Date: Thu, 15 Nov 2018 12:59:54 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
Message-ID: <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>

Upsample to 1m, then downsample to 5?

On 15-11-18 12:06, Kay F. Jahnke wrote:
> Hi all!
>
> I have a very detailed GeoTIFF DEM of part of my target area (2m 
> resolution). The remainder of the area is covered in 5m. So I'd like 
> to downsample the moore detailed data to have everything in 5m for 
> further processing. The nearest thing to what I have in mind is using 
> -r average, but from signal processing theory I know that using a 
> simple average over a block of data is not a good approximation for a 
> low-pass filter. Also, since some of the source pixels are fully 
> inside the target pixels and some are only partly (5 doesn't divide by 
> 2), An average over all participating source pixels seems wrong. What 
> would you advise?
>
> With regards
> Kay
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


From Mikael.Rittri at carmenta.com  Thu Nov 15 11:44:22 2018
From: Mikael.Rittri at carmenta.com (Mikael Rittri)
Date: Thu, 15 Nov 2018 19:44:22 +0000
Subject: [gdal-dev] Unusual RGB Tiff files with misleading
 PhotometricInterpretation: valid or not?
Message-ID: <E4AB3DD44D22854B819908379DE4AD49508C5CE9@SETHNWS023.carmenta.se>

Hello, list.

I have recently encountered two unusual Tiff files. According to gdalinfo, there are three bands with the color interpretations
Gray, Undefined and Undefined, but eventually I figured out that they are really Red, Green and Blue. Apparently, GDAL gets
the information from the Tiff tag PhotometricInterpretation, which is "min-is-black" for my files, according to tiffinfo.

One of the files has 8 bits per band and I found no further problems with it.

In the other file, each band contains signed 16-bit integers, but it seems that only the values in the range 0 to 253 are used,
plus the special value -32768 that appears to represent NODATA, although there is not enough metadata to make gdalinfo
understand that -32768 is NODATA.  By assuming that the min and max intensities are represented by 0 and 255 in the obvious
way, I could display a sensible image.

My questions are half-technical and half-legal:

1.  If an RGB Tiff file doesn't have PhotometricInterpretation = RGB, can it really be claimed that the file adheres to the Tiff standard, or is it corrupt?

When I open the files in QGIS or ArcMap, they assume RGB for the default visualization but I don't know why. One of the files looks great in
ArcMap by default (but slightly too white, I believe), while it looks very much too white by default in QGIS, although the QGIS display can be
fixed by color re-configuration. For the other file, it is QGIS that displays a sensible image by default, whereas ArcMap displays it with very
exaggerated contrast (the default QGIS display is brownish-rusty like Mars while the default ArcMap display is brightly reddish-white like Jupiter).
So the score is 1 - 1 for the ArcMap/QGIS contest... I think the very different default displays confirm that the files are troublesome or corrupt.

2.  If the min and max intensities are not the same as the min and max representable numbers for the integer type, then how are
they specified in Tiff? I read something about a TransferRange Tiff tag for this purpose but didn't pursue the details, as I suspect
that my 16-bit Tiff file lacks this information. So let me ask: if the file somehow does contain information about the min and max
intensities, how would that information appear in the output from gdalinfo or tiffinfo?

Kind regards,

Mikael Rittri
Carmenta Geospatial Technologies
http://www.carmenta.com



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181115/ef306978/attachment.html>

From even.rouault at spatialys.com  Thu Nov 15 12:20:36 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 15 Nov 2018 21:20:36 +0100
Subject: [gdal-dev] Unusual RGB Tiff files with misleading
	PhotometricInterpretation: valid or not?
In-Reply-To: <E4AB3DD44D22854B819908379DE4AD49508C5CE9@SETHNWS023.carmenta.se>
References: <E4AB3DD44D22854B819908379DE4AD49508C5CE9@SETHNWS023.carmenta.se>
Message-ID: <11600575.dzDDAylNq9@even-i700>

Mikael,

> 1.  If an RGB Tiff file doesn't have PhotometricInterpretation = RGB, can it
> really be claimed that the file adheres to the Tiff standard, or is it
> corrupt?

If it has 2 values for ExtraSamples, then I believe is technically legal (the 
TIFF spec is not really clear but libtiff interprets PhotometricInterpretation 
= MinIsBlack as meaning one nominal channel, all the other ones being extra 
samples), but of course, readers are not expected to interpret such 3-channel 
files as being RGB.

> 2.  If the min and max intensities are not the same as the min and max
> representable numbers for the integer type, then how are they specified in
> Tiff?

There are MinSampleValue and MaxSampleValue tags in the TIFF spec, but those 
are not really used by GDAL and are just reported as metadata.

$ cp byte.tif test.tif
$ tiffset -s MinSampleValue 1 0 test.tif
$ tiffset -s MaxSampleValue 1 255 test.tif
$ gdalinfo test.tif
[...]
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_MAXSAMPLEVALUE=255
  TIFFTAG_MINSAMPLEVALUE=0

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From andrew at aitchison.me.uk  Thu Nov 15 14:33:24 2018
From: andrew at aitchison.me.uk (Andrew C Aitchison)
Date: Thu, 15 Nov 2018 22:33:24 +0000 (GMT)
Subject: [gdal-dev] Unusual RGB Tiff files with misleading
 PhotometricInterpretation: valid or not?
In-Reply-To: <E4AB3DD44D22854B819908379DE4AD49508C5CE9@SETHNWS023.carmenta.se>
References: <E4AB3DD44D22854B819908379DE4AD49508C5CE9@SETHNWS023.carmenta.se>
Message-ID: <alpine.LRH.2.21.1811152217240.598@warden.aitchison.me.uk>

On Thu, 15 Nov 2018, Mikael Rittri wrote:

> When I open the files in QGIS or ArcMap, they assume RGB for the
> default visualization but I don't know why. One of the files looks
> great in ArcMap by default (but slightly too white, I believe),
> while it looks very much too white by default in QGIS, although the
> QGIS display can be fixed by color re-configuration. For the other
> file, it is QGIS that displays a sensible image by default, whereas
> ArcMap displays it with very exaggerated contrast (the default QGIS
> display is brownish-rusty like Mars while the default ArcMap display
> is brightly reddish-white like Jupiter).  So the score is 1 - 1 for
> the ArcMap/QGIS contest... I think the very different default
> displays confirm that the files are troublesome or corrupt.

Sounds like different default gamma correction values.

There are a couple of different default gamma values,
so unless the files specify their gamma, the two applications
could easily pick the right default for different pictures ...

-- 
Andrew C. Aitchison					Cambridge, UK
 			andrew at aitchison.me.uk

From _kfj at yahoo.com  Fri Nov 16 00:49:49 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Fri, 16 Nov 2018 09:49:49 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>
Message-ID: <bc5ef8ae-1cab-bae3-a5b8-eb3071ae43b8@yahoo.com>

On 15.11.18 12:59, Marco wrote:

> Upsample to 1m, then downsample to 5?

That helps with the 'five does not divide by two' aspect and would be an 
improvement on averaging over all contributing points. But it still uses 
a box filter on the interpolated signal, which does not have what you'd 
want in a low-pass filter, namely a short transition band and good 
stop-band attenuation.

Another problem with your proposal is that it initially requires to 
produce an intermediate data set which is four times (2*2) as large as 
the original one, which makes the process long and memory-hungry.

It's better to use a sensible smoothing method in the first place. I 
suppose noone has given this over much thought as in the past you were 
ever so happy about every bit of resolution you could get. But in a time 
where we get very high resolution LIDAR data, the need to downsample 
properly is arising. Look at the interpolation methods: gdalwarp lists 
twelve different ones. The first few are for upsampling, and the 
remainder mostly for dealing with noisy data. Upsampling is well 
covered: cubicspline and lanczos are reasonably sophisticated upsampling 
filters, but there is no good downsampling filter. I think this is an 
omission, hence my post. The problem is real; downsampling with 
'average' produces artifacts, even from previously upsampled data.

Kay

> On 15-11-18 12:06, Kay F. Jahnke wrote:
>>
>> I have a very detailed GeoTIFF DEM of part of my target area (2m 
>> resolution). The remainder of the area is covered in 5m. So I'd like 
>> to downsample the moore detailed data to have everything in 5m for 
>> further processing. The nearest thing to what I have in mind is using 
>> -r average, but from signal processing theory I know that using a 
>> simple average over a block of data is not a good approximation for a 
>> low-pass filter. Also, since some of the source pixels are fully 
>> inside the target pixels and some are only partly (5 doesn't divide by 
>> 2), An average over all participating source pixels seems wrong. What 
>> would you advise?
>>
>> With regards
>> Kay
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


From even.rouault at spatialys.com  Fri Nov 16 01:07:45 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 16 Nov 2018 10:07:45 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <bc5ef8ae-1cab-bae3-a5b8-eb3071ae43b8@yahoo.com>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>
 <bc5ef8ae-1cab-bae3-a5b8-eb3071ae43b8@yahoo.com>
Message-ID: <2622841.7iPav299Wl@even-i700>

> Upsampling is well
> covered: cubicspline and lanczos are reasonably sophisticated upsampling
> filters,

Did you actually try them for downsampling ? They are for sure widely used in 
that case already, for example when using gdaladdo to create overviews. For 
example cubicspline has a filter radius of 2. If you downsample by a factor of 
X, the effective radius will be 2 X.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From _kfj at yahoo.com  Fri Nov 16 02:35:33 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Fri, 16 Nov 2018 11:35:33 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <2622841.7iPav299Wl@even-i700>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>
 <bc5ef8ae-1cab-bae3-a5b8-eb3071ae43b8@yahoo.com>
 <2622841.7iPav299Wl@even-i700>
Message-ID: <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>

On 16.11.18 10:07, Even Rouault wrote:
>> Upsampling is well
>> covered: cubicspline and lanczos are reasonably sophisticated upsampling
>> filters,
> 
> Did you actually try them for downsampling ? They are for sure widely used in
> that case already, for example when using gdaladdo to create overviews. For
> example cubicspline has a filter radius of 2. If you downsample by a factor of
> X, the effective radius will be 2 X.

I did try them, and the result looks 'okay', but I have reservations. I 
come from a DSP background. If my understanding of the mathematics 
involved is correct, evaluating a spline over a data set will produce 
values which are appropriate at a given resolution. If you use these 
values at a lower resolution, you may get aliasing if the initial signal 
has high frequency content. Aliasing always happens if there is high 
frequency content and you resample with a lower sampling rate. You can 
only avoid it by using a low-pass filter before resampling. So I'm 
trying to find out if this does happen here.

If I understand this correctly, the effective radius signifies the 
number of spline coefficients contributing to the interpolated value, it 
does not imply a low-pass filter. If the spline (and I suspect it's a 
B-spline) is created by first prefiltering the data and then evaluating 
the spline at the desired target locations, the interpolation criterion 
is fulfilled and there is no smoothing.

Omitting the prefiltering and using the original data as spline 
coefficients does some smoothing, but from a cubic spline the effect is 
small and does not vary with the scale of the downsampling, so it would 
not work equally well for different scale changes.

Maybe you can point me to the place in the source code where the 
relevant math happens? I had a look but it's very complex and I did not 
find my way in easily.

 > They are for sure widely used

This doesn't automatically make them correct. If my suspicions are 
founded, then there may be room for improvement.

Kay




From even.rouault at spatialys.com  Fri Nov 16 02:57:10 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 16 Nov 2018 11:57:10 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <2622841.7iPav299Wl@even-i700>
 <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>
Message-ID: <17531119.x7q8VYbpSd@even-i700>

> If I understand this correctly, the effective radius signifies the
> number of spline coefficients contributing to the interpolated value, it
> does not imply a low-pass filter. If the spline (and I suspect it's a
> B-spline) is created by first prefiltering the data and then evaluating
> the spline at the desired target locations, the interpolation criterion
> is fulfilled and there is no smoothing.
> 
> Omitting the prefiltering and using the original data as spline
> coefficients does some smoothing, but from a cubic spline the effect is
> small and does not vary with the scale of the downsampling, so it would
> not work equally well for different scale changes.

There is no explicit code to do smoothing. For each target pixel, given the 
radius of the filter and the resampling factor, it determines the index of the 
first and last contributing source pixels and compute the associated weight 
using a filter specific function.

> 
> Maybe you can point me to the place in the source code where the
> relevant math happens? I had a look but it's very complex and I did not
> find my way in easily.

For gdal_translate/gdaladdo computation, the function is there:
https://github.com/OSGeo/gdal/blob/master/gdal/gcore/overview.cpp#L1859

There is functionnaly equivalent code for gdalwarp in
https://github.com/OSGeo/gdal/blob/master/gdal/alg/gdalwarpkernel.cpp#L3825 
for example (we don't use the same code, as the code can be more optimized in 
the gdal_translate/gdaladdo case as a source line gives a target line for 
gdal_translate, whereas for gdalwarp given that coordinate reprojection may 
occur, we cannot assume that, so must process each target pixel independently 
of its neighbours)

One of the function used to compute weights:
https://github.com/OSGeo/gdal/blob/master/gdal/alg/gdalwarpkernel.cpp#L3163

> 
>  > They are for sure widely used
> 
> This doesn't automatically make them correct.

Indeed.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jluis at ualg.pt  Fri Nov 16 03:21:18 2018
From: jluis at ualg.pt (=?utf-8?B?Sm9hcXVpbSBNYW51ZWwgRnJlaXJlIEx1w61z?=)
Date: Fri, 16 Nov 2018 11:21:18 +0000
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <17531119.x7q8VYbpSd@even-i700>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <2622841.7iPav299Wl@even-i700>
 <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>
 <17531119.x7q8VYbpSd@even-i700>
Message-ID: <AM6PR04MB5672B62CFACB453DF0E506DEA6DD0@AM6PR04MB5672.eurprd04.prod.outlook.com>

You may also want to look at GMT's grdfilter:
https://gmt.soest.hawaii.edu/doc/5.4.4/grdfilter.html

and the notes on "Filtering of data in GMT"
https://gmt.soest.hawaii.edu/doc/5.4.4/GMT_Docs.html#filtering-of-data-in-gmt

Joaquim

|>-----Original Message-----
|>From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Even Rouault
|>Sent: Friday, November 16, 2018 10:57 AM
|>To: Kay F. Jahnke <_kfj at yahoo.com>
|>Cc: gdal-dev at lists.osgeo.org
|>Subject: Re: [gdal-dev] downsampling geotiff with a low-pass filter
|>
|>> If I understand this correctly, the effective radius signifies the
|>> number of spline coefficients contributing to the interpolated value,
|>> it does not imply a low-pass filter. If the spline (and I suspect it's
|>> a
|>> B-spline) is created by first prefiltering the data and then
|>> evaluating the spline at the desired target locations, the
|>> interpolation criterion is fulfilled and there is no smoothing.
|>>
|>> Omitting the prefiltering and using the original data as spline
|>> coefficients does some smoothing, but from a cubic spline the effect
|>> is small and does not vary with the scale of the downsampling, so it
|>> would not work equally well for different scale changes.
|>
|>There is no explicit code to do smoothing. For each target pixel, given the
|>radius of the filter and the resampling factor, it determines the index of the
|>first and last contributing source pixels and compute the associated weight
|>using a filter specific function.
|>
|>>
|>> Maybe you can point me to the place in the source code where the
|>> relevant math happens? I had a look but it's very complex and I did not
|>> find my way in easily.
|>
|>For gdal_translate/gdaladdo computation, the function is there:
|>https://github.com/OSGeo/gdal/blob/master/gdal/gcore/overview.cpp#L1859
|>
|>There is functionnaly equivalent code for gdalwarp in
|>https://github.com/OSGeo/gdal/blob/master/gdal/alg/gdalwarpkernel.cpp#L38
|>25
|>for example (we don't use the same code, as the code can be more optimized in
|>the gdal_translate/gdaladdo case as a source line gives a target line for
|>gdal_translate, whereas for gdalwarp given that coordinate reprojection may
|>occur, we cannot assume that, so must process each target pixel independently
|>of its neighbours)
|>
|>One of the function used to compute weights:
|>https://github.com/OSGeo/gdal/blob/master/gdal/alg/gdalwarpkernel.cpp#L31
|>63
|>
|>>
|>>  > They are for sure widely used
|>>
|>> This doesn't automatically make them correct.
|>
|>Indeed.
|>
|>--
|>Spatialys - Geospatial professional services
|>http://www.spatialys.com
|>_______________________________________________
|>gdal-dev mailing list
|>gdal-dev at lists.osgeo.org
|>https://lists.osgeo.org/mailman/listinfo/gdal-dev

From jukka.rahkonen at maanmittauslaitos.fi  Fri Nov 16 04:13:24 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Fri, 16 Nov 2018 05:13:24 -0700 (MST)
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>
 <bc5ef8ae-1cab-bae3-a5b8-eb3071ae43b8@yahoo.com>
 <2622841.7iPav299Wl@even-i700>
 <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>
Message-ID: <1542370404605-0.post@n6.nabble.com>

Hi,

If a low-pass filter is needed before passing data to downsampling, I wonder
if it could be done by utilizing a VRT with KernelFilteredSource
https://www.gdal.org/gdal_vrttut.html. May well be that it is not relevant
at all, my understanding of mathematics coming from agricultural background.

-Jukka Rahkonen-




kfj wrote
> On 16.11.18 10:07, Even Rouault wrote:
>>> Upsampling is well
>>> covered: cubicspline and lanczos are reasonably sophisticated upsampling
>>> filters,
>> 
>> Did you actually try them for downsampling ? They are for sure widely
>> used in
>> that case already, for example when using gdaladdo to create overviews.
>> For
>> example cubicspline has a filter radius of 2. If you downsample by a
>> factor of
>> X, the effective radius will be 2 X.
> 
> I did try them, and the result looks 'okay', but I have reservations. I 
> come from a DSP background. If my understanding of the mathematics 
> involved is correct, evaluating a spline over a data set will produce 
> values which are appropriate at a given resolution. If you use these 
> values at a lower resolution, you may get aliasing if the initial signal 
> has high frequency content. Aliasing always happens if there is high 
> frequency content and you resample with a lower sampling rate. You can 
> only avoid it by using a low-pass filter before resampling. So I'm 
> trying to find out if this does happen here.
> 
> If I understand this correctly, the effective radius signifies the 
> number of spline coefficients contributing to the interpolated value, it 
> does not imply a low-pass filter. If the spline (and I suspect it's a 
> B-spline) is created by first prefiltering the data and then evaluating 
> the spline at the desired target locations, the interpolation criterion 
> is fulfilled and there is no smoothing.
> 
> Omitting the prefiltering and using the original data as spline 
> coefficients does some smoothing, but from a cubic spline the effect is 
> small and does not vary with the scale of the downsampling, so it would 
> not work equally well for different scale changes.
> 
> Maybe you can point me to the place in the source code where the 
> relevant math happens? I had a look but it's very complex and I did not 
> find my way in easily.
> 
>  > They are for sure widely used
> 
> This doesn't automatically make them correct. If my suspicions are 
> founded, then there may be room for improvement.
> 
> Kay
> 
> 
> 
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From jacob.dan.adams at gmail.com  Fri Nov 16 07:38:31 2018
From: jacob.dan.adams at gmail.com (JDA)
Date: Fri, 16 Nov 2018 08:38:31 -0700
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
Message-ID: <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>


> It's better to use a sensible smoothing method in the first place. I 
> suppose noone has given this over much thought as in the past you were 
> ever so happy about every bit of resolution you could get. But in a time 
> where we get very high resolution LIDAR data, the need to downsample 
> properly is arising. Look at the interpolation methods: gdalwarp lists 
> twelve different ones. The first few are for upsampling, and the 
> remainder mostly for dealing with noisy data. Upsampling is well 
> covered: cubicspline and lanczos are reasonably sophisticated upsampling 
> filters, but there is no good downsampling filter. I think this is an 
> omission, hence my post. The problem is real; downsampling with 
> 'average' produces artifacts, even from previously upsampled data.

There’s a wide array of smoothing options available If you’re willing to work in python. Based on https://gis.stackexchange.com/a/10467, the basic idea is to load the raster into a numpy array and then convolve it with either a kernel of arbitrary size. 

I’ve written a program implementing that idea with both a Gaussian and a mean kernel here:
https://github.com/jacobdadams/general_scripts/blob/master/raster_chunk_processing.py. It only smooths the data without downsampling, but there may be some python functions that downsample as well. 

There’s a lot of code in there for dealing with massive rasters by processing them in chunks in parallel, but the blur_mean and blur_gauss functions are where the smoothing is done. I’ve written an installation and usage guide at https://gisjake.blogspot.com/2018/10/rasterchunkprocessingpy-installation.html?m=1. 

I’ve successfully used both the Gaussian blur and the Mesh Denoise methods to get rid of the surface “noise” (grass, alfalfa fields, etc) on half-meter lidar. I’ve combined the resulting hillshade with a 10 meter hillshade using gdalbuildvrt, but I haven’t found a good way to combine the 10m and half-meter DEMs yet.  

The valley floor slope layers on the Cache County parcel and zoning viewer were produced from the smoothed lidar DEM (cachecounty.org/gis, click on Parcel and Zoning Viewer, or direct link: http://66.232.67.238/Websites/Parcel%20and%20Zoning%20Viewer/; in the map, open the layer list, expand Sensitive/Planning Layers, turn on the two slope layers, then zoom in close so the parcel numbers don’t cover everything). 

Jake
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181116/8ff0511b/attachment.html>

From neteler at osgeo.org  Fri Nov 16 08:04:12 2018
From: neteler at osgeo.org (Markus Neteler)
Date: Fri, 16 Nov 2018 17:04:12 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>
Message-ID: <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>

On Fri, Nov 16, 2018 at 4:38 PM JDA <jacob.dan.adams at gmail.com> wrote:
>
>
> It's better to use a sensible smoothing method in the first place. I
> suppose noone has given this over much thought as in the past you were
> ever so happy about every bit of resolution you could get. But in a time
> where we get very high resolution LIDAR data, the need to downsample
> properly is arising. Look at the interpolation methods: gdalwarp lists
> twelve different ones. The first few are for upsampling, and the
> remainder mostly for dealing with noisy data. Upsampling is well
> covered: cubicspline and lanczos are reasonably sophisticated upsampling
> filters, but there is no good downsampling filter. I think this is an
> omission, hence my post. The problem is real; downsampling with
> 'average' produces artifacts, even from previously upsampled data.
>
>
> There’s a wide array of smoothing options available If you’re willing to work in python. Based on https://gis.stackexchange.com/a/10467, the basic idea is to load the raster into a numpy array and then convolve it with either a kernel of arbitrary size.

There are plenty of different kernel smoothers in GRASS GIS, e.g.

box, bartlett, gauss, normal, hermite, sinc, lanczos1, lanczos2,
lanczos3, hann, hamming, blackman
https://grass.osgeo.org/grass76/manuals/r.resamp.filter.html

Using "grass-session" (https://github.com/zarch/grass-session) you can
use the functionality in Python also from "outside" without even
knowing much about GRASS GIS itself.

Markus

From _kfj at yahoo.com  Sat Nov 17 02:04:13 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Sat, 17 Nov 2018 11:04:13 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>
 <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>
Message-ID: <7e520169-21cc-497d-4912-a074943a9e4a@yahoo.com>

Thank you all for responding. Rather than responding to each individual 
post, I'll try and summarized what I have gleaned so far, please correct 
me if I have misunderstood something. This will be a long post, please 
forgive my verbosity, but this is not a trivial topic.

1.

I'll start with cubic spline resampling. Thanks to Even for pointing me 
to the GDAL code. It looks to me as if the sample of the B-spline basis 
function is applied directly to the source data, with no prefiltering 
applied to the source data. The sampled b-spline basis function is then 
used to produce a weighted average of source data values. If 
prefiltering is indeed omitted, the resulting interpolation has a 
slightly smoothing effect and does not fulfill the interpolation 
criterion, meaning that the result of the operation at locations 
coinciding with source data points does not precisely reproduce the 
source data. This seems to be what's happening: without a scale change, 
the application of cubic spline resampling seems to slightly smoothe the 
signal.

Application of the b-spline evaluation without previous prefiltering is 
commonly done, sometimes deliberately because the slight smoothing is 
intended and the resulting signal will stay within the convex hull of 
the coefficients (so, there won't be overshoots, which are possible with 
prefiltered coefficients) - and sometimes erroneously, because the need 
for prefiltering is not known. For slight downscaling, this smoothing 
may be 'just right', but it's only 'about right' for a small range of 
scaling factors. Note here that b-spline prefiltering is not the 
low-pass filter which has to be applied to the source data before 
resampling.

b-splines are not 'direct' interpolators. Direct interpolators 
approximate the continuous signal by using some operation over the given 
samples. b-splines instead use an operation over a set of coefficients, 
which are generated from the original samples by 'prefiltering' them. 
This can be explained simply: The 'reconstruction' filter for a given 
b-spline is a low-pass filter. Hence, applying it to the original signal 
will 'blur' that signal. The prefilter is a high-pass filter which 
'sharpens' the original signal by just so much that applying the 
reconstruction filter will produce the original signal. The problem with 
prefiltering is that it's done with an IIR filter and has theoretically 
infinite support (usually it's enough to have a handful of support 
either end, forgive my sloppy formulation), which makes margin treatment 
and handling of no-data value a dicey issue. This is probably one reason 
why prefiltering tends to be omitted.

2.

Looking at the source code, what I understand from it is that, as I have 
stated in my initial post, upsampling is indeed well-covered, but the 
only 'filter' which makes sense in a downsampling context is 'average', 
with all the disadvantages it has. In the GRASS codebase (Thanks to 
Markus for pointing to it) I noticed that the need for specialized 
technique for downsampling is acknowledged and there is a filtering 
method which is definitely better-suited than just averaging over 
contributing source data values: the 'weight according to area' 
parameter, which can be passed to the r.resamp.stats method. This is a 
technique which is also used in astronomy - I've seen it first in 
openCV, where it is one of the standard interpolators ('area'). It can 
produce output data which preserve the energy content of the input 
signal, looking at it as if it were composed of small rectangles of a 
uniform value and doing an average over a part of that pattern which is 
given by the extent of the (larger) target pixel. This method is 
definitely preferable to using the method without the -w parameter. It 
also has the nice property of having small support and the resulting 
signal will not over- or undershoot. I'd encourage GDAL to consider 
adopting this method to avoid the worst of downsampling errors that come 
with '-r average'.

3.

Downsampling usually has to be preceded by an appropriate low-pass 
filter. Let me iterate when such a filter is needed:

The highest representable frequency in the target (downsampled) signal 
is given by the Nyquist frequency for this signal's sampling rate. If 
the source signal has frequency content higher than that, it *must* be 
low-pass filtered before resampling, because otherwise the 
high-frequency content will 'alias' into the target signal and produce 
artifacts. If such high-frequency content is not present, resampling can 
proceed without previous low-pass filtering.

Oftentimes the high-frequency content is small, and especially when this 
comes together with small amounts of downscaling, omitting the low-pass 
filter will only produce small errors which are not easily seen, so the 
result may pass as correct, looking 'okay', when in fact is it slightly 
wrong, but not noticeably so. With increasing high-frequency content and 
larger downscaling factors, the error grows and may 'spoil' the signal 
so much that it becomes noticeable.

So, first, we have to establish if there is need for low-pass-filtering, 
and the advice would be to use it if there is relevant high-frequncy 
content. This might be seen from an FFT of the signal. If the FFT is at 
hand, the high-frequency part can be removed in the frequency domain, 
and after IFFT the signal is 'eligible' for resampling without further 
ado. This is a straightforward approach, but it does not play well with 
no-data values. It's also possible to apply a low-pass filter no matter 
if there is high-frequency content: if there is no high-frequency 
content, a good low-pass filter has no effect. So now we come to the 
next question, namely 'what is a good low-pass filter'.

4.

Thanks to Jakob for pointing me to your python code. I'll happily use 
Python :D

Using a gaussian to smoothe (or low-pass-filter) the source signal is a 
valid approach, especially since the radius of the gaussian can be 
chosen to match the desired degree of smoothing, which, in a 
downsampling context, depends on the scale change. Using a truncated 
gaussian (the 'true gaussian' is infinitely large) as a convolution 
kernel is common and well-understood. The suppression of high-frequency 
content is not as sharp as one might wish; there are filters with 
smaller transition bands and better stop-band attenuation, but they have 
to be custom-designed for a given downsampling factor, and from what 
I've seen this is not commonly done in general-purpose software.

I'd say that using a gaussian - or other convolution-based low-pass 
filter is a good idea and should outperform the 'weight according to 
area' method, with the downside of the wider support, which makes the 
handling of no-data values more difficult. Gaussian kernels will also 
not produce overshoots (because all weights are positive), which is a plus.

What has to be understood here is that the filter has to match the 
desired scale change. The kernel has to be produced by a process taking 
the scale change into account, which can be done for a gaussian by 
choosing an appropriate standard deviation. So a general-pupose 
downsampling algorithm would perform these steps:

- generate a custom filter (like, a kernel) given the desired scale change

- apply this filter to the source data

- use an interpolator over the low-pass filtered signal to obtain the 
target values for the given target locations.

Not taking the scale change into account and using a fixed kernel will 
only be appropriate for a specific scale change, so it's no good for the 
general purpose case, but can be used for specific scale changes, like 
halving the resolution ('half-band filter'), which may be repeated 
several times to cover larger scale changes.

5.

This gets me to Jukka's response pointing me to VRT files with 
KernelFilteredSource. I hadn't seen/noticed this before, thanks for 
pointing it out! With the proviso that the kernel suits the scaling 
factor (so, it has to be computed for a desired scale change) this looks 
like an excellent way of dealing with the problem: The filter is 
conceptually attached to the source data where it belongs, and 
interpolation of target values operates on the filtered data. Neat. It 
leaves the user with having to figure out a suitable kernel - a kernel 
derived from a truncated (or otherwise windowed) gaussian (needs to be 
normalized, though) would be a good starting point. I'll try that and 
report back. It also fits well with my current work flow of using shell 
scripts and gdal.

Also, thanks to Joaquim. The code you link to also looks like it will 
suit the problem, but I'll admit to a bit of overload here and defer 
looking at it in more detail to sometime later. What I found especially 
attractive is 'grdfft', which performs operations in the frequency 
domain, which is, as I have pointed out above, a very clean and 
desirable way of treating the problem and should be ideal, but might be 
difficult to use if there are no-data values - and the FFT and IFFT are 
sure computationally intensive. I think that the GRASS code base also 
offers FFT and IFFT, so it might be possible to use GRASS to the same 
effect.

6.

To conclude:

- downsampling without previous low-pass filtering is normally an error.

- upsampling is a very different matter and requires no previous 
filtering, it's necessary to see the distinction.

- there is a wide spectrum of possible low-pass filters, but the filter 
has to be customized to the given scaling factor. There is no 'one 
kernel fits all' approach.

- once the low-pass filtered signal has been obtained, it can be 
downsampled using any of the available methods, but preferably *not* 
nearest neighbour. Cubic spline is good here.

Still with me? Thanks for your patience! I hope I have understood all 
the source code and response posts correctly, don't hesitate to correct me.

Kay

From even.rouault at spatialys.com  Sat Nov 17 04:46:21 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 17 Nov 2018 13:46:21 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <7e520169-21cc-497d-4912-a074943a9e4a@yahoo.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>
 <7e520169-21cc-497d-4912-a074943a9e4a@yahoo.com>
Message-ID: <5738282.Gq529AdAku@even-i700>

Kay,

> This will be a long post, please forgive my verbosity, but this is not a 
trivial topic.

Thanks a lot for the in-depth analysis.

> 
> 1.
> 
> I'll start with cubic spline resampling. Thanks to Even for pointing me
> to the GDAL code. It looks to me as if the sample of the B-spline basis
> function is applied directly to the source data, with no prefiltering
> applied to the source data. 

I confirm.

> The prefilter is a high-pass filter which
> 'sharpens' the original signal by just so much that applying the
> reconstruction filter will produce the original signal. The problem with
> prefiltering is that it's done with an IIR filter and has theoretically
> infinite support (usually it's enough to have a handful of support
> either end, forgive my sloppy formulation), which makes margin treatment
> and handling of no-data value a dicey issue. This is probably one reason
> why prefiltering tends to be omitted.

So there would be a need for high-pass prefilter after a low-pass one, before 
applying the resampling function ?
How would that high-pass prefilter would be implemented ? Do you have 
references for that ?
Does that high-pass prefilter only applies to cubic bspline, or to other 
methods as welll ? currently the code logic is common for Bicubic (Catmull-
Rom), Bicubic-BSpline and Lanczos. They only differ by the kernel radius and 
the weighting function applied.


> 
> 2.
>  I'd encourage GDAL to consider
> adopting this method to avoid the worst of downsampling errors that come
> with '-r average'.

I somehow remember people mentionning this in the past too. (ah and "GDAL" 
would be an abstract concept, if not embodied by its contributors, like you 
potentially ;-) )

> 
> 3.
> 
> It's also possible to apply a low-pass filter no matter
> if there is high-frequency content: if there is no high-frequency
> content, a good low-pass filter has no effect. 

Would probably be faster from a computation point of view to just apply the 
filter than prior checking if it is needed. One point to have in mind is that 
for memory reasons, and also because users also want to process big images by 
chunks, GDAL operates by chunks and not on the whole image, so "infinite 
support" is at best limited to the source window being passed to the function.


> What has to be understood here is that the filter has to match the
> desired scale change. The kernel has to be produced by a process taking
> the scale change into account, which can be done for a gaussian by
> choosing an appropriate standard deviation.

For a down-to-earth approach, any recommended formulas to apply ? Does it 
depend only on the scaling factor ?

> 
> Still with me? Thanks for your patience! I hope I have understood all
> the source code and response posts correctly, don't hesitate to correct me.

While we are at assessing correctness of the implementation, one point that 
has sometimes been raised is the potential impact of the "pixel-is-area" 
versus "pixel-is-point" convention. Typically an imaging sensor will reflect 
the number of photons collected over an area in a range of wave-length, so the 
value of the pixel applies to the whole area it covers. Other datasets might 
be the result of a variable evaluated at the center of the pixel. GDAL 
currently computes the distances to the pixel centre when computing the 
weights of the resampling function, so it would seem to me that it is the 
natural way for "pixel-is-point" datasets, and I'm wondering how good it is 
for "pixel-is-area" ones.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From Mikael.Rittri at carmenta.com  Sat Nov 17 11:51:27 2018
From: Mikael.Rittri at carmenta.com (Mikael Rittri)
Date: Sat, 17 Nov 2018 19:51:27 +0000
Subject: [gdal-dev] Unusual RGB Tiff files with misleading
 PhotometricInterpretation: valid or not?
In-Reply-To: <11600575.dzDDAylNq9@even-i700>
References: <E4AB3DD44D22854B819908379DE4AD49508C5CE9@SETHNWS023.carmenta.se>,
 <11600575.dzDDAylNq9@even-i700>
Message-ID: <E4AB3DD44D22854B819908379DE4AD49508C707D@SETHNWS023.carmenta.se>

Thanks for the excellent and fast information, Even and Andrew. I think I have learned all I need to know,
for now. Much obliged.

ER>  ... but of course, readers are not expected to interpret such 3-channel files as being RGB.

That's what I thought, but I am glad that you confirm it. I was confused when both ArcMap and QGIS 
chose a default display that assumed some kind of RGB.  I suppose they have some built-in rule of thumb, 
saying that three channels declared as Gray/Undefined/Undefined are most likely to be a mis-tagged RGB file.

By the way, I also had got the impression that MinIsBlack would refer to all channels, but I suppose the libtiff
behaviour must be correct - that makes more sense. One of my files did have 2 values for Extra Samples, but 
not the other.  Weird. 

The default visualization for a Gray/Undefined/Undefined file in Carmenta Engine, when using our GdalDataSet
class (based on you-know-what), is to just show the first channel as a grayscale. I think this is faithful to the
declared Photometric Interpretation, but for these mis-tagged files I noticed a risk: a Red channel displayed
as grayscale can show enough of the map features that you don't notice something is wrong - you think you
are seeing a grayscale map correctly. If the brightness contrasts between foreground and background are
strong, it looks pretty good. But if you are really unlucky, I guess there could be a text "Danger! Minefield!"
that is colored so that it becomes invisible when only showing the Red channel. 

ER> There are MinSampleValue and MaxSampleValue tags in the TIFF spec, but those
ER> are not really used by GDAL and are just reported as metadata.

OK, but for the record, I checked them in the TIFF specification, and I think you misremember the purpose
of these tags. GDAL seems to be doing the right thing already, since they are supposed to give the min and
max of the range of values that occur in the file - they don't give the representations of min and max intensity. 
They are not supposed to alter the display, but maybe some GIS systems use them for non-standard contrast
enhancement or something.

The TIFF specification does seem to say that for RGB, the min and max intensities are always 0 and 255 for 8-bit
data, and 0 and 65535 for 16-bit data.  I think I finally figured out how the data provider documented that they
used 255 for the max intensity in their 16-bit data: they had a Raster Attribute Table in a .tif.aux.xml file, where
channel values in the range 0 to 255 had an attribute named Contrast of type Double, with the value b/255 for
each value b. Now that's unusual, I think - I have never seen anything like this before.

ACA> Sounds like different default gamma correction values.

That may be a useful clue. I don't know much about gamma correction but I think it may be a part of the problem,
but perhaps not the main one.

Kind regards,

Mikael Rittri
Carmenta Geospatial Technologies
http://www.carmenta.com

________________________________________
From: Even Rouault [even.rouault at spatialys.com]
Sent: Thursday, November 15, 2018 9:20 PM
To: gdal-dev at lists.osgeo.org
Cc: Mikael Rittri
Subject: Re: [gdal-dev] Unusual RGB Tiff files with misleading PhotometricInterpretation: valid or not?

Mikael,

> 1.  If an RGB Tiff file doesn't have PhotometricInterpretation = RGB, can it
> really be claimed that the file adheres to the Tiff standard, or is it
> corrupt?

If it has 2 values for ExtraSamples, then I believe is technically legal (the
TIFF spec is not really clear but libtiff interprets PhotometricInterpretation
= MinIsBlack as meaning one nominal channel, all the other ones being extra
samples), but of course, readers are not expected to interpret such 3-channel
files as being RGB.

> 2.  If the min and max intensities are not the same as the min and max
> representable numbers for the integer type, then how are they specified in
> Tiff?

There are MinSampleValue and MaxSampleValue tags in the TIFF spec, but those
are not really used by GDAL and are just reported as metadata.

$ cp byte.tif test.tif
$ tiffset -s MinSampleValue 1 0 test.tif
$ tiffset -s MaxSampleValue 1 255 test.tif
$ gdalinfo test.tif
[...]
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_MAXSAMPLEVALUE=255
  TIFFTAG_MINSAMPLEVALUE=0

Even

--
Spatialys - Geospatial professional services
http://www.spatialys.com

From oliverrausch99 at gmail.com  Sat Nov 17 17:36:41 2018
From: oliverrausch99 at gmail.com (Oliver Rausch)
Date: Sun, 18 Nov 2018 02:36:41 +0100
Subject: [gdal-dev] Use gdal_rasterize for two different layers with two
 different channels
Message-ID: <20181118023641.70279eb4@lydia>

Hi all,
I have two tables of geometries that I'd like to rasterize onto one
output. I can rasterize the tables individually using

gdal_rasterize -burn 255 -sql "SELECT way FROM lines" PG:'...' -te ...
-ts ... out.tif

Is there a way to get a raster where, for instance all the lines from
one table are on the red channel, and all the lines from the second
table are on the blue channel?

Thanks,
Oliver .

From jukka.rahkonen at maanmittauslaitos.fi  Sun Nov 18 00:31:23 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Sun, 18 Nov 2018 01:31:23 -0700 (MST)
Subject: [gdal-dev] Use gdal_rasterize for two different layers with two
 different channels
In-Reply-To: <20181118023641.70279eb4@lydia>
References: <20181118023641.70279eb4@lydia>
Message-ID: <1542529883418-0.post@n6.nabble.com>

Hi,

Create the raster to have as many bands as you will need and burn the first
set as red

... -burn 255 -burn 0 -burn 0 -ot byte ...

Then paint more features with reen  color to existing raster

... -b 1 -b 2 -b 3 -burn 0 -burn 255 -burn 255 ...

These parameters overwrite red and blue bands to zero and the result is
certainly green. If the data matters and you want to keep the existing
values on other bands then burn just the green band

... -b 2 -burn 255

Now the pixels which have overlap with the previous red geometries will have
RGB values (255 255 0) and appear yellow. 
The examples in https://www.gdal.org/gdal_rasterize.html try to cover this
use case but they may not be most clear.

-Jukka Rahkonen-




Oliver Rausch wrote
> Hi all,
> I have two tables of geometries that I'd like to rasterize onto one
> output. I can rasterize the tables individually using
> 
> gdal_rasterize -burn 255 -sql "SELECT way FROM lines" PG:'...' -te ...
> -ts ... out.tif
> 
> Is there a way to get a raster where, for instance all the lines from
> one table are on the red channel, and all the lines from the second
> table are on the blue channel?
> 
> Thanks,
> Oliver .
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From _kfj at yahoo.com  Sun Nov 18 02:49:02 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Sun, 18 Nov 2018 11:49:02 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <5738282.Gq529AdAku@even-i700>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>
 <7e520169-21cc-497d-4912-a074943a9e4a@yahoo.com>
 <5738282.Gq529AdAku@even-i700>
Message-ID: <252d72b2-9e6c-fe95-6671-dc6cad4e0e32@yahoo.com>

On 17.11.18 13:46, Even Rouault wrote:
> 
> Thanks a lot for the in-depth analysis.

You liked that? I'll give you more, and I hope that I can get my points 
across. It will be another long post.

First, I'm not really a DSP *expert*, but I'm doing my best to share my 
limited understanding. But it so happens that I know a lot about b-splines:

https://bitbucket.org/kfj/vspline

>> The prefilter is a high-pass filter which
>> 'sharpens' the original signal by just so much that applying the
>> reconstruction filter will produce the original signal. The problem with
>> prefiltering is that it's done with an IIR filter and has theoretically
>> infinite support (usually it's enough to have a handful of support
>> either end, forgive my sloppy formulation), which makes margin treatment
>> and handling of no-data value a dicey issue. This is probably one reason
>> why prefiltering tends to be omitted.
> 
> So there would be a need for high-pass prefilter after a low-pass one, before
> applying the resampling function ?
> How would that high-pass prefilter would be implemented ? Do you have
> references for that ?
> Does that high-pass prefilter only applies to cubic bspline, or to other
> methods as welll ? currently the code logic is common for Bicubic (Catmull-
> Rom), Bicubic-BSpline and Lanczos. They only differ by the kernel radius and
> the weighting function applied.

I see that this is confusing, so I'll try and clarify.

1. low-pass filtering

Before downsampling, high frequencies have to be removed from the signal 
if they are present. This is a simple fact of digital signal processing. 
You have to look at the signal, see if high frequencies are present, and 
remove them from the signal before proceeding. This is done with a 
low-pass filter and can only be omitted if the signal has no relevant 
high-frequency content. And, as I said, if you have a good low-pass 
filter, you may apply it anyway: if there are no high frequencies in the 
signal, the low-pass filter should have no effect.

This is the theory. In reality, though, low-pass filters are never truly 
perfect, so applying them on principle will always degrade the 
low-frequency content as well. An ideal low-pass filter would completely 
remove all frequencies above a given limit (this part of the spectrum is 
called the stop band) and pass all other frequencies unchanged (this is 
called the pass band) - with no in-between (the in-between is called the 
transition band). Real filters differ from this ideal, so usually the 
transition band is not zero-length, stop-band attenuation is not 
perfect, and there is some attenuation in the pass band as well.

So how can we approach an ideal low-pass? One approach of digital 
filtering is convolution. It's well-understood, easy to implement and 
has some advantages, especially for specific classes of kernels. But 
even with quite large kernels, to get near-ideal filter characteristics 
is hard. Much more effective than convolution is the use of 'IIR' 
filters. They tend to give very strong stop-band attenuation and short 
transition bands. But they are hard to design for a given set of 
requirements - there are many approaches, but it's all DSP black magic, 
and most of it is beyond my horizon, so here we'd have to call for help 
from the real experts.

Let's assume we have settled on a specific filter and applied it to the 
signal - or we have found the signal has no significant high-frequency 
content so we have omitted the filter. Let's call what we have now the 
'clean' signal. We are now ready for the next step.

It's important to acknowledge that the initial low-pass filter is 
needed. gdal does not use a low-pass filter before downsampling and 
requires users to know what they are doing: they have to apply the 
filter themselves. But most users will be unaware of this fact and rely 
on gdal to 'do things right'. But it doesn't.

2. downsampling the 'clean' signal

There are simple cases of downsampling, where we needn't think much 
about how to proceed. These cases occur when the downsampling can be 
done by simply picking every other, every third etc. sample from the 
clean signal. Doing so is certain not to 'miss' part of the signal, 
since the only thing we could miss here are the high frequencies, which 
are by definition absent from the clean signal. So this subsampling is 
safe. This special type of subsampling is called decimation, and if one 
can apply it, it's great because it's simple and mathematically correct.

Most of the time, though, things are not so easy: The subsampling is by 
a non-integer factor, or the points at which we want to pick up the 
subsamples aren't precisely at the locations where the samples of the 
input signal are located (in gdal term, ULLR for input and output may 
differ). So what needs to be done? We need to *interpolate*. 
Interpolation is a guess about how the signal looks where we don't have 
data. We only have data at the sampling locations, in between, we're 
reduced to guesswork, but we can make informed guesses guided by 
mathematical criteria, accepting that each way of guessing may have 
advantages and disadvantages. gdal offers quite a few interpolation 
methods, starting with the very fast but signal-degrading 
nearest-neighbour 'interpolation' and proceeding via linear 
interpolation to more sophisticated techniques like b-splines.

What do we expect of an interpolator? It should reproduce the input when 
it is evaluated at the sampling locations. This is called the 
'interpolation criterion'. 'in-between', it's informed guesswork, so it 
depends on the specific interpolator. Obviously, nearest-neighbour 
'interpolation' fulfills the interpolation criterion, as does linear 
interpolation. b-splines also do, but you can't simply apply the 
b-spline evaluation to the clean signal itself. b-spline mathematics 
require that the input signal be 'prefiltered' to obtain a set of 
'coefficients' which are then fed to the evaluation process. This 
prefilter is a high-pass filter which has to be applied to the input 
signal before the b-spline can be evaluated.

Let' stick with the cubic b-spline for now, and do a sample evaluation 
at an integral position (so, at a sample loaction). Let the clean signal 
be ... 0 , 1 , 0 ... and we'll evaluate right where the '1' is.

The b-spline reconstruction kernel (or, the set of weights at integral 
positions) is 1/6 2/3 1/6. If we convolve, we get

0 * 1/6 + 1 * 2/3 + 0*1/6 = 2/3

You can see that the interpolation criterion is *not* fulfilled, because 
we'd expect to see '1' as the result. Why is this? because we haven't 
prefiltered. I'll not go into prefiltering now, but a *prefiltered* 
signal at this position is

  -0.464285714 1.732142857 -0.464285714

and, voila, we get

  -0.464285714 * 1/6 + 1.732142857 * 2/3 + -0.464285714 * 1/6 = 1

When the b-spline is used for interpolation, so when it's evaluated at 
locations which are not the sample locations, the maths are less simple; 
the set of weights to apply to the coefficients has to be calculated, 
which is what the gdal code you have pointed me to does (in 
GWKBSpline4Values; it produces four weights, three weights as in my 
example above are a special case for evaluating at integral positions).

But applying this set of weights to the unmodified clean signal will, as 
in my little example, *not* reproduce the clean signal. Only forming the 
weighted sum from the b-spline coefficients will do so. Using b-spline 
evaluation on the input signal without prefiltering is, strictly 
speaking, wrong.

So what happens if you do it nevertheless? Obviously you lose some of 
the signal. And what you lose is some high-frequency content. The 
prefiltering boosts high-frequency content to compensate for the effect, 
and the boosting is fine-tuned to *precisely* counteract it, so that the 
interpolation criterion is fulfilled. If we don't apply the prefilter (a 
high-pass filter) before using the b-spline evaluation formula (a 
low-pass filter), we effectively low-pass-filter the signal.

Back to our processing chain. We have the 'clean' signal which has been 
stripped of high frequency content in step 1 above. Now we want to use 
b-spline interpolation on it to get our target signal. So before we can 
use b-spline evaluation, we need to prefilter the clean signal. This is 
something we do to the clean signal, and it has to be done, because 
otherwise we can't correctly interpolate. And this is what is missing in 
gdal, where the prefiltering is not done. What gdal does do instead is 
applying a slight low-pass filter instead of precisely interpolating. 
This low-pass has nothing to to with the low-pass in step 1, it simply 
happens to be yet another effect which is also a low-pass. The effect is 
mild and oftentimes it won't be easy to spot - And oftentimes it's even 
desired. It can even mask the problems arising from omitting step 1 above.

3. correct procedure

So, to finish this off, if you want to do everything right, how do you 
do it?

- first apply a low-pass filter to the signal to get the 'clean' signal

- then interpolate over the clean signal

And, if you want to use b-spline interpolation over the clean signal, 
you have to 'prefilter' it before using the b-spline evaluation formula. 
Other interpolators do not require this extra step, but usually their 
results are not as good.

>>
>> 2.
>>   I'd encourage GDAL to consider
>> adopting this method to avoid the worst of downsampling errors that come
>> with '-r average'.
> 
> I somehow remember people mentionning this in the past too. (ah and "GDAL"
> would be an abstract concept, if not embodied by its contributors, like you
> potentially ;-) )
> 

I'd like to help, but rather by explaining things. I'd not really like 
to get involved in coding, as I have a lot of work on my hands already.

I do owe the gdal project a debt, though. I am creating extremely 
detailed GPS maps of the Piedmont from government data using free 
software only, and if it weren't for QGIS, gdal and GRASS, my work would 
be very difficult indeed.

>>
>> 3.
>>
>> It's also possible to apply a low-pass filter no matter
>> if there is high-frequency content: if there is no high-frequency
>> content, a good low-pass filter has no effect.
> 
> Would probably be faster from a computation point of view to just apply the
> filter than prior checking if it is needed. One point to have in mind is that
> for memory reasons, and also because users also want to process big images by
> chunks, GDAL operates by chunks and not on the whole image, so "infinite
> support" is at best limited to the source window being passed to the function.

Jukka's hint to use kernel-filtered sources in a VRT file does do the 
trick and shows the way to go, but requires an intermediate file of the 
same size as the initial input. The maths is already there. Doing the 
step-1 low-pass this way is a reasonable choice, even if IIR filters may 
perform better. If the process is done in chunks, you need to cut 
overlapping chunks. The overlap has to be large enough to give support 
for the calculation of the pixels at the edge of the actual tiles. When 
using convolution, the size of the overlap has to be half the kernel 
size, which is not too much. With IIR filters, you can choose how much 
error you find acceptable and select the overlap size accordingly.

> 
>> What has to be understood here is that the filter has to match the
>> desired scale change. The kernel has to be produced by a process taking
>> the scale change into account, which can be done for a gaussian by
>> choosing an appropriate standard deviation.
> 
> For a down-to-earth approach, any recommended formulas to apply ? Does it
> depend only on the scaling factor ?

Theoretically, it does depend only on the scaling factor. But as I have 
outlined above, digital filters are not perfect. They have transition 
bands, pass-band and stop-band ripple - so, in reality, it depends. I 
know this is a frustrating answer, but this is a fact of life. In the 
real world, you have to compromise and find a solution which is 'good 
enough' for what you have in mind.

When using gaussians for low-pass filtering, there is a rule of thumb, 
but just now I can't seem to find it, sorry. I'll try and come up with 
the rule of thumb, which gives a standard deviation which will remove a 
'significant portion' of frequencies above a given limit. Given that 
standard deviation, you can truncate the gaussian and then normalize it. 
But there are many different low-pass filters, each with it's own 
special characteristics, and gaussians aren't necessarily the ones which 
are best suited for all tasks.

Don't you have a DSP specialist in your community? Would be nice to have 
someone else joining the discussion. My DSP knowledge is mainly through 
image processing, so I may miss fine points with geodata.

> 
>>
>> Still with me? Thanks for your patience! I hope I have understood all
>> the source code and response posts correctly, don't hesitate to correct me.
> 
> While we are at assessing correctness of the implementation, one point that
> has sometimes been raised is the potential impact of the "pixel-is-area"
> versus "pixel-is-point" convention. Typically an imaging sensor will reflect
> the number of photons collected over an area in a range of wave-length, so the
> value of the pixel applies to the whole area it covers. Other datasets might
> be the result of a variable evaluated at the center of the pixel. GDAL
> currently computes the distances to the pixel centre when computing the
> weights of the resampling function, so it would seem to me that it is the
> natural way for "pixel-is-point" datasets, and I'm wondering how good it is
> for "pixel-is-area" ones.

We could fill a whole new thread discussing this ;)

First the sensor. When it comes to images, you are right: the sensor has 
an area. But it's a smallish area, definitely smaller than the area a 
pixel 'occupies' later on (because the sensor chip has other stuff on 
it's surface), and the incoming signal is already low-pass filtered by 
the lambda filter, and then the light goes through a color filter to 
produce a bayer pattern which only produces 'pixel' values after a very 
complex process of demosaicking. All of this is so complex that it's 
more of an art than a science. But if you accept the set of pixels as a 
starting point, the pixel-as-area metaphor is usable just as the 
pixel-as-point metaphor. If you use pixel-as-area and you subsample, 
picking precisely the area which a target pixel would occupy in the 
source image is a reasonable choice and much better than simply 
averaging over all pixels-as-points which are nearer than a given 
maximum distance. Now what you do with the data in this area is a 
different matter. Averaging over the area is one possibility, but you 
might do a weighted sum to get better results. Again, it's a matter of 
what you want to achieve and what errors you can accept. There is no 
silver bullet. It's a bit like the duality of light. Is it a wave or a 
particle?

And when it comes to DEM data derived from LIDAR scans, which is what I 
am currently working on, the pixel-as-area approach is very valid: the 
LIDAR scan produces a point cloud, which is submitted to binning, so 
that all measurements happening to occur in a given small rectangular 
area are put together and averaged. Interpreting such a bin as something 
which has an area over which the signal is uniform is, again, an 
understandable choice, but it's not necessary. You might, for example, 
use weights on the point measurements when binning them. Or use a median 
filter or a specific quartile or or or to get data for a specific 
purpose. It's important that you understand what you're doing and pick 
your tools accordingly. And this is much easier said than done.

On top of that, using other people's data, you often don't precisely 
know how they have already 'messed' with the data. pixel-as-area is one 
way which is often quite close to a good choice. But it's important to 
understand that 'area' interpolation is, as every other method, a 
digital filter and produces certain errors. If that is okay with what 
you want to achieve, it's okay to use it.

So what's the upshot? If you are writing software for a large audience 
of people who mostly don't understand the fine points, you want to 
shield them from the worst mistakes by making it hard for them to make 
these mistakes. An automatic low-pass filter before downsampling is just 
such a shield. And using area interpolation instead of the average over 
contributing pixels would be another one. So having code in place to 
perform these tasks is good, making them the default is sensible, and 
allowing users to overrule the defaults is courteous to advanced users, 
whom you don't want to put into a straightjacket of what you think is 
'right'. And when it comes to b-splines, when they are used without 
prefiltering the data, this should be said in the documentation, because 
then it's no longer strictly speaking an interpolation but produces mild 
blur.

Kay

From even.rouault at spatialys.com  Sun Nov 18 04:18:57 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 18 Nov 2018 13:18:57 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <252d72b2-9e6c-fe95-6671-dc6cad4e0e32@yahoo.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <5738282.Gq529AdAku@even-i700>
 <252d72b2-9e6c-fe95-6671-dc6cad4e0e32@yahoo.com>
Message-ID: <2066458.T3VKzojTMn@even-i700>

Hi,

> Let' stick with the cubic b-spline for now, and do a sample evaluation
> at an integral position (so, at a sample loaction). Let the clean signal
> be ... 0 , 1 , 0 ... and we'll evaluate right where the '1' is.
> 
> The b-spline reconstruction kernel (or, the set of weights at integral
> positions) is 1/6 2/3 1/6. If we convolve, we get
> 
> 0 * 1/6 + 1 * 2/3 + 0*1/6 = 2/3

OK, indeed experimenting with "gdalwarp -r [method] in.tif out.tif" on in.tif 
having squared pixels, so the evaluation is done exactly at sample locations, 
I found that cubic and lanczos yield to identical result as the input, and 
indeed if you look at the weights, they are 1 at x = 0, and zero at other 
integral position. Wheras cubicspline indeed does not have thir interpolation 
criterion.
(note if you do it with gdal_translate -r without resizing, GDAL internals 
will see that no resampling is needed, and completely by-pass all the 
resampling code, so you'd get apparent perfect reconstruction...)

Found this paper http://bigwww.epfl.ch/publications/thevenaz0002.pdf 
confirming what you say :
"""No B-spline of degree n > 1 benefits from the property of being 
interpolating; [...] Unfortunately, some authors have failed to observe this 
rule, which led them to claim that B-splines typically blur data.  There-
fore,  such  claims  are  misleading,  even  though  they  can
be repeatedly found in the published literature"""
I'm not sure how widely cubicspline is used by GDAL users, but I suspect that 
some people avoid it because of this blurring side-effect (or conversely, 
maybe use it because they find it useful for their use case. who knows...)

> 
> You can see that the interpolation criterion is *not* fulfilled, because
> we'd expect to see '1' as the result. Why is this? because we haven't
> prefiltered. I'll not go into prefiltering now, but a *prefiltered*
> signal at this position is
> 
>   -0.464285714 1.732142857 -0.464285714

Where does those magic values come from ? 

Found this paper speaking about prefiltering for cubic b-spline interpolation:
http://dannyruijters.nl/docs/cudaPrefilter3.pdf

> I'd like to help, but rather by explaining things. I'd not really like 
> to get involved in coding, as I have a lot of work on my hands already.

Documentation contributions are also accepted ;-)

Relevant file:
https://github.com/OSGeo/gdal/blob/master/gdal/apps/gdal_utilities.dox
https://github.com/OSGeo/gdal/blob/master/gdal/apps/gdalwarp_bin.cpp
https://github.com/OSGeo/gdal/blob/master/gdal/gcore/gdal.h#L128
https://github.com/OSGeo/gdal/blob/master/gdal/alg/gdalwarper.h#L48

Although we might want to centralize a bit detailed information about the 
properties of the algorithm if we go to detail them.


> Jukka's hint to use kernel-filtered sources in a VRT file does do the
> trick and shows the way to go, but requires an intermediate file of the
> same size as the initial input. 

No. If you use the VRT directly, it is just a small XML file describing the 
processing you want to apply on source(s). You can use it directly as the 
input of gdal_translate -r, and the VRT specific computations will be done on-
the-fly.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From _kfj at yahoo.com  Sun Nov 18 12:16:31 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Sun, 18 Nov 2018 21:16:31 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <2066458.T3VKzojTMn@even-i700>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <5738282.Gq529AdAku@even-i700>
 <252d72b2-9e6c-fe95-6671-dc6cad4e0e32@yahoo.com>
 <2066458.T3VKzojTMn@even-i700>
Message-ID: <59114f44-8f01-08be-6516-64a2d6ac1baf@yahoo.com>

On 18.11.18 13:18, Even Rouault wrote:
> Hi,
> 
>> Let' stick with the cubic b-spline for now, and do a sample evaluation
>> at an integral position (so, at a sample loaction). Let the clean signal
>> be ... 0 , 1 , 0 ... and we'll evaluate right where the '1' is.
>>
>> The b-spline reconstruction kernel (or, the set of weights at integral
>> positions) is 1/6 2/3 1/6. If we convolve, we get
>>
>> 0 * 1/6 + 1 * 2/3 + 0*1/6 = 2/3
> 
> OK, indeed experimenting with "gdalwarp -r [method] in.tif out.tif" on in.tif
> having squared pixels, so the evaluation is done exactly at sample locations,
> I found that cubic and lanczos yield to identical result as the input, and
> indeed if you look at the weights, they are 1 at x = 0, and zero at other
> integral position. Wheras cubicspline indeed does not have thir interpolation
> criterion.

Yes. Because the prefilter was omitted. The cubic spline interpolation 
is the one method in gdal which needs prefiltering. But b-spline 
interpolation is the best method offered. So I picked it. Then I noticed 
the prefilter is omitted, so I made some noise.

The other interpolators you mention are 'direct' interpolators and 
require no prefiltering.

> (note if you do it with gdal_translate -r without resizing, GDAL internals
> will see that no resampling is needed, and completely by-pass all the
> resampling code, so you'd get apparent perfect reconstruction...)

That's good. I was using

gdalwarp -tr 1 1 -r cubicspline in.tif out.tif, that's where I found the 
difference..

> Found this paper http://bigwww.epfl.ch/publications/thevenaz0002.pdf
> confirming what you say :
> """No B-spline of degree n > 1 benefits from the property of being
> interpolating; [...] Unfortunately, some authors have failed to observe this
> rule, which led them to claim that B-splines typically blur data.  There-
> fore,  such  claims  are  misleading,  even  though  they  can
> be repeatedly found in the published literature"""
> I'm not sure how widely cubicspline is used by GDAL users, but I suspect that
> some people avoid it because of this blurring side-effect (or conversely,
> maybe use it because they find it useful for their use case. who knows...)

Let's be precise about it. what you link to above is

"Interpolation Revisited" by Philippe Thévenaz, Member, IEEE, Thierry 
Blu, Member, IEEE, and Michael Unser, Fellow, IEEE

from IEEE TRANSACTIONS ON MEDICAL IMAGING, VOL. 19, NO. 7, JULY 2000

This is the seminal paper which sparked my interest in b-splines some 
years ago. It's really thorough and a lot of it is beyond my 
mathematical horizon, but it sure explains all these things about 
b-splines I've been going on about. P. Thévenaz has also published 
example code for prefiltering and evaluating b-splines here:

http://bigwww.epfl.ch/thevenaz/interpolation/

>> You can see that the interpolation criterion is *not* fulfilled, because
>> we'd expect to see '1' as the result. Why is this? because we haven't
>> prefiltered. I'll not go into prefiltering now, but a *prefiltered*
>> signal at this position is
>>
>>    -0.464285714 1.732142857 -0.464285714
> 
> Where does those magic values come from ?

Just an example. I fed my b-spline calculator with a bunch of zeros and 
a single one, and this is what it produced after prefiltering. Another 
example:

-0.464101615138 1.732050807569 -0.464101615138

when you do the prefilter, what you get precisely depends on the *whole* 
signal - that's what is meant by 'indefinite support'. In real life, you 
limit the support to a good handful or two and live with a small error.

> Found this paper speaking about prefiltering for cubic b-spline interpolation:
> http://dannyruijters.nl/docs/cudaPrefilter3.pdf

You may want to stick with CPU implementations for the time being - 
prefiltering for a cubic b-spline is trivial in principle, just dealing 
with the infinite support of the forward-backward recursive filter needs 
some thought, especially when no-data values are involved. Have a look 
at Thévenaz' code I've linked to above, you'll see it's not difficult. 
If you need help with it, ask me.

There is no lack of papers on b-splines. This is very well known territory.

>> I'd like to help, but rather by explaining things. I'd not really like
>> to get involved in coding, as I have a lot of work on my hands already.
> 
> Documentation contributions are also accepted ;-)

I *may* consider this.

> Relevant file:
> https://github.com/OSGeo/gdal/blob/master/gdal/apps/gdal_utilities.dox
> https://github.com/OSGeo/gdal/blob/master/gdal/apps/gdalwarp_bin.cpp
> https://github.com/OSGeo/gdal/blob/master/gdal/gcore/gdal.h#L128
> https://github.com/OSGeo/gdal/blob/master/gdal/alg/gdalwarper.h#L48
> 
> Although we might want to centralize a bit detailed information about the
> properties of the algorithm if we go to detail them.
> 
> 
>> Jukka's hint to use kernel-filtered sources in a VRT file does do the
>> trick and shows the way to go, but requires an intermediate file of the
>> same size as the initial input.
> 
> No. If you use the VRT directly, it is just a small XML file describing the
> processing you want to apply on source(s). You can use it directly as the
> input of gdal_translate -r, and the VRT specific computations will be done on-
> the-fly.

I think here you are - at least partly - mistaken. Let me refer you to

https://www.gdal.org/gdal_vrttut.html

" ... For now kernel is not applied to sub-sampled or over-sampled data."

This makes sense: you can only apply a convolution to discrete samples. 
It's not an interpolator. So in order to subsample, you have to first 
use the VRT file to establish the convolution kernel, then save to a new 
file to have it applied, and then subsample the result with an 
interpolator. This makes the kernel-filtered source unsuitable for 
subsampling - unless it's subsampling by integer-valued factors 
('decimation'), where it could be applied on-the-fly, a special case 
which gdal does not seem to exploit.

Before I call it a day - let's not forget my core issue, which is the 
necessity for low-pass-filtering before subsampling. The -r cubicspline 
is a side issue which I noticed on top of the missing low-pass, as are 
my observations about -r average and 'area interpolation'. You can avoid 
these two issues by picking other interpolators in gdal, but you can't 
avoid the low-pass filter before subsampling.

Kay

From even.rouault at spatialys.com  Sun Nov 18 13:08:06 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 18 Nov 2018 22:08:06 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <59114f44-8f01-08be-6516-64a2d6ac1baf@yahoo.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <2066458.T3VKzojTMn@even-i700>
 <59114f44-8f01-08be-6516-64a2d6ac1baf@yahoo.com>
Message-ID: <2892952.uQ3iGGYr93@even-i700>

> > No. If you use the VRT directly, it is just a small XML file describing
> > the
> > processing you want to apply on source(s). You can use it directly as the
> > input of gdal_translate -r, and the VRT specific computations will be done
> > on- the-fly.
> 
> I think here you are - at least partly - mistaken. Let me refer you to
> 
> https://www.gdal.org/gdal_vrttut.html
> 
> " ... For now kernel is not applied to sub-sampled or over-sampled data."

That's true... But I've just checked gdal_translate -r, gdalwarp and gdaladdo 
code paths, and when they request the source data (here from the VRT dataset), 
they request it at its native resolution (which makes sense, since after all 
they have dedicated code to do the resampling, so they're not going to rely on 
resampling done by the source driver or from the default nearest-neighbour 
code path), so I'm quite confident you'd get the intended effect; it is if you 
request the VRT filtered source at their non-native resolution that the filter 
will actually be completely skipped.

For gdaladdo, my above observation would only be true of the first overview 
level you compute. For the second one, it would restart from the previously 
computed one, so by-passing the potential VRT filter.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From muccigrosso at icloud.com  Mon Nov 19 14:12:02 2018
From: muccigrosso at icloud.com (John Muccigrosso)
Date: Mon, 19 Nov 2018 14:12:02 -0800
Subject: [gdal-dev] New xml to csv problem
Message-ID: <E6211E8B-5B14-4013-B201-367BECBCD372@icloud.com>

Right after I upgraded to gdal2 2.3.2 via Homebrew a few weeks ago, I started getting the following error:

> ERROR 6: OGR/GeoRSS driver has not been built with read support. Expat library required

This is the command that generates it:

> ogr2ogr -f csv sheet.csv sheet.xml

Not sure where to go with this. TIA.

John

PS I also posted this as an issue on the OSGeo/homebrew-osgeo4mac GitHub page.

PPS I also got around the problem by using xmlstarlet instead of ogr2ogr to convert the xml to csv, but I’m still curious about the error.


From even.rouault at spatialys.com  Tue Nov 20 00:19:38 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 20 Nov 2018 09:19:38 +0100
Subject: [gdal-dev] New xml to csv problem
In-Reply-To: <E6211E8B-5B14-4013-B201-367BECBCD372@icloud.com>
References: <E6211E8B-5B14-4013-B201-367BECBCD372@icloud.com>
Message-ID: <1739557.EBN4LWAWVW@even-i700>

On lundi 19 novembre 2018 14:12:02 CET John Muccigrosso wrote:
> Right after I upgraded to gdal2 2.3.2 via Homebrew a few weeks ago, I 
started getting the following error:
> > ERROR 6: OGR/GeoRSS driver has not been built with read support. Expat
> > library required

The error message means that your GDAL binary has not been built with 
libexpat. Probably an issue with the homebrew build recipee (I'm not familiar 
at all with Mac things). Indeed something to report to the maintainers of the 
OSGeo homebrew package

Even

Spatialys - Geospatial professional services
http://www.spatialys.com

From peter.petrik at lutraconsulting.co.uk  Tue Nov 20 00:31:45 2018
From: peter.petrik at lutraconsulting.co.uk (Peter Petrik)
Date: Tue, 20 Nov 2018 09:31:45 +0100
Subject: [gdal-dev] New xml to csv problem
In-Reply-To: <1739557.EBN4LWAWVW@even-i700>
References: <E6211E8B-5B14-4013-B201-367BECBCD372@icloud.com>
 <1739557.EBN4LWAWVW@even-i700>
Message-ID: <CA+T_Ms+0ggC+kgfK7B+GJKVoF+dSijrXe1FoUp+_oSDxKAtVog@mail.gmail.com>

can you try to uninstall gdal2 and reinstall with

brew install osgeo/osgeo4mac/gdal2 --with-complete

Peter

On Tue, Nov 20, 2018 at 9:19 AM Even Rouault <even.rouault at spatialys.com>
wrote:

> On lundi 19 novembre 2018 14:12:02 CET John Muccigrosso wrote:
> > Right after I upgraded to gdal2 2.3.2 via Homebrew a few weeks ago, I
> started getting the following error:
> > > ERROR 6: OGR/GeoRSS driver has not been built with read support. Expat
> > > library required
>
> The error message means that your GDAL binary has not been built with
> libexpat. Probably an issue with the homebrew build recipee (I'm not
> familiar
> at all with Mac things). Indeed something to report to the maintainers of
> the
> OSGeo homebrew package
>
> Even
>
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181120/d4af2a85/attachment.html>

From muccigrosso at icloud.com  Tue Nov 20 08:36:33 2018
From: muccigrosso at icloud.com (John Muccigrosso)
Date: Tue, 20 Nov 2018 08:36:33 -0800
Subject: [gdal-dev] New xml to csv problem
In-Reply-To: <CA+T_Ms+0ggC+kgfK7B+GJKVoF+dSijrXe1FoUp+_oSDxKAtVog@mail.gmail.com>
References: <E6211E8B-5B14-4013-B201-367BECBCD372@icloud.com>
 <1739557.EBN4LWAWVW@even-i700>
 <CA+T_Ms+0ggC+kgfK7B+GJKVoF+dSijrXe1FoUp+_oSDxKAtVog@mail.gmail.com>
Message-ID: <2B17A32E-B2E3-49E4-B03C-B0A673805DC2@icloud.com>

Did that. Same result.

John 

> On Nov 20, 2018, at 00:31, Peter Petrik <peter.petrik at lutraconsulting.co.uk> wrote:
> 
> can you try to uninstall gdal2 and reinstall with 
> 
> brew install osgeo/osgeo4mac/gdal2 --with-complete 
> 
> Peter
> 
>> On Tue, Nov 20, 2018 at 9:19 AM Even Rouault <even.rouault at spatialys.com> wrote:
>> On lundi 19 novembre 2018 14:12:02 CET John Muccigrosso wrote:
>> > Right after I upgraded to gdal2 2.3.2 via Homebrew a few weeks ago, I 
>> started getting the following error:
>> > > ERROR 6: OGR/GeoRSS driver has not been built with read support. Expat
>> > > library required
>> 
>> The error message means that your GDAL binary has not been built with 
>> libexpat. Probably an issue with the homebrew build recipee (I'm not familiar 
>> at all with Mac things). Indeed something to report to the maintainers of the 
>> OSGeo homebrew package
>> 
>> Even
>> 
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181120/7658041d/attachment.html>

From muccigrosso at icloud.com  Tue Nov 20 13:29:03 2018
From: muccigrosso at icloud.com (John Muccigrosso)
Date: Tue, 20 Nov 2018 13:29:03 -0800
Subject: [gdal-dev] New xml to csv problem
In-Reply-To: <2B17A32E-B2E3-49E4-B03C-B0A673805DC2@icloud.com>
References: <E6211E8B-5B14-4013-B201-367BECBCD372@icloud.com>
 <1739557.EBN4LWAWVW@even-i700>
 <CA+T_Ms+0ggC+kgfK7B+GJKVoF+dSijrXe1FoUp+_oSDxKAtVog@mail.gmail.com>
 <2B17A32E-B2E3-49E4-B03C-B0A673805DC2@icloud.com>
Message-ID: <7FCC0D65-74D1-4FCC-A17C-CD46AB68FF5D@icloud.com>

Update to the homebrew formula to include expat as a dependency has solved the problem.


John


From _kfj at yahoo.com  Wed Nov 21 01:22:36 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Wed, 21 Nov 2018 10:22:36 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <1542370404605-0.post@n6.nabble.com>
References: <e796bb93-4b3a-2598-1da0-6c728e7d6147@yahoo.com>
 <1c930d8b-a07b-da0c-8ce1-96260d343be1@xs4all.nl>
 <bc5ef8ae-1cab-bae3-a5b8-eb3071ae43b8@yahoo.com>
 <2622841.7iPav299Wl@even-i700>
 <551f2d45-e6bc-a28a-5097-a703c29386ce@yahoo.com>
 <1542370404605-0.post@n6.nabble.com>
Message-ID: <fa2f43d5-4b71-1d53-10c4-cd1ab6a5410c@yahoo.com>

On 16.11.18 13:13, jratike80 wrote:
> 
> If a low-pass filter is needed before passing data to downsampling, I wonder
> if it could be done by utilizing a VRT with KernelFilteredSource
> https://www.gdal.org/gdal_vrttut.html. May well be that it is not relevant
> at all, my understanding of mathematics coming from agricultural background.

Jukka, thanks for your hint. Actually this is a very good idea, and I 
have tried applying it to my data, but I have some issues, so I thought 
I'd report back with my findings.

Using convolution for a low-pass filter is not the most efficient way, 
but it's not hard to set up and does work okay. To get a suitable 
filter, an easy approach is to use 'binomial filters'. They can be 
derived from Pascal's triangle (see 
https://en.wikipedia.org/wiki/Pascal%27s_triangle) by taking a row and 
dividing it by the sum of all numbers in that row. You want to pick a 
row with an odd number of numbers, like 1 2 1 or 1 4 6 4 1, so you can 
pick all odd rows. The rule of thumb is that 1 2 1 gives you an 
approximation of a gaussian with standard deviation 0.5, and with every 
two rows you go down, the standard deviation increases by 0.5. And more 
rule of thumb tells you to remove a 'significant' portion of the 
high-frequency part of a signal, you want a standard deviation of 1. In 
fact the method is used to create 'image pyramids', where an image is 
low-pass-filtered and then scaled down, which is pretty much what I need 
to do with my DEM data. I won't go into the mathematical details, but 
rather, I'll describe what precisely I did to my concrete use case of 
scaling down from 2m resolution to 5m resolution, and if anyone has good 
suggestions or criticism, please come forward!

1. Finding the right convolution kernel

Since all of this is a bit rule-of-thumb, I have decided to use a 
binomial filter with a standard deviation of ca. 1.5. So I picked the 
seventh row of pascal's triangle:

1 6 15 20 15 6 1

which I divided by 64, the sum of these numbers, obtaining

.015625 .09375 .234375 .3125 .234375 .09375 .015625

This would have been right for the second variant of a kernel-filtered 
source in the wiki, but I don't have GDAL 2.3 yet and I don't want to 
mess with my system, so I formed the cross product and came up with this 
argument in the VRT file:

       <Kernel normalized="1">
         <Size>7</Size>
         <Coefs>0.000244141 0.00146484 0.00366211 0.00488281
                0.00366211 0.00146484 0.000244141 0.00146484
                0.00878906 0.0219727 0.0292969 0.0219727
                0.00878906 0.00146484 0.00366211 0.0219727
                0.0549316 0.0732422 0.0549316 0.0219727
                0.00366211 0.00488281 0.0292969 0.0732422
                0.0976562 0.0732422 0.0292969 0.00488281
                0.00366211 0.0219727 0.0549316 0.0732422
                0.0549316 0.0219727 0.00366211 0.00146484
                0.00878906 0.0219727 0.0292969 0.0219727
                0.00878906 0.00146484 0.000244141 0.00146484
                0.00366211 0.00488281 0.00366211 0.00146484
                0.000244141
         </Coefs>
       </Kernel>

This does work on the original data; my understanding of the docu where 
it said it was 'not applied to sub-sampled or over-sampled data' was 
probably a misunderstanding on my part - I think it refers to the VRT 
file's source files, not to it's output, which is what I want to subsample.

2. subsampling

I decided to perform the subsampling with -r cubicspline, which, as the 
prefilter is missing, does not interpolate precisely, but it only does a 
little extra smoothing, which I don't mind since I want contour lines 
only. So with the VRT file at hand, I did

gdalwarp -tr 5 5 -r cubicspline in.vrt out.tif

3. looking at the result

The resulting data are indeed nicely low-pass-filtered, but I do have a 
problem here: My source data are regional DEMs, and such data are often 
done in such a way that they end at the borders of whatever 
administrative entity they are given for. To be concrete, I was working 
on the 2m DEM of the Valle d' Aosta, and this is cut into 914 little 
tiles, where the tiles on the border are cut off at the borders of the 
autonomous region, the remainder of the tile being filled with a 
no-data-value. gdalwarping the input data seems to result, internally, 
in replacing the no-data part with zero, then filtering zeros and 
nonzeros alike. The result is a 'gray zone' around the borders, where 
the convolution picks up both zeros from the 'unknown territory' and 
valid data. This is a problem, because it means that a margin of six 
pixels is now wrong (because it has been 'tainted' with the zeroes 
outside). I'd have to cut that off - but I have no easy way of doing so. 
The most straightforward solution I have come up with is flattening the 
data, feeding them to an image processing software, doing several 
erosions, and using the result as a mask. That's 'okay' for a one-off, 
but really, I'd like to see better treatment of no-data values. I 
wouldn't mind if the results around the edges were slightly less precise 
than further inside. I think the kernel-filtered source could be 
interpreted like this:

If the target point does coincide with only no-data-values in the 
source, produce a no-data-value

Otherwise, if it's source pixels (those used in convolution) are partly 
no-data, take zero instead of no-data, but re-normalize the kernel.

So in 1D, if we have a kernel of (1/4 1/2 1/4) and participating source 
data of (no-data 3 4), we'd use a kernel of (1/3 2/3 1/3) - the 
re-normalization is done by first multiplying by four, then dividing by 
three.

We get 0 * 1/3 + 3 * 2/3 + 4 * 1/3 as the result, effectively ignoring 
the no-data value but 'pulling up' the result.

Maybe this can be done anyway, but so far I haven't found parameters to 
do so.

The downsampling step seems to do such calculations automatically - the 
margin of the valid data does not look suspicious when downsampling the 
original data without first applying the low-pass. So the problematic 
step is the application of the kernel near the margin of the valid data 
- maybe this is already fixed in GDAL 2.3?

So much for my use of a kernel-filtered source in a VRT file, comments 
are of course welcome.

Kay



From _kfj at yahoo.com  Wed Nov 21 02:11:36 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Wed, 21 Nov 2018 11:11:36 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>
Message-ID: <66d523fc-4532-8c3f-9ae6-c6a32972f253@yahoo.com>

On 16.11.18 16:38, JDA wrote:
> 
> There’s a wide array of smoothing options available If you’re willing to 
> work in python. Based on https://gis.stackexchange.com/a/10467, the 
> basic idea is to load the raster into a numpy array and then convolve it 
> with either a kernel of arbitrary size.
> 
> I’ve written a program implementing that idea with both a Gaussian and a 
> mean kernel here:
> https://github.com/jacobdadams/general_scripts/blob/master/raster_chunk_processing.py. 
> It only smooths the data without downsampling, but there may be some 
> python functions that downsample as well.
> 
> There’s a lot of code in there for dealing with massive rasters by 
> processing them in chunks in parallel, but the blur_mean and blur_gauss 
> functions are where the smoothing is done. I’ve written an installation 
> and usage guide at 
> https://gisjake.blogspot.com/2018/10/rasterchunkprocessingpy-installation.html?m=1. 

I cloned your git repo and fetched the additional python modules my 
system did not have with the packet management system, namely astropy 
and skimage. At first I did this for python2, but no luck here, running 
the sript would throw an exception:

Processing chunks...

--- Error ---
__exit__


Traceback (most recent call last):
   File "/home/kfj/src/general_scripts/raster_chunk_processing.py", line 
1074, in <module>
     num_threads, verbose)
   File "/home/kfj/src/general_scripts/raster_chunk_processing.py", line 
961, in ParallelRCP
     maxtasksperchild=10
AttributeError: __exit__

So I picked up the packages in python 3, and got it to work. I used this 
command line:

python3 raster_chunk_processing.py -p 1 -m blur_gauss -o 25 \
         -s 1500 --verbose -r 15 -d 1.5 original.vrt jacob.tif

where original.vrt had a sample population of two DEM tiles on the 
border of my target area, having no-data values outside the region's 
territory. When inspecting the result in QGIS, it looked like it had 
done everything I wanted it to do:

- the VRT file was taken as valid input
- the no-data value coded in the VRT file was properly honoured
- there were no problems at tile borders
- there was a clean edge, valid data inside and no-data outside
- the applied blur looked like what I'd expect from the parameters
- the resulting contours were smooth and as intended

So, compared to the attempts with a kernel-filtered source in a VRT file 
which I outlined in my previous post, I'd say that using your script is 
the winner, because the margin treatment is what one might expect and 
the parametrization is straightforward. I'll just have to tweak the 
parameters to get precisely the amount of smoothing I want. I'll store 
the smoothed data as GeoTIFF in the original resolution and then proceed 
to downsample from that, and my problem should be solved.

Thank you for your reply and for sharing your scripts!

Kay

From _kfj at yahoo.com  Wed Nov 21 02:58:27 2018
From: _kfj at yahoo.com (Kay F. Jahnke)
Date: Wed, 21 Nov 2018 11:58:27 +0100
Subject: [gdal-dev] downsampling geotiff with a low-pass filter
In-Reply-To: <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>
References: <mailman.28487.1542367282.22916.gdal-dev@lists.osgeo.org>
 <45488915-CD9D-4FE5-8283-AAFEEF7B005E@gmail.com>
 <CALFmHhujJMWpeXb+MiGdOxKWkKCd2b2iATva_D-fBY5nA__sYA@mail.gmail.com>
Message-ID: <29c328bd-5f26-7d81-764f-16018e87768b@yahoo.com>

On 16.11.18 17:04, Markus Neteler wrote:
> 
> There are plenty of different kernel smoothers in GRASS GIS, e.g.
> 
> box, bartlett, gauss, normal, hermite, sinc, lanczos1, lanczos2,
> lanczos3, hann, hamming, blackman
> https://grass.osgeo.org/grass76/manuals/r.resamp.filter.html
> 
> Using "grass-session" (https://github.com/zarch/grass-session) you can
> use the functionality in Python also from "outside" without even
> knowing much about GRASS GIS itself.

Thank you for your reply! I tried out using a gauss filter via 
r.resamp.filter, and the result is just as usable as the one I got with 
my previous attempt, using Jake's python script. I think I prefer to 
stick with the direct python approach, rather, because I find all the 
extra work of having to set up the right grass location and mapset, the 
importing and exporting and work in the grass console window too much of 
a bother, when I can simply call the filter script on the command line. 
I'll have a look at grass-session when I get around to it, maybe that 
makes it easier.

The grass process performed as intended, read the VRT file correctly and 
did properly cut off the 'grey area' where the valid data bordered on 
no-data values, so I think if a user is comfortable with GRASS this is 
just as good a way to receive a smoothed data set before resampling.

Kay

From a09550 at gmail.com  Wed Nov 21 07:33:38 2018
From: a09550 at gmail.com (Pham Huu Bang)
Date: Wed, 21 Nov 2018 16:33:38 +0100
Subject: [gdal-dev] How to find correct 2D bounding box to subset in
 different CRS with gdal (different outputs for gdalwarp)?
Message-ID: <CAJGa3-=wx9A+vdCNzajKADSQp1uVhYjbrbC--505cfjqx3sYbA@mail.gmail.com>

Hello,

I'm using GDAL version 1.11.4 and I have a problem how to use gdal to
translate a bounding box correctly [Lat(62:63), Long(10:11)] from source
CRS EPSG:4326 to target CRS EPSG:32632.

I've tried so far with gdaltransform to translate coordinates: Long min,
Lat min and Long max, Lat max (EPSG:4326) to E min, N min and E max, N Max
(EPSG:32632) like this:

gdaltransform -s_srs EPSG:4326 -t_srs EPSG:32632

10 61.9999999999999 0
552375.799656895 6874583.72713382

11 62.9999999999954 0
601293.020582477 6987164.64881585

Then, I use these translated coordinates to create a bounding box in
EPSG:32632 E(552375.799656895:601293.020582477),
N(6874583.72713382:6987164.64881585) in EPSG:32632 for subsetting a 32632
tiff file and then using gdalwarp the cropped result to EPSG:4326.

The problem is the results of 2 cropped tiff files (both in EPSG:4326) are
significantly different and I could not understand the reason (I think
bounding box in EPSG:32632 are wrong but how to find the correct bounding
box in EPSG:32632 from bounding box EPSG:4326)?

32632.tiff is a tiff file with grid size: 6820, 4632 and 4326.tiff is a
file created by using gdalwarp -t_srs EPSG:4326 32632.tiff 4326.tiff with
grid size: 8213, 2654.

 Test 1:
 # Subset on 32632 tiff by 32632 subset which are translated point by point
 from 4326 subset
 gdalwarp -te 552375.799656895 6874583.72713382 601293.020582477
 6987164.64881585 32632.tiff subset_32632.tiff
 Creating output file that is 1631P x 3753L.

 # Warp cropped 32632 tiff file to 4326
 gdalwarp -t_srs EPSG:4326 subset_32632.tiff subset_4326.tiff
 Creating output file that is 3009P x 3070L.

 Test 2:
 # Subset 4326 on 4326 tiff file directly
 gdalwarp -te 10 61.9999999999999 11 62.9999999999954 4326.tiff
 subset_4326_org.tif
 Creating output file that is 2019P x 2019L.

Thanks,
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181121/fe366fd1/attachment-0001.html>

From andre+joost at nurfuerspam.de  Wed Nov 21 08:28:30 2018
From: andre+joost at nurfuerspam.de (Andre Joost)
Date: Wed, 21 Nov 2018 17:28:30 +0100
Subject: [gdal-dev] How to find correct 2D bounding box to subset in
 different CRS with gdal (different outputs for gdalwarp)?
In-Reply-To: <CAJGa3-=wx9A+vdCNzajKADSQp1uVhYjbrbC--505cfjqx3sYbA@mail.gmail.com>
References: <CAJGa3-=wx9A+vdCNzajKADSQp1uVhYjbrbC--505cfjqx3sYbA@mail.gmail.com>
Message-ID: <pt4124$v9r$1@blaine.gmane.org>

Hello Pham,

note that an EPSG:4326 rectangle of full degrees gets rotated and bended 
in almost any projected CRS (except Mercator).

Since the EPSG:32632 raster has to be an unrotated rectangle again, the 
corners of the projected EPSG:4326 rectangle are different from the 
corners of the EPSG:32632 rectangle. The difference will be filled with 
NODATA pixels.

Try to vsualize your problem in a GIS software like QGIS, and you see 
what I mean.

HTH,
Andre Joost

Am 21.11.18 um 16:33 schrieb Pham Huu Bang:
> Hello,
>
> I'm using GDAL version 1.11.4 and I have a problem how to use gdal to
> translate a bounding box correctly [Lat(62:63), Long(10:11)] from source
> CRS EPSG:4326 to target CRS EPSG:32632.
>
> I've tried so far with gdaltransform to translate coordinates: Long min,
> Lat min and Long max, Lat max (EPSG:4326) to E min, N min and E max, N Max
> (EPSG:32632) like this:
>
> gdaltransform -s_srs EPSG:4326 -t_srs EPSG:32632
>
> 10 61.9999999999999 0
> 552375.799656895 6874583.72713382
>
> 11 62.9999999999954 0
> 601293.020582477 6987164.64881585
>
> Then, I use these translated coordinates to create a bounding box in
> EPSG:32632 E(552375.799656895:601293.020582477),
> N(6874583.72713382:6987164.64881585) in EPSG:32632 for subsetting a 32632
> tiff file and then using gdalwarp the cropped result to EPSG:4326.
>
> The problem is the results of 2 cropped tiff files (both in EPSG:4326) are
> significantly different and I could not understand the reason (I think
> bounding box in EPSG:32632 are wrong but how to find the correct bounding
> box in EPSG:32632 from bounding box EPSG:4326)?
>
> 32632.tiff is a tiff file with grid size: 6820, 4632 and 4326.tiff is a
> file created by using gdalwarp -t_srs EPSG:4326 32632.tiff 4326.tiff with
> grid size: 8213, 2654.
>
>   Test 1:
>   # Subset on 32632 tiff by 32632 subset which are translated point by point
>   from 4326 subset
>   gdalwarp -te 552375.799656895 6874583.72713382 601293.020582477
>   6987164.64881585 32632.tiff subset_32632.tiff
>   Creating output file that is 1631P x 3753L.
>
>   # Warp cropped 32632 tiff file to 4326
>   gdalwarp -t_srs EPSG:4326 subset_32632.tiff subset_4326.tiff
>   Creating output file that is 3009P x 3070L.
>
>   Test 2:
>   # Subset 4326 on 4326 tiff file directly
>   gdalwarp -te 10 61.9999999999999 11 62.9999999999954 4326.tiff
>   subset_4326_org.tif
>   Creating output file that is 2019P x 2019L.
>
> Thanks,
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>



From chiara.marmo at u-psud.fr  Thu Nov 22 06:43:00 2018
From: chiara.marmo at u-psud.fr (Chiara Marmo)
Date: Thu, 22 Nov 2018 14:43:00 +0000 (GMT)
Subject: [gdal-dev] Core dumped: last GDAL dev version
In-Reply-To: <1181333232.27265833.1542896816112.JavaMail.zimbra@u-psud.fr>
Message-ID: <1990939504.27287190.1542897780822.JavaMail.zimbra@u-psud.fr>

Hello,

I have sinchronized my dev version of GDAL with the last upstream/master today (commit 9f0bbc321e11d7f88ee59af5ccdfb58204ec04f6), and experimented a core dumped error.

The following checks had been done on the master branch (not modified by me).
Compilation went well, then

$ ~/software/gdal/gdal/apps/ogr2ogr --version

throws

lt-ogr2ogr: malloc.c:2401: sysmalloc: Assertion `(old_top == initial_top (av) && old_size == 0) || ((unsigned long) (old_size) >= MINSIZE && prev_inuse (old_top) && ((unsigned long) old_end & (pagesize - 1)) == 0)' failed.
Aborted (core dumped)

Another example:
$ ~/software/gdal/gdal/apps/gdalinfo Mercury_MESSENGER_MDIS_Basemap_BDR_Mosaic_Global_166m.tif
lt-gdalinfo: malloc.c:2401: sysmalloc: Assertion `(old_top == initial_top (av) && old_size == 0) || ((unsigned long) (old_size) >= MINSIZE && prev_inuse (old_top) && ((unsigned long) old_end & (pagesize - 1)) == 0)' failed.
Aborted (core dumped)

This is true for all the executables in apps.

The installed version of gdal apps is still working

$ ogr2ogr --version
GDAL 2.4.0dev-d88e13e529-dirty, released 2018/11/05
$ gdalinfo Mercury_MESSENGER_MDIS_Basemap_BDR_Mosaic_Global_166m.tif
Driver: GTiff/GeoTIFF
Files: Mercury_MESSENGER_MDIS_Basemap_BDR_Mosaic_Global_166m.tif
Size is 92160, 46080
Coordinate System is:
.... blahblah
  NoData Value=0

and it corresponds to that commit (https://github.com/epn-vespa/gdal/commit/d88e13e529928bfc72b6283b5e360c441bf40754)

Where is my problem? I'm lost...

Thanks for any help,

Chiara

-- 
Chiara Marmo
Ingénieur de Recherche GEOPS - Paris Sud-11
Bât 509
Tel: +33 (0)1 69 15 49 03 

From even.rouault at spatialys.com  Thu Nov 22 06:55:18 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 22 Nov 2018 15:55:18 +0100
Subject: [gdal-dev] Core dumped: last GDAL dev version
In-Reply-To: <1990939504.27287190.1542897780822.JavaMail.zimbra@u-psud.fr>
References: <1990939504.27287190.1542897780822.JavaMail.zimbra@u-psud.fr>
Message-ID: <3823290.aS3kKeATmT@even-i700>

On jeudi 22 novembre 2018 14:43:00 CET Chiara Marmo wrote:
> Hello,
> 
> I have sinchronized my dev version of GDAL with the last upstream/master
> today (commit 9f0bbc321e11d7f88ee59af5ccdfb58204ec04f6), and experimented a
> core dumped error.

Make sure to 'make clean' before rebuilding.
Also check if you don't have GDAL plugins corresponding to an older version of 
GDAL.


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ari.jolma at gmail.com  Thu Nov 22 07:06:04 2018
From: ari.jolma at gmail.com (Ari Jolma)
Date: Thu, 22 Nov 2018 17:06:04 +0200
Subject: [gdal-dev] problem with loading libraries
Message-ID: <9f47c65f-f49d-13ed-c610-3232d3a7cdc4@gmail.com>

Sorry, this is not strictly a GDAL question, but it is related.

I have built postgis with raster support, which required gdal. Now, when I

CREATE EXTENSION postgis;

I get

ERROR:  could not load library 
"/home/ajolma/ods/server/parts/postgresql/lib/postgis-2.5.so": 
libgeos_c.so.1: cannot open shared object file: No such file or directory

However, postgis-2.5.so finds libgeos:

ldd parts/postgresql/lib/postgis-2.5.so

does not show anything missing -- but it also does not show libgdal.

I have paths to gdal and other libs in LD_LIBRARY_PATH. I don't want to 
make the libraries known to run-time linker with ldconfig since that 
would make them global(?) and this system should be strictly non-global 
in the system (there are several database servers etc running).

Any ideas what could be the issue?

Ari



From chiara.marmo at u-psud.fr  Thu Nov 22 07:39:37 2018
From: chiara.marmo at u-psud.fr (Chiara Marmo)
Date: Thu, 22 Nov 2018 15:39:37 +0000 (GMT)
Subject: [gdal-dev] Core dumped: last GDAL dev version
In-Reply-To: <3823290.aS3kKeATmT@even-i700>
References: <1990939504.27287190.1542897780822.JavaMail.zimbra@u-psud.fr>
 <3823290.aS3kKeATmT@even-i700>
Message-ID: <378709887.27363935.1542901177797.JavaMail.zimbra@u-psud.fr>

Thanks Even,

and sorry for the noise.

The 'make clean' did the job.

Chiara

----- Original Message -----
> From: "Even Rouault" <even.rouault at spatialys.com>
> To: gdal-dev at lists.osgeo.org
> Cc: "Chiara Marmo" <chiara.marmo at u-psud.fr>
> Sent: Thursday, November 22, 2018 3:55:18 PM
> Subject: Re: [gdal-dev] Core dumped: last GDAL dev version
> 
> On jeudi 22 novembre 2018 14:43:00 CET Chiara Marmo wrote:
> > Hello,
> > 
> > I have sinchronized my dev version of GDAL with the last upstream/master
> > today (commit 9f0bbc321e11d7f88ee59af5ccdfb58204ec04f6), and experimented a
> > core dumped error.
> 
> Make sure to 'make clean' before rebuilding.
> Also check if you don't have GDAL plugins corresponding to an older version
> of
> GDAL.
> 
> 
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> 

-- 
Chiara Marmo
Ingénieur de Recherche GEOPS - Paris Sud-11
Bât 509
Tel: +33 (0)1 69 15 49 03 

From ari.jolma at gmail.com  Thu Nov 22 10:43:00 2018
From: ari.jolma at gmail.com (Ari Jolma)
Date: Thu, 22 Nov 2018 20:43:00 +0200
Subject: [gdal-dev] problem with loading libraries
In-Reply-To: <9f47c65f-f49d-13ed-c610-3232d3a7cdc4@gmail.com>
References: <9f47c65f-f49d-13ed-c610-3232d3a7cdc4@gmail.com>
Message-ID: <487084d8-9816-fdb9-a321-081587ed8b8d@gmail.com>

I figured out a solution to the problem. The library is loaded by the 
postgres process, so it needs to have its library path appended. The 
simplest way is to start it with command

LD_LIBRARY_PATH=<library paths> pg_ctl -D database start

Ari

Ari Jolma kirjoitti 22.11.2018 klo 17.06:
> Sorry, this is not strictly a GDAL question, but it is related.
>
> I have built postgis with raster support, which required gdal. Now, 
> when I
>
> CREATE EXTENSION postgis;
>
> I get
>
> ERROR:  could not load library 
> "/home/ajolma/ods/server/parts/postgresql/lib/postgis-2.5.so": 
> libgeos_c.so.1: cannot open shared object file: No such file or directory
>
> However, postgis-2.5.so finds libgeos:
>
> ldd parts/postgresql/lib/postgis-2.5.so
>
> does not show anything missing -- but it also does not show libgdal.
>
> I have paths to gdal and other libs in LD_LIBRARY_PATH. I don't want 
> to make the libraries known to run-time linker with ldconfig since 
> that would make them global(?) and this system should be strictly 
> non-global in the system (there are several database servers etc 
> running).
>
> Any ideas what could be the issue?
>
> Ari
>
>

From zazhil_ha at hotmail.com  Thu Nov 22 14:35:32 2018
From: zazhil_ha at hotmail.com (ZAZHIL-HA HERENA)
Date: Thu, 22 Nov 2018 22:35:32 +0000
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
Message-ID: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>

Hello, I am not sure if I should use this mailing list to ask questions but I wanted to try, I am a developer trying to use GDAL to open rasters in HDFS.


I read in GDAL documentation that starting 2.4 it is possible to open a raster in HDFS. I downloaded and compiled the latest source code available version and the generated libraries show it is 2.4 (libgdal.so.20.4.2). I compiled with option "-with-hdfs=yes" and "--with-java=yes".

I am trying to open a raster using:



    Dataset raster = gdal.Open("/vsihdfs/hdfs://node:8020/user/hdfs /spatial_raster/input_raster/kahoolawe.tif", gdalconst.GA_ReadOnly);


but I am getting the following error: "ERROR 4: No such file or directory"


HDFS system is accesible and the raster exists in that path.

could anyone please tell me if hdfs virtual system not supported yet?, or maybe I configured it wrong when compiling?


I truly appreciate your help, thanks!


Zazhil-ha

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181122/4c626887/attachment.html>

From nik at nikosalexandris.net  Thu Nov 22 17:13:54 2018
From: nik at nikosalexandris.net (Nikos Alexandris)
Date: Fri, 23 Nov 2018 02:13:54 +0100
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
Message-ID: <20181123011354.m5hkafjyaumfjohy@imap.dreamhost.com>

* ZAZHIL-HA HERENA <zazhil_ha at hotmail.com> [2018-11-22 22:35:32 +0000]:

>Hello, I am not sure if I should use this mailing list to ask questions but I wanted to try, I am a developer trying to use GDAL to open rasters in HDFS.
>
>
>I read in GDAL documentation that starting 2.4 it is possible to open a raster in HDFS. I downloaded and compiled the latest source code available version and the generated libraries show it is 2.4 (libgdal.so.20.4.2). I compiled with option "-with-hdfs=yes" and "--with-java=yes".
>
>I am trying to open a raster using:
>
>
>
>    Dataset raster = gdal.Open("/vsihdfs/hdfs://node:8020/user/hdfs /spatial_raster/input_raster/kahoolawe.tif", gdalconst.GA_ReadOnly);

Is your path correct? There is a space here (in "/hfds /").

Nikos

>
>
>but I am getting the following error: "ERROR 4: No such file or directory"

[rest deleted]

From james.mcclain at gmail.com  Thu Nov 22 18:27:11 2018
From: james.mcclain at gmail.com (James McClain)
Date: Thu, 22 Nov 2018 21:27:11 -0500
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <20181123011354.m5hkafjyaumfjohy@imap.dreamhost.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <20181123011354.m5hkafjyaumfjohy@imap.dreamhost.com>
Message-ID: <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>

Hello,

I am the author of the vsihdfs code, I am ready and willing to help.

I just rebuilt it from current master and was able to successfully open an
dataset via an HDFS URI with the GDAL Python bindings.  I have a few
suggestions.

First, please try putting the file into a local directory and try something
like `gdalinfo /vsihdfs/file:/tmp/kahoolawe.tif` to establish a baseline.

Second, if you are using the Python bindings, please make sure that they
have been built and installed (and that you are using the ones that you
built rather than other ones that exist on your system).  Instructions for
building the Python bindings can be found here:
https://trac.osgeo.org/gdal/wiki/BuildingOnUnix .

In my case, after building and installing the library and bindings, I was
able to successfully open a dataset by starting a python REPL like this:

```bash
export
LD_LIBRARY_PATH=$HOME/local/hadoop-2.7.7/lib/native:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server:$HOME/local/gdal-master-vsihdfs/lib
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export CLASSPATH=$($HOME/local/hadoop-2.7.7/bin/hadoop classpath --glob)
PYTHONPATH=$HOME/local/gdal-master-vsihdfs/lib/python2.7/site-packages
python
```

then typing this into it:

```python
from osgeo import gdal, gdalconst
ds = gdal.Open('/vsihdfs/file:/tmp/testfile.tif', gdalconst.GA_ReadOnly)
```

(I do not have easy access to and HDFS cluster right at the moment, so I
only tested a local HDFS URI.)

A note: After having done a build without HDFS support in the tree, I had
do a `make clean distclean` before I was able to get a build with working
HDFS support.

Sincerely,
James McClain

On Thu, Nov 22, 2018 at 8:13 PM Nikos Alexandris <nik at nikosalexandris.net>
wrote:

> * ZAZHIL-HA HERENA <zazhil_ha at hotmail.com> [2018-11-22 22:35:32 +0000]:
>
> >Hello, I am not sure if I should use this mailing list to ask questions
> but I wanted to try, I am a developer trying to use GDAL to open rasters in
> HDFS.
> >
> >
> >I read in GDAL documentation that starting 2.4 it is possible to open a
> raster in HDFS. I downloaded and compiled the latest source code available
> version and the generated libraries show it is 2.4 (libgdal.so.20.4.2). I
> compiled with option "-with-hdfs=yes" and "--with-java=yes".
> >
> >I am trying to open a raster using:
> >
> >
> >
> >    Dataset raster = gdal.Open("/vsihdfs/hdfs://node:8020/user/hdfs
> /spatial_raster/input_raster/kahoolawe.tif", gdalconst.GA_ReadOnly);
>
> Is your path correct? There is a space here (in "/hfds /").
>
> Nikos
>
> >
> >
> >but I am getting the following error: "ERROR 4: No such file or directory"
>
> [rest deleted]
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
"I prayed for freedom for twenty years, but received no answer until I
prayed with my legs."
     -- Frederick Douglass
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181122/464b04a8/attachment.html>

From timbodin at comcast.net  Thu Nov 22 21:09:15 2018
From: timbodin at comcast.net (timbodin at comcast.net)
Date: Thu, 22 Nov 2018 23:09:15 -0600
Subject: [gdal-dev] windows install - best practices?  install from source,
	or from precompiled binaries?
Message-ID: <005501d482ea$aeaeb3b0$0c0c1b10$@comcast.net>

I'm working reasonably successfully with GDAL as a learner, in command line
mode using warp and translate, and then from within C++ in Visual Studio.  I
had first used GDAL from Python a year or two ago, before resuming pretty
intensely via C++ recently.

 

I had a problem with my PC, so I went to a new machine in the last few days.
Oh my, how little nitty things can challenge, to restabilize, particularly
when I don't have complete understanding of what I am doing.

 

Things are finally working, but I didn't get there in a straight line at
all, and I might have some redundant stuff on my new machine, so I'd like
some advice please.

 

Specifically, I think I installed twice unnecessarily, as follows:

 

1.	I did the install from source using the
https://trac.osgeo.org/gdal/wiki/DownloadSource page, then followed this
youtube video for every detail: https://www.youtube.com/watch?v=Yf8rYOfvZjY.
With a couple of tweaks, I ended up with all the GDAL folders and files in
one directory, c:\gdal.
2.	I did a much simpler install of .msi precompiled binaries using the
Generic Installer for the Core components from:
http://www.gisinternals.com/.  I ended up with all the x64 gdal libraries in
C:\Program Files\GDAL.  This youtube was helpful:
https://www.youtube.com/watch?v=hQt9tmfl-x8 

 

Things would not work...I got some post-compile execution errors about not
being able to find gdal203.dll.  I found this youtube video (
https://www.youtube.com/watch?v=yKTeNVvF4gM  ) that guided me to fix my path
variables, something I had done long ago in the Python period, and
overlooked in recent thrashing. 

 

In setting path and system variables in the last stage, I came to believe
that I had installed GDAL twice, though there was a small difference.  There
was no gdalplugins files it seems from step 1, they were from step 2.  So I
pointed the all 3 environment settings at the C:\Program Files\GDAL sections
from step 2.

 

Now when building a C++ console app (they are working), I'm manually setting
include libraries for gdal, apps, gcore, port, and ogr to the c:\gdal area
in step 1, and to c:\gdal\gdal_i.lib from step 1.  It seems bizarre what I
am doing, pointing to both area 1 (libs) and area 2 (paths), but things for
now are working.

 

Can someone please share some "best practices" insight for setup for the
benefit of this novice (me), so I hopefully can clean up the messy stuff I
have created and that I am doing?  I'm pretty sure what I am doing is screwy
and far from best practices!  

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181122/2bf9eb95/attachment-0001.html>

From mohdfathin3293 at gmail.com  Fri Nov 23 00:33:47 2018
From: mohdfathin3293 at gmail.com (Athin)
Date: Fri, 23 Nov 2018 01:33:47 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1541712749720-0.post@n6.nabble.com>
References: <1540950114674-0.post@n6.nabble.com>
 <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
 <1541554430069-0.post@n6.nabble.com>
 <BBC87CB3-8662-453C-9945-795033939615@outlook.com>
 <CACALY+SMNAa_W1v4YGWn9VJk149t9XpbpdCo6phqyupSywoCBQ@mail.gmail.com>
 <1541638212107-0.post@n6.nabble.com> <1541712749720-0.post@n6.nabble.com>
Message-ID: <1542962027653-0.post@n6.nabble.com>

Hi Gigas002,

If possible can you share with some guide how to use the gdal nuget and how
can i view the map on wpf not on console?




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From gigas002 at yandex.ru  Fri Nov 23 08:58:50 2018
From: gigas002 at yandex.ru (Gigas002)
Date: Fri, 23 Nov 2018 09:58:50 -0700 (MST)
Subject: [gdal-dev] How to Use Gdal in Microsoft Visual Studio C++
In-Reply-To: <1542962027653-0.post@n6.nabble.com>
References: <1541064705634-0.post@n6.nabble.com>
 <3822CCF2-42C9-4C9A-8B4F-FDCC7DB6AC37@outlook.com>
 <1541119696181-0.post@n6.nabble.com>
 <862AD6A3-0145-45D5-BE8D-186902DD3507@outlook.com>
 <1541554430069-0.post@n6.nabble.com>
 <BBC87CB3-8662-453C-9945-795033939615@outlook.com>
 <CACALY+SMNAa_W1v4YGWn9VJk149t9XpbpdCo6phqyupSywoCBQ@mail.gmail.com>
 <1541638212107-0.post@n6.nabble.com> <1541712749720-0.post@n6.nabble.com>
 <1542962027653-0.post@n6.nabble.com>
Message-ID: <1542992330318-0.post@n6.nabble.com>

Athin wrote
> If possible can you share with some guide how to use the gdal nuget and
> how
> can i view the map on wpf not on console?

Sure. You should right-click on "References" in your open project in VS and
choose "Manage nuget packages". Then search for "GDAL.NET" and install it.
Necessary references and GdalConfigurator class will automatically be added
to your project.

If you don't have internet on your PC to download nuget packages directly
from VS, you can download GDAL.NET package from nuget:
https://www.nuget.org/packages/GDAL.NET/. Then, you should change you nuget
search path, here's good answer on stackoverflow how to do it:
https://stackoverflow.com/questions/10240029/how-do-i-install-a-nuget-package-nupkg-file-locally.

After you build your project once, compiled gdal bindings will be placed in
your dubug/release directory near .exe file. 

Now you should call "GdalConfigurator.ConfigureGdal()" (or ConfigureOgr(),
depends on what you need) method in you program. If it doesn't throw any
exceptions, then gdal is found and all EnvironmentVariables set correctly.
If it throws exceptions, try changing solution platform on x64 and change
the following line in GdalConfiguration class from:

var executingAssemblyFile = new
Uri(Assembly.GetExecutingAssembly().GetName().CodeBase).LocalPath;

to

string executingAssemblyFile = Assembly.GetExecutingAssembly().Location;

The thing is, that original version works bad, if path contains some special
symbols, like "#", etc.

After you made your ConfigureGdal() method work correctly, you should add
"using OSGeo.*" namespaces to your code files, and now you can use all
gdal's c# bindings.

Unfortunately, I can't answer to your second question, I haven't done it
before. If I'll have time, I'll check it out and write you about results.



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From zazhil_ha at hotmail.com  Fri Nov 23 09:48:47 2018
From: zazhil_ha at hotmail.com (ZAZHIL-HA HERENA)
Date: Fri, 23 Nov 2018 17:48:47 +0000
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <20181123011354.m5hkafjyaumfjohy@imap.dreamhost.com>,
 <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
Message-ID: <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>

Thank you for the reply.

Nikos,

The path is correct, the space was an error in my redaction.

James,

I tried to run a GDALINFO in my Linux command line using the GDAL I configured and installed and I am not able to open the raster, even trying to read it from local:

      -bash-4.2$ gdalinfo /vsihdfs/file:/scratch/zherena/test/write/data/rasters/hawaii.tif
      ERROR 4: /vsihdfs/file:/scratch/zherena/test/write/data/rasters/hawaii.tif: No such file or directory
      gdalinfo failed - unable to open '/vsihdfs/file:/scratch/zherena/test/write/data/rasters/hawaii.tif'.

If I try the same commad withouth /vsihdfs/file:/... it works fine.

I also tried:

      -bash-4.2$ gdalinfo --version
      GDAL 2.3.2, released 2018/09/21

Version says 2.3.2 but libraries say: libgdal.so.20.4.2 . I am not sure if I got the latest code, this is the first time I compile it myself, I used this link to download source code:  http://download.osgeo.org/gdal/CURRENT/gdal-2.3.2.tar.gz


And I have a doubt, when configuring I used: --with-hdfs=yes, made another using: --with-hdfs = /scratch/zherena/gdal/hadoop/lib/native. Both tries did not work. I am not really sure what should I pass as a parameter to --with-hdfs?

This is the list of steps I used to build, I am using Java in my application where I plan to use gdal:


  *     make clean distclean(per your suggestion)
  *    ./configure --prefix=/scratch/zherena/gdal/build/gdal-2.3.2/outputb/ --with-complete=yes --with-java=yes --with-swig-java=yes --with-hdfs=/scratch/zherena/gdal/hadoop/lib/native --with-curl=/usr/bin/curl-config
  *   make
  *   make install
  *   cd /swig/java
  *   make veryclean
  *   make
  *   cp *.so ../../outputb/lib/
  *   cp *.jar ../../outputb/lib/


Maybe I am missing something during compile?

Thank you!!
Zazhil-ha
________________________________
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> on behalf of James McClain <james.mcclain at gmail.com>
Sent: Thursday, November 22, 2018 8:27 PM
Cc: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] Question on how to open a raster in HDFS using GDAL

Hello,

I am the author of the vsihdfs code, I am ready and willing to help.

I just rebuilt it from current master and was able to successfully open an dataset via an HDFS URI with the GDAL Python bindings.  I have a few suggestions.

First, please try putting the file into a local directory and try something like `gdalinfo /vsihdfs/file:/tmp/kahoolawe.tif` to establish a baseline.

Second, if you are using the Python bindings, please make sure that they have been built and installed (and that you are using the ones that you built rather than other ones that exist on your system).  Instructions for building the Python bindings can be found here: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix .

In my case, after building and installing the library and bindings, I was able to successfully open a dataset by starting a python REPL like this:

```bash
export LD_LIBRARY_PATH=$HOME/local/hadoop-2.7.7/lib/native:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server:$HOME/local/gdal-master-vsihdfs/lib
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export CLASSPATH=$($HOME/local/hadoop-2.7.7/bin/hadoop classpath --glob)
PYTHONPATH=$HOME/local/gdal-master-vsihdfs/lib/python2.7/site-packages python
```

then typing this into it:

```python
from osgeo import gdal, gdalconst
ds = gdal.Open('/vsihdfs/file:/tmp/testfile.tif', gdalconst.GA_ReadOnly)
```

(I do not have easy access to and HDFS cluster right at the moment, so I only tested a local HDFS URI.)

A note: After having done a build without HDFS support in the tree, I had do a `make clean distclean` before I was able to get a build with working HDFS support.

Sincerely,
James McClain

On Thu, Nov 22, 2018 at 8:13 PM Nikos Alexandris <nik at nikosalexandris.net<mailto:nik at nikosalexandris.net>> wrote:
* ZAZHIL-HA HERENA <zazhil_ha at hotmail.com<mailto:zazhil_ha at hotmail.com>> [2018-11-22 22:35:32 +0000]:

>Hello, I am not sure if I should use this mailing list to ask questions but I wanted to try, I am a developer trying to use GDAL to open rasters in HDFS.
>
>
>I read in GDAL documentation that starting 2.4 it is possible to open a raster in HDFS. I downloaded and compiled the latest source code available version and the generated libraries show it is 2.4 (libgdal.so.20.4.2). I compiled with option "-with-hdfs=yes" and "--with-java=yes".
>
>I am trying to open a raster using:
>
>
>
>    Dataset raster = gdal.Open("/vsihdfs/hdfs://node:8020/user/hdfs /spatial_raster/input_raster/kahoolawe.tif", gdalconst.GA_ReadOnly);

Is your path correct? There is a space here (in "/hfds /").

Nikos

>
>
>but I am getting the following error: "ERROR 4: No such file or directory"

[rest deleted]
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
https://lists.osgeo.org/mailman/listinfo/gdal-dev


--
"I prayed for freedom for twenty years, but received no answer until I prayed with my legs."
     -- Frederick Douglass

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181123/99957872/attachment.html>

From even.rouault at spatialys.com  Fri Nov 23 09:52:02 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 23 Nov 2018 18:52:02 +0100
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
 <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>
Message-ID: <2403916.OSkJQ3OgpL@even-i700>

> Version says 2.3.2 but libraries say: libgdal.so.20.4.2 .

Libtool number (.so.20.4.2) has nothing to do with user-friendly version 
number (2.3.2)

> I am not sure if I
> got the latest code, this is the first time I compile it myself, I used
> this link to download source code: 
> http://download.osgeo.org/gdal/CURRENT/gdal-2.3.2.tar.gz

This is the latest release, but /vsihdfs/ is in the development version, not 
yet released, so download

https://github.com/OSGeo/gdal/archive/master.zip

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From zazhil_ha at hotmail.com  Fri Nov 23 11:15:10 2018
From: zazhil_ha at hotmail.com (ZAZHIL-HA HERENA)
Date: Fri, 23 Nov 2018 19:15:10 +0000
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <2403916.OSkJQ3OgpL@even-i700>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
 <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>,
 <2403916.OSkJQ3OgpL@even-i700>
Message-ID: <BYAPR07MB4231F1245AF652E84FD66F9E95D40@BYAPR07MB4231.namprd07.prod.outlook.com>

Thank you so much!, now I am working on 2.4 source code but I am getting an error when trying to configure using:

./configure --prefix=/scratch/zherena/gdal/build/gdal-master/gdal/outputb/ --with-complete=yes --with-java=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/ --with-swig-java=yes --with-hdfs=/scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/ --with-curl=/usr/bin/curl-config

The error I get is:

      checking for HDFS in /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/... checking for hdfsConnect in -lhdfs... no
      checking for /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678//include/hdfs.h... yes
      configure: error: HDFS support not enabled.


Is there any configuration in my environment that I should consider? or maybe another distribution of Hadoop?


________________________________
From: Even Rouault <even.rouault at spatialys.com>
Sent: Friday, November 23, 2018 11:52 AM
To: gdal-dev at lists.osgeo.org
Cc: ZAZHIL-HA HERENA; James McClain; nik at nikosalexandris.net
Subject: Re: [gdal-dev] Question on how to open a raster in HDFS using GDAL

> Version says 2.3.2 but libraries say: libgdal.so.20.4.2 .

Libtool number (.so.20.4.2) has nothing to do with user-friendly version
number (2.3.2)

> I am not sure if I
> got the latest code, this is the first time I compile it myself, I used
> this link to download source code:
> http://download.osgeo.org/gdal/CURRENT/gdal-2.3.2.tar.gz

This is the latest release, but /vsihdfs/ is in the development version, not
yet released, so download

https://github.com/OSGeo/gdal/archive/master.zip

--
Spatialys - Geospatial professional services
http://www.spatialys.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181123/29c6aa81/attachment-0001.html>

From james.mcclain at gmail.com  Fri Nov 23 13:18:35 2018
From: james.mcclain at gmail.com (James McClain)
Date: Fri, 23 Nov 2018 16:18:35 -0500
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <BYAPR07MB4231F1245AF652E84FD66F9E95D40@BYAPR07MB4231.namprd07.prod.outlook.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
 <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>
 <2403916.OSkJQ3OgpL@even-i700>
 <BYAPR07MB4231F1245AF652E84FD66F9E95D40@BYAPR07MB4231.namprd07.prod.outlook.com>
Message-ID: <CAD5SdwKS6K9DZxFy=G0ftwq5JSj49G67mwZDy4_5VhwKAiQ04g@mail.gmail.com>

Hello,

It may not be finding the native HDFS libraries.  Please see the pull
request https://github.com/OSGeo/gdal/pull/714 for build instructions (in
particular, you may need to augment the LD_LIBRARY_PATH environment
variable).

If trouble persists, I would suggest building against Apache Hadoop 2.7.6
or 2.7.7 (both of those are know to work) as an experiment.

Sincerely,
James McClian

On Fri, Nov 23, 2018 at 2:15 PM ZAZHIL-HA HERENA <zazhil_ha at hotmail.com>
wrote:

> Thank you so much!, now I am working on 2.4 source code but I am getting
> an error when trying to configure using:
>
> *./configure
> --prefix=/scratch/zherena/gdal/build/gdal-master/gdal/outputb/
> --with-complete=yes
> --with-java=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/
> --with-swig-java=yes
> --with-hdfs=/scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/
> --with-curl=/usr/bin/curl-config*
>
> The error I get is:
>
>
> *      checking for HDFS in
> /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/... checking for
> hdfsConnect in -lhdfs... no *
>
> *      checking for
> /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678//include/hdfs.h... yes
> *
> *      configure: error: HDFS support not enabled.*
>
>
> Is there any configuration in my environment that I should consider? or
> maybe another distribution of Hadoop?
>
>
> ------------------------------
> *From:* Even Rouault <even.rouault at spatialys.com>
> *Sent:* Friday, November 23, 2018 11:52 AM
> *To:* gdal-dev at lists.osgeo.org
> *Cc:* ZAZHIL-HA HERENA; James McClain; nik at nikosalexandris.net
> *Subject:* Re: [gdal-dev] Question on how to open a raster in HDFS using
> GDAL
>
> > Version says 2.3.2 but libraries say: libgdal.so.20.4.2 .
>
> Libtool number (.so.20.4.2) has nothing to do with user-friendly version
> number (2.3.2)
>
> > I am not sure if I
> > got the latest code, this is the first time I compile it myself, I used
> > this link to download source code:
> > http://download.osgeo.org/gdal/CURRENT/gdal-2.3.2.tar.gz
>
> This is the latest release, but /vsihdfs/ is in the development version,
> not
> yet released, so download
>
> https://github.com/OSGeo/gdal/archive/master.zip
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>


-- 
"I prayed for freedom for twenty years, but received no answer until I
prayed with my legs."
     -- Frederick Douglass
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181123/969ca725/attachment.html>

From markus.metz.giswork at gmail.com  Sat Nov 24 07:27:33 2018
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sat, 24 Nov 2018 16:27:33 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
Message-ID: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>

I have a NetCDF file with west > east, gdalinfo reports
Corner Coordinates:
Upper Left  (     335.257,      70.000)
Lower Left  (     335.257,      30.000)
Upper Right (  44.7424710,  69.9999970)
Lower Right (  44.7424710,  29.9999954)
Center      (     190.000,      50.000)

west =  335.257 > east = 44.7424710

The reason is that west has been wrapped such that it is in the range [0,
360], and GDAL thinks that columns need to be read from right to left
instead of left to right.

The fix is to convert west with west -= 360, then assign corrected extents
with gdal_translate -a_ullr

There is a config option GDAL_NETCDF_BOTTOMUP. Could something similar be
implemented for west > east, something like GDAL_NETCDF_LEFTISLEFT? Or is
it a corrupted file and manual correction is the only option?

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181124/fbf2f4b9/attachment.html>

From even.rouault at spatialys.com  Sat Nov 24 08:07:56 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 24 Nov 2018 17:07:56 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
Message-ID: <1959970.ozPCLTmHTb@even-i700>

On samedi 24 novembre 2018 16:27:33 CET Markus Metz wrote:
> I have a NetCDF file with west > east, gdalinfo reports
> Corner Coordinates:
> Upper Left  (     335.257,      70.000)
> Lower Left  (     335.257,      30.000)
> Upper Right (  44.7424710,  69.9999970)
> Lower Right (  44.7424710,  29.9999954)
> Center      (     190.000,      50.000)
> 
> west =  335.257 > east = 44.7424710
> 
> The reason is that west has been wrapped such that it is in the range [0,
> 360], and GDAL thinks that columns need to be read from right to left
> instead of left to right.
> 
> The fix is to convert west with west -= 360, then assign corrected extents
> with gdal_translate -a_ullr
> 
> There is a config option GDAL_NETCDF_BOTTOMUP. Could something similar be
> implemented for west > east, something like GDAL_NETCDF_LEFTISLEFT? Or is
> it a corrupted file and manual correction is the only option?

Couldn't find anything related mentionned in the CF convention, but that 
doesn't make that file illegal. I guess that could be auto-corrected by 
detecting there's a discontinuity in the values of the longitude variable.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From markus.metz.giswork at gmail.com  Sat Nov 24 08:39:31 2018
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sat, 24 Nov 2018 17:39:31 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <1959970.ozPCLTmHTb@even-i700>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <1959970.ozPCLTmHTb@even-i700>
Message-ID: <CAG+h=FGTyRSJd6raAYFz5TqdyvE5rP_h1Gn1JNda1tTzxB4yuw@mail.gmail.com>

On Sat, Nov 24, 2018 at 5:07 PM Even Rouault <even.rouault at spatialys.com>
wrote:
>
> On samedi 24 novembre 2018 16:27:33 CET Markus Metz wrote:
> > I have a NetCDF file with west > east, gdalinfo reports
> > Corner Coordinates:
> > Upper Left  (     335.257,      70.000)
> > Lower Left  (     335.257,      30.000)
> > Upper Right (  44.7424710,  69.9999970)
> > Lower Right (  44.7424710,  29.9999954)
> > Center      (     190.000,      50.000)
> >
> > west =  335.257 > east = 44.7424710
> >
> > The reason is that west has been wrapped such that it is in the range
[0,
> > 360], and GDAL thinks that columns need to be read from right to left
> > instead of left to right.
> >
> > The fix is to convert west with west -= 360, then assign corrected
extents
> > with gdal_translate -a_ullr
> >
> > There is a config option GDAL_NETCDF_BOTTOMUP. Could something similar
be
> > implemented for west > east, something like GDAL_NETCDF_LEFTISLEFT? Or
is
> > it a corrupted file and manual correction is the only option?
>
> Couldn't find anything related mentionned in the CF convention, but that
> doesn't make that file illegal. I guess that could be auto-corrected by
> detecting there's a discontinuity in the values of the longitude variable.

This particular NetCDF file, PM10 analysis from CAMS
http://www.regional.atmosphere.copernicus.eu/, does not have a longitude
variable, also no subdatasets. Resolution should be 0.1 degrees, but GDAL
reports
Pixel Size = (-0.415021467959250,-0.100000003824258)
because west > east

full gdalinfo output without band info:

Warning 1: No UNIDATA NC_GLOBAL:Conventions attribute
Driver: netCDF/Network Common Data Format
Files:
W_fr-meteofrance,MODEL,ENSEMBLE+ANALYSIS+SURFACE+PM10+-24H-1H_C_LFPW_20181120000000.nc
Size is 700, 400
Coordinate System is `'
Origin = (335.257498526948382,69.999996950154312)
Pixel Size = (-0.415021467959250,-0.100000003824258)
Metadata:
  latitude#long_name=latitude
  latitude#units=degrees_north
  level#long_name=level
  level#units=m
  longitude#long_name=longitude
  longitude#units=degrees_east
  NC_GLOBAL#ANALYSIS=Europe, 20181119+[0H_23H]
  NC_GLOBAL#comment=Tools used: CDO V1.6.1rc6 and NCO V4.3.7
  NC_GLOBAL#history=Model ENSEMBLE ANALYSIS
  NC_GLOBAL#institution=Data produced by Meteo France
  NC_GLOBAL#nco_openmp_thread_number=1
  NC_GLOBAL#project=MACC-RAQ (http://macc-raq.gmes-atmosphere.eu)
  NC_GLOBAL#source=Data from ENSEMBLE model
  NC_GLOBAL#summary=ENSEMBLE model hourly ANALYSIS of PM10 concentration at
the Surface from 20181119+[0H_23H] on Europe
  NC_GLOBAL#title=PM10 Air Pollutant ANALYSIS at the Surface
  NETCDF_DIM_EXTRA={time,level}
  NETCDF_DIM_level_DEF={1,5}
  NETCDF_DIM_level_VALUES=0
  NETCDF_DIM_time_DEF={24,5}

NETCDF_DIM_time_VALUES={0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23}
  pm10_conc#species=PM10 Aerosol
  pm10_conc#standard_name=mass_concentration_of_pm10_ambient_aerosol_in_air
  pm10_conc#units=µg/m3
  pm10_conc#value=hourly values
  time#long_name=ANALYSIS time from 20181119
  time#units=hours
Corner Coordinates:
Upper Left  (     335.257,      70.000)
Lower Left  (     335.257,      30.000)
Upper Right (  44.7424710,  69.9999970)
Lower Right (  44.7424710,  29.9999954)
Center      (     190.000,      50.000)
Band 1 Block=700x1 Type=Float32, ColorInterp=Undefined
...
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181124/621399dd/attachment-0001.html>

From even.rouault at spatialys.com  Sat Nov 24 08:56:32 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 24 Nov 2018 17:56:32 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <CAG+h=FGTyRSJd6raAYFz5TqdyvE5rP_h1Gn1JNda1tTzxB4yuw@mail.gmail.com>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <1959970.ozPCLTmHTb@even-i700>
 <CAG+h=FGTyRSJd6raAYFz5TqdyvE5rP_h1Gn1JNda1tTzxB4yuw@mail.gmail.com>
Message-ID: <4278690.cM759OZkQX@even-i700>

> This particular NetCDF file, PM10 analysis from CAMS
> http://www.regional.atmosphere.copernicus.eu/, does not have a longitude
> variable, also no subdatasets. Resolution should be 0.1 degrees, but GDAL
> reports
> Pixel Size = (-0.415021467959250,-0.100000003824258)
> because west > east
> 

ok, ncdump on it confirms there's a clean discontinuity, and regular spacing
before and after:

 longitude = 335.05, 335.15,[...], 359.85, 359.95, 
    0.04998779, 0.1499939, [...] 44.84998, 44.94998;

the netCDF driver could detect and autocorrect this. Should be around line 
3174 of frmts/netcdf/netcdfdataset.cpp

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From markus.metz.giswork at gmail.com  Sat Nov 24 09:24:14 2018
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sat, 24 Nov 2018 18:24:14 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <4278690.cM759OZkQX@even-i700>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <1959970.ozPCLTmHTb@even-i700>
 <CAG+h=FGTyRSJd6raAYFz5TqdyvE5rP_h1Gn1JNda1tTzxB4yuw@mail.gmail.com>
 <4278690.cM759OZkQX@even-i700>
Message-ID: <CAG+h=FGTWrw_F1oe_s36ptqvM4MmxUgn7UTxgDshsJqZJ4QSng@mail.gmail.com>

On Sat, Nov 24, 2018 at 5:56 PM Even Rouault <even.rouault at spatialys.com>
wrote:
>
> > This particular NetCDF file, PM10 analysis from CAMS
> > http://www.regional.atmosphere.copernicus.eu/, does not have a longitude
> > variable, also no subdatasets. Resolution should be 0.1 degrees, but
GDAL
> > reports
> > Pixel Size = (-0.415021467959250,-0.100000003824258)
> > because west > east
> >
>
> ok, ncdump on it confirms there's a clean discontinuity, and regular
spacing
> before and after:
>
>  longitude = 335.05, 335.15,[...], 359.85, 359.95,
>     0.04998779, 0.1499939, [...] 44.84998, 44.94998;

ncdump also confirms that longitudes are increasing from west:
longitude = 335.05, 335.15
this is correct, while GDAL assumes that longitudes are decreasing from west

The discontinuity  359.95, 0.04998779 is not a discontinuity with regard to
their location on earth, the spacing is still about 0.1 because 0.04998779
= 360.04998779
>
> the netCDF driver could detect and autocorrect this. Should be around line
> 3174 of frmts/netcdf/netcdfdataset.cpp

I will have a look.

Thanks for your very fast feedback!

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181124/ba6b26ed/attachment.html>

From markus.metz.giswork at gmail.com  Sat Nov 24 14:09:34 2018
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sat, 24 Nov 2018 23:09:34 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <CAG+h=FGTWrw_F1oe_s36ptqvM4MmxUgn7UTxgDshsJqZJ4QSng@mail.gmail.com>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <1959970.ozPCLTmHTb@even-i700>
 <CAG+h=FGTyRSJd6raAYFz5TqdyvE5rP_h1Gn1JNda1tTzxB4yuw@mail.gmail.com>
 <4278690.cM759OZkQX@even-i700>
 <CAG+h=FGTWrw_F1oe_s36ptqvM4MmxUgn7UTxgDshsJqZJ4QSng@mail.gmail.com>
Message-ID: <CAG+h=FFfWOoPsccZLf=1-rOvZ2G5kEAr7-NNT2+fo8ZK_-GyKQ@mail.gmail.com>

I have created a PR for this, but there are still issues:

is
Pixel Size = (0.099999991285714,-0.100000004000000)
Corner Coordinates:
Upper Left  ( -25.0000122,  69.9999970)
Lower Left  ( -25.0000122,  29.9999954)
Upper Right (  44.9999817,  69.9999970)
Lower Right (  44.9999817,  29.9999954)
Center      (   9.9999847,  49.9999962)

should be
Pixel Size = (0.100000000000000,-0.100000000000000)
Corner Coordinates:
Upper Left  ( -25.0000000,  70.0000000)
Lower Left  ( -25.0000000,  30.0000000)
Upper Right (  45.0000000,  70.0000000)
Lower Right (  45.0000000,  30.0000000)
Center      (  10.0000000,  50.0000000)

Markus M

On Sat, Nov 24, 2018 at 6:24 PM Markus Metz <markus.metz.giswork at gmail.com>
wrote:

>
>
> On Sat, Nov 24, 2018 at 5:56 PM Even Rouault <even.rouault at spatialys.com>
> wrote:
> >
> > > This particular NetCDF file, PM10 analysis from CAMS
> > > http://www.regional.atmosphere.copernicus.eu/, does not have a
> longitude
> > > variable, also no subdatasets. Resolution should be 0.1 degrees, but
> GDAL
> > > reports
> > > Pixel Size = (-0.415021467959250,-0.100000003824258)
> > > because west > east
> > >
> >
> > ok, ncdump on it confirms there's a clean discontinuity, and regular
> spacing
> > before and after:
> >
> >  longitude = 335.05, 335.15,[...], 359.85, 359.95,
> >     0.04998779, 0.1499939, [...] 44.84998, 44.94998;
>
> ncdump also confirms that longitudes are increasing from west:
> longitude = 335.05, 335.15
> this is correct, while GDAL assumes that longitudes are decreasing from
> west
>
> The discontinuity  359.95, 0.04998779 is not a discontinuity with regard
> to their location on earth, the spacing is still about 0.1 because
> 0.04998779 = 360.04998779
> >
> > the netCDF driver could detect and autocorrect this. Should be around
> line
> > 3174 of frmts/netcdf/netcdfdataset.cpp
>
> I will have a look.
>
> Thanks for your very fast feedback!
>
> Markus M
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181124/d3f12527/attachment.html>

From even.rouault at spatialys.com  Sat Nov 24 17:24:11 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 25 Nov 2018 02:24:11 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <CAG+h=FFfWOoPsccZLf=1-rOvZ2G5kEAr7-NNT2+fo8ZK_-GyKQ@mail.gmail.com>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <CAG+h=FGTWrw_F1oe_s36ptqvM4MmxUgn7UTxgDshsJqZJ4QSng@mail.gmail.com>
 <CAG+h=FFfWOoPsccZLf=1-rOvZ2G5kEAr7-NNT2+fo8ZK_-GyKQ@mail.gmail.com>
Message-ID: <2103703.UcQ3EzsYyg@even-i700>

On samedi 24 novembre 2018 23:09:34 CET Markus Metz wrote:
> I have created a PR for this, but there are still issues:
> 
> is
> Pixel Size = (0.099999991285714,-0.100000004000000)
> Corner Coordinates:
> Upper Left  ( -25.0000122,  69.9999970)
> Lower Left  ( -25.0000122,  29.9999954)
> Upper Right (  44.9999817,  69.9999970)
> Lower Right (  44.9999817,  29.9999954)
> Center      (   9.9999847,  49.9999962)
> 
> should be
> Pixel Size = (0.100000000000000,-0.100000000000000)
> Corner Coordinates:
> Upper Left  ( -25.0000000,  70.0000000)
> Lower Left  ( -25.0000000,  30.0000000)
> Upper Right (  45.0000000,  70.0000000)
> Lower Right (  45.0000000,  30.0000000)
> Center      (  10.0000000,  50.0000000)

Yes, the issue is that the data type for the x variable in the .nc file is 
float32, so it has not enough precision. You could try to round the coodinates 
with some heuristics, like (untested !)

for the resolution:

double K = std::pow(10, 4 - std::round(std::log(res) / std::log(10)));
if( std::fabs(K * res - std::round(K * res)) < 1 )
{
	res = std::round(K * res) / K;
}

for the coordinates:

// Case where coordinates are aligned on a multiple of the resolution
if ( std::fabs(x / res - std::round(x / res)) < 1e-3 )
{
    x = std::round(x / res) * res
}
// Case were they are aligned with a half-pixel shift
else if (std::fabs((x - res/2)/res) - std::round((x - res/2)/res)) < 1e-3 )
{
    x = std::round((x - res/2)/res) * res + res/2;
}


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From markus.metz.giswork at gmail.com  Sun Nov 25 12:26:20 2018
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sun, 25 Nov 2018 21:26:20 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <2103703.UcQ3EzsYyg@even-i700>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <CAG+h=FGTWrw_F1oe_s36ptqvM4MmxUgn7UTxgDshsJqZJ4QSng@mail.gmail.com>
 <CAG+h=FFfWOoPsccZLf=1-rOvZ2G5kEAr7-NNT2+fo8ZK_-GyKQ@mail.gmail.com>
 <2103703.UcQ3EzsYyg@even-i700>
Message-ID: <CAG+h=FHCtCnSHSdDPa3rtxHjVvac0L5Z2qMPtXZ9Efi=kJ-M3Q@mail.gmail.com>

On Sun, Nov 25, 2018 at 2:24 AM Even Rouault <even.rouault at spatialys.com>
wrote:
>
> On samedi 24 novembre 2018 23:09:34 CET Markus Metz wrote:
> > I have created a PR for this, but there are still issues:
> >
> > is
> > Pixel Size = (0.099999991285714,-0.100000004000000)
> > Corner Coordinates:
> > Upper Left  ( -25.0000122,  69.9999970)
> > Lower Left  ( -25.0000122,  29.9999954)
> > Upper Right (  44.9999817,  69.9999970)
> > Lower Right (  44.9999817,  29.9999954)
> > Center      (   9.9999847,  49.9999962)
> >
> > should be
> > Pixel Size = (0.100000000000000,-0.100000000000000)
> > Corner Coordinates:
> > Upper Left  ( -25.0000000,  70.0000000)
> > Lower Left  ( -25.0000000,  30.0000000)
> > Upper Right (  45.0000000,  70.0000000)
> > Lower Right (  45.0000000,  30.0000000)
> > Center      (  10.0000000,  50.0000000)
>
> Yes, the issue is that the data type for the x variable in the .nc file is
> float32, so it has not enough precision. You could try to round the
coodinates
> with some heuristics, like (untested !)
>
> for the resolution:
>
> double K = std::pow(10, 4 - std::round(std::log(res) / std::log(10)));
> if( std::fabs(K * res - std::round(K * res)) < 1 )
> {
>         res = std::round(K * res) / K;
> }
>
> for the coordinates:
>
> // Case where coordinates are aligned on a multiple of the resolution
> if ( std::fabs(x / res - std::round(x / res)) < 1e-3 )
> {
>     x = std::round(x / res) * res
> }
> // Case were they are aligned with a half-pixel shift
> else if (std::fabs((x - res/2)/res) - std::round((x - res/2)/res)) < 1e-3
)
> {
>     x = std::round((x - res/2)/res) * res + res/2;
> }

Many datasets with degrees as coordinate units have resolution and extents
that can be expressed as integer or 0.5 seconds, e.g. SRTM at 1, 3, and 30
arc seconds. Some of these deviations caused by fp precision limits go away
if you convert to arc seconds and then round to the nearest e.g. 1e-6 arc
second. GRASS GIS is using this approach successfully.

About the PR: if the tested nc files are formally legal with their
longitude jump at 359.95, 0.04998779, then this could be regarded as a bug
fix, right?

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181125/d15d6af3/attachment.html>

From even.rouault at spatialys.com  Sun Nov 25 12:49:15 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 25 Nov 2018 21:49:15 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <CAG+h=FHCtCnSHSdDPa3rtxHjVvac0L5Z2qMPtXZ9Efi=kJ-M3Q@mail.gmail.com>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <2103703.UcQ3EzsYyg@even-i700>
 <CAG+h=FHCtCnSHSdDPa3rtxHjVvac0L5Z2qMPtXZ9Efi=kJ-M3Q@mail.gmail.com>
Message-ID: <10573953.ZC1VNkyv9o@even-i700>

> About the PR: if the tested nc files are formally legal with their
> longitude jump at 359.95, 0.04998779, then this could be regarded as a bug
> fix, right?

Hard to tell what is legal from what is not sometimes. Anyway the mission of a 
driver is to make it as easy as possible to use the data that is available, so 
when "patching" is needed and doable without compromising the reading of 
"normal" products, it is legit to do it. And as the fix is non-intrusive, I've 
just backported it to the 2.3 branch

Thanks

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From markus.metz.giswork at gmail.com  Sun Nov 25 13:21:51 2018
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sun, 25 Nov 2018 22:21:51 +0100
Subject: [gdal-dev] NetCDF config option for west > east?
In-Reply-To: <10573953.ZC1VNkyv9o@even-i700>
References: <CAG+h=FEAJ2KnF_C1uL9YpsGyeW0zhcmzzAg_VurSJ=jiYxZJFw@mail.gmail.com>
 <2103703.UcQ3EzsYyg@even-i700>
 <CAG+h=FHCtCnSHSdDPa3rtxHjVvac0L5Z2qMPtXZ9Efi=kJ-M3Q@mail.gmail.com>
 <10573953.ZC1VNkyv9o@even-i700>
Message-ID: <CAG+h=FFcuB9cpi1TYq8Np0tT2wjYxQfMjgTo94RWDeJVC_OC=g@mail.gmail.com>

On Sun, Nov 25, 2018 at 9:49 PM Even Rouault <even.rouault at spatialys.com>
wrote:
>
> > About the PR: if the tested nc files are formally legal with their
> > longitude jump at 359.95, 0.04998779, then this could be regarded as a
bug
> > fix, right?
>
> Hard to tell what is legal from what is not sometimes. Anyway the mission
of a
> driver is to make it as easy as possible to use the data that is
available, so
> when "patching" is needed and doable without compromising the reading of
> "normal" products, it is legit to do it. And as the fix is non-intrusive,
I've
> just backported it to the 2.3 branch

Great, thanks for backporting to the 2.3 branch! This makes at least the
CAMS products easily usable, probably also other NetCDF files covering
Europe.

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181125/127aa6dd/attachment.html>

From ari.jolma at gmail.com  Mon Nov 26 02:51:57 2018
From: ari.jolma at gmail.com (Ari Jolma)
Date: Mon, 26 Nov 2018 12:51:57 +0200
Subject: [gdal-dev] libgdal runpath
Message-ID: <0c44780f-e911-219b-6150-dae36dcc4ffa@gmail.com>

I'm building compartmentalized systems on servers. There may be several 
systems with different setups, thus library management is important.

I'm wondering why libgdal looks like this

readelf -d parts/gdal/lib/libgdal.so

  0x0000000000000001 (NEEDED)             Shared library: [libgeos_c.so.1]
  0x0000000000000001 (NEEDED)             Shared library: [libexpat.so.1]
  0x0000000000000001 (NEEDED)             Shared library: [libgeotiff.so.2]
  0x0000000000000001 (NEEDED)             Shared library: [libproj.so.0]
  0x0000000000000001 (NEEDED)             Shared library: [libtiff.so.3]
  0x0000000000000001 (NEEDED)             Shared library: [libpthread.so.0]
  0x0000000000000001 (NEEDED)             Shared library: [libxml2.so.2]
  0x0000000000000001 (NEEDED)             Shared library: [libz.so.1]
  0x0000000000000001 (NEEDED)             Shared library: [libiconv.so.2]
  0x0000000000000001 (NEEDED)             Shared library: [libdl.so.2]
  0x0000000000000001 (NEEDED)             Shared library: [libstdc++.so.6]
  0x0000000000000001 (NEEDED)             Shared library: [libm.so.6]
  0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]
  0x0000000000000001 (NEEDED)             Shared library: [libgcc_s.so.1]
  0x000000000000000e (SONAME)             Library soname: [libgdal.so.20]
  0x000000000000001d (RUNPATH)            Library runpath: 
[/home/ajolma/fims-server/parts/expat/lib:/home/ajolma/fims-server/parts/libxml2/lib]

when GDAL was built with 
--with-libtiff=/home/ajolma/fims-server/parts/tiff, i.e., why the 
libtiff directory did not get into RUNPATH?

LD_LIBRARY_PATH can be used to make libtiff found from the correct 
location but it is an extra hassle.

Ari



From even.rouault at spatialys.com  Mon Nov 26 03:34:05 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 26 Nov 2018 12:34:05 +0100
Subject: [gdal-dev] libgdal runpath
In-Reply-To: <0c44780f-e911-219b-6150-dae36dcc4ffa@gmail.com>
References: <0c44780f-e911-219b-6150-dae36dcc4ffa@gmail.com>
Message-ID: <1960650.y836iUUNP2@even-i700>

On lundi 26 novembre 2018 12:51:57 CET Ari Jolma wrote:
> I'm building compartmentalized systems on servers. There may be several
> systems with different setups, thus library management is important.
> 
> I'm wondering why libgdal looks like this

GDAL configure only adds -L/path/to/lib to the LIBS, not
-Wl,-rpath,/path/to/lib (except for the JDK .so)

Adding rpath by default might be a good enhancement (but I suspect that this 
should be ammended in every place in configure.ac where we modify LIBS or set 
custom LIB variables)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From bjorn.harrtell at gmail.com  Tue Nov 27 03:25:06 2018
From: bjorn.harrtell at gmail.com (=?UTF-8?Q?Bj=C3=B6rn_Harrtell?=)
Date: Tue, 27 Nov 2018 12:25:06 +0100
Subject: [gdal-dev] GML element/attribute discovery inconsistency
Message-ID: <CANhDX=ZTsvHys5+Tz2Sni779APmZO1OzhcAM3czdNutt9J5nXQ@mail.gmail.com>

I think I've found some inconsistencies in GML parsing.

Given the following example GML:

<?xml version="1.0" encoding="UTF-8"?>
<gml:FeatureCollection
  xmlns:gml="http://www.opengis.net/gml/3.2"
  xmlns:ex="http://example.com"
  xmlns:xlink="http://www.w3.org/1999/xlink"
  xmlns:xml="http://www.w3.org/XML/1998/namespace"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  gml:id="id.05e55fe5-b525-4cf2-9977-fedfc0532fd6">
  <gml:featureMember>
    <ex:MyFeaturetype1 gml:id="id.8685d1b8-a851-4034-b8ed-a4c785667386">
      <ex:a1 xsi:nil="true" nilReason="unknown" />
      <ex:a2 uom="m" />
      <ex:a3 xlink:href="https://test.com/value" xlink:title="title" />
      <ex:a4 xlink:href="#id.8685d1b8-a851-4034-b8ed-a4c785667386" />
      <ex:a5 />
    </ex:MyFeaturetype1>
  </gml:featureMember>
</gml:FeatureCollection>

ogrinfo -al will list the following columns:

gml_id: String (0.0) NOT NULL
a1: String (0.0)
a2_uom: String (1.0)

AFAIK it should not define the field a2_uom as GML_ATTRIBUTES_TO_OGR_FIELDS
is NO as default. If I rerun it with GML_ATTRIBUTES_TO_OGR_FIELDS set to
YES the result is:

gml_id: String (0.0) NOT NULL
a1: String (0.0)
a2_uom: String (1.0)
a3_title: String (5.0)
a3_href: String (22.0)
a4_href: String (40.0)

In this case we get more attributes but I think a1_nilReason is missing.

Also, in both cases it seems fields for empty elements are missing (a2, a3,
a4 and a5).

Are my observations correct?

Regards,

Björn
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181127/10c4deca/attachment.html>

From even.rouault at spatialys.com  Tue Nov 27 03:46:37 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 27 Nov 2018 12:46:37 +0100
Subject: [gdal-dev] GML element/attribute discovery inconsistency
In-Reply-To: <CANhDX=ZTsvHys5+Tz2Sni779APmZO1OzhcAM3czdNutt9J5nXQ@mail.gmail.com>
References: <CANhDX=ZTsvHys5+Tz2Sni779APmZO1OzhcAM3czdNutt9J5nXQ@mail.gmail.com>
Message-ID: <1846385.h1pvXr3RRh@even-i700>

> Are my observations correct?

Björn,

It would be difficult to deny the results of tests :-)

The GML driver has a lot of particular handling tailored for particular 
datasets, which makes understanding its behaviour non-obvious

From the code (which confirms your observations),
- if an element has a xsi:nil attribute, then its other attributes are ignored 
and the content of the element is set to NULL (what you observe with a1)
- there is a particular case for the uom attribute, which is always reported 
even if GML_ATTRIBUTES_TO_OGR_FIELDS is not set (the _uom case was added 
before the generalization of GML_ATTRIBUTES_TO_OGR_FIELDS)
- empty elements (if empty for all features) are not reported as OGR fields

You may want to try the GMLAS driver for something that involves less 
guessing. The GML driver can work without any schema, and if the schema is 
present only supports simple constructs in it. Contrary to the GMLAS driver, 
which is (almost) completely schema driven to create the OGR layer and 
attribute structure:
https://www.gdal.org/drv_gmlas.html

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jukka.rahkonen at maanmittauslaitos.fi  Tue Nov 27 03:57:01 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Tue, 27 Nov 2018 04:57:01 -0700 (MST)
Subject: [gdal-dev] GML element/attribute discovery inconsistency
In-Reply-To: <1846385.h1pvXr3RRh@even-i700>
References: <CANhDX=ZTsvHys5+Tz2Sni779APmZO1OzhcAM3czdNutt9J5nXQ@mail.gmail.com>
 <1846385.h1pvXr3RRh@even-i700>
Message-ID: <1543319821185-0.post@n6.nabble.com>

Hi,

I would mention also an open option EMPTY_AS_NULL=NO that seems to adds some
fields into ogrinfo result:

gml_id: String (0.0) NOT NULL
a1: StringList (0.0)
a2: String (0.0)
a2_uom: String (1.0)
a3_title: String (5.0)
a3: String (0.0)
a3_href: String (22.0)
a4: String (0.0)
a4_href: String (40.0)
a5: String (0.0)
OGRFeature(MyFeaturetype1):785667386
  gml_id (String) = id.8685d1b8-a851-4034-b8ed-a4c785667386
  a1 (StringList) = (null)
  a2 (String) =
  a2_uom (String) = m
  a3_title (String) = title
  a3 (String) =
  a3_href (String) = https://test.com/value
  a4 (String) =
  a4_href (String) = #id.8685d1b8-a851-4034-b8ed-a4c785667386
  a5 (String) =

-Jukka Rahkonen-



 
Even Rouault-2 wrote
>> Are my observations correct?
> 
> Björn,
> 
> It would be difficult to deny the results of tests :-)
> 
> The GML driver has a lot of particular handling tailored for particular 
> datasets, which makes understanding its behaviour non-obvious
> 
> From the code (which confirms your observations),
> - if an element has a xsi:nil attribute, then its other attributes are
> ignored 
> and the content of the element is set to NULL (what you observe with a1)
> - there is a particular case for the uom attribute, which is always
> reported 
> even if GML_ATTRIBUTES_TO_OGR_FIELDS is not set (the _uom case was added 
> before the generalization of GML_ATTRIBUTES_TO_OGR_FIELDS)
> - empty elements (if empty for all features) are not reported as OGR
> fields
> 
> You may want to try the GMLAS driver for something that involves less 
> guessing. The GML driver can work without any schema, and if the schema is 
> present only supports simple constructs in it. Contrary to the GMLAS
> driver, 
> which is (almost) completely schema driven to create the OGR layer and 
> attribute structure:
> https://www.gdal.org/drv_gmlas.html
> 
> Even
> 
> -- 
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list

> gdal-dev at .osgeo

> https://lists.osgeo.org/mailman/listinfo/gdal-dev





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From bjorn.harrtell at gmail.com  Tue Nov 27 05:16:19 2018
From: bjorn.harrtell at gmail.com (=?UTF-8?Q?Bj=C3=B6rn_Harrtell?=)
Date: Tue, 27 Nov 2018 14:16:19 +0100
Subject: [gdal-dev] GML element/attribute discovery inconsistency
In-Reply-To: <1846385.h1pvXr3RRh@even-i700>
References: <CANhDX=ZTsvHys5+Tz2Sni779APmZO1OzhcAM3czdNutt9J5nXQ@mail.gmail.com>
 <1846385.h1pvXr3RRh@even-i700>
Message-ID: <CANhDX=biYzLaaHa85gMmmV+zVdYv70zA+FiAqbvstMSQj73j8g@mail.gmail.com>

Thanks for the clarifications Even,

I've tried GMLAS but been unsuccessful in getting it to produce useful
output.

I'm actually quite happy with the standard GML driver, except that it
ignores other attributes when element has xsi:nil. Would it be a welcome
change to remove that behavior, treating other attributes as normal, and if
so does that change need to be opt in?

Björn

Den tis 27 nov. 2018 kl 12:46 skrev Even Rouault <even.rouault at spatialys.com
>:

> > Are my observations correct?
>
> Björn,
>
> It would be difficult to deny the results of tests :-)
>
> The GML driver has a lot of particular handling tailored for particular
> datasets, which makes understanding its behaviour non-obvious
>
> From the code (which confirms your observations),
> - if an element has a xsi:nil attribute, then its other attributes are
> ignored
> and the content of the element is set to NULL (what you observe with a1)
> - there is a particular case for the uom attribute, which is always
> reported
> even if GML_ATTRIBUTES_TO_OGR_FIELDS is not set (the _uom case was added
> before the generalization of GML_ATTRIBUTES_TO_OGR_FIELDS)
> - empty elements (if empty for all features) are not reported as OGR fields
>
> You may want to try the GMLAS driver for something that involves less
> guessing. The GML driver can work without any schema, and if the schema is
> present only supports simple constructs in it. Contrary to the GMLAS
> driver,
> which is (almost) completely schema driven to create the OGR layer and
> attribute structure:
> https://www.gdal.org/drv_gmlas.html
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181127/78a82ad3/attachment.html>

From even.rouault at spatialys.com  Tue Nov 27 05:31:20 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 27 Nov 2018 14:31:20 +0100
Subject: [gdal-dev] GML element/attribute discovery inconsistency
In-Reply-To: <CANhDX=biYzLaaHa85gMmmV+zVdYv70zA+FiAqbvstMSQj73j8g@mail.gmail.com>
References: <CANhDX=ZTsvHys5+Tz2Sni779APmZO1OzhcAM3czdNutt9J5nXQ@mail.gmail.com>
 <1846385.h1pvXr3RRh@even-i700>
 <CANhDX=biYzLaaHa85gMmmV+zVdYv70zA+FiAqbvstMSQj73j8g@mail.gmail.com>
Message-ID: <1700678.GpxHZrrf1v@even-i700>

On mardi 27 novembre 2018 14:16:19 CET Björn Harrtell wrote:
> Thanks for the clarifications Even,
> 
> I've tried GMLAS but been unsuccessful in getting it to produce useful
> output.

I assume you had a schema to point to.
The GMLAS driver has been tested on a number of fairly complicated models 
(Inspire, CityGML, etc.) as well as Simple Feature ones, but I cannot exclude 
it might fail on some schemas. Or perhaps the structure it generates was too 
complicated (which just reflects the complexity of the original schemas) ?

> 
> I'm actually quite happy with the standard GML driver, except that it
> ignores other attributes when element has xsi:nil. Would it be a welcome
> change to remove that behavior, treating other attributes as normal, and if
> so does that change need to be opt in?

If GML_ATTRIBUTES_TO_OGR_FIELDS is set, we could probably avoid treating 
xsi:nil as a particular case.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From marcel.wendler at pointcloudtechnology.com  Tue Nov 27 08:53:10 2018
From: marcel.wendler at pointcloudtechnology.com (Marcel Wendler)
Date: Tue, 27 Nov 2018 16:53:10 +0000
Subject: [gdal-dev] Get area of use of a spatial reference system
Message-ID: <DB6P192MB0103E1876CEC63C22885802CF7D00@DB6P192MB0103.EURP192.PROD.OUTLOOK.COM>

Hi all,


I am wondering if GDAL has a method that returns the area of use/the areas epsg code of a particular spatial reference system.

>From what I could find (e.g. in the OGRSpatialReference class doc and in the data provided in GDALs share folder) I think it's not possible. It seems a little bit strange as other information (like Inverse Flattening, Semi Major Axis etc.) from the EPSG dataset is present and can be accessed via methods in OGRSpatialReference.


I'd be happy if anyone can clarify this for me and, at best, prove me wrong ;)



Thanks,


Marcel
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181127/2dfe6932/attachment-0001.html>

From even.rouault at spatialys.com  Tue Nov 27 08:59:54 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 27 Nov 2018 17:59:54 +0100
Subject: [gdal-dev] Early GDAL 2.4.0 release ?
Message-ID: <3480702.ZBnXc4afsm@even-i700>

Hi,

I've been considering an early GDAL 2.4.0 release for the end of this year 
instead of the traditionnal mid-April / May target.

The rationale is that the work related to the GDAL/PROJ SRS revamp effort (aka 
"GDAL barn": https://gdalbarn.com/) will probably require non-null integration 
work from GDAL users, which will unnecessarily delay the "time-to-market" of 
features currently in GDAL master.

I've just began integrating the PROJ changes in a GDAL branch of mine and the 
current and future changes can be classified in the following categories:
- for sure: behaviour changes. exportToWKT() / exportToProj4() will for 
example return different strings. Most of the time equivalent, but nonetheless 
different, which can break other software unit tests
- probable: some OGRSpatialReference methods / OSR functions might be removed, 
or become no-operation
- uncertain at this point: impact of being axis order and unit compliant with 
the CRS definition from the authority.

I'd like the GDAL 2.5.0 release that will integrate the GDAL barn work to 
still be scheduled for mid-April / May date, and with my branch being 
hopefully ready for being merged into master in January.

A temptative schedule for 2.4.0 might be:

- December 14th: GDAL 2.4.0RC1 (I believe master is mature enough to go to RC 
stage directly, with no/very few changes affecting backward compatibility, but 
this is just from memory. The updated NEWS would help to confirm, but creating 
it is the bulk of the release work), likely coupled with a GDAL 2.3.3RC1 that 
would be the final point release for the GDAL 2.3 series

- December 21th: GDAL 2.4.0final

Thoughts ? Ah, and the release manager role is still open for volunteers (or 
any help, particularly updating NEWS, would be appreciated)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Tue Nov 27 09:02:38 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 27 Nov 2018 18:02:38 +0100
Subject: [gdal-dev] Get area of use of a spatial reference system
In-Reply-To: <DB6P192MB0103E1876CEC63C22885802CF7D00@DB6P192MB0103.EURP192.PROD.OUTLOOK.COM>
References: <DB6P192MB0103E1876CEC63C22885802CF7D00@DB6P192MB0103.EURP192.PROD.OUTLOOK.COM>
Message-ID: <3141582.xEHBOX4bFK@even-i700>

On mardi 27 novembre 2018 16:53:10 CET Marcel Wendler wrote:
> Hi all,
> 
> 
> I am wondering if GDAL has a method that returns the area of use/the areas
> epsg code of a particular spatial reference system.

Marcel,

No, this is not currently imported from the EPSG dataset in the .csv files 
used by GDAL. As part of my ongoing work on the SRS front in GDAL/PROJ, this 
should be available in the GDAL version that will be out around May next year 
(see my previous message)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From dmorissette at mapgears.com  Tue Nov 27 09:05:17 2018
From: dmorissette at mapgears.com (Daniel Morissette)
Date: Tue, 27 Nov 2018 12:05:17 -0500
Subject: [gdal-dev] Early GDAL 2.4.0 release ?
In-Reply-To: <3480702.ZBnXc4afsm@even-i700>
References: <3480702.ZBnXc4afsm@even-i700>
Message-ID: <e2488400-5879-b17f-fe30-53f589286789@mapgears.com>

+1 for me. I like your plan.

Daniel


On 2018-11-27 11:59 a.m., Even Rouault wrote:
> Hi,
> 
> I've been considering an early GDAL 2.4.0 release for the end of this year
> instead of the traditionnal mid-April / May target.
> 
> The rationale is that the work related to the GDAL/PROJ SRS revamp effort (aka
> "GDAL barn": https://gdalbarn.com/) will probably require non-null integration
> work from GDAL users, which will unnecessarily delay the "time-to-market" of
> features currently in GDAL master.
> 
> I've just began integrating the PROJ changes in a GDAL branch of mine and the
> current and future changes can be classified in the following categories:
> - for sure: behaviour changes. exportToWKT() / exportToProj4() will for
> example return different strings. Most of the time equivalent, but nonetheless
> different, which can break other software unit tests
> - probable: some OGRSpatialReference methods / OSR functions might be removed,
> or become no-operation
> - uncertain at this point: impact of being axis order and unit compliant with
> the CRS definition from the authority.
> 
> I'd like the GDAL 2.5.0 release that will integrate the GDAL barn work to
> still be scheduled for mid-April / May date, and with my branch being
> hopefully ready for being merged into master in January.
> 
> A temptative schedule for 2.4.0 might be:
> 
> - December 14th: GDAL 2.4.0RC1 (I believe master is mature enough to go to RC
> stage directly, with no/very few changes affecting backward compatibility, but
> this is just from memory. The updated NEWS would help to confirm, but creating
> it is the bulk of the release work), likely coupled with a GDAL 2.3.3RC1 that
> would be the final point release for the GDAL 2.3 series
> 
> - December 21th: GDAL 2.4.0final
> 
> Thoughts ? Ah, and the release manager role is still open for volunteers (or
> any help, particularly updating NEWS, would be appreciated)
> 
> Even
> 


-- 
Daniel Morissette
Mapgears Inc
T: +1 418-696-5056 #201

From landa.martin at gmail.com  Tue Nov 27 11:32:42 2018
From: landa.martin at gmail.com (Martin Landa)
Date: Tue, 27 Nov 2018 20:32:42 +0100
Subject: [gdal-dev] Early GDAL 2.4.0 release ?
In-Reply-To: <e2488400-5879-b17f-fe30-53f589286789@mapgears.com>
References: <3480702.ZBnXc4afsm@even-i700>
 <e2488400-5879-b17f-fe30-53f589286789@mapgears.com>
Message-ID: <CA+Ei1OfjinJN4H-jPBUifP6iOTLHR58TH2uO7=jX_Ybi7rrMMQ@mail.gmail.com>

Hi,

út 27. 11. 2018 v 18:12 odesílatel Daniel Morissette
<dmorissette at mapgears.com> napsal:
> +1 for me. I like your plan.

make sense to me

+1

Martin

-- 
Martin Landa
http://geo.fsv.cvut.cz/gwiki/Landa
http://gismentors.cz/mentors/landa

From sean at mapbox.com  Tue Nov 27 13:24:11 2018
From: sean at mapbox.com (Sean Gillies)
Date: Tue, 27 Nov 2018 14:24:11 -0700
Subject: [gdal-dev] Early GDAL 2.4.0 release ?
In-Reply-To: <3480702.ZBnXc4afsm@even-i700>
References: <3480702.ZBnXc4afsm@even-i700>
Message-ID: <CADPhZXxWRehpxt2yRPbYJm51wpqNBw8RFXfNs_w=M3CR-8A2cw@mail.gmail.com>

Hi Even,

Many of the tasks in
https://github.com/OSGeo/gdal/edit/master/gdal/HOWTO-RELEASE are beyond me
(looks like it needs root on the osgeo server and Maven knowledge) but I
signed myself up for writing the NEWS file in
https://github.com/OSGeo/gdal/issues/1119.


On Tue, Nov 27, 2018 at 10:00 AM Even Rouault <even.rouault at spatialys.com>
wrote:

> Hi,
>
> I've been considering an early GDAL 2.4.0 release for the end of this year
> instead of the traditionnal mid-April / May target.
>
> The rationale is that the work related to the GDAL/PROJ SRS revamp effort
> (aka
> "GDAL barn": https://gdalbarn.com/) will probably require non-null
> integration
> work from GDAL users, which will unnecessarily delay the "time-to-market"
> of
> features currently in GDAL master.
>
> I've just began integrating the PROJ changes in a GDAL branch of mine and
> the
> current and future changes can be classified in the following categories:
> - for sure: behaviour changes. exportToWKT() / exportToProj4() will for
> example return different strings. Most of the time equivalent, but
> nonetheless
> different, which can break other software unit tests
> - probable: some OGRSpatialReference methods / OSR functions might be
> removed,
> or become no-operation
> - uncertain at this point: impact of being axis order and unit compliant
> with
> the CRS definition from the authority.
>
> I'd like the GDAL 2.5.0 release that will integrate the GDAL barn work to
> still be scheduled for mid-April / May date, and with my branch being
> hopefully ready for being merged into master in January.
>
> A temptative schedule for 2.4.0 might be:
>
> - December 14th: GDAL 2.4.0RC1 (I believe master is mature enough to go to
> RC
> stage directly, with no/very few changes affecting backward compatibility,
> but
> this is just from memory. The updated NEWS would help to confirm, but
> creating
> it is the bulk of the release work), likely coupled with a GDAL 2.3.3RC1
> that
> would be the final point release for the GDAL 2.3 series
>
> - December 21th: GDAL 2.4.0final
>
> Thoughts ? Ah, and the release manager role is still open for volunteers
> (or
> any help, particularly updating NEWS, would be appreciated)
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Sean Gillies
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181127/30e5dd84/attachment.html>

From zazhil_ha at hotmail.com  Tue Nov 27 14:44:29 2018
From: zazhil_ha at hotmail.com (ZAZHIL-HA HERENA)
Date: Tue, 27 Nov 2018 22:44:29 +0000
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <CAD5SdwKS6K9DZxFy=G0ftwq5JSj49G67mwZDy4_5VhwKAiQ04g@mail.gmail.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
 <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>
 <2403916.OSkJQ3OgpL@even-i700>
 <BYAPR07MB4231F1245AF652E84FD66F9E95D40@BYAPR07MB4231.namprd07.prod.outlook.com>,
 <CAD5SdwKS6K9DZxFy=G0ftwq5JSj49G67mwZDy4_5VhwKAiQ04g@mail.gmail.com>
Message-ID: <BYAPR07MB4231F97B1D2C39E1911BDBDC95D00@BYAPR07MB4231.namprd07.prod.outlook.com>

Hi there,

Thanks everybody for your valuable help, with your suggestions I finally got it working in my cluster with Cloudera 6 distribution(Hadoop 3) with Java, I would like to list here a few things I had to do to make it work since I used Cloudera to compile:


  *   In Cloudera, Hadoop libraries are under $CLOUDERA_PATH/lib/hadoop so this is the path I use for ./configure in --with-hdfs
  *   Then ./configure is looking for  a file include/hdfs.h , this directory in Cloudera exists in different path (outside Hadoop) $CLOUDERA_PATH/include, so I had to copy it under Hadoop path.
  *   Same for libhdfs.so , make expects to find it in lib/native/libhdfs.so, for Cloudera it is in $CLOUDERA_PATH/lib64 , so I just copied it to the expected location.

I tested using command line and also my Java application and /vsihdfs/ works as expected.

Thanks!!!
Zazhil-ha
________________________________
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> on behalf of James McClain <james.mcclain at gmail.com>
Sent: Friday, November 23, 2018 3:18 PM
To: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] Question on how to open a raster in HDFS using GDAL

Hello,

It may not be finding the native HDFS libraries.  Please see the pull request https://github.com/OSGeo/gdal/pull/714 for build instructions (in particular, you may need to augment the LD_LIBRARY_PATH environment variable).

If trouble persists, I would suggest building against Apache Hadoop 2.7.6 or 2.7.7 (both of those are know to work) as an experiment.

Sincerely,
James McClian

On Fri, Nov 23, 2018 at 2:15 PM ZAZHIL-HA HERENA <zazhil_ha at hotmail.com<mailto:zazhil_ha at hotmail.com>> wrote:
Thank you so much!, now I am working on 2.4 source code but I am getting an error when trying to configure using:

./configure --prefix=/scratch/zherena/gdal/build/gdal-master/gdal/outputb/ --with-complete=yes --with-java=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/ --with-swig-java=yes --with-hdfs=/scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/ --with-curl=/usr/bin/curl-config

The error I get is:

      checking for HDFS in /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/... checking for hdfsConnect in -lhdfs... no
      checking for /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678//include/hdfs.h... yes
      configure: error: HDFS support not enabled.


Is there any configuration in my environment that I should consider? or maybe another distribution of Hadoop?


________________________________
From: Even Rouault <even.rouault at spatialys.com<mailto:even.rouault at spatialys.com>>
Sent: Friday, November 23, 2018 11:52 AM
To: gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
Cc: ZAZHIL-HA HERENA; James McClain; nik at nikosalexandris.net<mailto:nik at nikosalexandris.net>
Subject: Re: [gdal-dev] Question on how to open a raster in HDFS using GDAL

> Version says 2.3.2 but libraries say: libgdal.so.20.4.2 .

Libtool number (.so.20.4.2) has nothing to do with user-friendly version
number (2.3.2)

> I am not sure if I
> got the latest code, this is the first time I compile it myself, I used
> this link to download source code:
> http://download.osgeo.org/gdal/CURRENT/gdal-2.3.2.tar.gz

This is the latest release, but /vsihdfs/ is in the development version, not
yet released, so download

https://github.com/OSGeo/gdal/archive/master.zip

--
Spatialys - Geospatial professional services
http://www.spatialys.com


--
"I prayed for freedom for twenty years, but received no answer until I prayed with my legs."
     -- Frederick Douglass

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181127/998625d3/attachment.html>

From james.mcclain at gmail.com  Tue Nov 27 14:47:13 2018
From: james.mcclain at gmail.com (James McClain)
Date: Tue, 27 Nov 2018 17:47:13 -0500
Subject: [gdal-dev] Question on how to open a raster in HDFS using GDAL
In-Reply-To: <BYAPR07MB4231F97B1D2C39E1911BDBDC95D00@BYAPR07MB4231.namprd07.prod.outlook.com>
References: <BYAPR07MB4231E69CA5F7EF8E171BB6DE95DB0@BYAPR07MB4231.namprd07.prod.outlook.com>
 <CAD5SdwLUyhmJXRFWbhwUtRAx0aFmBhp1fixhciXa+J2jdFVJVQ@mail.gmail.com>
 <BYAPR07MB4231F362D054090E03C23E3195D40@BYAPR07MB4231.namprd07.prod.outlook.com>
 <2403916.OSkJQ3OgpL@even-i700>
 <BYAPR07MB4231F1245AF652E84FD66F9E95D40@BYAPR07MB4231.namprd07.prod.outlook.com>
 <CAD5SdwKS6K9DZxFy=G0ftwq5JSj49G67mwZDy4_5VhwKAiQ04g@mail.gmail.com>
 <BYAPR07MB4231F97B1D2C39E1911BDBDC95D00@BYAPR07MB4231.namprd07.prod.outlook.com>
Message-ID: <CAD5SdwJtrJB=ExgYLvwi-mLA2S5K-xXwNcQBRH8Pkuzh6svCmg@mail.gmail.com>

You are very welcome, thank you for the report!

On Tue, Nov 27, 2018 at 5:44 PM ZAZHIL-HA HERENA <zazhil_ha at hotmail.com>
wrote:

> Hi there,
>
> Thanks everybody for your valuable help, with your suggestions I finally
> got it working in my cluster with Cloudera 6 distribution(Hadoop 3) with
> Java, I would like to list here a few things I had to do to make it work
> since I used Cloudera to compile:
>
>
>    - In Cloudera, Hadoop libraries are under $CLOUDERA_PATH/lib/hadoop so
>    this is the path I use for ./configure in --with-hdfs
>    - Then* ./configure* is looking for  a file *include/hdfs.h* , this
>    directory in Cloudera exists in different path (outside Hadoop)
>    $CLOUDERA_PATH/include, so I had to copy it under Hadoop path.
>    - Same for libhdfs.so , *make* expects to find it in
>    *lib/native/libhdfs.so*, for Cloudera it is in $CLOUDERA_PATH/lib64 ,
>    so I just copied it to the expected location.
>
>
> I tested using command line and also my Java application and /vsihdfs/
> works as expected.
>
> Thanks!!!
> Zazhil-ha
> ------------------------------
> *From:* gdal-dev <gdal-dev-bounces at lists.osgeo.org> on behalf of James
> McClain <james.mcclain at gmail.com>
> *Sent:* Friday, November 23, 2018 3:18 PM
> *To:* gdal-dev at lists.osgeo.org
> *Subject:* Re: [gdal-dev] Question on how to open a raster in HDFS using
> GDAL
>
> Hello,
>
> It may not be finding the native HDFS libraries.  Please see the pull
> request https://github.com/OSGeo/gdal/pull/714 for build instructions (in
> particular, you may need to augment the LD_LIBRARY_PATH environment
> variable).
>
> If trouble persists, I would suggest building against Apache Hadoop 2.7.6
> or 2.7.7 (both of those are know to work) as an experiment.
>
> Sincerely,
> James McClian
>
> On Fri, Nov 23, 2018 at 2:15 PM ZAZHIL-HA HERENA <zazhil_ha at hotmail.com>
> wrote:
>
> Thank you so much!, now I am working on 2.4 source code but I am getting
> an error when trying to configure using:
>
> *./configure
> --prefix=/scratch/zherena/gdal/build/gdal-master/gdal/outputb/
> --with-complete=yes
> --with-java=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/
> --with-swig-java=yes
> --with-hdfs=/scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/
> --with-curl=/usr/bin/curl-config*
>
> The error I get is:
>
>
> *      checking for HDFS in
> /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678/... checking for
> hdfsConnect in -lhdfs... no *
>
> *      checking for
> /scratch/zherena/gdal/CDH-6.0.1-1.cdh6.0.1.p0.590678//include/hdfs.h... yes
> *
> *      configure: error: HDFS support not enabled.*
>
>
> Is there any configuration in my environment that I should consider? or
> maybe another distribution of Hadoop?
>
>
> ------------------------------
> *From:* Even Rouault <even.rouault at spatialys.com>
> *Sent:* Friday, November 23, 2018 11:52 AM
> *To:* gdal-dev at lists.osgeo.org
> *Cc:* ZAZHIL-HA HERENA; James McClain; nik at nikosalexandris.net
> *Subject:* Re: [gdal-dev] Question on how to open a raster in HDFS using
> GDAL
>
> > Version says 2.3.2 but libraries say: libgdal.so.20.4.2 .
>
> Libtool number (.so.20.4.2) has nothing to do with user-friendly version
> number (2.3.2)
>
> > I am not sure if I
> > got the latest code, this is the first time I compile it myself, I used
> > this link to download source code:
> > http://download.osgeo.org/gdal/CURRENT/gdal-2.3.2.tar.gz
>
> This is the latest release, but /vsihdfs/ is in the development version,
> not
> yet released, so download
>
> https://github.com/OSGeo/gdal/archive/master.zip
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
>
>
> --
> "I prayed for freedom for twenty years, but received no answer until I
> prayed with my legs."
>      -- Frederick Douglass
>
>

-- 
"I prayed for freedom for twenty years, but received no answer until I
prayed with my legs."
     -- Frederick Douglass
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181127/23bf2f77/attachment-0001.html>

From TimBodin at comcast.net  Tue Nov 27 20:28:40 2018
From: TimBodin at comcast.net (timbo1711)
Date: Tue, 27 Nov 2018 21:28:40 -0700 (MST)
Subject: [gdal-dev] windows install - best practices? install from
 source, or from precompiled binaries?
In-Reply-To: <005501d482ea$aeaeb3b0$0c0c1b10$@comcast.net>
References: <005501d482ea$aeaeb3b0$0c0c1b10$@comcast.net>
Message-ID: <1543379320128-0.post@n6.nabble.com>

Anyone have a chance to read this and give me a few tips please?



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From robert.coup at koordinates.com  Wed Nov 28 15:25:42 2018
From: robert.coup at koordinates.com (Robert Coup)
Date: Wed, 28 Nov 2018 23:25:42 +0000
Subject: [gdal-dev] Early GDAL 2.4.0 release ?
In-Reply-To: <3480702.ZBnXc4afsm@even-i700>
References: <3480702.ZBnXc4afsm@even-i700>
Message-ID: <CAFLLRpJ=gGq2_Or3vi=vdcTgYgzxe2ACC6n5pafZBbZenoXMGA@mail.gmail.com>

Hi Even,

Would be great to get Craig's pytest revamp (
https://github.com/OSGeo/gdal/pull/963) landed for 2.4 so the old unit
tests can die a quiet death in the 2.3 branch. Otherwise backporting tests
to 2.4 will be a struggle.

Feels like it’s very nearly ready though, so your timeline should work.

Rob :)



On Tue, 27 Nov 2018 at 17:00, Even Rouault <even.rouault at spatialys.com>
wrote:

> Hi,
>
> I've been considering an early GDAL 2.4.0 release for the end of this year
> instead of the traditionnal mid-April / May target.
>
> The rationale is that the work related to the GDAL/PROJ SRS revamp effort
> (aka
> "GDAL barn": https://gdalbarn.com/) will probably require non-null
> integration
> work from GDAL users, which will unnecessarily delay the "time-to-market"
> of
> features currently in GDAL master.
>
> I've just began integrating the PROJ changes in a GDAL branch of mine and
> the
> current and future changes can be classified in the following categories:
> - for sure: behaviour changes. exportToWKT() / exportToProj4() will for
> example return different strings. Most of the time equivalent, but
> nonetheless
> different, which can break other software unit tests
> - probable: some OGRSpatialReference methods / OSR functions might be
> removed,
> or become no-operation
> - uncertain at this point: impact of being axis order and unit compliant
> with
> the CRS definition from the authority.
>
> I'd like the GDAL 2.5.0 release that will integrate the GDAL barn work to
> still be scheduled for mid-April / May date, and with my branch being
> hopefully ready for being merged into master in January.
>
> A temptative schedule for 2.4.0 might be:
>
> - December 14th: GDAL 2.4.0RC1 (I believe master is mature enough to go to
> RC
> stage directly, with no/very few changes affecting backward compatibility,
> but
> this is just from memory. The updated NEWS would help to confirm, but
> creating
> it is the bulk of the release work), likely coupled with a GDAL 2.3.3RC1
> that
> would be the final point release for the GDAL 2.3 series
>
> - December 21th: GDAL 2.4.0final
>
> Thoughts ? Ah, and the release manager role is still open for volunteers
> (or
> any help, particularly updating NEWS, would be appreciated)
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 

Chief Technology Officer Koordinates

+44 759 987 3480 <+44%20759%209873480> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-- 

Chief Technology Officer Koordinates

+44 759 987 3480 <+44%20759%209873480> / koordinates.com / @koordinates
<https://twitter.com/koordinates>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181128/9718daf9/attachment.html>

From sethg at geographika.co.uk  Thu Nov 29 00:56:28 2018
From: sethg at geographika.co.uk (Seth G)
Date: Thu, 29 Nov 2018 09:56:28 +0100
Subject: [gdal-dev] ogr2ogr skipfailures and sqlite missing indexes
Message-ID: <1543481788.4159824.1592838632.59D6D4AB@webmail.messagingengine.com>

Hi all,

When running a command similar to below (GDAL 2.3.1 on Windows):

ogr2ogr -f "SQLite" test.db test.shp -skipfailures -dsco SPATIALITE=YES -lco SPATIAL_INDEX=YES

If there are any errors (e.g. a MULTILINESTRING in a LINESTRING dataset), ogr2ogr skips the errors, but also skips creating the spatial index in SQLite. It took awhile to find why certain spatial queries weren't bringing back results later on. 

Is there any reason to not create the spatial index anyway? If not a warning message as part of the output would be useful. 
I got around the issue by adding the "-nlt GEOMETRY" parameter.

Regards,

Seth

--
web:http://geographika.co.uk
twitter: @geographika

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov 29 01:36:04 2018
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Thu, 29 Nov 2018 09:36:04 +0000
Subject: [gdal-dev] Issue with validate_gpkg.py
Message-ID: <d9efb965dce84c0e81803fe55fa3dcd9@C119S212VM042.msvyvi.vaha.local>

Hi,

I try to run validate_gpkg.py that I downloaded today from GitHub. I run it under OSGeo4W installation on Windows, GDAL version GDAL 2.3.2, released 2018/09/21, and Python version Python 2.7.14.

Validation stops at this error message:

Traceback (most recent call last):
  File "validate_gpkg.py", line 1611, in <module>
    verbose=verbose)
  File "validate_gpkg.py", line 1578, in check
    checker.check()
  File "validate_gpkg.py", line 1555, in check
    self._check_features(c)
  File "validate_gpkg.py", line 596, in _check_features
    self._check_vector_user_table(c, table_name)
  File "validate_gpkg.py", line 367, in _check_vector_user_table
    self._assert(_is_valid_data_type(typ), 5,
  File "validate_gpkg.py", line 59, in _is_valid_data_type
    type.startswith('TEXT(') or type.startswith('BLOB(')
AttributeError: type object 'type' has no attribute 'startswith'

Is there something that a user can do for making the script to run?

-Jukka Rahkonen-
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181129/523c46b6/attachment.html>

From bradh at frogmouth.net  Thu Nov 29 01:43:13 2018
From: bradh at frogmouth.net (bradh at frogmouth.net)
Date: Thu, 29 Nov 2018 20:43:13 +1100
Subject: [gdal-dev] Issue with validate_gpkg.py
In-Reply-To: <d9efb965dce84c0e81803fe55fa3dcd9@C119S212VM042.msvyvi.vaha.local>
References: <d9efb965dce84c0e81803fe55fa3dcd9@C119S212VM042.msvyvi.vaha.local>
Message-ID: <003601d487c7$f27b1020$d7713060$@frogmouth.net>

Looks like (line 59)
type.startswith('TEXT(') or type.startswith('BLOB(')

Should be 

typ.startswith('TEXT(') or typ.startswith('BLOB(')

 

(i.e. remove the two "e" characters)

 

Brad

 

From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Rahkonen
Jukka (MML)
Sent: Thursday, 29 November 2018 8:36 PM
To: 'gdal-dev at lists.osgeo.org' (gdal-dev at lists.osgeo.org)
<gdal-dev at lists.osgeo.org>
Subject: [gdal-dev] Issue with validate_gpkg.py

 

Hi,

 

I try to run validate_gpkg.py that I downloaded today from GitHub. I run it
under OSGeo4W installation on Windows, GDAL version GDAL 2.3.2, released
2018/09/21, and Python version Python 2.7.14.

 

Validation stops at this error message:

 

Traceback (most recent call last):

  File "validate_gpkg.py", line 1611, in <module>

    verbose=verbose)

  File "validate_gpkg.py", line 1578, in check

    checker.check()

  File "validate_gpkg.py", line 1555, in check

    self._check_features(c)

  File "validate_gpkg.py", line 596, in _check_features

    self._check_vector_user_table(c, table_name)

  File "validate_gpkg.py", line 367, in _check_vector_user_table

    self._assert(_is_valid_data_type(typ), 5,

  File "validate_gpkg.py", line 59, in _is_valid_data_type

    type.startswith('TEXT(') or type.startswith('BLOB(')

AttributeError: type object 'type' has no attribute 'startswith'

 

Is there something that a user can do for making the script to run?

 

-Jukka Rahkonen-

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181129/5a0b074a/attachment-0001.html>

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov 29 01:48:41 2018
From: jukka.rahkonen at maanmittauslaitos.fi (Rahkonen Jukka (MML))
Date: Thu, 29 Nov 2018 09:48:41 +0000
Subject: [gdal-dev] Issue with validate_gpkg.py
Message-ID: <c71555aa3fa94ffa8d6791c0809d3c8f@C119S212VM042.msvyvi.vaha.local>

Thanks Brad, works after those edits and gives me an occasion to have a try with a pull request!

-Jukka-

Lähettäjä: bradh at frogmouth.net [mailto:bradh at frogmouth.net]
Lähetetty: 29. marraskuuta 2018 11:43
Vastaanottaja: Rahkonen Jukka (MML) <jukka.rahkonen at maanmittauslaitos.fi>; gdal-dev at lists.osgeo.org
Aihe: RE: [gdal-dev] Issue with validate_gpkg.py

Looks like (line 59)
type.startswith('TEXT(') or type.startswith('BLOB(')
Should be
typ.startswith('TEXT(') or typ.startswith('BLOB(')

(i.e. remove the two "e" characters)

Brad

From: gdal-dev <gdal-dev-bounces at lists.osgeo.org<mailto:gdal-dev-bounces at lists.osgeo.org>> On Behalf Of Rahkonen Jukka (MML)
Sent: Thursday, 29 November 2018 8:36 PM
To: 'gdal-dev at lists.osgeo.org' (gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>) <gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>>
Subject: [gdal-dev] Issue with validate_gpkg.py

Hi,

I try to run validate_gpkg.py that I downloaded today from GitHub. I run it under OSGeo4W installation on Windows, GDAL version GDAL 2.3.2, released 2018/09/21, and Python version Python 2.7.14.

Validation stops at this error message:

Traceback (most recent call last):
  File "validate_gpkg.py", line 1611, in <module>
    verbose=verbose)
  File "validate_gpkg.py", line 1578, in check
    checker.check()
  File "validate_gpkg.py", line 1555, in check
    self._check_features(c)
  File "validate_gpkg.py", line 596, in _check_features
    self._check_vector_user_table(c, table_name)
  File "validate_gpkg.py", line 367, in _check_vector_user_table
    self._assert(_is_valid_data_type(typ), 5,
  File "validate_gpkg.py", line 59, in _is_valid_data_type
    type.startswith('TEXT(') or type.startswith('BLOB(')
AttributeError: type object 'type' has no attribute 'startswith'

Is there something that a user can do for making the script to run?

-Jukka Rahkonen-
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181129/1eb6863c/attachment.html>

From even.rouault at spatialys.com  Thu Nov 29 02:57:48 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 29 Nov 2018 11:57:48 +0100
Subject: [gdal-dev] ogr2ogr skipfailures and sqlite missing indexes
In-Reply-To: <1543481788.4159824.1592838632.59D6D4AB@webmail.messagingengine.com>
References: <1543481788.4159824.1592838632.59D6D4AB@webmail.messagingengine.com>
Message-ID: <3295737.r9dNOHWq69@even-i700>

On jeudi 29 novembre 2018 09:56:28 CET Seth G wrote:
> Hi all,
> 
> When running a command similar to below (GDAL 2.3.1 on Windows):
> 
> ogr2ogr -f "SQLite" test.db test.shp -skipfailures -dsco SPATIALITE=YES -lco
> SPATIAL_INDEX=YES
> 
> If there are any errors (e.g. a MULTILINESTRING in a LINESTRING dataset),
> ogr2ogr skips the errors, but also skips creating the spatial index in
> SQLite. It took awhile to find why certain spatial queries weren't bringing
> back results later on.

Fixed. Thanks

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sethg at geographika.co.uk  Thu Nov 29 03:33:28 2018
From: sethg at geographika.co.uk (Seth G)
Date: Thu, 29 Nov 2018 12:33:28 +0100
Subject: [gdal-dev] ogr2ogr skipfailures and sqlite missing indexes
In-Reply-To: <3295737.r9dNOHWq69@even-i700>
References: <1543481788.4159824.1592838632.59D6D4AB@webmail.messagingengine.com>
 <3295737.r9dNOHWq69@even-i700>
Message-ID: <1543491208.5878.1592980968.01D798C6@webmail.messagingengine.com>

Excellent - thanks for the incredibly fast fix Even - wasn't expecting that!

Seth

--
web:http://geographika.co.uk
twitter: @geographika

On Thu, Nov 29, 2018, at 11:57 AM, Even Rouault wrote:
> On jeudi 29 novembre 2018 09:56:28 CET Seth G wrote:
> > Hi all,
> > 
> > When running a command similar to below (GDAL 2.3.1 on Windows):
> > 
> > ogr2ogr -f "SQLite" test.db test.shp -skipfailures -dsco SPATIALITE=YES -lco
> > SPATIAL_INDEX=YES
> > 
> > If there are any errors (e.g. a MULTILINESTRING in a LINESTRING dataset),
> > ogr2ogr skips the errors, but also skips creating the spatial index in
> > SQLite. It took awhile to find why certain spatial queries weren't bringing
> > back results later on.
> 
> Fixed. Thanks
> 
> Even
> 
> -- 
> Spatialys - Geospatial professional services
> http://www.spatialys.com

From guyd at satellogic.com  Thu Nov 29 03:34:50 2018
From: guyd at satellogic.com (Guy Doulberg)
Date: Thu, 29 Nov 2018 13:34:50 +0200
Subject: [gdal-dev] VRT, how should I create overviews on the mask
Message-ID: <CAJ18MZo4uBTnj0-jiOngeaUonmXpeayXwOVdkawJqAUGGY3D0A@mail.gmail.com>

Hi guys

I am using a VRT in front of many geotif rasters, the size of the vrt could
be in thousands

I am using gdaladdo on that vrt to per-calculate overviews, and I get an
ovr file.

In the orginal vrt file I have also definition of a mask, basically each of
the origin files has mask, so I am using the mask from the original geotiff
files

gdalinfo on the vrt:

Band 1 Block=128x128 Type=UInt16, ColorInterp=Gray
  Overviews: 4096x6144, 2048x3072, 1024x1536, 512x768, 256x384, 128x192
  Mask Flags: PER_DATASET


gdalinfo of the ovr file:

Band 1 Block=128x128 Type=UInt16, ColorInterp=Gray
  Overviews: 2048x3072, 1024x1536, 512x768, 256x384, 128x192


So it seems like there are no overviews on top of the mask, and when trying
to fetch the mask I can see that each of the original tifs is being
accessed,
this is not the case if I don't read the mask

So my question is, is there a way to create overviews with mask and when
accessing a vrt that has overviews on mask to use the overviews on mask?

Thanks, Guy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181129/f385188a/attachment.html>

From jukka.rahkonen at maanmittauslaitos.fi  Thu Nov 29 04:09:02 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Thu, 29 Nov 2018 05:09:02 -0700 (MST)
Subject: [gdal-dev] ogr2ogr skipfailures and sqlite missing indexes
In-Reply-To: <1543491208.5878.1592980968.01D798C6@webmail.messagingengine.com>
References: <1543481788.4159824.1592838632.59D6D4AB@webmail.messagingengine.com>
 <3295737.r9dNOHWq69@even-i700>
 <1543491208.5878.1592980968.01D798C6@webmail.messagingengine.com>
Message-ID: <1543493342603-0.post@n6.nabble.com>

Hi Seth,

Even if the creation of spatial index with -skipfeatures is now fixed,
generally that is a thing that should not really be used with GeoPackage and
SQLite/Spatialite. That leads to single-row transactions and very poor
performance. 
There are usually other ways to avoid the problems and still keep large
transactions. You already used "-nlt GEOMETRY" (I would have used "-nlt
PROMOTE_TO_MULTI"), invalid geometries can be skipped with SQL (-sql "select
* from my_layer where ST_IsValid(my_geometry)=1"), geometry collections can
be skipped with SQL and so on. Fixing the data before conversion is the
solution I prefer if I have time for that.

-Jukka Rahkonen-


Seth G-2 wrote
> Excellent - thanks for the incredibly fast fix Even - wasn't expecting
> that!
> 
> Seth





--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From mdsumner at gmail.com  Thu Nov 29 12:31:26 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 30 Nov 2018 07:31:26 +1100
Subject: [gdal-dev] HDF data mis-applied sinusoidal
Message-ID: <CAAcGz9_umSEvWaAgFJZd0qsDn43w_eVYDSwSx=AQwJXtO6bfEg@mail.gmail.com>

Hello, these data in HDF4 format are interpreted as being in sinusoidal
projection, I guess some conflation with the MODIS logic about some
products (?).

ftp://ftp.glcf.umd.edu/glcf/GLASS/ABD/MODIS/0.05D/2013/

Particular file is here, but note there's also an auxiliarly .hdf.xml with
it:
ftp://ftp.glcf.umd.edu/glcf/GLASS/ABD/MODIS/0.05D/2013/GLASS02B06.V04.A2013169.2017128.hdf

A plot of the first subdataset shows that it is trivially in regular
longlat (or eqc), the gdalinfo output is below.

I'd appreciate any insights into why this is interpreted this way, and
whether the GDAL detection logic could be improved - or whether the data
providers need to update the internal metadata.

Cheers, Mike.

gdalinfo --version GDAL 2.3.2, released 2018/09/21

gdalinfo
HDF4_EOS:EOS_GRID:"GLASS02B06.V04.A2013169.2017128.hdf":GLASS02B06:ABD_BSA_VIS
Driver: HDF4Image/HDF4 Dataset
Files: GLASS02B06.V04.A2013169.2017128.hdf
Size is 7200, 3600
Coordinate System is:
PROJCS["unnamed",
    GEOGCS["Unknown datum based upon the custom spheroid",
        DATUM["Not specified (based on custom spheroid)",
            SPHEROID["Custom spheroid",6371007.181,0]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433]],
    PROJECTION["Sinusoidal"],
    PARAMETER["longitude_of_center",0],
    PARAMETER["false_easting",0],
    PARAMETER["false_northing",0],
    UNIT["Meter",1]]
Origin = (-20015109.353999998420477,10007554.676999999210238)
Pixel Size = (154.437572175972150,-308.875144351944300)
Metadata:
  add_offset=0
  add_offset_err=0
  ASSOCIATEDINSTRUMENTSHORTNAME.1=AVHRR
  ASSOCIATEDPLATFORMSHORTNAME.1=NOAA
  ASSOCIATEDSENSORSHORTNAME.1=AVHRR
  BANDDEFINITION=Surface
  CHARACTERISTICBINSIZE=926.6
  DATACOLUMNS=7200
  DATAROWS=3600
  DATASETNAME=GLASS02B06
  DAYNIGHTFLAG=Both
  EASTHBOUNDINGCOORDINATE=180
  EXCLUSIONGRINGFLAG=N
  GLOBALGRIDCOLUMNS=7200
  GLOBALGRIDROWS=3600
  GRIDTYPE=Geographic Lat/Lon
  GRINGPOINTLATITUDE.1=90,90,-90,-90
  GRINGPOINTLONGITUDE.1=-180,180,180,-180
  GRINGPOINTSEQUENCENO.1=1,2,3,4
  HDFEOSVersion=HDFEOS_V2.16
  HORIZONTALTILENUMBER=00
  HORIZONTALTILENUMBER=00
  INPUTFILESNAME=Multi-Source Data
  INPUTPOINTER=Multi-Source Data
  INSTITUTENAME=BEIJING
  LOCALGRANULEID=GLASS02B06.V04.A2013169.2017128.hdf
  LOCALVERSIONID=V04
  long_name=Black-sky Albedo in Visible band
  NORTHBOUNDINGCOORDINATE=90
  PARAMETERNAME.1=GLASS02B06
  PGEVERSION=V04
  PROCESSINGENVIRONMENT=High Performance Computing System
  PRODUCTDATEANDTIME=2017-05-08 16:00:12
  PRODUCTIONDATETIME=2017-05-08 16:00:12
  PRODUCTNAME=Surface
  PRODUCTQUALITY=CLOUDREMOVED
  REPROCESSINGACTUAL=reprocessed
  REPROCESSINGPLANNED=further update is anticipated
  scale_factor=0.0001
  scale_factor_err=0
  SHORTNAME=GLASS02B06
  SOUTHBOUNDINGCOORDINATE=-90
  TILENUMBER=H00V00
  units=Albedo,no units
  valid_range=0, 10000
  VERSIONID=1
  VERTICALTILENUMBER=00
  VERTICALTILENUMBER=00
  WEBSITE=http://glass-product.bnu.edu.cn
  WESTHBOUNDINGCOORDINATE=-180
  _FillValue=-1
Corner Coordinates:
Upper Left  (-20015109.354,10007554.677) (124d17'29.21"W, 90d 0' 0.00"N)
Lower Left  (-20015109.354, 8895604.157) ( 43d25'16.73"E, 80d 0' 0.00"N)
Upper Right (-18903158.834,10007554.677) ( 77d21'53.56"W, 90d 0' 0.00"N)
Lower Right (-18903158.834, 8895604.157) (101d 0'32.47"E, 80d 0' 0.00"N)
Center      (-19459134.094, 9451579.417) (152d 6' 0.67"E, 85d 0' 0.00"N)
Band 1 Block=7200x3600 Type=Int16, ColorInterp=Gray
  Description = Black-sky Albedo in Visible band
  NoData Value=-1
  Unit Type: Albedo,no units
  Offset: 0,   Scale:
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181130/b158979f/attachment.html>

From Peter.Marlow at scisys.co.uk  Fri Nov 30 02:12:30 2018
From: Peter.Marlow at scisys.co.uk (Peter Marlow)
Date: Fri, 30 Nov 2018 10:12:30 +0000
Subject: [gdal-dev] Import Shapefile into SQL Server on Ubuntu
In-Reply-To: <CABUeae-HkmLg5umovn3Ei3czt02g1Ns=mw3taZOypLTNsEET6A@mail.gmail.com>
References: <AA48096CDCDA4745B245B6A21526D998400FD0AA@CITCH-MXEXCH1.scisys.co.uk>
 <CABUeae-HkmLg5umovn3Ei3czt02g1Ns=mw3taZOypLTNsEET6A@mail.gmail.com>
Message-ID: <AA48096CDCDA4745B245B6A21526D9984010DFFB@CITCH-MXEXCH1.scisys.co.uk>

I've had a bit of time to look at this again and I have got it working, I didn't rebuild GDAL myself though, just used a build that had ODBC support. I've listed the steps below in case anyone else finds them useful, they are as Mateusz suggested so thank you for your help!

Steps to connect to MS SQL Server using GDAL/ogr2ogr on Ubuntu 16.04:

--- Install GDAL (version with ODBC support)
sudo apt-get update
sudo apt-get install gdal-bin


--- Install unixodbc
sudo apt-get install unixodbc unixodbc-dev


--- Install Microsoft ODBC Driver 17 for SQL Server on Ubuntu 16.04 (see https://docs.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-2017)
sudo su
curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -
curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list
exit
sudo apt-get update
sudo ACCEPT_EULA=Y apt-get install msodbcsql17


--- Run ogr2ogr using driver
ogr2ogr -f MSSQLSpatial "MSSQL:server=[server];database=[database];uid=[username];Pwd=[password];Driver={ODBC Driver 17 for SQL Server}" [shape file]


Thanks,
Pete

-----Original Message-----
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Mateusz Loskot
Sent: 22 October 2018 16:31
To: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] Import Shapefile into SQL Server on Ubuntu

On Mon, 22 Oct 2018 at 17:25, Peter Marlow <Peter.Marlow at scisys.co.uk> wrote:
>
> I’m trying to import a Shapefile into an SQL Server database using ogr2ogr on Ubuntu. The command I’m running looks like:
>
> ogr2ogr -f MSSQLSpatial 
> "MSSQL:server=localhost;database=[database-name];username=sa;password=
> *****;trusted_connection=yes" [path-to-shape-file]
>
> It returns an error stating:
>
> ERROR 1: Unable to find driver `MSSQLSpatial'.

I guess, GDAL/OGR version you are using on Linux is not built with ODBC/SQL Server support.

> Is it possible to get the driver on linux? Or use an alternative driver? I’ve had a google and can’t seem to see any workarounds.
>
> The docs here (https://www.gdal.org/drv_mssqlspatial.html) talk about 
> specifying a Driver parameter that could be a custom SQL Server driver, however this is in the connection string and not as a parameter for the ogr2ogr command.

Once you get GDAL/OGR built with SQL Server, install ODBC Driver for SQL Server (there are clear docs on Microsoft site, you will find easily searching the web)

Then, try sticking the Driver option into the connection string Driver={ODBC Driver 11 for SQL Server} Driver={ODBC Driver 13 for SQL Server} Driver={ODBC Driver 13.1 for SQL Server} Driver={ODBC Driver 17 for SQL Server} depending which version you install.

Best regards,
--
Mateusz Loskot, http://mateusz.loskot.net _______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/gdal-dev


SCISYS UK Limited. Registered in England and Wales No. 4373530.
Registered Office: Methuen Park, Chippenham, Wiltshire SN14 0GB, UK.
 
Before printing, please think about the environment.


From sethg at geographika.co.uk  Fri Nov 30 03:47:29 2018
From: sethg at geographika.co.uk (Seth G)
Date: Fri, 30 Nov 2018 12:47:29 +0100
Subject: [gdal-dev] ogr2ogr skipfailures and sqlite missing indexes
In-Reply-To: <1543493342603-0.post@n6.nabble.com>
References: <1543481788.4159824.1592838632.59D6D4AB@webmail.messagingengine.com>
 <3295737.r9dNOHWq69@even-i700>
 <1543491208.5878.1592980968.01D798C6@webmail.messagingengine.com>
 <1543493342603-0.post@n6.nabble.com>
Message-ID: <1543578449.2543245.1594237048.155BC3BD@webmail.messagingengine.com>

Hi Jukka,

Thanks for the note about row by row inserts - this would explain the large performance difference. 
I'd agree it is best to filter out features explicitly. Sometimes -skipfeatures is just handy for having a quick look at the data though in a different format. 

The main issue was the results could be inconsistent - 4 datasets would be created with indexes and the 5th would not, with no warning or error. Then later on there could be a query in SQLite with a WHERE clause such as:

ogc_fid in (select rowid from SpatialIndex WHERE f_table_name = 'mydataset5' AND search_frame = ST_Buffer(p.Shape, 50)) 

Would cause no results would be returned, as there is no spatial index named 'mydataset5' (which appears to be a flaw in the suggested use of spatial indexes in Spatialite). The ogr2ogr fix avoids this case. 

Seth

--
web:http://geographika.co.uk
twitter: @geographika

On Thu, Nov 29, 2018, at 1:09 PM, jratike80 wrote:
> Hi Seth,
> 
> Even if the creation of spatial index with -skipfeatures is now fixed,
> generally that is a thing that should not really be used with GeoPackage and
> SQLite/Spatialite. That leads to single-row transactions and very poor
> performance. 
> There are usually other ways to avoid the problems and still keep large
> transactions. You already used "-nlt GEOMETRY" (I would have used "-nlt
> PROMOTE_TO_MULTI"), invalid geometries can be skipped with SQL (-sql "select
> * from my_layer where ST_IsValid(my_geometry)=1"), geometry collections can
> be skipped with SQL and so on. Fixing the data before conversion is the
> solution I prefer if I have time for that.
> 
> -Jukka Rahkonen-
> 
> 
> Seth G-2 wrote
> > Excellent - thanks for the incredibly fast fix Even - wasn't expecting
> > that!
> > 
> > Seth
> 
> 
> 
> 
> 
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

From bo.victor.thomsen at gmail.com  Fri Nov 30 06:12:43 2018
From: bo.victor.thomsen at gmail.com (Bo Victor Thomsen)
Date: Fri, 30 Nov 2018 15:12:43 +0100
Subject: [gdal-dev] Import Shapefile into SQL Server on Ubuntu
In-Reply-To: <AA48096CDCDA4745B245B6A21526D9984010DFFB@CITCH-MXEXCH1.scisys.co.uk>
References: <AA48096CDCDA4745B245B6A21526D998400FD0AA@CITCH-MXEXCH1.scisys.co.uk>
 <CABUeae-HkmLg5umovn3Ei3czt02g1Ns=mw3taZOypLTNsEET6A@mail.gmail.com>
 <AA48096CDCDA4745B245B6A21526D9984010DFFB@CITCH-MXEXCH1.scisys.co.uk>
Message-ID: <CAAJbAXuPuvmbHCxCjTnHUYNLkygzoP4UU6RvmuBS_apkSb=3_A@mail.gmail.com>

Hi Pete -

Your first take on the commandstring probably contains an error...

ogr2ogr -f MSSQLSpatial
"MSSQL:server=localhost;database=[database-name];username=sa;password=*****
*;trusted_connection=yes*" [path-to-shape-file]

You probably hasn't made the necessary setup with kerberos to use
"integrated security" (the  "*trusted_connection=yes*" part in the
connection string)

This command might have worked ( no trusted_connection parameter):
ogr2ogr -f
MSSQLSpatial  "MSSQL:server=localhost;database=[database-name];username=sa;password=*****"
[path-to-shape-file]

Your second take  doesn't contain the "trusted_connection" part
ogr2ogr -f MSSQLSpatial
"MSSQL:server=[server];database=[database];uid=[username];Pwd=[password];Driver={ODBC
Driver 17 for SQL Server}" [shape file]




> --- Run ogr2ogr using driver
> ogr2ogr -f MSSQLSpatial
> "MSSQL:server=[server];database=[database];uid=[username];Pwd=[password];Driver={ODBC
> Driver 17 for SQL Server}" [shape file]
>
>
> Thanks,
> Pete
>
> -----Original Message-----
> From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Mateusz
> Loskot
> Sent: 22 October 2018 16:31
> To: gdal-dev at lists.osgeo.org
> Subject: Re: [gdal-dev] Import Shapefile into SQL Server on Ubuntu
>
> On Mon, 22 Oct 2018 at 17:25, Peter Marlow <Peter.Marlow at scisys.co.uk>
> wrote:
> >
> > I’m trying to import a Shapefile into an SQL Server database using
> ogr2ogr on Ubuntu. The command I’m running looks like:
> >
> > ogr2ogr -f MSSQLSpatial
> > "MSSQL:server=localhost;database=[database-name];username=sa;password=
> > *****;trusted_connection=yes" [path-to-shape-file]
> >
> > It returns an error stating:
> >
> > ERROR 1: Unable to find driver `MSSQLSpatial'.
>
> I guess, GDAL/OGR version you are using on Linux is not built with
> ODBC/SQL Server support.
>
> > Is it possible to get the driver on linux? Or use an alternative driver?
> I’ve had a google and can’t seem to see any workarounds.
> >
> > The docs here (https://www.gdal.org/drv_mssqlspatial.html) talk about
> > specifying a Driver parameter that could be a custom SQL Server driver,
> however this is in the connection string and not as a parameter for the
> ogr2ogr command.
>
> Once you get GDAL/OGR built with SQL Server, install ODBC Driver for SQL
> Server (there are clear docs on Microsoft site, you will find easily
> searching the web)
>
> Then, try sticking the Driver option into the connection string
> Driver={ODBC Driver 11 for SQL Server} Driver={ODBC Driver 13 for SQL
> Server} Driver={ODBC Driver 13.1 for SQL Server} Driver={ODBC Driver 17 for
> SQL Server} depending which version you install.
>
> Best regards,
> --
> Mateusz Loskot, http://mateusz.loskot.net
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> SCISYS UK Limited. Registered in England and Wales No. 4373530.
> Registered Office: Methuen Park, Chippenham, Wiltshire SN14 0GB, UK.
>
> Before printing, please think about the environment.
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Med venlig hilsen

Bo Victor Thomsen
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181130/0adbca89/attachment-0001.html>

From Peter.Marlow at scisys.co.uk  Fri Nov 30 06:27:40 2018
From: Peter.Marlow at scisys.co.uk (Peter Marlow)
Date: Fri, 30 Nov 2018 14:27:40 +0000
Subject: [gdal-dev] Import Shapefile into SQL Server on Ubuntu
In-Reply-To: <CAAJbAXuPuvmbHCxCjTnHUYNLkygzoP4UU6RvmuBS_apkSb=3_A@mail.gmail.com>
References: <AA48096CDCDA4745B245B6A21526D998400FD0AA@CITCH-MXEXCH1.scisys.co.uk>
 <CABUeae-HkmLg5umovn3Ei3czt02g1Ns=mw3taZOypLTNsEET6A@mail.gmail.com>
 <AA48096CDCDA4745B245B6A21526D9984010DFFB@CITCH-MXEXCH1.scisys.co.uk>
 <CAAJbAXuPuvmbHCxCjTnHUYNLkygzoP4UU6RvmuBS_apkSb=3_A@mail.gmail.com>
Message-ID: <AA48096CDCDA4745B245B6A21526D9984010E020@CITCH-MXEXCH1.scisys.co.uk>

Hi Bo,

Yes the original commandstring did have that error, however the main error was that I didn’t have access to the MSSQLSpatial driver because the ODBC driver wasn’t bundled with the version of GDAL that I installed via conda-forge. When I installed GDAL via ‘apt-get install gdal-bin’ it did have the ODBC support.

Cheers,
Pete

From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> On Behalf Of Bo Victor Thomsen
Sent: 30 November 2018 14:13
To: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] Import Shapefile into SQL Server on Ubuntu

Hi Pete -

Your first take on the commandstring probably contains an error...

ogr2ogr -f MSSQLSpatial  "MSSQL:server=localhost;database=[database-name];username=sa;password=*****;trusted_connection=yes" [path-to-shape-file]

You probably hasn't made the necessary setup with kerberos to use "integrated security" (the  "trusted_connection=yes" part in the connection string)

This command might have worked ( no trusted_connection parameter):
ogr2ogr -f MSSQLSpatial  "MSSQL:server=localhost;database=[database-name];username=sa;password=*****" [path-to-shape-file]

Your second take  doesn't contain the "trusted_connection" part
ogr2ogr -f MSSQLSpatial "MSSQL:server=[server];database=[database];uid=[username];Pwd=[password];Driver={ODBC Driver 17 for SQL Server}" [shape file]




--- Run ogr2ogr using driver
ogr2ogr -f MSSQLSpatial "MSSQL:server=[server];database=[database];uid=[username];Pwd=[password];Driver={ODBC Driver 17 for SQL Server}" [shape file]


Thanks,
Pete

-----Original Message-----
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org<mailto:gdal-dev-bounces at lists.osgeo.org>> On Behalf Of Mateusz Loskot
Sent: 22 October 2018 16:31
To: gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
Subject: Re: [gdal-dev] Import Shapefile into SQL Server on Ubuntu

On Mon, 22 Oct 2018 at 17:25, Peter Marlow <Peter.Marlow at scisys.co.uk<mailto:Peter.Marlow at scisys.co.uk>> wrote:
>
> I’m trying to import a Shapefile into an SQL Server database using ogr2ogr on Ubuntu. The command I’m running looks like:
>
> ogr2ogr -f MSSQLSpatial
> "MSSQL:server=localhost;database=[database-name];username=sa;password=
> *****;trusted_connection=yes" [path-to-shape-file]
>
> It returns an error stating:
>
> ERROR 1: Unable to find driver `MSSQLSpatial'.

I guess, GDAL/OGR version you are using on Linux is not built with ODBC/SQL Server support.

> Is it possible to get the driver on linux? Or use an alternative driver? I’ve had a google and can’t seem to see any workarounds.
>
> The docs here (https://www.gdal.org/drv_mssqlspatial.html) talk about
> specifying a Driver parameter that could be a custom SQL Server driver, however this is in the connection string and not as a parameter for the ogr2ogr command.

Once you get GDAL/OGR built with SQL Server, install ODBC Driver for SQL Server (there are clear docs on Microsoft site, you will find easily searching the web)

Then, try sticking the Driver option into the connection string Driver={ODBC Driver 11 for SQL Server} Driver={ODBC Driver 13 for SQL Server} Driver={ODBC Driver 13.1 for SQL Server} Driver={ODBC Driver 17 for SQL Server} depending which version you install.

Best regards,
--
Mateusz Loskot, http://mateusz.loskot.net _______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
https://lists.osgeo.org/mailman/listinfo/gdal-dev


SCISYS UK Limited. Registered in England and Wales No. 4373530.
Registered Office: Methuen Park, Chippenham, Wiltshire SN14 0GB, UK.

Before printing, please think about the environment.

_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
https://lists.osgeo.org/mailman/listinfo/gdal-dev


--
Med venlig hilsen

Bo Victor Thomsen

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181130/27cbedd5/attachment.html>

From andre+joost at nurfuerspam.de  Fri Nov 30 07:02:56 2018
From: andre+joost at nurfuerspam.de (Andre Joost)
Date: Fri, 30 Nov 2018 16:02:56 +0100
Subject: [gdal-dev] HDF data mis-applied sinusoidal
In-Reply-To: <CAAcGz9_umSEvWaAgFJZd0qsDn43w_eVYDSwSx=AQwJXtO6bfEg@mail.gmail.com>
References: <CAAcGz9_umSEvWaAgFJZd0qsDn43w_eVYDSwSx=AQwJXtO6bfEg@mail.gmail.com>
Message-ID: <ptrjbm$a0h$1@blaine.gmane.org>

Hi Michael,

running eosdump on the file, I get:

File Size: 94926773
Number of grids: 1
Number of swaths: 0
Number of points: 0
Grid: GLASS02B06
	projection: SNSOID
	griddataclash:


   GRID GLASS02B06 {{{
     xdim: 7200
     ydim: 3600
     upleft: -2.00151e+07, 1.00076e+07
     lowright: -1.89032e+07, 8.8956e+06
     PROJECTION {
       projection: 16
       zone: -1
       sphere: -1
       param: ...
         6.37101e+06 0 0 0 0 0 0 0
         0 0 0 0 0 3.14511e+35 4.21472e-153 1.72352e+45
       pix: 0
       origin: 0
   }

So they defined the wrong projection, and gdal can't do much about it.

You can sanitize it with gdal_translate -a_ullr -180 90 180 -90 -a_srs 
EPSG:4326 src dst

HTH,
Andre Joost

Am 29.11.18 um 21:31 schrieb Michael Sumner:
> Hello, these data in HDF4 format are interpreted as being in sinusoidal
> projection, I guess some conflation with the MODIS logic about some
> products (?).
>
> ftp://ftp.glcf.umd.edu/glcf/GLASS/ABD/MODIS/0.05D/2013/
>
> Particular file is here, but note there's also an auxiliarly .hdf.xml with
> it:
> ftp://ftp.glcf.umd.edu/glcf/GLASS/ABD/MODIS/0.05D/2013/GLASS02B06.V04.A2013169.2017128.hdf
>
> A plot of the first subdataset shows that it is trivially in regular
> longlat (or eqc), the gdalinfo output is below.
>
> I'd appreciate any insights into why this is interpreted this way, and
> whether the GDAL detection logic could be improved - or whether the data
> providers need to update the internal metadata.
>
> Cheers, Mike.
>
> gdalinfo --version GDAL 2.3.2, released 2018/09/21
>
> gdalinfo
> HDF4_EOS:EOS_GRID:"GLASS02B06.V04.A2013169.2017128.hdf":GLASS02B06:ABD_BSA_VIS
> Driver: HDF4Image/HDF4 Dataset
> Files: GLASS02B06.V04.A2013169.2017128.hdf
> Size is 7200, 3600
> Coordinate System is:
> PROJCS["unnamed",
>      GEOGCS["Unknown datum based upon the custom spheroid",
>          DATUM["Not specified (based on custom spheroid)",
>              SPHEROID["Custom spheroid",6371007.181,0]],
>          PRIMEM["Greenwich",0],
>          UNIT["degree",0.0174532925199433]],
>      PROJECTION["Sinusoidal"],
>      PARAMETER["longitude_of_center",0],
>      PARAMETER["false_easting",0],
>      PARAMETER["false_northing",0],
>      UNIT["Meter",1]]
> Origin = (-20015109.353999998420477,10007554.676999999210238)
> Pixel Size = (154.437572175972150,-308.875144351944300)
> Metadata:
>    add_offset=0
>    add_offset_err=0
>    ASSOCIATEDINSTRUMENTSHORTNAME.1=AVHRR
>    ASSOCIATEDPLATFORMSHORTNAME.1=NOAA
>    ASSOCIATEDSENSORSHORTNAME.1=AVHRR
>    BANDDEFINITION=Surface
>    CHARACTERISTICBINSIZE=926.6
>    DATACOLUMNS=7200
>    DATAROWS=3600
>    DATASETNAME=GLASS02B06
>    DAYNIGHTFLAG=Both
>    EASTHBOUNDINGCOORDINATE=180
>    EXCLUSIONGRINGFLAG=N
>    GLOBALGRIDCOLUMNS=7200
>    GLOBALGRIDROWS=3600
>    GRIDTYPE=Geographic Lat/Lon
>    GRINGPOINTLATITUDE.1=90,90,-90,-90
>    GRINGPOINTLONGITUDE.1=-180,180,180,-180
>    GRINGPOINTSEQUENCENO.1=1,2,3,4
>    HDFEOSVersion=HDFEOS_V2.16
>    HORIZONTALTILENUMBER=00
>    HORIZONTALTILENUMBER=00
>    INPUTFILESNAME=Multi-Source Data
>    INPUTPOINTER=Multi-Source Data
>    INSTITUTENAME=BEIJING
>    LOCALGRANULEID=GLASS02B06.V04.A2013169.2017128.hdf
>    LOCALVERSIONID=V04
>    long_name=Black-sky Albedo in Visible band
>    NORTHBOUNDINGCOORDINATE=90
>    PARAMETERNAME.1=GLASS02B06
>    PGEVERSION=V04
>    PROCESSINGENVIRONMENT=High Performance Computing System
>    PRODUCTDATEANDTIME=2017-05-08 16:00:12
>    PRODUCTIONDATETIME=2017-05-08 16:00:12
>    PRODUCTNAME=Surface
>    PRODUCTQUALITY=CLOUDREMOVED
>    REPROCESSINGACTUAL=reprocessed
>    REPROCESSINGPLANNED=further update is anticipated
>    scale_factor=0.0001
>    scale_factor_err=0
>    SHORTNAME=GLASS02B06
>    SOUTHBOUNDINGCOORDINATE=-90
>    TILENUMBER=H00V00
>    units=Albedo,no units
>    valid_range=0, 10000
>    VERSIONID=1
>    VERTICALTILENUMBER=00
>    VERTICALTILENUMBER=00
>    WEBSITE=http://glass-product.bnu.edu.cn
>    WESTHBOUNDINGCOORDINATE=-180
>    _FillValue=-1
> Corner Coordinates:
> Upper Left  (-20015109.354,10007554.677) (124d17'29.21"W, 90d 0' 0.00"N)
> Lower Left  (-20015109.354, 8895604.157) ( 43d25'16.73"E, 80d 0' 0.00"N)
> Upper Right (-18903158.834,10007554.677) ( 77d21'53.56"W, 90d 0' 0.00"N)
> Lower Right (-18903158.834, 8895604.157) (101d 0'32.47"E, 80d 0' 0.00"N)
> Center      (-19459134.094, 9451579.417) (152d 6' 0.67"E, 85d 0' 0.00"N)
> Band 1 Block=7200x3600 Type=Int16, ColorInterp=Gray
>    Description = Black-sky Albedo in Visible band
>    NoData Value=-1
>    Unit Type: Albedo,no units
>    Offset: 0,   Scale:
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>



From even.rouault at spatialys.com  Fri Nov 30 07:22:17 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 30 Nov 2018 16:22:17 +0100
Subject: [gdal-dev] SRS barn: 6th status report
Message-ID: <1583030.Bc31IgOXBS@even-i700>

Hi

Please find my 6th status report at
https://erouault.blogspot.com/2018/11/srs-barn-raising-6th-report.html

Best regards,

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From mdsumner at gmail.com  Fri Nov 30 13:42:09 2018
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 1 Dec 2018 08:42:09 +1100
Subject: [gdal-dev] HDF data mis-applied sinusoidal
In-Reply-To: <ptrjbm$a0h$1@blaine.gmane.org>
References: <CAAcGz9_umSEvWaAgFJZd0qsDn43w_eVYDSwSx=AQwJXtO6bfEg@mail.gmail.com>
 <ptrjbm$a0h$1@blaine.gmane.org>
Message-ID: <CAAcGz9-NXeA_QqrEhP0LiiHegwh_tXrVOFbZ3pEU_TQ9ZgBCxw@mail.gmail.com>

Thanks for clarifying!

Cheers, Mike

On Sat, Dec 1, 2018, 02:04 Andre Joost <andre+joost at nurfuerspam.de> wrote:

> Hi Michael,
>
> running eosdump on the file, I get:
>
> File Size: 94926773
> Number of grids: 1
> Number of swaths: 0
> Number of points: 0
> Grid: GLASS02B06
>         projection: SNSOID
>         griddataclash:
>
>
>    GRID GLASS02B06 {{{
>      xdim: 7200
>      ydim: 3600
>      upleft: -2.00151e+07, 1.00076e+07
>      lowright: -1.89032e+07, 8.8956e+06
>      PROJECTION {
>        projection: 16
>        zone: -1
>        sphere: -1
>        param: ...
>          6.37101e+06 0 0 0 0 0 0 0
>          0 0 0 0 0 3.14511e+35 4.21472e-153 1.72352e+45
>        pix: 0
>        origin: 0
>    }
>
> So they defined the wrong projection, and gdal can't do much about it.
>
> You can sanitize it with gdal_translate -a_ullr -180 90 180 -90 -a_srs
> EPSG:4326 src dst
>
> HTH,
> Andre Joost
>
> Am 29.11.18 um 21:31 schrieb Michael Sumner:
> > Hello, these data in HDF4 format are interpreted as being in sinusoidal
> > projection, I guess some conflation with the MODIS logic about some
> > products (?).
> >
> > ftp://ftp.glcf.umd.edu/glcf/GLASS/ABD/MODIS/0.05D/2013/
> >
> > Particular file is here, but note there's also an auxiliarly .hdf.xml
> with
> > it:
> >
> ftp://ftp.glcf.umd.edu/glcf/GLASS/ABD/MODIS/0.05D/2013/GLASS02B06.V04.A2013169.2017128.hdf
> >
> > A plot of the first subdataset shows that it is trivially in regular
> > longlat (or eqc), the gdalinfo output is below.
> >
> > I'd appreciate any insights into why this is interpreted this way, and
> > whether the GDAL detection logic could be improved - or whether the data
> > providers need to update the internal metadata.
> >
> > Cheers, Mike.
> >
> > gdalinfo --version GDAL 2.3.2, released 2018/09/21
> >
> > gdalinfo
> >
> HDF4_EOS:EOS_GRID:"GLASS02B06.V04.A2013169.2017128.hdf":GLASS02B06:ABD_BSA_VIS
> > Driver: HDF4Image/HDF4 Dataset
> > Files: GLASS02B06.V04.A2013169.2017128.hdf
> > Size is 7200, 3600
> > Coordinate System is:
> > PROJCS["unnamed",
> >      GEOGCS["Unknown datum based upon the custom spheroid",
> >          DATUM["Not specified (based on custom spheroid)",
> >              SPHEROID["Custom spheroid",6371007.181,0]],
> >          PRIMEM["Greenwich",0],
> >          UNIT["degree",0.0174532925199433]],
> >      PROJECTION["Sinusoidal"],
> >      PARAMETER["longitude_of_center",0],
> >      PARAMETER["false_easting",0],
> >      PARAMETER["false_northing",0],
> >      UNIT["Meter",1]]
> > Origin = (-20015109.353999998420477,10007554.676999999210238)
> > Pixel Size = (154.437572175972150,-308.875144351944300)
> > Metadata:
> >    add_offset=0
> >    add_offset_err=0
> >    ASSOCIATEDINSTRUMENTSHORTNAME.1=AVHRR
> >    ASSOCIATEDPLATFORMSHORTNAME.1=NOAA
> >    ASSOCIATEDSENSORSHORTNAME.1=AVHRR
> >    BANDDEFINITION=Surface
> >    CHARACTERISTICBINSIZE=926.6
> >    DATACOLUMNS=7200
> >    DATAROWS=3600
> >    DATASETNAME=GLASS02B06
> >    DAYNIGHTFLAG=Both
> >    EASTHBOUNDINGCOORDINATE=180
> >    EXCLUSIONGRINGFLAG=N
> >    GLOBALGRIDCOLUMNS=7200
> >    GLOBALGRIDROWS=3600
> >    GRIDTYPE=Geographic Lat/Lon
> >    GRINGPOINTLATITUDE.1=90,90,-90,-90
> >    GRINGPOINTLONGITUDE.1=-180,180,180,-180
> >    GRINGPOINTSEQUENCENO.1=1,2,3,4
> >    HDFEOSVersion=HDFEOS_V2.16
> >    HORIZONTALTILENUMBER=00
> >    HORIZONTALTILENUMBER=00
> >    INPUTFILESNAME=Multi-Source Data
> >    INPUTPOINTER=Multi-Source Data
> >    INSTITUTENAME=BEIJING
> >    LOCALGRANULEID=GLASS02B06.V04.A2013169.2017128.hdf
> >    LOCALVERSIONID=V04
> >    long_name=Black-sky Albedo in Visible band
> >    NORTHBOUNDINGCOORDINATE=90
> >    PARAMETERNAME.1=GLASS02B06
> >    PGEVERSION=V04
> >    PROCESSINGENVIRONMENT=High Performance Computing System
> >    PRODUCTDATEANDTIME=2017-05-08 16:00:12
> >    PRODUCTIONDATETIME=2017-05-08 16:00:12
> >    PRODUCTNAME=Surface
> >    PRODUCTQUALITY=CLOUDREMOVED
> >    REPROCESSINGACTUAL=reprocessed
> >    REPROCESSINGPLANNED=further update is anticipated
> >    scale_factor=0.0001
> >    scale_factor_err=0
> >    SHORTNAME=GLASS02B06
> >    SOUTHBOUNDINGCOORDINATE=-90
> >    TILENUMBER=H00V00
> >    units=Albedo,no units
> >    valid_range=0, 10000
> >    VERSIONID=1
> >    VERTICALTILENUMBER=00
> >    VERTICALTILENUMBER=00
> >    WEBSITE=http://glass-product.bnu.edu.cn
> >    WESTHBOUNDINGCOORDINATE=-180
> >    _FillValue=-1
> > Corner Coordinates:
> > Upper Left  (-20015109.354,10007554.677) (124d17'29.21"W, 90d 0' 0.00"N)
> > Lower Left  (-20015109.354, 8895604.157) ( 43d25'16.73"E, 80d 0' 0.00"N)
> > Upper Right (-18903158.834,10007554.677) ( 77d21'53.56"W, 90d 0' 0.00"N)
> > Lower Right (-18903158.834, 8895604.157) (101d 0'32.47"E, 80d 0' 0.00"N)
> > Center      (-19459134.094, 9451579.417) (152d 6' 0.67"E, 85d 0' 0.00"N)
> > Band 1 Block=7200x3600 Type=Int16, ColorInterp=Gray
> >    Description = Black-sky Albedo in Visible band
> >    NoData Value=-1
> >    Unit Type: Albedo,no units
> >    Offset: 0,   Scale:
> >
> >
> >
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > https://lists.osgeo.org/mailman/listinfo/gdal-dev
> >
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20181201/025fdae0/attachment.html>

