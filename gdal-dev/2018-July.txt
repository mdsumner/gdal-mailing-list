From stephenwoodbridge37 at gmail.com  Sun Jul  1 07:07:36 2018
From: stephenwoodbridge37 at gmail.com (Stephen Woodbridge)
Date: Sun, 1 Jul 2018 10:07:36 -0400
Subject: [gdal-dev] gdalwarp ERROR 6: PHOTOMETRIC=YCBCR requires a source
 raster with only 3 bands (RGB)
Message-ID: <b839ea37-9f08-cea6-1fc3-7d5bf7ca92e9@gmail.com>

Hi all,

I'm trying to convert a utm jp2 file to a wgs84 tif file and getting 
"ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 bands 
(RGB)" but the src file has only 3 RBG bands.

gdalwarp -t_srs EPSG:4326 -dstalpha -r bilinear -of GTiff -co 
BIGTIFF=YES -co TILED=YES -co COMPRESS=JPEG -co JPEG_QUALITY=90 -co 
PHOTOMETRIC=YCBCR '00010.jp2' 'tif/00010.tif'

The command works if I remove -dstalpha so it seems that the error 
message is erroneous and might need fixed. Regardless, I don't want the 
transformed image to have black around it, so how do I do that?

-Steve

# gdalinfo 00010.jp2
Driver: JP2OpenJPEG/JPEG-2000 driver based on OpenJPEG library
Files: 00010.jp2
        00010.jp2.aux.xml
Size is 340668, 65335
Coordinate System is:
PROJCS["UTM_Zone_38_Northern_Hemisphere",
     GEOGCS["GCS_WGS_1984",
         DATUM["WGS84",
             SPHEROID["WGS84",6378137,298.257223563]],
         PRIMEM["Greenwich",0],
         UNIT["Degree",0.017453292519943295]],
     PROJECTION["Transverse_Mercator"],
     PARAMETER["latitude_of_origin",0],
     PARAMETER["central_meridian",45],
     PARAMETER["scale_factor",0.9996],
     PARAMETER["false_easting",500000],
     PARAMETER["false_northing",0],
     UNIT["Meter",1]]
Origin = (265998.000000000000000,1848002.000000000000000)
Pixel Size = (3.000000000000000,-3.000000000000000)
Image Structure Metadata:
   INTERLEAVE=PIXEL
Corner Coordinates:
Upper Left  (  265998.000, 1848002.000) ( 42d48'19.81"E, 16d42'11.25"N)
Lower Left  (  265998.000, 1651997.000) ( 42d49'28.30"E, 14d55'56.73"N)
Upper Right ( 1288002.000, 1848002.000) ( 52d22'11.02"E, 16d35' 0.58"N)
Lower Right ( 1288002.000, 1651997.000) ( 52d18'23.31"E, 14d49'33.87"N)
Center      (  777000.000, 1749999.500) ( 47d35' 9.06"E, 15d48'48.25"N)
Band 1 Block=1024x1024 Type=Byte, ColorInterp=Red
   Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
   Overviews: arbitrary
   Image Structure Metadata:
     COMPRESSION=JPEG2000
Band 2 Block=1024x1024 Type=Byte, ColorInterp=Green
   Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
   Overviews: arbitrary
   Image Structure Metadata:
     COMPRESSION=JPEG2000
Band 3 Block=1024x1024 Type=Byte, ColorInterp=Blue
   Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
   Overviews: arbitrary
   Image Structure Metadata:
     COMPRESSION=JPEG2000


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From michael.smith.erdc at gmail.com  Sun Jul  1 07:14:18 2018
From: michael.smith.erdc at gmail.com (Michael Smith)
Date: Sun, 1 Jul 2018 10:14:18 -0400
Subject: [gdal-dev] gdalwarp ERROR 6: PHOTOMETRIC=YCBCR requires a
	source raster with only 3 bands (RGB)
In-Reply-To: <b839ea37-9f08-cea6-1fc3-7d5bf7ca92e9@gmail.com>
References: <b839ea37-9f08-cea6-1fc3-7d5bf7ca92e9@gmail.com>
Message-ID: <1AF0A65A-3F3B-41DB-B449-A9B53B603922@gmail.com>

Steve,

Setting that alpha channel makes it 4 bands. RGB + alpha channel. Either remove the ycbcr or the alpha channel. 

Michael Smith
Remote Sensing/GIS Center
US Army Corps of Engineers

> On Jul 1, 2018, at 10:07 AM, Stephen Woodbridge <stephenwoodbridge37 at gmail.com> wrote:
> 
> Hi all,
> 
> I'm trying to convert a utm jp2 file to a wgs84 tif file and getting "ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 bands (RGB)" but the src file has only 3 RBG bands.
> 
> gdalwarp -t_srs EPSG:4326 -dstalpha -r bilinear -of GTiff -co BIGTIFF=YES -co TILED=YES -co COMPRESS=JPEG -co JPEG_QUALITY=90 -co PHOTOMETRIC=YCBCR '00010.jp2' 'tif/00010.tif'
> 
> The command works if I remove -dstalpha so it seems that the error message is erroneous and might need fixed. Regardless, I don't want the transformed image to have black around it, so how do I do that?
> 
> -Steve
> 
> # gdalinfo 00010.jp2
> Driver: JP2OpenJPEG/JPEG-2000 driver based on OpenJPEG library
> Files: 00010.jp2
>        00010.jp2.aux.xml
> Size is 340668, 65335
> Coordinate System is:
> PROJCS["UTM_Zone_38_Northern_Hemisphere",
>     GEOGCS["GCS_WGS_1984",
>         DATUM["WGS84",
>             SPHEROID["WGS84",6378137,298.257223563]],
>         PRIMEM["Greenwich",0],
>         UNIT["Degree",0.017453292519943295]],
>     PROJECTION["Transverse_Mercator"],
>     PARAMETER["latitude_of_origin",0],
>     PARAMETER["central_meridian",45],
>     PARAMETER["scale_factor",0.9996],
>     PARAMETER["false_easting",500000],
>     PARAMETER["false_northing",0],
>     UNIT["Meter",1]]
> Origin = (265998.000000000000000,1848002.000000000000000)
> Pixel Size = (3.000000000000000,-3.000000000000000)
> Image Structure Metadata:
>   INTERLEAVE=PIXEL
> Corner Coordinates:
> Upper Left  (  265998.000, 1848002.000) ( 42d48'19.81"E, 16d42'11.25"N)
> Lower Left  (  265998.000, 1651997.000) ( 42d49'28.30"E, 14d55'56.73"N)
> Upper Right ( 1288002.000, 1848002.000) ( 52d22'11.02"E, 16d35' 0.58"N)
> Lower Right ( 1288002.000, 1651997.000) ( 52d18'23.31"E, 14d49'33.87"N)
> Center      (  777000.000, 1749999.500) ( 47d35' 9.06"E, 15d48'48.25"N)
> Band 1 Block=1024x1024 Type=Byte, ColorInterp=Red
>   Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
>   Overviews: arbitrary
>   Image Structure Metadata:
>     COMPRESSION=JPEG2000
> Band 2 Block=1024x1024 Type=Byte, ColorInterp=Green
>   Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
>   Overviews: arbitrary
>   Image Structure Metadata:
>     COMPRESSION=JPEG2000
> Band 3 Block=1024x1024 Type=Byte, ColorInterp=Blue
>   Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
>   Overviews: arbitrary
>   Image Structure Metadata:
>     COMPRESSION=JPEG2000
> 
> 
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

From stephenwoodbridge37 at gmail.com  Sun Jul  1 08:18:39 2018
From: stephenwoodbridge37 at gmail.com (Stephen Woodbridge)
Date: Sun, 1 Jul 2018 11:18:39 -0400
Subject: [gdal-dev] gdalwarp ERROR 6: PHOTOMETRIC=YCBCR requires a
 source raster with only 3 bands (RGB)
In-Reply-To: <1AF0A65A-3F3B-41DB-B449-A9B53B603922@gmail.com>
References: <b839ea37-9f08-cea6-1fc3-7d5bf7ca92e9@gmail.com>
 <1AF0A65A-3F3B-41DB-B449-A9B53B603922@gmail.com>
Message-ID: <c139fb56-f2e9-3f88-db9a-ef69188c0b00@gmail.com>

Right, but the point 1 is the message says:
ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 bands (RGB)
ie: requires a source raster with only 3 bands (RGB) and the source 
raster has only 3 bands!
-dstalpha if I understand correctly is to create a alpha band in the 
output file. So the error message is misleading at best.

Point 2 is how does one translate a utm to wgs84 using YCBCR and 
generate an appropriate mask or alpha channel to hide the pixels that 
are outside the transformed image. I suppose it needs to be done in 
multiple steps of warp and translate in some specific order with 
specific options but its not obvious how.

-Steve

On 7/1/2018 10:14 AM, Michael Smith wrote:
> Steve,
>
> Setting that alpha channel makes it 4 bands. RGB + alpha channel. Either remove the ycbcr or the alpha channel.
>
> Michael Smith
> Remote Sensing/GIS Center
> US Army Corps of Engineers
>
>> On Jul 1, 2018, at 10:07 AM, Stephen Woodbridge <stephenwoodbridge37 at gmail.com> wrote:
>>
>> Hi all,
>>
>> I'm trying to convert a utm jp2 file to a wgs84 tif file and getting "ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 bands (RGB)" but the src file has only 3 RBG bands.
>>
>> gdalwarp -t_srs EPSG:4326 -dstalpha -r bilinear -of GTiff -co BIGTIFF=YES -co TILED=YES -co COMPRESS=JPEG -co JPEG_QUALITY=90 -co PHOTOMETRIC=YCBCR '00010.jp2' 'tif/00010.tif'
>>
>> The command works if I remove -dstalpha so it seems that the error message is erroneous and might need fixed. Regardless, I don't want the transformed image to have black around it, so how do I do that?
>>
>> -Steve
>>
>> # gdalinfo 00010.jp2
>> Driver: JP2OpenJPEG/JPEG-2000 driver based on OpenJPEG library
>> Files: 00010.jp2
>>         00010.jp2.aux.xml
>> Size is 340668, 65335
>> Coordinate System is:
>> PROJCS["UTM_Zone_38_Northern_Hemisphere",
>>      GEOGCS["GCS_WGS_1984",
>>          DATUM["WGS84",
>>              SPHEROID["WGS84",6378137,298.257223563]],
>>          PRIMEM["Greenwich",0],
>>          UNIT["Degree",0.017453292519943295]],
>>      PROJECTION["Transverse_Mercator"],
>>      PARAMETER["latitude_of_origin",0],
>>      PARAMETER["central_meridian",45],
>>      PARAMETER["scale_factor",0.9996],
>>      PARAMETER["false_easting",500000],
>>      PARAMETER["false_northing",0],
>>      UNIT["Meter",1]]
>> Origin = (265998.000000000000000,1848002.000000000000000)
>> Pixel Size = (3.000000000000000,-3.000000000000000)
>> Image Structure Metadata:
>>    INTERLEAVE=PIXEL
>> Corner Coordinates:
>> Upper Left  (  265998.000, 1848002.000) ( 42d48'19.81"E, 16d42'11.25"N)
>> Lower Left  (  265998.000, 1651997.000) ( 42d49'28.30"E, 14d55'56.73"N)
>> Upper Right ( 1288002.000, 1848002.000) ( 52d22'11.02"E, 16d35' 0.58"N)
>> Lower Right ( 1288002.000, 1651997.000) ( 52d18'23.31"E, 14d49'33.87"N)
>> Center      (  777000.000, 1749999.500) ( 47d35' 9.06"E, 15d48'48.25"N)
>> Band 1 Block=1024x1024 Type=Byte, ColorInterp=Red
>>    Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
>>    Overviews: arbitrary
>>    Image Structure Metadata:
>>      COMPRESSION=JPEG2000
>> Band 2 Block=1024x1024 Type=Byte, ColorInterp=Green
>>    Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
>>    Overviews: arbitrary
>>    Image Structure Metadata:
>>      COMPRESSION=JPEG2000
>> Band 3 Block=1024x1024 Type=Byte, ColorInterp=Blue
>>    Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 10645x2041
>>    Overviews: arbitrary
>>    Image Structure Metadata:
>>      COMPRESSION=JPEG2000
>>
>>
>> ---
>> This email has been checked for viruses by Avast antivirus software.
>> https://www.avast.com/antivirus
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev



From jukka.rahkonen at maanmittauslaitos.fi  Sun Jul  1 08:39:25 2018
From: jukka.rahkonen at maanmittauslaitos.fi (jratike80)
Date: Sun, 1 Jul 2018 08:39:25 -0700 (MST)
Subject: [gdal-dev] [EXTERNAL]  Convert VRT+JPEG with gdalwarp
In-Reply-To: <VI1PR08MB31993C629C11B440C24D7785BA4A0@VI1PR08MB3199.eurprd08.prod.outlook.com>
References: <1529589603275-0.post@n6.nabble.com>
 <CALQGVr15naoJ8grAdAKS6c8-zO4WZFpLgfhsXHDriLdStXFf9w@mail.gmail.com>
 <VI1PR08MB31993C629C11B440C24D7785BA4A0@VI1PR08MB3199.eurprd08.prod.outlook.com>
Message-ID: <1530459565573-0.post@n6.nabble.com>

kalevj wrote
> Hi Doug,
> 
> Thanks for the info. I know that JPEG is lossy but our datasets are very
> large. That’s why we use JPEG, which is good enough for our needs and the
> file sizes are smaller.

Hi,

If your datasets are large you should not create plain JPEG files with the
GDAL JPEG driver. Create JPEG compressed tiled GeoTIFFs instead. With JPEG
you must decompress the whole image before you can read a small region of
interest of your image but from tiled GeoTIFF you can access the right tiles
directly. You can read usage examples for example from here
http://blog.cleverelephant.ca/2015/02/geotiff-compression-for-dummies.html.

-Jukka Rahkonen-


 



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Sun Jul  1 14:42:33 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 01 Jul 2018 23:42:33 +0200
Subject: [gdal-dev] gdalwarp ERROR 6: PHOTOMETRIC=YCBCR requires a
	source raster with only 3 bands (RGB)
In-Reply-To: <c139fb56-f2e9-3f88-db9a-ef69188c0b00@gmail.com>
References: <b839ea37-9f08-cea6-1fc3-7d5bf7ca92e9@gmail.com>
 <1AF0A65A-3F3B-41DB-B449-A9B53B603922@gmail.com>
 <c139fb56-f2e9-3f88-db9a-ef69188c0b00@gmail.com>
Message-ID: <3316553.ypAhvAyLFA@even-i700>

On dimanche 1 juillet 2018 11:18:39 CEST Stephen Woodbridge wrote:
> Right, but the point 1 is the message says:
> ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 bands (RGB)
> ie: requires a source raster with only 3 bands (RGB) and the source
> raster has only 3 bands!
> -dstalpha if I understand correctly is to create a alpha band in the
> output file. So the error message is misleading at best.

I've adjusted the error message

> 
> Point 2 is how does one translate a utm to wgs84 using YCBCR and
> generate an appropriate mask or alpha channel to hide the pixels that
> are outside the transformed image. I suppose it needs to be done in
> multiple steps of warp and translate in some specific order with
> specific options but its not obvious how.

try:

gdalwarp -t_srs EPSG:4326 -dstalpha -r bilinear -of GTiff \
	 -co TILED=YES '00010.jp2' 'tif/00010_rgba.tif'
gdal_translate -b 1 -b 2 -b 3 -mask 4 -co BIGTIFF=YES -co TILED=YES \
	 -co COMPRESS=JPEG -co JPEG_QUALITY=90 -co PHOTOMETRIC=YCBCR \
	 --config GDAL_TIFF_INTERNAL_MASK YES \
	 'tif/00010_rgba.tif' 'tif/00010_rgb_with_mask.tif'

Potentially to save space / time, you can warp to VRT in the first step;

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From stephenwoodbridge37 at gmail.com  Sun Jul  1 15:02:32 2018
From: stephenwoodbridge37 at gmail.com (Stephen Woodbridge)
Date: Sun, 1 Jul 2018 18:02:32 -0400
Subject: [gdal-dev] gdalwarp ERROR 6: PHOTOMETRIC=YCBCR requires a
 source raster with only 3 bands (RGB)
In-Reply-To: <c139fb56-f2e9-3f88-db9a-ef69188c0b00@gmail.com>
References: <b839ea37-9f08-cea6-1fc3-7d5bf7ca92e9@gmail.com>
 <1AF0A65A-3F3B-41DB-B449-A9B53B603922@gmail.com>
 <c139fb56-f2e9-3f88-db9a-ef69188c0b00@gmail.com>
Message-ID: <f529a9b4-ac07-1251-bb5d-e416dc4a105a@gmail.com>

OK, digging deep into my old emails I think I found a solution ( still 
to be proved):

gdalwarp -t_srs EPSG:4326 -r bilinear -co TILED=YES -co BIGTIFF=YES 
-dstalpha -multi  '00010.jp2' '/data/satmap/tmp.tif'

This took 39 min and expanded the 2.1G jp2 into 87G tif, then this gets 
followed by:

gdal_translate -co TILED=YES -co JPEG_QUALITY=90 -co COMPRESS=JPEG -co 
PHOTOMETRIC=YCBCR -b 1 -b 2 -b 3 -mask 4 --config 
GDAL_TIFF_INTERNAL_MASK YES /data/satmap/tmp.tif /data/satmap/tmp/00010.tif

Which takes 53 min and compresses into a 1.8G tif. And then add overviews:

gdaladdo 00010.tif 2 4 8 18 32 64 128 256

Which takes 51 min and the file size goes to 2.6G.

This two step process takes a lot of disk and processing time. It would 
seem that this could be optimized if the warp and translate 
functionality where merged into a single command.

-Steve

On 7/1/2018 11:18 AM, Stephen Woodbridge wrote:
> Right, but the point 1 is the message says:
> ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 bands 
> (RGB)
> ie: requires a source raster with only 3 bands (RGB) and the source 
> raster has only 3 bands!
> -dstalpha if I understand correctly is to create a alpha band in the 
> output file. So the error message is misleading at best.
>
> Point 2 is how does one translate a utm to wgs84 using YCBCR and 
> generate an appropriate mask or alpha channel to hide the pixels that 
> are outside the transformed image. I suppose it needs to be done in 
> multiple steps of warp and translate in some specific order with 
> specific options but its not obvious how.
>
> -Steve
>
> On 7/1/2018 10:14 AM, Michael Smith wrote:
>> Steve,
>>
>> Setting that alpha channel makes it 4 bands. RGB + alpha channel. 
>> Either remove the ycbcr or the alpha channel.
>>
>> Michael Smith
>> Remote Sensing/GIS Center
>> US Army Corps of Engineers
>>
>>> On Jul 1, 2018, at 10:07 AM, Stephen Woodbridge 
>>> <stephenwoodbridge37 at gmail.com> wrote:
>>>
>>> Hi all,
>>>
>>> I'm trying to convert a utm jp2 file to a wgs84 tif file and getting 
>>> "ERROR 6: PHOTOMETRIC=YCBCR requires a source raster with only 3 
>>> bands (RGB)" but the src file has only 3 RBG bands.
>>>
>>> gdalwarp -t_srs EPSG:4326 -dstalpha -r bilinear -of GTiff -co 
>>> BIGTIFF=YES -co TILED=YES -co COMPRESS=JPEG -co JPEG_QUALITY=90 -co 
>>> PHOTOMETRIC=YCBCR '00010.jp2' 'tif/00010.tif'
>>>
>>> The command works if I remove -dstalpha so it seems that the error 
>>> message is erroneous and might need fixed. Regardless, I don't want 
>>> the transformed image to have black around it, so how do I do that?
>>>
>>> -Steve
>>>
>>> # gdalinfo 00010.jp2
>>> Driver: JP2OpenJPEG/JPEG-2000 driver based on OpenJPEG library
>>> Files: 00010.jp2
>>>         00010.jp2.aux.xml
>>> Size is 340668, 65335
>>> Coordinate System is:
>>> PROJCS["UTM_Zone_38_Northern_Hemisphere",
>>>      GEOGCS["GCS_WGS_1984",
>>>          DATUM["WGS84",
>>>              SPHEROID["WGS84",6378137,298.257223563]],
>>>          PRIMEM["Greenwich",0],
>>>          UNIT["Degree",0.017453292519943295]],
>>>      PROJECTION["Transverse_Mercator"],
>>>      PARAMETER["latitude_of_origin",0],
>>>      PARAMETER["central_meridian",45],
>>>      PARAMETER["scale_factor",0.9996],
>>>      PARAMETER["false_easting",500000],
>>>      PARAMETER["false_northing",0],
>>>      UNIT["Meter",1]]
>>> Origin = (265998.000000000000000,1848002.000000000000000)
>>> Pixel Size = (3.000000000000000,-3.000000000000000)
>>> Image Structure Metadata:
>>>    INTERLEAVE=PIXEL
>>> Corner Coordinates:
>>> Upper Left  (  265998.000, 1848002.000) ( 42d48'19.81"E, 16d42'11.25"N)
>>> Lower Left  (  265998.000, 1651997.000) ( 42d49'28.30"E, 14d55'56.73"N)
>>> Upper Right ( 1288002.000, 1848002.000) ( 52d22'11.02"E, 16d35' 0.58"N)
>>> Lower Right ( 1288002.000, 1651997.000) ( 52d18'23.31"E, 14d49'33.87"N)
>>> Center      (  777000.000, 1749999.500) ( 47d35' 9.06"E, 15d48'48.25"N)
>>> Band 1 Block=1024x1024 Type=Byte, ColorInterp=Red
>>>    Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 
>>> 10645x2041
>>>    Overviews: arbitrary
>>>    Image Structure Metadata:
>>>      COMPRESSION=JPEG2000
>>> Band 2 Block=1024x1024 Type=Byte, ColorInterp=Green
>>>    Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 
>>> 10645x2041
>>>    Overviews: arbitrary
>>>    Image Structure Metadata:
>>>      COMPRESSION=JPEG2000
>>> Band 3 Block=1024x1024 Type=Byte, ColorInterp=Blue
>>>    Overviews: 170334x32667, 85167x16333, 42583x8166, 21291x4083, 
>>> 10645x2041
>>>    Overviews: arbitrary
>>>    Image Structure Metadata:
>>>      COMPRESSION=JPEG2000
>>>
>>>
>>> ---
>>> This email has been checked for viruses by Avast antivirus software.
>>> https://www.avast.com/antivirus
>>>
>>> _______________________________________________
>>> gdal-dev mailing list
>>> gdal-dev at lists.osgeo.org
>>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>


From sawan.nikam22 at gmail.com  Sun Jul  1 22:55:30 2018
From: sawan.nikam22 at gmail.com (sawan nikam)
Date: Mon, 2 Jul 2018 11:25:30 +0530
Subject: [gdal-dev] GDAL-Georefrencing already Georefrenced single band
	Raster
Message-ID: <CABw2rhjWW74PhaJdrNt4DDnUZb=Qaq4DdJ6sbaHSGWpAa00cTA@mail.gmail.com>

Hello,

I am trying to georeference already georeferenced single band raster data
using GDAL with four GCP's.

Input image is having Coordinate system GCS- WGS1984 (EPSG:4326).
Following Command is run on command Prompt:

*"gdal_translate -of GTiff -gcp 72.4819 23.0179 72.4819 23.0179 -gcp 72.492
23.0079 72.492 23.0079 -gcp 72.4819 23.0086 72.4819 23.0086 -gcp 72.496
23.0169 72.496 23.0169 input.tiff output1.tiff*
*gdalwarp -r near -order 1 -co COMPRESS=NONE -s_srs EPSG:4326 -t_srs
EPSG:4326 output1.tiff" output.tiff"*

*Issues*:
-> After running this command on command prompt and opening output
generated file  in QGIS the output is not having the coordinate system as
EPSG:4326.

-> Image is opening somewhere else location in QGIS viewer. Hence the image
is not properly georeferenced.

-> For cross verification I ran  georefrencing tool in QGIS with same input
dataset it is giving the expected output and image is opening on exact
Geographic location.

-> For cross verification, I copied generated gdal script from QGIS and ran
again in Command Prompt and opened output  again in QGIS. The image is not
as expected.


*Questions*:
1. Is this above command is correct for georeferencing already
georeferenced data?
2. Apart from above command Is there any another internal Command QGIS
using for georeferencing image?
3. After running gdalwarp, why the output generated is not resampled and
not having mentioned coordinate system.

Waiting For your valuable response.

-- 
With Regards,

*Sawan Nikam*
*Mob: +91-9753123988*
*Mail: sawan.nikam22 at gmail.com <sawan.nikam22 at gmail.com>*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180702/4b2d1075/attachment.html>

From even.rouault at spatialys.com  Sun Jul  1 23:48:39 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 02 Jul 2018 08:48:39 +0200
Subject: [gdal-dev] GDAL-Georefrencing already Georefrenced single band
	Raster
In-Reply-To: <CABw2rhjWW74PhaJdrNt4DDnUZb=Qaq4DdJ6sbaHSGWpAa00cTA@mail.gmail.com>
References: <CABw2rhjWW74PhaJdrNt4DDnUZb=Qaq4DdJ6sbaHSGWpAa00cTA@mail.gmail.com>
Message-ID: <1593141.j9SLKlFbXU@even-i700>

On lundi 2 juillet 2018 11:25:30 CEST sawan nikam wrote:
> Hello,
> 
> I am trying to georeference already georeferenced single band raster data
> using GDAL with four GCP's.
> 
> Input image is having Coordinate system GCS- WGS1984 (EPSG:4326).
> Following Command is run on command Prompt:
> 
> *"gdal_translate -of GTiff -gcp 72.4819 23.0179 72.4819 23.0179 -gcp 72.492
> 23.0079 72.492 23.0079 -gcp 72.4819 23.0086 72.4819 23.0086 -gcp 72.496
> 23.0169 72.496 23.0169 input.tiff output1.tiff*

Those GCPs do not make sense. The first 2 values of each GCP should be X,Y in 
pixel coordinates, and the last 2 ones should be longitude, latitude (for 
EPSG:4326)


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From laasunde at hotmail.com  Mon Jul  2 00:28:09 2018
From: laasunde at hotmail.com (Lars)
Date: Mon, 2 Jul 2018 07:28:09 +0000
Subject: [gdal-dev] ogr2ogr adding metadata
In-Reply-To: <5B3339DC.6080807@t-kartor.se>
References: <HE1PR03MB1338AB823DC751EBA41D8F14CA750@HE1PR03MB1338.eurprd03.prod.outlook.com>
 <2558914.Q1IQ8xsQXi@even-i700>
 <HE1PR03MB133855B909319FC33419F094CA490@HE1PR03MB1338.eurprd03.prod.outlook.com>,
 <5B3339DC.6080807@t-kartor.se>
Message-ID: <HE1PR03MB13384A91FE6096ED830F7427CA430@HE1PR03MB1338.eurprd03.prod.outlook.com>

Andreas;

Thank you for your suggestion.

How would this workflow handle

  *
multiple import operations spread over time into the same database and schema? The first import will yield a number of tables depending on data. The second import will need to determine which tables already contain a trigger and skip truncating it.
  *
adding (one or more) user specified metadata string. For example I would like to add description information or name of organization that produced data.

Another suggestion, add optional foreign key and value parameter to ogr2ogr. Using this option would add a extra colum to each created table which references a user define "metadata" table. The workflow could be
1. Create custom metadata table
2. Insert record into metadata table
3. Run ogr2ogr with reference to record created in step 2.

In this scenario ogr2ogr does not need to know much about any additional information and it reduces duplicated information.

kind regards, Lars

________________________________
Fra: gdal-dev <gdal-dev-bounces at lists.osgeo.org> på vegne av Andreas Oxenstierna <ao at t-kartor.se>
Sendt: onsdag 27. juni 2018 09.16
Til: gdal-dev at lists.osgeo.org
Emne: Re: [gdal-dev] ogr2ogr adding metadata

A S57 file with only 6 feature object classes? Normally there should be many more.

I would add triggers to each table in the database for timestamps.
Potential workflow:
1 ogr for initial import into own schema
2 Postgre script, reading all tables in the schema using the information_schema info, to truncate and add triggers
3 ogr for final import


Even,

Appreciate the response.

Your example is interesting but there are a couple of issues. Importing a random .000 file using ogr2ogr yields 6 tables in the database. Which tables are created depend on the data and are unknown to me prior to import, so it is difficult to generate the SQL in advance. This approach does not scale very well if data yields a number of tables.

Another issue was when adding the SQL statement for one specific table caused the import to ignore the other 5 tables. Is this the expect result or should all 6 table be imported?

Regards, Lars

________________________________
Fra: Even Rouault <even.rouault at spatialys.com><mailto:even.rouault at spatialys.com>
Sendt: fredag 22. juni 2018 23.15
Til: gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
Kopi: Lars
Emne: Re: [gdal-dev] ogr2ogr adding metadata

On vendredi 22 juin 2018 09:41:02 CEST Lars wrote:
> Hello folks,
>
> Using ogr2ogr (version 2.2.3) to import s57 into PostgreSQL which works
> great.
>
> What is the recommended approach for adding metadata to all inserted data?
>
> Say I wanted to add current date to all inserted data. Does ogr2ogr support
> such operation? Tried using the "-mo" argument but it did not make any
> inpact (same result with argument as without). Ideally I do not want the
> client to be adding this information as a post insert operation (if even
> possible).

Lars,

-mo will work only with very few target drivers (I can only think to
GeoPackage actually). This is per-layer/per-table metadata. There's perhaps
the equivalent in PostgreSQL but this isn't implemented by GDAL

But you can add a column with the current timestamp for example with

ogr2ogr -update PG:xxxxxx poly.shp \
       -sql "SELECT *, CURRENT_TIMESTAMP FROM poly" -dialect SQLITE

Even

--
Spatialys - Geospatial professional services
http://www.spatialys.com



_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org<mailto:gdal-dev at lists.osgeo.org>
https://lists.osgeo.org/mailman/listinfo/gdal-dev



--
Hälsningar

Andreas Oxenstierna
T-Kartor Geospatial AB
mobile: +46 733 206831
mailto: ao at t-kartor.se<mailto:ao at t-kartor.se>
http://www.t-kartor.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180702/062d4515/attachment-0001.html>

From ao at t-kartor.se  Mon Jul  2 00:35:24 2018
From: ao at t-kartor.se (Andreas Oxenstierna)
Date: Mon, 2 Jul 2018 09:35:24 +0200
Subject: [gdal-dev] ogr2ogr adding metadata
In-Reply-To: <HE1PR03MB13384A91FE6096ED830F7427CA430@HE1PR03MB1338.eurprd03.prod.outlook.com>
References: <HE1PR03MB1338AB823DC751EBA41D8F14CA750@HE1PR03MB1338.eurprd03.prod.outlook.com>
 <2558914.Q1IQ8xsQXi@even-i700>
 <HE1PR03MB133855B909319FC33419F094CA490@HE1PR03MB1338.eurprd03.prod.outlook.com>
 <5B3339DC.6080807@t-kartor.se>
 <HE1PR03MB13384A91FE6096ED830F7427CA430@HE1PR03MB1338.eurprd03.prod.outlook.com>
Message-ID: <5B39D5BC.4060404@t-kartor.se>


> Andreas;
>
> Thank you for your suggestion.
>
> How would this workflow handle
>
>  *
>     multiple import operations spread over time into the same database
>     and schema? The first import will yield a number of tables
>     depending on data. The second import will need to determine which
>     tables already contain a trigger and skip truncating it.
>
Initial import into specific empty schema. Then compare and add missing 
tables in the "real" schema. Note that the S57 object schema is 
something like 300 feature object classes.

>  *
>
>
>  *
>     adding (one or more) user specified metadata string. For example I
>     would like to add description information or name of organization
>     that produced data.
>
Can be done with triggers etc. as well for each import. Ask if you need 
practical examples - but this is clearly outside of the GDAL list.
>
>  *
>
>
> Another suggestion, add optional foreign key and value parameter to 
> ogr2ogr. Using this option would add a extra colum to each created 
> table which references a user define "metadata" table. The workflow 
> could be
> 1. Create custom metadata table
> 2. Insert record into metadata table
> 3. Run ogr2ogr with reference to record created in step 2.
>
> In this scenario ogr2ogr does not need to know much about any 
> additional information and it reduces duplicated information.
>
> kind regards, Lars
>
> ------------------------------------------------------------------------
> *Fra:* gdal-dev <gdal-dev-bounces at lists.osgeo.org> på vegne av Andreas 
> Oxenstierna <ao at t-kartor.se>
> *Sendt:* onsdag 27. juni 2018 09.16
> *Til:* gdal-dev at lists.osgeo.org
> *Emne:* Re: [gdal-dev] ogr2ogr adding metadata
> A S57 file with only 6 feature object classes? Normally there should 
> be many more.
>
> I would add triggers to each table in the database for timestamps.
> Potential workflow:
> 1 ogr for initial import into own schema
> 2 Postgre script, reading all tables in the schema using the 
> information_schema info, to truncate and add triggers
> 3 ogr for final import
>
>
>> Even,
>>
>> Appreciate the response.
>>
>> Your example is interesting but there are a couple of issues. 
>> Importing a random .000 file using ogr2ogr yields 6 tables in the 
>> database. Which tables are created depend on the data and are unknown 
>> to me prior to import, so it is difficult to generate the SQL in 
>> advance. This approach does not scale very well if data yields a 
>> number of tables.
>>
>> Another issue was when adding the SQL statement for one specific 
>> table caused the import to ignore the other 5 tables. Is this the 
>> expect result or should all 6 table be imported?
>>
>> Regards, Lars
>>
>> ------------------------------------------------------------------------
>> *Fra:* Even Rouault <even.rouault at spatialys.com> 
>> <mailto:even.rouault at spatialys.com>
>> *Sendt:* fredag 22. juni 2018 23.15
>> *Til:* gdal-dev at lists.osgeo.org <mailto:gdal-dev at lists.osgeo.org>
>> *Kopi:* Lars
>> *Emne:* Re: [gdal-dev] ogr2ogr adding metadata
>> On vendredi 22 juin 2018 09:41:02 CEST Lars wrote:
>> > Hello folks,
>> >
>> > Using ogr2ogr (version 2.2.3) to import s57 into PostgreSQL which works
>> > great.
>> >
>> > What is the recommended approach for adding metadata to all 
>> inserted data?
>> >
>> > Say I wanted to add current date to all inserted data. Does ogr2ogr 
>> support
>> > such operation? Tried using the "-mo" argument but it did not make any
>> > inpact (same result with argument as without). Ideally I do not 
>> want the
>> > client to be adding this information as a post insert operation (if 
>> even
>> > possible).
>>
>> Lars,
>>
>> -mo will work only with very few target drivers (I can only think to
>> GeoPackage actually). This is per-layer/per-table metadata. There's 
>> perhaps
>> the equivalent in PostgreSQL but this isn't implemented by GDAL
>>
>> But you can add a column with the current timestamp for example with
>>
>> ogr2ogr -update PG:xxxxxx poly.shp \
>>        -sql "SELECT *, CURRENT_TIMESTAMP FROM poly" -dialect SQLITE
>>
>> Even
>>
>> -- 
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>>
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org <mailto:gdal-dev at lists.osgeo.org>
>> https://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> -- 
> Hälsningar
>
> Andreas Oxenstierna
> T-Kartor Geospatial AB
> mobile: +46 733 206831
> mailto:ao at t-kartor.se <mailto:ao at t-kartor.se>
> http://www.t-kartor.com


-- 
Hälsningar

Andreas Oxenstierna
T-Kartor Geospatial AB
mobile: +46 733 206831
mailto: ao at t-kartor.se
http://www.t-kartor.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180702/878d8d56/attachment.html>

From even.rouault at spatialys.com  Mon Jul  2 08:08:03 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 02 Jul 2018 17:08:03 +0200
Subject: [gdal-dev] /vsizip/ improvements: multi-threaded compression,
	ZIP64 creation
Message-ID: <3226021.ZM5GoroVRt@even-i700>

Hi,

Following a discussion with 'velix' on IRC who pointed to me the pigz utility
( https://zlib.net/pigz/ ) that does multi-threaded compression of gzip files,
I've committed in GDAL master a similar mechanism in the /vsigzip/ and
/vsizip/ virtual file systems. If you set GDAL_NUM_THREADS to a value greater
than 1 or to ALL_CPUS, multi-threaded DEFLATE compression will be done. This
uses the equivalent of the pigz independent mode, where uncompressed chunks
(of size 1 megabyte by default) are compressed in an independent way [1],
and compressed chunks are simply appended. The resulting codestream is
perfectly standard. If the reading of the input data is not the limiting
factor, this scales quite well with the number of threads.

You can use the following small Python script to test creation of zip files
(it enables GDAL_NUM_THREADS=ALL_CPUS by default).

https://raw.githubusercontent.com/OSGeo/gdal/master/gdal/swig/python/samples/gdal_zip.py

$ python gdal_zip.py my.zip srcfile1 srcfile2 ...

(Note that the multi-threaded compression is per file, not parallelized
compression of several files at once.)

Given that I've opted for the equivalent of pigz independent mode, one
drawback is a slight decrease in the compression ratio, due to the 
clearing of the dictionary, but given the large enough chunk size, this is
normally barely noticeable.

But the main advantage of independent mode is that independent decompression
could potentially be implemented. If we would serialize the offset of each
independant chunk, we could implement efficient seeking in the file, whereas,
currently if you want to read a byte at the end of a deflate stream, you need
to decompress the whole stream. Here you would need to decompress at most 1MB.
This could be done by writting a special file with those offsets of independent
chunks inside a .zip archive, potentially hidden for other applications (you 
can have holes in zip). It could also be possible to do multithreaded 
decompression (if enough uncompressed data is requested at once, or if we detect 
a read pattern that seems to imply the whole file would be read). If people are
interested to fund the implementation of such functionalities, feel free to
contact me.

Another fix/improvement I did is ZIP64 ([2]) creation. ZIP64 reading was
supported, but up to now, if using /vsizip/ in write mode and the uncompressed
or compressed size of a file was greater than 4GB, or the whole .zip was > 4 GB,
the resulting .zip would be corrupted (file sizes and internal offsets
truncated to their lower 32 bit part), due to ZIP64 not being used. I've thus
resynchronized with zlib' minizip to fix that.
One potential downside is that given how GDAL creates zip file and zip file
structural constraints, GDAL must add a ZIP64 extra field in the "local file
header", even if it is eventually unused. The unzip utility on Linux and the
Windows file manager of Windows 7 are happy with that, but I'd appreciate
if some testing could be done by users with other zip readers (on Mac
particularly that apparently may have issues with ZIP64).
You can try opening this smallish zip archive:

https://github.com/OSGeo/gdal/blob/master/autotest/gcore/data/byte_zip64_local_header_zeroed.zip?raw=true

Even

[1] pigz in standard mode can also compress in a multithreaded way, with
non-initial chunks depending on the history of the last 32 KB of the
preceding uncompressed chunk. The resulting stream is thus nearly as small
as classical compression, but independent decompression of the chunks is
not possible. In independent mode, a full synchronization marker terminates
each compressed chunk and the decompressor clears its dictionary.

[2] not to be confused with Deflate64, a proprietary variant of Deflate, that
some Windows versions unfortunately and unnecessarily use for files > 4 GB,
and which is unsupported by zlib.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From klassen.js at gmail.com  Mon Jul  2 11:40:07 2018
From: klassen.js at gmail.com (Jim Klassen)
Date: Mon, 2 Jul 2018 13:40:07 -0500
Subject: [gdal-dev]  Esri JSON Curves
In-Reply-To: <3910957.a1sd9sZLSe@even-i700>
References: <CAHqX796fb24M9yV9_PQ3A4C9BhJwyiB2wFs+KJ-9Sk+daY8ipQ@mail.gmail.com>
 <1987619.y9MCUktVRS@even-i700>
 <e4e7e572-5de8-1f8b-f301-c809fdd4ff38@gmail.com>
 <3910957.a1sd9sZLSe@even-i700>
Message-ID: <ff96c5fc-a780-0a30-78bf-330dadea0be5@gmail.com>


On Mon, Jun 25, 2018 at 4:14 PM, Even Rouault
<even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>> wrote:


    > > If my memories are right, you only need to set it for write
    support. So
    > > shouldn't be needed there.
    >
    > All I know is that without it set, the curved geometries were
    linearized
    > somewhere in OGR before they were passed to the PostGIS driver.

    You should double check and spot where this comes from.
    You can set a breakpoint on OGRGeometryFactory::curveToLineString
    which should
    be taken when linearization occurs.

    As an experience, I've disabled OLCCurveGeometries and
    ODsCCurveGeometries
    capability declaration in the CSV driver, and no linearization
    occurs when
    converting to PostGIS


I've narrowed it down some more... it looks like OLCCurveGeometries is
necessary for the geometry type to be passed correctly to PostGIS.
ODsCCurveGeometries doesn't seem to matter.

Command:
gdb --args ${OGR2OGR} \
    -overwrite \
    Pg: \
    "${SRC_URL}" \
    -nln temp.parcels_test \
    -nlt PROMOTE_TO_MULTI \
    ESRIJSON
break OGRGeometryFactory::curveToLineString
run


With OLCCurveGeometries and ODsCCurveGeometries false, I get the following:

Warning 1: Geometry to be inserted is of type Multi Polygon, whereas the
layer geometry type is Multi Surface.
Insertion is likely to fail
ERROR 1: COPY statement failed.
ERROR:  Geometry type (MultiPolygon) does not match column type
(MultiSurface)
CONTEXT:  COPY parcels_test, line 1, column wkb_geometry:
"010600002032BF0D000100000001030000000100000007000000803E1A3ACD582241005A55E36CF00A4100DF0D0B13582241..."

With OLCCurveGeometries false and ODsCCurveGeometries true:

Warning 1: Geometry to be inserted is of type Multi Polygon, whereas the
layer geometry type is Multi Surface.
Insertion is likely to fail
ERROR 1: COPY statement failed.
ERROR:  Geometry type (MultiPolygon) does not match column type
(MultiSurface)
CONTEXT:  COPY parcels_test, line 1, column wkb_geometry:
"010600002032BF0D000100000001030000000100000007000000803E1A3ACD582241005A55E36CF00A4100DF0D0B13582241..."

With OLCCurveGeometries true and ODsCCurveGeometries false:

No Warning.
Works as expected.

With OLCCurveGeometries true and ODsCCurveGeometries true:

No Warning.
Works as expected.


In the first two cases (without OLCCurveGeometries set) I see
curveToLineString is being called when there are curves in the data, but
not on every result page (again curves are relatively rare in the dataset).


(gdb) bt
#0  0x00007ffff6f66f50 in OGRGeometryFactory::curveToLineString(double,
double, double, double, double, double, double, double, double, int,
double, char const* const*)@plt () from
/srv/www/apps/ogr-esricurve/lib/libgdal.so.20
#1  0x00007ffff6fadf37 in OGRCircularString::CurveToLine (this=0x10436d0,
    dfMaxAngleStepSizeDegrees=0, papszOptions=0x0) at
ogrcircularstring.cpp:677
#2  0x00007ffff6fb04a2 in OGRCompoundCurve::CurveToLineInternal (
    this=0x10435e0, dfMaxAngleStepSizeDegrees=0, papszOptions=0x0,
    bIsLinearRing=<optimized out>) at ogrcompoundcurve.cpp:357
#3  0x00007ffff6fb55f7 in OGRCurvePolygon::CurvePolyToPoly (this=0x10435b0,
    dfMaxAngleStepSizeDegrees=0, papszOptions=0x0) at
ogrcurvepolygon.cpp:578
#4  0x00007ffff6fd7ae2 in OGRGeometryFactory::forceToPolygon
(poGeom=0x10435b0)
    at ogrgeometryfactory.cpp:688
#5  0x00007ffff6fd9118 in OGRGeometryFactory::forceTo (poGeom=0x10435b0,
    eTargetType=eTargetType at entry=wkbPolygon,
    papszOptions=papszOptions at entry=0x0) at ogrgeometryfactory.cpp:4494
#6  0x00007ffff7641bcc in OGRLayer::ConvertGeomsIfNecessary (
    this=this at entry=0x2bd3320, poFeature=poFeature at entry=0xf7f790)
    at ogrlayer.cpp:576
#7  0x00007ffff7641bf1 in OGRLayer::SetFeature (this=0x2bd3320,
    poFeature=0xf7f790) at ogrlayer.cpp:590
#8  0x00007ffff75e25a9 in OGRGeoJSONLayer::AddFeature (this=0x2bd3320,
    poFeature=poFeature at entry=0xf7f790) at ogrgeojsonlayer.cpp:513
#9  0x00007ffff75da482 in OGRESRIJSONReader::AddFeature (this=<optimized
out>,
---Type <return> to continue, or q <return> to quit---
    poFeature=0xf7f790) at ogresrijsonreader.cpp:287
#10 0x00007ffff75dbcfd in OGRESRIJSONReader::ReadFeatureCollection (
    this=this at entry=0x7fffffffd6c0, poObj=<optimized out>)
    at ogresrijsonreader.cpp:464
#11 0x00007ffff75dbdfb in OGRESRIJSONReader::ReadLayers
(this=0x7fffffffd6c0,
    poDS=0x1679750, eSourceType=<optimized out>) at
ogresrijsonreader.cpp:139
#12 0x00007ffff75defeb in OGRGeoJSONDataSource::LoadLayers (
    this=this at entry=0x1679750, poOpenInfo=poOpenInfo at entry=0x7fffffffd860,
    nSrcType=nSrcType at entry=eGeoJSONSourceService,
    pszUnprefixed=pszUnprefixed at entry=0x15ecd20 "https://maps..."...,
pszJSonFlavor=pszJSonFlavor at entry=0x1c4e628 "ESRIJSON")
    at ogrgeojsondatasource.cpp:785
#13 0x00007ffff75dffa0 in OGRGeoJSONDataSource::Open (
    this=this at entry=0x1679750, poOpenInfo=poOpenInfo at entry=0x7fffffffd860,
    nSrcType=eGeoJSONSourceService, pszJSonFlavor=0x1c4e628 "ESRIJSON")
    at ogrgeojsondatasource.cpp:179
#14 0x00007ffff75e133e in OGRESRIFeatureServiceDataset::LoadPage (
    this=0x6956e0) at ogrgeojsondriver.cpp:408
#15 0x00007ffff75e14e7 in OGRESRIFeatureServiceDataset::LoadNextPage (
    this=<optimized out>) at ogrgeojsondriver.cpp:390
#16 0x00007ffff75e1628 in OGRESRIFeatureServiceLayer::GetNextFeature (
---Type <return> to continue, or q <return> to quit---
    this=0x9009c0) at ogrgeojsondriver.cpp:177
#17 0x00007ffff70b90a9 in LayerTranslator::Translate (
    this=this at entry=0x7fffffffdd20, poFeatureIn=poFeatureIn at entry=0x0,
    psInfo=psInfo at entry=0x29ae270, nCountLayerFeatures=0,
    pnReadFeatureCount=pnReadFeatureCount at entry=0x0,
    nTotalEventsDone=@0x7fffffffdb58: 0, pfnProgress=0x0, pProgressArg=0x0,
    psOptions=0x6960b0) at ogr2ogr_lib.cpp:4392
#18 0x00007ffff70c0779 in GDALVectorTranslate (pszDest=<optimized out>,
    hDstDS=hDstDS at entry=0x0, nSrcCount=nSrcCount at entry=1,
    pahSrcDS=pahSrcDS at entry=0x7fffffffdeb0,
    psOptionsIn=psOptionsIn at entry=0x693b40,
    pbUsageError=pbUsageError at entry=0x7fffffffdeac) at ogr2ogr_lib.cpp:3060
#19 0x00000000004019e7 in main (nArgc=<optimized out>, papszArgv=0x693ae0)
    at ogr2ogr_bin.cpp:412


In the last two cases (with OLCCurveGeometries set) I see
curveToLineString is being called with a different back trace (related
to OGRGeometryFactory::organizePolygons):

#0  0x00007ffff6f66f50 in OGRGeometryFactory::curveToLineString(double,
double, double, double, double, double, double, double, double, int,
double, char const* const*)@plt () from
/srv/www/apps/ogr-esricurve/lib/libgdal.so.20
#1  0x00007ffff6fadf37 in OGRCircularString::CurveToLine
(this=0x19ce4d0, dfMaxAngleStepSizeDegrees=0, papszOptions=0x0) at
ogrcircularstring.cpp:677
#2  0x00007ffff6fb04a2 in OGRCompoundCurve::CurveToLineInternal
(this=0x19ce3e0, dfMaxAngleStepSizeDegrees=0, papszOptions=0x0,
    bIsLinearRing=<optimized out>) at ogrcompoundcurve.cpp:357
#3  0x00007ffff6fd2f95 in OGRGeometryFactory::organizePolygons
(papoPolygons=papoPolygons at entry=0x19ce390,
nPolygonCount=nPolygonCount at entry=2,
    pbIsValidGeometry=pbIsValidGeometry at entry=0x0,
papszOptions=papszOptions at entry=0x0) at ogrgeometryfactory.cpp:1537
#4  0x00007ffff75daff7 in OGRESRIJSONReadPolygon
(poObj=poObj at entry=0x1e50050) at ogresrijsonreader.cpp:1070
#5  0x00007ffff75db761 in OGRESRIJSONReader::ReadGeometry
(this=this at entry=0x7fffffffd6c0, poObj=poObj at entry=0x1e50050) at
ogresrijsonreader.cpp:307
#6  0x00007ffff75db990 in OGRESRIJSONReader::ReadFeature
(this=this at entry=0x7fffffffd6c0, poObj=poObj at entry=0x1e4a590) at
ogresrijsonreader.cpp:415
#7  0x00007ffff75dbcf2 in OGRESRIJSONReader::ReadFeatureCollection
(this=this at entry=0x7fffffffd6c0, poObj=<optimized out>)
    at ogresrijsonreader.cpp:463
#8  0x00007ffff75dbdfb in OGRESRIJSONReader::ReadLayers
(this=0x7fffffffd6c0, poDS=0x3433f70, eSourceType=<optimized out>)
    at ogresrijsonreader.cpp:139
#9  0x00007ffff75defeb in OGRGeoJSONDataSource::LoadLayers
(this=this at entry=0x3433f70, poOpenInfo=poOpenInfo at entry=0x7fffffffd860,
    nSrcType=nSrcType at entry=eGeoJSONSourceService,
    pszUnprefixed=pszUnprefixed at entry=0x2c2f680 "https://maps...."...,
    pszJSonFlavor=pszJSonFlavor at entry=0x1011c48 "ESRIJSON") at
ogrgeojsondatasource.cpp:785
#10 0x00007ffff75dffa0 in OGRGeoJSONDataSource::Open
(this=this at entry=0x3433f70, poOpenInfo=poOpenInfo at entry=0x7fffffffd860,
    nSrcType=eGeoJSONSourceService, pszJSonFlavor=0x1011c48 "ESRIJSON")
at ogrgeojsondatasource.cpp:179
#11 0x00007ffff75e133e in OGRESRIFeatureServiceDataset::LoadPage
(this=0x6956e0) at ogrgeojsondriver.cpp:408
#12 0x00007ffff75e14e7 in OGRESRIFeatureServiceDataset::LoadNextPage
(this=<optimized out>) at ogrgeojsondriver.cpp:390
#13 0x00007ffff75e1628 in OGRESRIFeatureServiceLayer::GetNextFeature
(this=0x9009c0) at ogrgeojsondriver.cpp:177
#14 0x00007ffff70b90a9 in LayerTranslator::Translate
(this=this at entry=0x7fffffffdd20, poFeatureIn=poFeatureIn at entry=0x0,
    psInfo=psInfo at entry=0x2bb59c0, nCountLayerFeatures=0,
pnReadFeatureCount=pnReadFeatureCount at entry=0x0,
nTotalEventsDone=@0x7fffffffdb58: 6000,
    pfnProgress=0x0, pProgressArg=0x0, psOptions=0x6960b0) at
ogr2ogr_lib.cpp:4392
#15 0x00007ffff70c0779 in GDALVectorTranslate (pszDest=<optimized out>,
hDstDS=hDstDS at entry=0x0, nSrcCount=nSrcCount at entry=1,
    pahSrcDS=pahSrcDS at entry=0x7fffffffdeb0,
psOptionsIn=psOptionsIn at entry=0x693b40,
pbUsageError=pbUsageError at entry=0x7fffffffdeac)
    at ogr2ogr_lib.cpp:3060
#16 0x00000000004019e7 in main (nArgc=<optimized out>,
papszArgv=0x693ae0) at ogr2ogr_bin.cpp:412
(gdb) cont
Continuing.

From even.rouault at spatialys.com  Mon Jul  2 11:56:42 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 02 Jul 2018 20:56:42 +0200
Subject: [gdal-dev] Esri JSON Curves
In-Reply-To: <ff96c5fc-a780-0a30-78bf-330dadea0be5@gmail.com>
References: <CAHqX796fb24M9yV9_PQ3A4C9BhJwyiB2wFs+KJ-9Sk+daY8ipQ@mail.gmail.com>
 <3910957.a1sd9sZLSe@even-i700>
 <ff96c5fc-a780-0a30-78bf-330dadea0be5@gmail.com>
Message-ID: <1799257.XZN1n8Dzpk@even-i700>

> 
> In the first two cases (without OLCCurveGeometries set) I see
> curveToLineString is being called when there are curves in the data, but
> not on every result page (again curves are relatively rare in the dataset).

ok, then replace the call to OGRMemLayer::SetFeature() with 
OGRMemLayer::ISetFeature() in ogrgeojsonlayer.cpp to shortcut the 
linearization that is done by the generic OGRLayer::SetFeature()

And you can then remove OLCCurveGeometries


> In the last two cases (with OLCCurveGeometries set) I see
> curveToLineString is being called with a different back trace (related
> to OGRGeometryFactory::organizePolygons):

That one is fine. It is an implementation detail of organizePolygons()

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From guyd at satellogic.com  Mon Jul  2 23:06:49 2018
From: guyd at satellogic.com (Guy Doulberg)
Date: Tue, 3 Jul 2018 09:06:49 +0300
Subject: [gdal-dev] Cache when dealing with several processes and COG
Message-ID: <CAJ18MZr6o25ndTSPu16tOrN+B1sWy+rP3sGjHSWnvRTw_Cx1Yg@mail.gmail.com>

Hi guys,

I am working on a tileserver use case on top of cogs.

I  want to find a cache mechanism to my architecture.

The tile-server architecture is several python processes(gunicorn) running
on several VMs.

I understand how GDAL caches the curl blocks or the raster using
intra-process caching, but I can't use this cache in the other
processes/vms.

I was thinking maybe to use some kind of http proxy server that will cache
the bytes content retrieved from the http server holding the cogs (Azure
blob storage)

There is some data that can be reused(therefore cached) across all tile
requests for example:
1. The file size (HEAD)
2. The first header block
3. The other header blocks
4. maybe in some cases the image blocks themselves (in case you take the
same blocks all the time but change something in the presentation layer)

did any of you tried this architecture or used a different way to cache
across servers?  maybe there is a way to share GDAL_CACHE across process
that I missed?

Thanks,
Guy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180703/cd8b1647/attachment.html>

From guyd at satellogic.com  Mon Jul  2 23:16:34 2018
From: guyd at satellogic.com (Guy Doulberg)
Date: Tue, 3 Jul 2018 09:16:34 +0300
Subject: [gdal-dev] Tiled GeoTiff that reduce the amount of reads in XYZ
	maps
In-Reply-To: <CAJ18MZpZUt4bctqBHLe8KwV6_mcRwaLjWewbmAojr5eVEWre_w@mail.gmail.com>
References: <CAJ18MZoKqSB0FQEnbdJ+hSk5hTU9JETSe9yA+jEUNqbYBGVWfg@mail.gmail.com>
 <4584053.NxyQt6sEcZ@even-i700>
 <CAJ18MZoPD+1sfqtf+CXmPK6V6zkeinZS1T7i1Df5yRiCm5sTfA@mail.gmail.com>
 <CAJ18MZpZUt4bctqBHLe8KwV6_mcRwaLjWewbmAojr5eVEWre_w@mail.gmail.com>
Message-ID: <CAJ18MZona4awi9_TZ5uuCzCUd6pGznTo-qdz=+LUaKTwwCSdfw@mail.gmail.com>

Even suggestions worked for me,

I am working on code that can ease the process of doing that

https://github.com/satellogic/telluric/blob/get_tile_aligned/telluric/georaster.py#L1344

I will update when it is done

After working with that I realized that now I have a new question. How
deep(low) to go in alignments.

If I align the raster only in the zoom level the raster is at then I might
fetch more then one tile of overviews image data when overviews are used,
but to align the raster to zoom level that is very low doesn't make sense
either since the headers will be huge.

How do you guys deal with this case?



On Sun, Jun 17, 2018 at 5:25 PM, Guy Doulberg <guyd at satellogic.com> wrote:

> it is 1/3 because the original was not compressed,
>
> anyhow I am still getting too many requests when fetching a tile, maybe my
> read code is not doing what I think it is doing
>
>
>
> On Sun, Jun 17, 2018 at 4:51 PM, Guy Doulberg <guyd at satellogic.com> wrote:
>
>> Thanks Even
>>
>> I tried both ways and in both I am still getting a lot of requests, I am
>> exepcting only few, one for the headers and one for the tile:
>>
>>
>> The resolution I used is driven from https://wiki.openstreetmap.org
>> /wiki/Zoom_levels
>>
>> and the bounds I calculated using mercantile
>>
>> so an example of what I ran is:
>>
>> gdal_translate source.tif target.tif -co TILED=YES -co
>> COPY_SRC_OVERVIEWS=YES -co COMPRESS=LZW -tr 0.596 0.596   -projwin
>> 675091.8338146766 4706074.957461731 684875.7734351791 4696291.017841227
>>
>> One more thing, the raster I got is 1/3 of the size of the original raster
>>
>> On Sun, Jun 17, 2018 at 12:00 PM, Even Rouault <
>> even.rouault at spatialys.com> wrote:
>>
>>> On dimanche 17 juin 2018 10:19:34 CEST Guy Doulberg wrote:
>>> > Hi all,
>>> >
>>> > I am trying to use cloud optimized geotiff(cog) to reduce the block
>>> fetched
>>> > when accessing a raster.
>>> >
>>> > The use case I am trying to build, is a TileServer that serves tile in
>>> > openlayer map.
>>> > The rasters are to be stored on a remote location, in my case azure
>>> blob
>>> > storage.
>>> >
>>> > We were able to do that, and you can see the code here:
>>> > https://github.com/satellogic/telluric/blob/master/telluric/
>>> > georaster.py#L1497
>>> >
>>> > The problem is, when running in verbose mode I can see that there are
>>> many
>>> > requests to the blob storage,
>>> >
>>> > I am responsible of creating the raster, is there a way in your
>>> opinion I
>>> > can create the raster aligned to the XYZ tiling system so when I try to
>>> > fetch a tile from the raster I will be able to do that with a single or
>>> > close to that call?
>>>
>>> If your raster source is not already in WebMercator projection, you
>>> could use
>>> gdalwarp with the appropriate -te and -tr to align on the boundaries of
>>> XYZ
>>> tiling scheme at a given zoom level.
>>>
>>> If your raster is already in WebMercator, gdal_translate -projwin -tr
>>> would do
>>>
>>> If you don't want to compute the bounds, you could use gdal_translate to
>>> MBTiles that will use gdalwarp internally to reproject and align on XYZ
>>> tiling
>>> scheme automatically, followed by gdal_translate to TIFF with -oo
>>> USE_BOUNDS=NO so that the extent used aligns on tile boundaries.
>>>
>>> Even
>>>
>>> --
>>> Spatialys - Geospatial professional services
>>> http://www.spatialys.com
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180703/138e563b/attachment.html>

From sean at mapbox.com  Tue Jul  3 09:34:32 2018
From: sean at mapbox.com (Sean Gillies)
Date: Tue, 3 Jul 2018 10:34:32 -0600
Subject: [gdal-dev] Cache when dealing with several processes and COG
In-Reply-To: <CAJ18MZr6o25ndTSPu16tOrN+B1sWy+rP3sGjHSWnvRTw_Cx1Yg@mail.gmail.com>
References: <CAJ18MZr6o25ndTSPu16tOrN+B1sWy+rP3sGjHSWnvRTw_Cx1Yg@mail.gmail.com>
Message-ID: <CADPhZXxC_E1_Zt-equ6z2YYwa5LKp80nk1YZmoCCjDj0vcSOmQ@mail.gmail.com>

Hi Guy,

On Tue, Jul 3, 2018 at 12:06 AM Guy Doulberg <guyd at satellogic.com> wrote:

> Hi guys,
>
> I am working on a tileserver use case on top of cogs.
>
> I  want to find a cache mechanism to my architecture.
>
> The tile-server architecture is several python processes(gunicorn) running
> on several VMs.
>
> I understand how GDAL caches the curl blocks or the raster using
> intra-process caching, but I can't use this cache in the other
> processes/vms.
>
> I was thinking maybe to use some kind of http proxy server that will cache
> the bytes content retrieved from the http server holding the cogs (Azure
> blob storage)
>
> There is some data that can be reused(therefore cached) across all tile
> requests for example:
> 1. The file size (HEAD)
> 2. The first header block
> 3. The other header blocks
> 4. maybe in some cases the image blocks themselves (in case you take the
> same blocks all the time but change something in the presentation layer)
>
> did any of you tried this architecture or used a different way to cache
> across servers?  maybe there is a way to share GDAL_CACHE across process
> that I missed?
>
> Thanks,
> Guy
>

Nginx advertises some support for byte range caching that I've been meaning
to try: https://www.nginx.com/blog/smart-efficient-byte-range-caching-nginx/
.

My own strategy so far has been to deploy to the same cloud as the data and
profit from higher bandwidth and not to think about caching very much at
all.

-- 
Sean Gillies
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180703/ace2cd8e/attachment.html>

From even.rouault at spatialys.com  Wed Jul  4 11:11:56 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 04 Jul 2018 20:11:56 +0200
Subject: [gdal-dev] Tiled GeoTiff that reduce the amount of reads in XYZ
	maps
In-Reply-To: <CAJ18MZona4awi9_TZ5uuCzCUd6pGznTo-qdz=+LUaKTwwCSdfw@mail.gmail.com>
References: <CAJ18MZoKqSB0FQEnbdJ+hSk5hTU9JETSe9yA+jEUNqbYBGVWfg@mail.gmail.com>
 <CAJ18MZpZUt4bctqBHLe8KwV6_mcRwaLjWewbmAojr5eVEWre_w@mail.gmail.com>
 <CAJ18MZona4awi9_TZ5uuCzCUd6pGznTo-qdz=+LUaKTwwCSdfw@mail.gmail.com>
Message-ID: <6346927.bPnA9cgIW1@even-i700>

On mardi 3 juillet 2018 09:16:34 CEST Guy Doulberg wrote:
> Even suggestions worked for me,
> 
> I am working on code that can ease the process of doing that
> 
> https://github.com/satellogic/telluric/blob/get_tile_aligned/telluric/georas
> ter.py#L1344
> 
> I will update when it is done
> 
> After working with that I realized that now I have a new question. How
> deep(low) to go in alignments.
> 
> If I align the raster only in the zoom level the raster is at then I might
> fetch more then one tile of overviews image data when overviews are used,
> but to align the raster to zoom level that is very low doesn't make sense
> either since the headers will be huge.
> 
> How do you guys deal with this case?

There's no good way of solving this with a single GeoTIFF File. You would need 
each overview level to have possibly a different extent than the main overview 
level. While you could put several images in the same GeoTIFF file with each 
their GeoTIFF keys, that would no longer be overviews in the TIFF meaning (and 
there is no support in GDAL for that).

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From guyd at satellogic.com  Thu Jul  5 04:00:13 2018
From: guyd at satellogic.com (Guy Doulberg)
Date: Thu, 5 Jul 2018 14:00:13 +0300
Subject: [gdal-dev] Cache when dealing with several processes and COG
In-Reply-To: <CADPhZXxC_E1_Zt-equ6z2YYwa5LKp80nk1YZmoCCjDj0vcSOmQ@mail.gmail.com>
References: <CAJ18MZr6o25ndTSPu16tOrN+B1sWy+rP3sGjHSWnvRTw_Cx1Yg@mail.gmail.com>
 <CADPhZXxC_E1_Zt-equ6z2YYwa5LKp80nk1YZmoCCjDj0vcSOmQ@mail.gmail.com>
Message-ID: <CAJ18MZpRzae_bzTM+TVwYF3EAq+=cSGigm3zrW8b1gLrssmCAQ@mail.gmail.com>

Thanks, Sean

I followed the links. it seem to be working only for HTTP and not for
HTTPS, I might still use it.

One thing you need to consider when using Nginx split caching is to
configure the range of the content you want to cache.

if you are caching range is 1K and your block is 999-1500 nginx will fetch
blocks 0-1024 and 1024-2048 to return you the block you originally
requested, I wonder if I can align this range configuration to the data
blocks in a COG, I think I can't right? there is no way of knowing the
sizes of the block without reading the headers, right? especially if I am
using compression,

Guy



On Tue, Jul 3, 2018 at 7:34 PM, Sean Gillies <sean at mapbox.com> wrote:

> Hi Guy,
>
> On Tue, Jul 3, 2018 at 12:06 AM Guy Doulberg <guyd at satellogic.com> wrote:
>
>> Hi guys,
>>
>> I am working on a tileserver use case on top of cogs.
>>
>> I  want to find a cache mechanism to my architecture.
>>
>> The tile-server architecture is several python processes(gunicorn)
>> running on several VMs.
>>
>> I understand how GDAL caches the curl blocks or the raster using
>> intra-process caching, but I can't use this cache in the other
>> processes/vms.
>>
>> I was thinking maybe to use some kind of http proxy server that will
>> cache the bytes content retrieved from the http server holding the cogs
>> (Azure blob storage)
>>
>> There is some data that can be reused(therefore cached) across all tile
>> requests for example:
>> 1. The file size (HEAD)
>> 2. The first header block
>> 3. The other header blocks
>> 4. maybe in some cases the image blocks themselves (in case you take the
>> same blocks all the time but change something in the presentation layer)
>>
>> did any of you tried this architecture or used a different way to cache
>> across servers?  maybe there is a way to share GDAL_CACHE across process
>> that I missed?
>>
>> Thanks,
>> Guy
>>
>
> Nginx advertises some support for byte range caching that I've been
> meaning to try: https://www.nginx.com/blog/smart-efficient-byte-range-
> caching-nginx/.
>
> My own strategy so far has been to deploy to the same cloud as the data
> and profit from higher bandwidth and not to think about caching very much
> at all.
>
> --
> Sean Gillies
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/15c61332/attachment.html>

From tom.van.tilburg at gmail.com  Thu Jul  5 05:22:16 2018
From: tom.van.tilburg at gmail.com (Tom van Tilburg)
Date: Thu, 5 Jul 2018 14:22:16 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
Message-ID: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>

I have a fresh gdal 2.3.1 build on a ubuntu 17.10 that tells me:

> gdalinfo dem.tif -stats -mm
[..snip...]
Band 1 Block=2200x1 Type=Float32, ColorInterp=Gray
  Min=-2.233 Max=340282346638529993179660072199368212480.000   Computed
Min/Max=-2.233,340282346638528859811704183484516925440.000
  Minimum=-2.233, Maximum=340282346638529993179660072199368212480.000,
Mean=42029510023671999325552505715632898048.000,
StdDev=111961692493879995008202507419807383552.000
  NoData Value=3.40282346638529011e+38
  Metadata:
    STATISTICS_MAXIMUM=3.4028234663853e+38
    STATISTICS_MEAN=4.2029510023672e+37
    STATISTICS_MINIMUM=-2.2330000400543
    STATISTICS_STDDEV=1.1196169249388e+38

Obviously, cells with nodata value are included in the stats, although
rounded. This seems wrong to me and I know gdal propagates the values with
for instance gdal_translate.

When doing the same thing on my osgeo4w64 with gdal 2.2.4 or gdal 2.4.0
(dev) it tells me:

> gdalinfo dem.tif -stats -mm
[..snip...]
Band 1 Block=2200x1 Type=Float32, ColorInterp=Gray
  Min=-2.233 Max=2.176   Computed Min/Max=-2.233,2.176
  Minimum=-2.233, Maximum=2.176, Mean=0.169, StdDev=0.316
  NoData Value=3.40282346638529011e+38
  Metadata:
    STATISTICS_MAXIMUM=2.1760001182556
    STATISTICS_MEAN=0.16871771630616
    STATISTICS_MINIMUM=-2.2330000400543
    STATISTICS_STDDEV=0.31600319455862

This seems to be the correct answer.

Worth noticing: there is another gdal libs from package on the linux
machine:
gdal-data                                  2.2.1+dfsg-2build3
libgdal20                                  2.2.1+dfsg-2build3
python3-gdal                               2.2.1+dfsg-2build3

Any thoughts?

Best,
 Tom
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/a293a072/attachment.html>

From even.rouault at spatialys.com  Thu Jul  5 09:06:56 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 05 Jul 2018 18:06:56 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
Message-ID: <4519399.145nyadzmu@even-i700>

On jeudi 5 juillet 2018 14:22:16 CEST Tom van Tilburg wrote:
> I have a fresh gdal 2.3.1 build on a ubuntu 17.10 that tells me:
> > gdalinfo dem.tif -stats -mm
> 
> [..snip...]
> Band 1 Block=2200x1 Type=Float32, ColorInterp=Gray
>   Min=-2.233 Max=340282346638529993179660072199368212480.000   Computed
> Min/Max=-2.233,340282346638528859811704183484516925440.000
>   Minimum=-2.233, Maximum=340282346638529993179660072199368212480.000,
> Mean=42029510023671999325552505715632898048.000,
> StdDev=111961692493879995008202507419807383552.000
>   NoData Value=3.40282346638529011e+38
>   Metadata:
>     STATISTICS_MAXIMUM=3.4028234663853e+38
>     STATISTICS_MEAN=4.2029510023672e+37
>     STATISTICS_MINIMUM=-2.2330000400543
>     STATISTICS_STDDEV=1.1196169249388e+38
> 
> Obviously, cells with nodata value are included in the stats, although
> rounded. This seems wrong to me and I know gdal propagates the values with
> for instance gdal_translate.

could you share the file ? (possibly in private if needed)

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sborda at umich.edu  Thu Jul  5 09:41:08 2018
From: sborda at umich.edu (Susan Borda)
Date: Thu, 5 Jul 2018 12:41:08 -0400
Subject: [gdal-dev] FITS format not listed in gdalinfo --formats
Message-ID: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>

Hi-
I'm new to gdal and am trying to use gdalinfo to read a *.fits file
(astronomy files), specifically the header. When I list the formats
supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS no longer
supported?

My end goal here is to have Apache Tika use the GDAL CLI to parse the
*.fits header so I can use Solr to index in my repository.

Any advice would be greatly appreciated.

Thanks,
Susan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/5f157bf3/attachment.html>

From WILLIAM.K.MAGEE at leidos.com  Thu Jul  5 09:38:45 2018
From: WILLIAM.K.MAGEE at leidos.com (Magee, Kelly)
Date: Thu, 5 Jul 2018 16:38:45 +0000
Subject: [gdal-dev] Support for S-100 and S-102
Message-ID: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>

Hi,

I know GDAL/OGR supports S-57 format, but could not see where it supports S-100.

Is there a plan to support the latest IHO S-100 and S-102 standards in the near future?

Regards,

Kelly Magee


--

William Kelly Magee | Leidos

Senior Software Engineer | Maritime Solutions Division

phone: 401.847.4210
<mailto:william.kelly.magee at leidos.com>william.kelly.magee at leidos.com <mailto:william.kelly.magee at leidos.com> | leidos.com/maritime <http://www.leidos.com/maritime>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/e318e538/attachment.html>

From even.rouault at spatialys.com  Thu Jul  5 09:45:10 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 05 Jul 2018 18:45:10 +0200
Subject: [gdal-dev] FITS format not listed in gdalinfo --formats
In-Reply-To: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
Message-ID: <2870428.kdFM3TiZ8S@even-i700>

On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
> Hi-
> I'm new to gdal and am trying to use gdalinfo to read a *.fits file
> (astronomy files), specifically the header. When I list the formats
> supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS no longer
> supported?

It is, but you must build GDAL against the CFITSIO library:
http://gdal.org/frmt_various.html#FITS

On Debian and derivatives, this is the libcfitsio-dev package.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sborda at umich.edu  Thu Jul  5 09:58:26 2018
From: sborda at umich.edu (Susan Borda)
Date: Thu, 5 Jul 2018 12:58:26 -0400
Subject: [gdal-dev] FITS format not listed in gdalinfo --formats
In-Reply-To: <2870428.kdFM3TiZ8S@even-i700>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
Message-ID: <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>

Thanks Evan, I saw that mentioned in the formats list but I'm not sure how
to "build GDAL" with this library. I just downloaded GDAL and it uses
Python 3.6 but the version of CFITSIO I found uses Python 2.x. I'm using a
Mac but can easily run all of this on Linux VM if need be.

-susan

On Thu, Jul 5, 2018 at 12:45 PM Even Rouault <even.rouault at spatialys.com>
wrote:

> On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
> > Hi-
> > I'm new to gdal and am trying to use gdalinfo to read a *.fits file
> > (astronomy files), specifically the header. When I list the formats
> > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS no longer
> > supported?
>
> It is, but you must build GDAL against the CFITSIO library:
> http://gdal.org/frmt_various.html#FITS
>
> On Debian and derivatives, this is the libcfitsio-dev package.
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>


-- 
Susan Borda
Data Workflows Specialist
Research Data Services
University of Michigan Libraries
3175 Shapiro Library
734-764-9134 | sborda at umich.edu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/f182ca3f/attachment.html>

From thare at usgs.gov  Thu Jul  5 10:12:10 2018
From: thare at usgs.gov (Trent Hare)
Date: Thu, 5 Jul 2018 10:12:10 -0700
Subject: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo
	--formats
In-Reply-To: <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
 <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
Message-ID: <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>

 Susan,
   Yes -  the FITS format is supported in GDAL once compilation has been
linked to CFITSIO.

Note this driver is currently being enhanced to (1) better support FITS
files within GDAL and (2) the format FITS will have an extension added to
it, which allows more typical GIS map projection support. That branch of
GDAL is being worked on Chiara Marmo:
https://github.com/epn-vespa/gdal/tree/fits_driver

For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu) this
should get you FITS support in GDAL (and also get QGIS with FITS also).

*In order to have QGIS working with FITS*

   - install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
   - install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
   - install QGIS


*Temporary workaround:  *
  So a method Chiara created to test GDAL for FITS users is a simple Python
script which creates a GDAL VRT header pointing into the FITS file. Once
the VRT is created, any GDAL program can use it by pointing at the VRT file
(gdal_translate, QGIS, ArcMap, ...). Perhaps that is worth a shot.
https://github.com/epn-vespa/fits2vrt

Lastly, once the FITS driver is updated we will try to support an anaconda
version of GDAL with CFITSIO pre-built for users (should help Macs users
too).

Good luck,
Trent


P.S. maybe a little un-tested *build help* (linux again - sorry).

Install CFITSIO
Clone/download the GDAL repo.
$ cd gdal/gdal
you have compiled there the 'fits-driver' branch, using
$ ./configure
In that same repo you have a config.log file.
If you grep cfitsio in config.log you must have (among others, and
depending on your distro)
EXTRA_INCLUDES='-I/usr/include/cfitsio '
LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio -lz
-lpthread -lm -lrt -ldl  -lpcre'
now
$ ./make
more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix


On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu> wrote:

> Thanks Evan, I saw that mentioned in the formats list but I'm not sure how
> to "build GDAL" with this library. I just downloaded GDAL and it uses
> Python 3.6 but the version of CFITSIO I found uses Python 2.x. I'm using a
> Mac but can easily run all of this on Linux VM if need be.
>
> -susan
>
> On Thu, Jul 5, 2018 at 12:45 PM Even Rouault <even.rouault at spatialys.com>
> wrote:
>
>> On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
>> > Hi-
>> > I'm new to gdal and am trying to use gdalinfo to read a *.fits file
>> > (astronomy files), specifically the header. When I list the formats
>> > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS no longer
>> > supported?
>>
>> It is, but you must build GDAL against the CFITSIO library:
>> http://gdal.org/frmt_various.html#FITS
>>
>> On Debian and derivatives, this is the libcfitsio-dev package.
>>
>> --
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>>
>
>
> --
> Susan Borda
> Data Workflows Specialist
> Research Data Services
> University of Michigan Libraries
> 3175 Shapiro Library
> 734-764-9134 | sborda at umich.edu
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/3926ee3f/attachment.html>

From even.rouault at spatialys.com  Thu Jul  5 10:43:01 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 05 Jul 2018 19:43:01 +0200
Subject: [gdal-dev] Support for S-100 and S-102
In-Reply-To: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>
References: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>
Message-ID: <2391908.kjktXhKX3H@even-i700>

Kelly,

> 
> I know GDAL/OGR supports S-57 format, but could not see where it supports
> S-100.
> 
> Is there a plan to support the latest IHO S-100 and S-102 standards in the
> near future?

I'm not aware of anyone working on that currently.

I had difficulties finding concrete documentation about those standards 
(specification and test products). From my quick search, it looks like :
- S-100 is a conceptual model,
- S-101 is for ENC encoding, a successor of S-57. Apparently still using 
ISO-8211 for low level encoding.
- S-102 is bathymetric grid encoding in GeoTIFF or in BAG. So should be 
already handled by GDAL

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sborda at umich.edu  Thu Jul  5 10:54:29 2018
From: sborda at umich.edu (Susan Borda)
Date: Thu, 5 Jul 2018 13:54:29 -0400
Subject: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo
	--formats
In-Reply-To: <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
 <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
 <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
Message-ID: <CAKicayxYx-XQu_dVp+9A=U4_ZWx-AHkcjPbyGB9EMDyM=Ln2YA@mail.gmail.com>

Thanks, Trent and Evan, I'm building GDAL from source download rather than
using the "recommended" dmg listed. I'll let you know when I get it working
with CFITSIO and provide the steps in case you need them for someone else.

-susan

On Thu, Jul 5, 2018 at 1:13 PM Trent Hare <thare at usgs.gov> wrote:

> Susan,
>    Yes -  the FITS format is supported in GDAL once compilation has been
> linked to CFITSIO.
>
> Note this driver is currently being enhanced to (1) better support FITS
> files within GDAL and (2) the format FITS will have an extension added to
> it, which allows more typical GIS map projection support. That branch of
> GDAL is being worked on Chiara Marmo:
> https://github.com/epn-vespa/gdal/tree/fits_driver
>
> For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu)
> this should get you FITS support in GDAL (and also get QGIS with FITS also).
>
> *In order to have QGIS working with FITS*
>
>    - install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
>    - install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
>    - install QGIS
>
>
> *Temporary workaround:  *
>   So a method Chiara created to test GDAL for FITS users is a simple
> Python script which creates a GDAL VRT header pointing into the FITS file.
> Once the VRT is created, any GDAL program can use it by pointing at the VRT
> file (gdal_translate, QGIS, ArcMap, ...). Perhaps that is worth a shot.
> https://github.com/epn-vespa/fits2vrt
>
> Lastly, once the FITS driver is updated we will try to support an anaconda
> version of GDAL with CFITSIO pre-built for users (should help Macs users
> too).
>
> Good luck,
> Trent
>
>
> P.S. maybe a little un-tested *build help* (linux again - sorry).
>
> Install CFITSIO
> Clone/download the GDAL repo.
> $ cd gdal/gdal
> you have compiled there the 'fits-driver' branch, using
> $ ./configure
> In that same repo you have a config.log file.
> If you grep cfitsio in config.log you must have (among others, and
> depending on your distro)
> EXTRA_INCLUDES='-I/usr/include/cfitsio '
> LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio
> -lz -lpthread -lm -lrt -ldl  -lpcre'
> now
> $ ./make
> more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
>
>
> On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu> wrote:
>
>> Thanks Evan, I saw that mentioned in the formats list but I'm not sure
>> how to "build GDAL" with this library. I just downloaded GDAL and it uses
>> Python 3.6 but the version of CFITSIO I found uses Python 2.x. I'm using a
>> Mac but can easily run all of this on Linux VM if need be.
>>
>> -susan
>>
>> On Thu, Jul 5, 2018 at 12:45 PM Even Rouault <even.rouault at spatialys.com>
>> wrote:
>>
>>> On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
>>> > Hi-
>>> > I'm new to gdal and am trying to use gdalinfo to read a *.fits file
>>> > (astronomy files), specifically the header. When I list the formats
>>> > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS no longer
>>> > supported?
>>>
>>> It is, but you must build GDAL against the CFITSIO library:
>>> http://gdal.org/frmt_various.html#FITS
>>>
>>> On Debian and derivatives, this is the libcfitsio-dev package.
>>>
>>> --
>>> Spatialys - Geospatial professional services
>>> http://www.spatialys.com
>>>
>>
>>
>> --
>> Susan Borda
>> Data Workflows Specialist
>> Research Data Services
>> University of Michigan Libraries
>> 3175 Shapiro Library
>> 734-764-9134 | sborda at umich.edu
>>
>>
>

-- 
Susan Borda
Data Workflows Specialist
Research Data Services
University of Michigan Libraries
3175 Shapiro Library
734-764-9134 | sborda at umich.edu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/d8cc0a99/attachment-0001.html>

From jmckenna at gatewaygeomatics.com  Thu Jul  5 11:18:50 2018
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Thu, 5 Jul 2018 15:18:50 -0300
Subject: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo
 --formats
In-Reply-To: <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
 <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
 <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
Message-ID: <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>

Trent, is it possible that you record all these steps and hints for 
compiling FITS support at https://trac.osgeo.org/gdal/wiki/BuildHints 
(i.e. create a new wiki page there and add a link to your build page in 
the "External Library Issues" section)  That way the steps are recorded 
and easy to find (instead of lost in the email archives)

I'm happy to add a Windows section for compiling FITS as well.

thanks!

-jeff



On 2018-07-05 2:12 PM, Trent Hare wrote:
> Susan,
>     Yes -  the FITS format is supported in GDAL once compilation has 
> been linked to CFITSIO.
> 
> Note this driver is currently being enhanced to (1) better support FITS 
> files within GDAL and (2) the format FITS will have an extension added 
> to it, which allows more typical GIS map projection support. That branch 
> of GDAL is being worked on Chiara Marmo: 
> https://github.com/epn-vespa/gdal/tree/fits_driver
> 
> For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu) 
> this should get you FITS support in GDAL (and also get QGIS with FITS also).
> 
> _In order to have QGIS working with FITS_
> 
>   * install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
>   * install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
>   * install QGIS
> 
> 
> *_Temporary workaround_: *
>    So a method Chiara created to test GDAL for FITS users is a simple 
> Python script which creates a GDAL VRT header pointing into the FITS 
> file. Once the VRT is created, any GDAL program can use it by pointing 
> at the VRT file (gdal_translate, QGIS, ArcMap, ...). Perhaps that is 
> worth a shot.
> https://github.com/epn-vespa/fits2vrt
> 
> Lastly, once the FITS driver is updated we will try to support an 
> anaconda version of GDAL with CFITSIO pre-built for users (should help 
> Macs users too).
> 
> Good luck,
> Trent
> 
> 
> P.S. maybe a little un-tested *build help* (linux again - sorry).
> 
> Install CFITSIO
> Clone/download the GDAL repo.
> $ cd gdal/gdal
> you have compiled there the 'fits-driver' branch, using
> $ ./configure
> In that same repo you have a config.log file.
> If you grep cfitsio in config.log you must have (among others, and 
> depending on your distro)
> EXTRA_INCLUDES='-I/usr/include/cfitsio '
> LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio 
> -lz -lpthread -lm -lrt -ldl  -lpcre'
> now
> $ ./make
> more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
> 
> 
> On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu 
> <mailto:sborda at umich.edu>> wrote:
> 
>     Thanks Evan, I saw that mentioned in the formats list but I'm not
>     sure how to "build GDAL" with this library. I just downloaded GDAL
>     and it uses Python 3.6 but the version of CFITSIO I found uses
>     Python 2.x. I'm using a Mac but can easily run all of this on Linux
>     VM if need be.
> 
>     -susan
> 
>     On Thu, Jul 5, 2018 at 12:45 PM Even Rouault
>     <even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>> wrote:
> 
>         On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
>          > Hi-
>          > I'm new to gdal and am trying to use gdalinfo to read a
>         *.fits file
>          > (astronomy files), specifically the header. When I list the
>         formats
>          > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS
>         no longer
>          > supported?
> 
>         It is, but you must build GDAL against the CFITSIO library:
>         http://gdal.org/frmt_various.html#FITS
> 
>         On Debian and derivatives, this is the libcfitsio-dev package.
> 
>         -- 
>         Spatialys - Geospatial professional services
>         http://www.spatialys.com
> 
> 
> 
>     -- 
>     Susan Borda
>     Data Workflows Specialist
>     Research Data Services
>     University of Michigan Libraries
>     3175 Shapiro Library
>     734-764-9134 | sborda at umich.edu <mailto:sborda at umich.edu>
> 
> 
-- 
Jeff McKenna
MapServer Consulting and Training Services
https://gatewaygeomatics.com/

From sborda at umich.edu  Thu Jul  5 11:40:22 2018
From: sborda at umich.edu (Susan Borda)
Date: Thu, 5 Jul 2018 14:40:22 -0400
Subject: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo
	--formats
In-Reply-To: <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
 <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
 <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
 <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
Message-ID: <CAKicayyOZeoE=74huvJOj7XcZ=q0+V+-BevrfkYfaFmtkYCmPg@mail.gmail.com>

To build on Mac you can basically follow the Linux steps:
Download from http://download.osgeo.org/gdal/CURRENT/
cp or mv file to /usr/local (or wherever you'd like to install it)
gunzip
tar xvf
In my case I wanted to add in CFITSIO so I:
sudo ./configure --with-cfitsio
sudo make
sudo make install

It's running like a champ and parsing the *.fits headers!
Thanks for pointing me in the right direction!
-susan

On Thu, Jul 5, 2018 at 2:18 PM Jeff McKenna <jmckenna at gatewaygeomatics.com>
wrote:

> Trent, is it possible that you record all these steps and hints for
> compiling FITS support at https://trac.osgeo.org/gdal/wiki/BuildHints
> (i.e. create a new wiki page there and add a link to your build page in
> the "External Library Issues" section)  That way the steps are recorded
> and easy to find (instead of lost in the email archives)
>
> I'm happy to add a Windows section for compiling FITS as well.
>
> thanks!
>
> -jeff
>
>
>
> On 2018-07-05 2:12 PM, Trent Hare wrote:
> > Susan,
> >     Yes -  the FITS format is supported in GDAL once compilation has
> > been linked to CFITSIO.
> >
> > Note this driver is currently being enhanced to (1) better support FITS
> > files within GDAL and (2) the format FITS will have an extension added
> > to it, which allows more typical GIS map projection support. That branch
> > of GDAL is being worked on Chiara Marmo:
> > https://github.com/epn-vespa/gdal/tree/fits_driver
> >
> > For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu)
> > this should get you FITS support in GDAL (and also get QGIS with FITS
> also).
> >
> > _In order to have QGIS working with FITS_
> >
> >   * install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
> >   * install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
> >   * install QGIS
> >
> >
> > *_Temporary workaround_: *
> >    So a method Chiara created to test GDAL for FITS users is a simple
> > Python script which creates a GDAL VRT header pointing into the FITS
> > file. Once the VRT is created, any GDAL program can use it by pointing
> > at the VRT file (gdal_translate, QGIS, ArcMap, ...). Perhaps that is
> > worth a shot.
> > https://github.com/epn-vespa/fits2vrt
> >
> > Lastly, once the FITS driver is updated we will try to support an
> > anaconda version of GDAL with CFITSIO pre-built for users (should help
> > Macs users too).
> >
> > Good luck,
> > Trent
> >
> >
> > P.S. maybe a little un-tested *build help* (linux again - sorry).
> >
> > Install CFITSIO
> > Clone/download the GDAL repo.
> > $ cd gdal/gdal
> > you have compiled there the 'fits-driver' branch, using
> > $ ./configure
> > In that same repo you have a config.log file.
> > If you grep cfitsio in config.log you must have (among others, and
> > depending on your distro)
> > EXTRA_INCLUDES='-I/usr/include/cfitsio '
> > LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio
> > -lz -lpthread -lm -lrt -ldl  -lpcre'
> > now
> > $ ./make
> > more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
> >
> >
> > On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu
> > <mailto:sborda at umich.edu>> wrote:
> >
> >     Thanks Evan, I saw that mentioned in the formats list but I'm not
> >     sure how to "build GDAL" with this library. I just downloaded GDAL
> >     and it uses Python 3.6 but the version of CFITSIO I found uses
> >     Python 2.x. I'm using a Mac but can easily run all of this on Linux
> >     VM if need be.
> >
> >     -susan
> >
> >     On Thu, Jul 5, 2018 at 12:45 PM Even Rouault
> >     <even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>>
> wrote:
> >
> >         On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
> >          > Hi-
> >          > I'm new to gdal and am trying to use gdalinfo to read a
> >         *.fits file
> >          > (astronomy files), specifically the header. When I list the
> >         formats
> >          > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS
> >         no longer
> >          > supported?
> >
> >         It is, but you must build GDAL against the CFITSIO library:
> >         http://gdal.org/frmt_various.html#FITS
> >
> >         On Debian and derivatives, this is the libcfitsio-dev package.
> >
> >         --
> >         Spatialys - Geospatial professional services
> >         http://www.spatialys.com
> >
> >
> >
> >     --
> >     Susan Borda
> >     Data Workflows Specialist
> >     Research Data Services
> >     University of Michigan Libraries
> >     3175 Shapiro Library
> >     734-764-9134 | sborda at umich.edu <mailto:sborda at umich.edu>
> >
> >
> --
> Jeff McKenna
> MapServer Consulting and Training Services
> https://gatewaygeomatics.com/
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Susan Borda
Data Workflows Specialist
Research Data Services
University of Michigan Libraries
3175 Shapiro Library
734-764-9134 | sborda at umich.edu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/fc3a5cd2/attachment.html>

From sean at mapbox.com  Thu Jul  5 12:58:37 2018
From: sean at mapbox.com (Sean Gillies)
Date: Thu, 5 Jul 2018 13:58:37 -0600
Subject: [gdal-dev] Announcing a Rasterio users discussion group
Message-ID: <CADPhZXyqEifyHZnF6SJgL6dZLOMp1XN0i95QHf7YOMGi55J-CA@mail.gmail.com>

Hi all,

Rasterio is one of the Python interfaces to GDAL mentioned at
https://trac.osgeo.org/gdal/#GDALOGRInOtherLanguages. I've started a
Rasterio users discussion group on groups.io to support the 1.0 version
coming out next week: https://rasterio.groups.io/g/main/. This group, and
not gdal-dev, is where questions about Rasterio should be sent.

I hope you'll considering joining if you are a user or are curious about
the project.

Yours,

-- 
Sean Gillies
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/5049f679/attachment.html>

From WILLIAM.K.MAGEE at leidos.com  Thu Jul  5 13:12:15 2018
From: WILLIAM.K.MAGEE at leidos.com (Magee, Kelly)
Date: Thu, 5 Jul 2018 20:12:15 +0000
Subject: [gdal-dev] EXTERNAL: Re:  Support for S-100 and S-102
References: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>
 <2391908.kjktXhKX3H@even-i700>
Message-ID: <DFDA8B91111F2E40833202CAE291FC95013302AA9E@EMP-EXMR201.corp.leidos.com>

Evan,

Thanks for the reply, Do agree with you about the difficulty in finding concrete documentation.  There's plenty of enthusiasm and discussion regarding S-100, 101, 102 as the replacement for S-57 but that's about it.  Looking to see if there was a plan but it sounds like until things are well established this may be a ways off.  Do you know if there's a working group within the community that specifically monitors the IHO specs?

Thanks again,

- Kelly

On 07/05/2018 01:43 PM, Even Rouault wrote:

Kelly,




I know GDAL/OGR supports S-57 format, but could not see where it supports
S-100.

Is there a plan to support the latest IHO S-100 and S-102 standards in the
near future?



I'm not aware of anyone working on that currently.

I had difficulties finding concrete documentation about those standards
(specification and test products). From my quick search, it looks like :
- S-100 is a conceptual model,
- S-101 is for ENC encoding, a successor of S-57. Apparently still using
ISO-8211 for low level encoding.
- S-102 is bathymetric grid encoding in GeoTIFF or in BAG. So should be
already handled by GDAL

Even




--

William Kelly Magee | Leidos

Senior Software Engineer | Maritime Solutions Division

phone: 401.847.4210
<mailto:william.kelly.magee at leidos.com>william.kelly.magee at leidos.com <mailto:william.kelly.magee at leidos.com> | leidos.com/maritime <http://www.leidos.com/maritime>


[cid:part4.D0F526F3.2C8972E9 at leidos.com]

This email and any attachments to it are intended only for the identified recipients. It may contain proprietary or otherwise legally protected information of Leidos. Any unauthorized use or disclosure of this communication is strictly prohibited. If you have received this communication in error, please notify the sender and delete or otherwise destroy the email and all attachments immediately.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/14259635/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: kmagee-signature_html_2d3ec5e1.gif
Type: image/gif
Size: 3947 bytes
Desc: kmagee-signature_html_2d3ec5e1.gif
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/14259635/attachment.gif>

From schwehr at gmail.com  Thu Jul  5 15:44:24 2018
From: schwehr at gmail.com (Kurt Schwehr)
Date: Thu, 5 Jul 2018 15:44:24 -0700
Subject: [gdal-dev] Support for S-100 and S-102
In-Reply-To: <2391908.kjktXhKX3H@even-i700>
References: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>
 <2391908.kjktXhKX3H@even-i700>
Message-ID: <CACmBxyvULGdrr1fwEjWs4d_DyaL5Od00LZOzjAhE5BEgiTXWaw@mail.gmail.com>

I'd be happy to connect anyone with the folks at NOAA, CCOM-JHC, and
elsewhere who have been participating in drafting S-10x.  I only sat in on
a few of the meetings long ago.

Specs should eventually end up here...
https://www.iho.int/iho_pubs/IHO_Download.htm#S-100

On Thu, Jul 5, 2018 at 10:43 AM, Even Rouault <even.rouault at spatialys.com>
wrote:

> Kelly,
>
> >
> > I know GDAL/OGR supports S-57 format, but could not see where it supports
> > S-100.
> >
> > Is there a plan to support the latest IHO S-100 and S-102 standards in
> the
> > near future?
>
> I'm not aware of anyone working on that currently.
>
> I had difficulties finding concrete documentation about those standards
> (specification and test products). From my quick search, it looks like :
> - S-100 is a conceptual model,
> - S-101 is for ENC encoding, a successor of S-57. Apparently still using
> ISO-8211 for low level encoding.
> - S-102 is bathymetric grid encoding in GeoTIFF or in BAG. So should be
> already handled by GDAL
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev




-- 
--
http://schwehr.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/034b885b/attachment.html>

From kusala9 at googlemail.com  Thu Jul  5 15:47:29 2018
From: kusala9 at googlemail.com (kusala nine)
Date: Thu, 5 Jul 2018 23:47:29 +0100
Subject: [gdal-dev] EXTERNAL: Re:  Support for S-100 and S-102
In-Reply-To: <DFDA8B91111F2E40833202CAE291FC95013302AA9E@EMP-EXMR201.corp.leidos.com>
References: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>
 <2391908.kjktXhKX3H@even-i700>
 <DFDA8B91111F2E40833202CAE291FC95013302AA9E@EMP-EXMR201.corp.leidos.com>
Message-ID: <CB34C8F5-6B54-48E5-86E2-4A0080ABA5FA@googlemail.com>

Hi - I don’t post a lot to this group but I work extensively with the IHO and the group developing S-100. It’s a fairly broad framework standard with multiple product specifications emerging from it and its own GML profile included in the encodings. Iso8211 is another encoding included in the main standard and would be a great place to start with any interoperability effort. S-100 ed4 is just being drafted - if anyone’s interested in building any compatible tools please get in touch, we’d be really keen to work with developers on it as we use the Gdal drivers extensively in the community....

Cheers

Jonathan
IIC technologies.

Sent from my iPhone

> On 5 Jul 2018, at 21:12, Magee, Kelly <WILLIAM.K.MAGEE at leidos.com> wrote:
> 
> Evan,
> 
> Thanks for the reply, Do agree with you about the difficulty in finding concrete documentation.  There's plenty of enthusiasm and discussion regarding S-100, 101, 102 as the replacement for S-57 but that's about it.  Looking to see if there was a plan but it sounds like until things are well established this may be a ways off.  Do you know if there's a working group within the community that specifically monitors the IHO specs?
> 
> Thanks again,
> 
> - Kelly
> 
>> On 07/05/2018 01:43 PM, Even Rouault wrote:
>> Kelly,
>> 
>>> I know GDAL/OGR supports S-57 format, but could not see where it supports
>>> S-100.
>>> 
>>> Is there a plan to support the latest IHO S-100 and S-102 standards in the
>>> near future?
>> I'm not aware of anyone working on that currently.
>> 
>> I had difficulties finding concrete documentation about those standards 
>> (specification and test products). From my quick search, it looks like :
>> - S-100 is a conceptual model,
>> - S-101 is for ENC encoding, a successor of S-57. Apparently still using 
>> ISO-8211 for low level encoding.
>> - S-102 is bathymetric grid encoding in GeoTIFF or in BAG. So should be 
>> already handled by GDAL
>> 
>> Even
>> 
> 
> -- 
> William Kelly Magee | Leidos
> 
> Senior Software Engineer | Maritime Solutions Division
> phone: 401.847.4210
> william.kelly.magee at leidos.com | leidos.com/maritime
> 
> <kmagee-signature_html_2d3ec5e1.gif>
> 
> This email and any attachments to it are intended only for the identified recipients. It may contain proprietary or otherwise legally protected information of Leidos. Any unauthorized use or disclosure of this communication is strictly prohibited. If you have received this communication in error, please notify the sender and delete or otherwise destroy the email and all attachments immediately.
> 
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180705/a272a1e1/attachment-0001.html>

From even.rouault at spatialys.com  Fri Jul  6 03:14:43 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 06 Jul 2018 12:14:43 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
Message-ID: <6868642.acaTliTEoa@even-i700>

On jeudi 5 juillet 2018 14:22:16 CEST Tom van Tilburg wrote:
> I have a fresh gdal 2.3.1 build on a ubuntu 17.10 that tells me:
> > gdalinfo dem.tif -stats -mm
> 
> [..snip...]
> Band 1 Block=2200x1 Type=Float32, ColorInterp=Gray
>   Min=-2.233 Max=340282346638529993179660072199368212480.000   Computed
> Min/Max=-2.233,340282346638528859811704183484516925440.000
>   Minimum=-2.233, Maximum=340282346638529993179660072199368212480.000,
> Mean=42029510023671999325552505715632898048.000,
> StdDev=111961692493879995008202507419807383552.000
>   NoData Value=3.40282346638529011e+38
>   Metadata:
>     STATISTICS_MAXIMUM=3.4028234663853e+38
>     STATISTICS_MEAN=4.2029510023672e+37
>     STATISTICS_MINIMUM=-2.2330000400543
>     STATISTICS_STDDEV=1.1196169249388e+38

ok, the issue is that nodata value (stored as text in GeoTIFF) is slightly 
above the maximum value of a float32. Presumably due to rounding issues when 
formatting it. I've pushed a fix to detect that situation and clamp it to the 
max value of float32. A bit strange that the issue wasn't found on Windows 
though.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tom.van.tilburg at gmail.com  Fri Jul  6 05:00:16 2018
From: tom.van.tilburg at gmail.com (Tom van Tilburg)
Date: Fri, 6 Jul 2018 14:00:16 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <6868642.acaTliTEoa@even-i700>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
 <6868642.acaTliTEoa@even-i700>
Message-ID: <CAP3PPDhEqEOe+T6JxofzwCRrfyj_nnj7PSJWMdpAsqnbd=y-Fg@mail.gmail.com>

I just did a fresh build of trunk (2.4.0) but noticed 2 issues:
1. The installed version in /usr/local/bin is still version 2.3.1:
> ls /usr/local/bin/gdalinfo -lrth
-rwxr-xr-x 1 root root 40K Jul  6 13:51 /usr/local/bin/gdalinfo
> /usr/local/bin/gdalinfo --version
GDAL 2.3.1, released 2018/06/22

(I did an ldconfig to be sure, but no to avail)

2. The newly build version in the git repo segfaults on:
/var/data/git_repos/gdal/gdal/apps/gdalinfo dem.tif
[..snip..]
Origin = (171950.000000000000000,437050.000000000000000)
Pixel Size = (0.500000000000000,-0.500000000000000)
Metadata:
  AREA_OR_POINT=Area
Image Structure Metadata:
  INTERLEAVE=BAND
Corner Coordinates:
ERROR 1: illegal axis orientation combination
Upper Left  (  171950.000,  437050.000)
ERROR 1: illegal axis orientation combination
Lower Left  (  171950.000,  435950.000)
ERROR 1: illegal axis orientation combination
Upper Right (  173050.000,  437050.000)
ERROR 1: illegal axis orientation combination
Lower Right (  173050.000,  435950.000)
ERROR 1: illegal axis orientation combination
Center      (  172500.000,  436500.000)
Segmentation fault (core dumped)

Since there is a second version of proj on the system, I have used
./configure --with-static-proj4

Thanks for dealing with this.

Best,
 Tom

On Fri, Jul 6, 2018 at 12:14 PM, Even Rouault <even.rouault at spatialys.com>
wrote:

> On jeudi 5 juillet 2018 14:22:16 CEST Tom van Tilburg wrote:
> > I have a fresh gdal 2.3.1 build on a ubuntu 17.10 that tells me:
> > > gdalinfo dem.tif -stats -mm
> >
> > [..snip...]
> > Band 1 Block=2200x1 Type=Float32, ColorInterp=Gray
> >   Min=-2.233 Max=340282346638529993179660072199368212480.000   Computed
> > Min/Max=-2.233,340282346638528859811704183484516925440.000
> >   Minimum=-2.233, Maximum=340282346638529993179660072199368212480.000,
> > Mean=42029510023671999325552505715632898048.000,
> > StdDev=111961692493879995008202507419807383552.000
> >   NoData Value=3.40282346638529011e+38
> >   Metadata:
> >     STATISTICS_MAXIMUM=3.4028234663853e+38
> >     STATISTICS_MEAN=4.2029510023672e+37
> >     STATISTICS_MINIMUM=-2.2330000400543
> >     STATISTICS_STDDEV=1.1196169249388e+38
>
> ok, the issue is that nodata value (stored as text in GeoTIFF) is slightly
> above the maximum value of a float32. Presumably due to rounding issues
> when
> formatting it. I've pushed a fix to detect that situation and clamp it to
> the
> max value of float32. A bit strange that the issue wasn't found on Windows
> though.
>
>


> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180706/8c4a169e/attachment.html>

From even.rouault at spatialys.com  Fri Jul  6 05:09:49 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 06 Jul 2018 14:09:49 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <CAP3PPDhEqEOe+T6JxofzwCRrfyj_nnj7PSJWMdpAsqnbd=y-Fg@mail.gmail.com>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
 <6868642.acaTliTEoa@even-i700>
 <CAP3PPDhEqEOe+T6JxofzwCRrfyj_nnj7PSJWMdpAsqnbd=y-Fg@mail.gmail.com>
Message-ID: <3648694.Up4Kx5NPi2@even-i700>

On vendredi 6 juillet 2018 14:00:16 CEST Tom van Tilburg wrote:
> I just did a fresh build of trunk (2.4.0) but noticed 2 issues:
> 
> 1. The installed version in /usr/local/bin is still version 2.3.1:

You may have to defined LD_LIBRARY_PATH since it probably links against your 
system libgdal

Otherwise you don't need to install the master, but just make and source the
scripts/setdevenv.sh that will set PATH, LD_LIBRARY_PATH, GDAL_DATA and 
PYTHONPATH to appropriate values in the built tree.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From tom.van.tilburg at gmail.com  Fri Jul  6 06:54:36 2018
From: tom.van.tilburg at gmail.com (Tom van Tilburg)
Date: Fri, 6 Jul 2018 15:54:36 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <3648694.Up4Kx5NPi2@even-i700>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
 <6868642.acaTliTEoa@even-i700>
 <CAP3PPDhEqEOe+T6JxofzwCRrfyj_nnj7PSJWMdpAsqnbd=y-Fg@mail.gmail.com>
 <3648694.Up4Kx5NPi2@even-i700>
Message-ID: <CAP3PPDisvFgd8wt9ajKZFPQtOzncgt9BL0tZCpctq0mwwzn4Vg@mail.gmail.com>

 Got myself a build that has the correct proj version now (./configure
--with-proj) so it doesn't segfault.
I can confirm that the nodata values are correctly dealt with now :)

Still battling the linked gdal version though, will post when I dealt with
that.

Tom



On Fri, Jul 6, 2018 at 2:09 PM, Even Rouault <even.rouault at spatialys.com>
wrote:

> On vendredi 6 juillet 2018 14:00:16 CEST Tom van Tilburg wrote:
> > I just did a fresh build of trunk (2.4.0) but noticed 2 issues:
> >
> > 1. The installed version in /usr/local/bin is still version 2.3.1:
>
> You may have to defined LD_LIBRARY_PATH since it probably links against
> your
> system libgdal
>
> Otherwise you don't need to install the master, but just make and source
> the
> scripts/setdevenv.sh that will set PATH, LD_LIBRARY_PATH, GDAL_DATA and
> PYTHONPATH to appropriate values in the built tree.
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180706/f3f651e7/attachment.html>

From sreed at ccom.unh.edu  Fri Jul  6 07:56:01 2018
From: sreed at ccom.unh.edu (sreed at ccom.unh.edu)
Date: Fri, 6 Jul 2018 10:56:01 -0400
Subject: [gdal-dev] EXTERNAL: Re:  Support for S-100 and S-102
In-Reply-To: <CB34C8F5-6B54-48E5-86E2-4A0080ABA5FA@googlemail.com>
References: <DFDA8B91111F2E40833202CAE291FC95013302A95E@EMP-EXMR201.corp.leidos.com>
 <2391908.kjktXhKX3H@even-i700>
 <DFDA8B91111F2E40833202CAE291FC95013302AA9E@EMP-EXMR201.corp.leidos.com>
 <CB34C8F5-6B54-48E5-86E2-4A0080ABA5FA@googlemail.com>
Message-ID: <3d04d1b7ad1e64458e55af834ea29f09.squirrel@webmail.ccom.unh.edu>

Hi all,

I would be happy to connect anyone from GDAL development to CCOM-JHC as I
am a grad student there.

Thanks,
Sam



From: gdal-dev [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of
kusala nine
Sent: Thursday, July 5, 2018 6:47 PM
To: Magee, Kelly <WILLIAM.K.MAGEE at leidos.com>
Cc: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] EXTERNAL: Re: Support for S-100 and S-102

Hi - I dont post a lot to this group but I work extensively with the IHO
and the group developing S-100. Its a fairly broad framework standard
with multiple product specifications emerging from it and its own GML
profile included in the encodings. Iso8211 is another encoding included in
the main standard and would be a great place to start with any
interoperability effort. S-100 ed4 is just being drafted - if anyones
interested in building any compatible tools please get in touch, wed be
really keen to work with developers on it as we use the Gdal drivers
extensively in the community....

Cheers

Jonathan
IIC technologies.
Sent from my iPhone

On 5 Jul 2018, at 21:12, Magee, Kelly <WILLIAM.K.MAGEE at leidos.com> wrote:
Evan,

Thanks for the reply, Do agree with you about the difficulty in finding
concrete documentation.  There's plenty of enthusiasm and discussion
regarding S-100, 101, 102 as the replacement for S-57 but that's about it.
 Looking to see if there was a plan but it sounds like until things are
well established this may be a ways off.  Do you know if there's a working
group within the community that specifically monitors the IHO specs?

Thanks again,

- Kelly

On 07/05/2018 01:43 PM, Even Rouault wrote:
Kelly,

I know GDAL/OGR supports S-57 format, but could not see where it supports
S-100.

Is there a plan to support the latest IHO S-100 and S-102 standards in the
near future?
I'm not aware of anyone working on that currently.

I had difficulties finding concrete documentation about those standards
(specification and test products). From my quick search, it looks like :
- S-100 is a conceptual model,
- S-101 is for ENC encoding, a successor of S-57. Apparently still using
ISO-8211 for low level encoding.
- S-102 is bathymetric grid encoding in GeoTIFF or in BAG. So should be
already handled by GDAL

Even


-- 
William Kelly Magee | Leidos
Senior Software Engineer | Maritime Solutions Division
phone: 401.847.4210
william.kelly.magee at leidos.com | leidos.com/maritime

<kmagee-signature_html_2d3ec5e1.gif>
This email and any attachments to it are intended only for the identified
recipients. It may contain proprietary or otherwise legally protected
information of Leidos. Any unauthorized use or disclosure of this
communication is strictly prohibited. If you have received this
communication in error, please notify the sender and delete or otherwise
destroy the email and all attachments immediately.

_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/gdal-dev



From csbruce at cubewerx.com  Fri Jul  6 13:06:12 2018
From: csbruce at cubewerx.com (Craig Bruce)
Date: Fri, 6 Jul 2018 17:06:12 -0300
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <6868642.acaTliTEoa@even-i700>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
 <6868642.acaTliTEoa@even-i700>
Message-ID: <183bd369-3ee2-5d80-0fdc-bb5541e21755@cubewerx.com>

An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180706/170255d4/attachment.html>

From tom.van.tilburg at gmail.com  Mon Jul  9 04:50:21 2018
From: tom.van.tilburg at gmail.com (Tom van Tilburg)
Date: Mon, 9 Jul 2018 13:50:21 +0200
Subject: [gdal-dev] GDAL 2.3.1 on linux disregarding nodata values
In-Reply-To: <CAP3PPDg-x5-jjyjo4WEpgK=BZifkxxhdw2=+QVy7AabcvpkFvA@mail.gmail.com>
References: <CAP3PPDjSt3K8f4CwjaMC2MSUhpyqN9BEOdFHqoQNPHBdNNaBmg@mail.gmail.com>
 <6868642.acaTliTEoa@even-i700>
 <CAP3PPDhEqEOe+T6JxofzwCRrfyj_nnj7PSJWMdpAsqnbd=y-Fg@mail.gmail.com>
 <3648694.Up4Kx5NPi2@even-i700>
 <CAP3PPDg-x5-jjyjo4WEpgK=BZifkxxhdw2=+QVy7AabcvpkFvA@mail.gmail.com>
Message-ID: <CAP3PPDjMGnxsMZRu=kzg2kWs9zeQs9Gcn+1=RV=w2kQaq6t8zA@mail.gmail.com>

A follow up on the previous problem with versions (see below):

I removed all old libgdal versions that were in /usr/local/lib and that has
solved the issue.

Best,
Tom


------------------------------
I thought LD_LIBRARY_PATH could be untouched since I'm doing a
system-install according to: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
Anyway, even when setting LD_LIBRARY_PATH to /usr/local/lib and rebuilding,
It shows the same issue.

It seems the linking is correct according to:

> ldd /usr/local/bin/gdalinfo |grep libgdal
        libgdal.so.20 => /usr/local/lib/libgdal.so.20 (0x00007fb64a7d4000)

> ls -lrt /usr/local/lib/libgdal*
-rwxr-xr-x 1 root root  95610360 Nov 10  2016 /usr/local/lib/libgdal.so.20.
1.0
-rwxr-xr-x 1 root root  96245776 Jan  5  2017 /usr/local/lib/libgdal.so.20.
1.2
-rwxr-xr-x 1 root root  95857208 Jan  5  2017 /usr/local/lib/libgdal.so.20.
1.1
-rwxr-xr-x 1 root root  96494352 Mar 13  2017 /usr/local/lib/libgdal.so.20.
1.3
-rwxr-xr-x 1 root root 120481920 May 16  2017 /usr/local/lib/libgdal.so.20.
2.0
-rwxr-xr-x 1 root root 135179608 Aug 17  2017 /usr/local/lib/libgdal.so.20.
3.0
-rwxr-xr-x 1 root root 136095424 Jul  5 13:58 /usr/local/lib/libgdal.so.20.
3.2
-rwxr-xr-x 1 root root 156131272 Jul  5 14:01 /usr/local/lib/libgdal.so.20.
4.1
-rwxr-xr-x 1 root root 160334560 Jul  6 14:00 /usr/local/lib/libgdal.so.20.
4.0
lrwxrwxrwx 1 root root        17 Jul  6 14:00 /usr/local/lib/libgdal.so ->
libgdal.so.20.4.0
-rwxr-xr-x 1 root root      1525 Jul  6 14:00 /usr/local/lib/libgdal.la
-rw-r--r-- 1 root root 406912300 Jul  6 14:00 /usr/local/lib/libgdal.a
lrwxrwxrwx 1 root root        17 Jul  6 14:00 /usr/local/lib/libgdal.so.20
-> libgdal.so.20.4.1

> /usr/local/bin/gdalinfo --version
GDAL 2.3.1, released 2018/06/22

> /usr/local/bin/gdal-config --version
2.4.0


I'm a bit lost, this version 2.3.1 was the previous custom build I did and
it all resides in /usr/local
The only caveat I have is that there is an older libgdal20 2.2.1 package
installed on the same system, but that doesn't seem to interfere.

Any hints on where to dig deeper?

Best,
 Tom



On Fri, Jul 6, 2018 at 2:44 PM, Tom van Tilburg <tom.van.tilburg at gmail.com>
wrote:

> I thought LD_LIBRARY_PATH could be untouched since I'm doing a
> system-install according to: https://trac.osgeo.org/gdal/
> wiki/BuildingOnUnix
> Anyway, even when setting LD_LIBRARY_PATH to /usr/local/lib and
> rebuilding, It shows the same issue.
>
> It seems the linking is correct according to:
>
> > ldd /usr/local/bin/gdalinfo |grep libgdal
>         libgdal.so.20 => /usr/local/lib/libgdal.so.20 (0x00007fb64a7d4000)
>
> > ls -lrt /usr/local/lib/libgdal*
> -rwxr-xr-x 1 root root  95610360 Nov 10  2016 /usr/local/lib/libgdal.so.20.
> 1.0
> -rwxr-xr-x 1 root root  96245776 Jan  5  2017 /usr/local/lib/libgdal.so.20.
> 1.2
> -rwxr-xr-x 1 root root  95857208 Jan  5  2017 /usr/local/lib/libgdal.so.20.
> 1.1
> -rwxr-xr-x 1 root root  96494352 Mar 13  2017 /usr/local/lib/libgdal.so.20.
> 1.3
> -rwxr-xr-x 1 root root 120481920 May 16  2017 /usr/local/lib/libgdal.so.20.
> 2.0
> -rwxr-xr-x 1 root root 135179608 Aug 17  2017 /usr/local/lib/libgdal.so.20.
> 3.0
> -rwxr-xr-x 1 root root 136095424 Jul  5 13:58 /usr/local/lib/libgdal.so.20.
> 3.2
> -rwxr-xr-x 1 root root 156131272 Jul  5 14:01 /usr/local/lib/libgdal.so.20.
> 4.1
> -rwxr-xr-x 1 root root 160334560 Jul  6 14:00 /usr/local/lib/libgdal.so.20.
> 4.0
> lrwxrwxrwx 1 root root        17 Jul  6 14:00 /usr/local/lib/libgdal.so ->
> libgdal.so.20.4.0
> -rwxr-xr-x 1 root root      1525 Jul  6 14:00 /usr/local/lib/libgdal.la
> -rw-r--r-- 1 root root 406912300 Jul  6 14:00 /usr/local/lib/libgdal.a
> lrwxrwxrwx 1 root root        17 Jul  6 14:00 /usr/local/lib/libgdal.so.20
> -> libgdal.so.20.4.1
>
> > /usr/local/bin/gdalinfo --version
> GDAL 2.3.1, released 2018/06/22
>
> > /usr/local/bin/gdal-config --version
> 2.4.0
>
>
> I'm a bit lost, this version 2.3.1 was the previous custom build I did and
> it all resides in /usr/local
> The only caveat I have is that there is an older libgdal20 2.2.1 package
> installed on the same system, but that doesn't seem to interfere.
>
> Any hints on where to dig deeper?
>
> Best,
>  Tom
>
> On Fri, Jul 6, 2018 at 2:09 PM, Even Rouault <even.rouault at spatialys.com>
> wrote:
>
>> On vendredi 6 juillet 2018 14:00:16 CEST Tom van Tilburg wrote:
>> > I just did a fresh build of trunk (2.4.0) but noticed 2 issues:
>> >
>> > 1. The installed version in /usr/local/bin is still version 2.3.1:
>>
>> You may have to defined LD_LIBRARY_PATH since it probably links against
>> your
>> system libgdal
>>
>> Otherwise you don't need to install the master, but just make and source
>> the
>> scripts/setdevenv.sh that will set PATH, LD_LIBRARY_PATH, GDAL_DATA and
>> PYTHONPATH to appropriate values in the built tree.
>>
>> --
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180709/3ee4a9fa/attachment.html>

From arno at agerrius.nl  Mon Jul  9 11:00:52 2018
From: arno at agerrius.nl (Arno Gerretsen)
Date: Mon, 09 Jul 2018 20:00:52 +0200
Subject: [gdal-dev] WMS, blocksize and black lines
Message-ID: <a81dd60bee618a8ed091ae9752cd54cc@agerrius.nl>

Hi all,

I'm trying to create a WMS XML to access some WMS data in GDAL. But I 
get black lines in the resulting image. I have found out that if I 
reduce the size of the BlockSize in the WMS XML that the lines get more 
narrow, but the download speed of the images also reduces a lot. Am I 
missing some setting here to make it work?

This is the XML file I use:

<GDAL_WMS>
   <Service name="WMS">
     <Version>1.1.1</Version>
     
<ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServer/WMSServer?SERVICE=WMS</ServerUrl>
     <Layers>0</Layers>
     <SRS>EPSG:4326</SRS>
     <ImageFormat>image/tiff</ImageFormat>
     <Transparent>FALSE</Transparent>
     <BBoxOrder>xyXY</BBoxOrder>
   </Service>
   <DataWindow>
     <UpperLeftX>-91.562525</UpperLeftX>
     <UpperLeftY>42.562525</UpperLeftY>
     <LowerRightX>-87.437470</LowerRightX>
     <LowerRightY>36.937474</LowerRightY>
	<SizeX>370834</SizeX>
     <SizeY>625056</SizeY>
   </DataWindow>
   <BandsCount>4</BandsCount>
   <UnsafeSSL>true</UnsafeSSL>
   <BlockSizeX>1024</BlockSizeX>
   <BlockSizeY>1024</BlockSizeY>
</GDAL_WMS>

And this is a sample call that shows the black lines:

gdal_translate -projwin -88.0 42.0 -87.99 41.99 wms.xml test.tif

With regards,

-- 
Arno

From vincent.sarago at gmail.com  Mon Jul  9 14:26:21 2018
From: vincent.sarago at gmail.com (Vincent Sarago)
Date: Mon, 9 Jul 2018 17:26:21 -0400
Subject: [gdal-dev] Missing Alpha flag for Warped VRT Single band UInt16
	dataset
Message-ID: <92092E0E-50E9-431E-A4E5-0D046CC2EBC6@gmail.com>

Previous discussion can be found in https://github.com/mapbox/rasterio/issues/1403 <https://github.com/mapbox/rasterio/issues/1403>

When creating Warped VRT of a 1band Uint16 dataset with internal mask, gdal creates an Alpha band but don’t seems to set the Alpha/Mask flags.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180709/f464f65e/attachment.html>

From csmemoe at aquaveo.com  Mon Jul  9 22:04:27 2018
From: csmemoe at aquaveo.com (Chris Smemoe)
Date: Mon, 9 Jul 2018 23:04:27 -0600
Subject: [gdal-dev] WMS, blocksize and black lines
In-Reply-To: <a81dd60bee618a8ed091ae9752cd54cc@agerrius.nl>
References: <a81dd60bee618a8ed091ae9752cd54cc@agerrius.nl>
Message-ID: <E4954861B9544F5B8C45DCD07E3BD739@aquaveo.local>

Arno,

I suspect the black lines has something to do with using the -projwin
argument to gdal_translate along with the DataWindow tag information in the
XML file.  The following XML works fine for me with the following command
line: "gdal_translate wms.xml test.tif"

<GDAL_WMS>
   <Service name="WMS">
     <Version>1.1.1</Version>
 
<ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServ
er/WMSServer</ServerUrl>
     <ImageFormat>tiff</ImageFormat>
     <Layers>0</Layers>
     <BBoxOrder>xyXY</BBoxOrder>
     <SRS>EPSG:4326</SRS>
   </Service>
   <DataWindow>
     <UpperLeftX>-89.0</UpperLeftX>
     <UpperLeftY>42.0</UpperLeftY>
     <LowerRightX>-88.0</LowerRightX>
     <LowerRightY>41.0</LowerRightY>
     <SizeX>1024</SizeX>
     <SizeY>1024</SizeY>
   </DataWindow>
   <UnsafeSSL>true</UnsafeSSL>
</GDAL_WMS>

Chris

-----Original Message-----
From: gdal-dev [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of Arno
Gerretsen
Sent: Monday, July 09, 2018 12:01 PM
To: gdal-dev at lists.osgeo.org
Subject: [gdal-dev] WMS, blocksize and black lines

Hi all,

I'm trying to create a WMS XML to access some WMS data in GDAL. But I 
get black lines in the resulting image. I have found out that if I 
reduce the size of the BlockSize in the WMS XML that the lines get more 
narrow, but the download speed of the images also reduces a lot. Am I 
missing some setting here to make it work?

This is the XML file I use:

<GDAL_WMS>
   <Service name="WMS">
     <Version>1.1.1</Version>
     
<ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServ
er/WMSServer?SERVICE=WMS</ServerUrl>
     <Layers>0</Layers>
     <SRS>EPSG:4326</SRS>
     <ImageFormat>image/tiff</ImageFormat>
     <Transparent>FALSE</Transparent>
     <BBoxOrder>xyXY</BBoxOrder>
   </Service>
   <DataWindow>
     <UpperLeftX>-91.562525</UpperLeftX>
     <UpperLeftY>42.562525</UpperLeftY>
     <LowerRightX>-87.437470</LowerRightX>
     <LowerRightY>36.937474</LowerRightY>
	<SizeX>370834</SizeX>
     <SizeY>625056</SizeY>
   </DataWindow>
   <BandsCount>4</BandsCount>
   <UnsafeSSL>true</UnsafeSSL>
   <BlockSizeX>1024</BlockSizeX>
   <BlockSizeY>1024</BlockSizeY>
</GDAL_WMS>

And this is a sample call that shows the black lines:

gdal_translate -projwin -88.0 42.0 -87.99 41.99 wms.xml test.tif

With regards,

-- 
Arno
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/gdal-dev


From arno at agerrius.nl  Mon Jul  9 22:46:47 2018
From: arno at agerrius.nl (Arno Gerretsen)
Date: Tue, 10 Jul 2018 07:46:47 +0200
Subject: [gdal-dev] WMS, blocksize and black lines
In-Reply-To: <E4954861B9544F5B8C45DCD07E3BD739@aquaveo.local>
References: <a81dd60bee618a8ed091ae9752cd54cc@agerrius.nl>
 <E4954861B9544F5B8C45DCD07E3BD739@aquaveo.local>
Message-ID: <9f04b1e46f4ced7cd86d04885233f796@agerrius.nl>

Chris,

Thanks for the answer, if I put the window in the XML file it indeed 
also works for me.

But in my application I am sampling the GDAL dataset from code and 
setting a different window each time from code as well. So to modify the 
WMS XML every time in that case would not really be a work able 
solution.

This approach worked fine in the past with another WMS server, so I was 
hoping I missed some setting somewhere or so. I'll do some more 
experimentation.

Arno


On 2018-07-10 07:04, Chris Smemoe wrote:
> Arno,
> 
> I suspect the black lines has something to do with using the -projwin
> argument to gdal_translate along with the DataWindow tag information in 
> the
> XML file.  The following XML works fine for me with the following 
> command
> line: "gdal_translate wms.xml test.tif"
> 
> <GDAL_WMS>
>    <Service name="WMS">
>      <Version>1.1.1</Version>
> 
> <ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServ
> er/WMSServer</ServerUrl>
>      <ImageFormat>tiff</ImageFormat>
>      <Layers>0</Layers>
>      <BBoxOrder>xyXY</BBoxOrder>
>      <SRS>EPSG:4326</SRS>
>    </Service>
>    <DataWindow>
>      <UpperLeftX>-89.0</UpperLeftX>
>      <UpperLeftY>42.0</UpperLeftY>
>      <LowerRightX>-88.0</LowerRightX>
>      <LowerRightY>41.0</LowerRightY>
>      <SizeX>1024</SizeX>
>      <SizeY>1024</SizeY>
>    </DataWindow>
>    <UnsafeSSL>true</UnsafeSSL>
> </GDAL_WMS>
> 
> Chris
> 
> -----Original Message-----
> From: gdal-dev [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of 
> Arno
> Gerretsen
> Sent: Monday, July 09, 2018 12:01 PM
> To: gdal-dev at lists.osgeo.org
> Subject: [gdal-dev] WMS, blocksize and black lines
> 
> Hi all,
> 
> I'm trying to create a WMS XML to access some WMS data in GDAL. But I
> get black lines in the resulting image. I have found out that if I
> reduce the size of the BlockSize in the WMS XML that the lines get more
> narrow, but the download speed of the images also reduces a lot. Am I
> missing some setting here to make it work?
> 
> This is the XML file I use:
> 
> <GDAL_WMS>
>    <Service name="WMS">
>      <Version>1.1.1</Version>
> 
> <ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServ
> er/WMSServer?SERVICE=WMS</ServerUrl>
>      <Layers>0</Layers>
>      <SRS>EPSG:4326</SRS>
>      <ImageFormat>image/tiff</ImageFormat>
>      <Transparent>FALSE</Transparent>
>      <BBoxOrder>xyXY</BBoxOrder>
>    </Service>
>    <DataWindow>
>      <UpperLeftX>-91.562525</UpperLeftX>
>      <UpperLeftY>42.562525</UpperLeftY>
>      <LowerRightX>-87.437470</LowerRightX>
>      <LowerRightY>36.937474</LowerRightY>
> 	<SizeX>370834</SizeX>
>      <SizeY>625056</SizeY>
>    </DataWindow>
>    <BandsCount>4</BandsCount>
>    <UnsafeSSL>true</UnsafeSSL>
>    <BlockSizeX>1024</BlockSizeX>
>    <BlockSizeY>1024</BlockSizeY>
> </GDAL_WMS>
> 
> And this is a sample call that shows the black lines:
> 
> gdal_translate -projwin -88.0 42.0 -87.99 41.99 wms.xml test.tif
> 
> With regards,

-- 
Arno

From chiara.marmo at u-psud.fr  Wed Jul 11 08:40:21 2018
From: chiara.marmo at u-psud.fr (Chiara Marmo)
Date: Wed, 11 Jul 2018 17:40:21 +0200 (CEST)
Subject: [gdal-dev] Trac page on compiling GDAL with FITS support (was FITS
 format not listed in gdalinfo --formats)
In-Reply-To: <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
 <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
 <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
 <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
Message-ID: <785777516.1729130.1531323621610.JavaMail.zimbra@u-psud.fr>

Hi,
I'm Chiara, as Trent said I'm working on FITS driver improvement in GDAL.

I have prepared a documentation page on the VESPA-Europlanet wiki [1]

I'm not an official contributor to GDAL code, but I will be happy to contribute to the Trac documentation if I may.
May I? :)

Thanks for listening,
Chiara


[1] https://voparis-confluence.obspm.fr/display/VES/GDAL+with+FITS

----- Original Message -----
> From: "Jeff McKenna" <jmckenna at gatewaygeomatics.com>
> To: gdal-dev at lists.osgeo.org
> Sent: Thursday, July 5, 2018 8:18:50 PM
> Subject: Re: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo --formats
> 
> Trent, is it possible that you record all these steps and hints for
> compiling FITS support at https://trac.osgeo.org/gdal/wiki/BuildHints
> (i.e. create a new wiki page there and add a link to your build page in
> the "External Library Issues" section)  That way the steps are recorded
> and easy to find (instead of lost in the email archives)
> 
> I'm happy to add a Windows section for compiling FITS as well.
> 
> thanks!
> 
> -jeff
> 
> 
> 
> On 2018-07-05 2:12 PM, Trent Hare wrote:
> > Susan,
> >     Yes -  the FITS format is supported in GDAL once compilation has
> > been linked to CFITSIO.
> > 
> > Note this driver is currently being enhanced to (1) better support FITS
> > files within GDAL and (2) the format FITS will have an extension added
> > to it, which allows more typical GIS map projection support. That branch
> > of GDAL is being worked on Chiara Marmo:
> > https://github.com/epn-vespa/gdal/tree/fits_driver
> > 
> > For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu)
> > this should get you FITS support in GDAL (and also get QGIS with FITS
> > also).
> > 
> > _In order to have QGIS working with FITS_
> > 
> >   * install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
> >   * install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
> >   * install QGIS
> > 
> > 
> > *_Temporary workaround_: *
> >    So a method Chiara created to test GDAL for FITS users is a simple
> > Python script which creates a GDAL VRT header pointing into the FITS
> > file. Once the VRT is created, any GDAL program can use it by pointing
> > at the VRT file (gdal_translate, QGIS, ArcMap, ...). Perhaps that is
> > worth a shot.
> > https://github.com/epn-vespa/fits2vrt
> > 
> > Lastly, once the FITS driver is updated we will try to support an
> > anaconda version of GDAL with CFITSIO pre-built for users (should help
> > Macs users too).
> > 
> > Good luck,
> > Trent
> > 
> > 
> > P.S. maybe a little un-tested *build help* (linux again - sorry).
> > 
> > Install CFITSIO
> > Clone/download the GDAL repo.
> > $ cd gdal/gdal
> > you have compiled there the 'fits-driver' branch, using
> > $ ./configure
> > In that same repo you have a config.log file.
> > If you grep cfitsio in config.log you must have (among others, and
> > depending on your distro)
> > EXTRA_INCLUDES='-I/usr/include/cfitsio '
> > LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio
> > -lz -lpthread -lm -lrt -ldl  -lpcre'
> > now
> > $ ./make
> > more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
> > 
> > 
> > On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu
> > <mailto:sborda at umich.edu>> wrote:
> > 
> >     Thanks Evan, I saw that mentioned in the formats list but I'm not
> >     sure how to "build GDAL" with this library. I just downloaded GDAL
> >     and it uses Python 3.6 but the version of CFITSIO I found uses
> >     Python 2.x. I'm using a Mac but can easily run all of this on Linux
> >     VM if need be.
> > 
> >     -susan
> > 
> >     On Thu, Jul 5, 2018 at 12:45 PM Even Rouault
> >     <even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>> wrote:
> > 
> >         On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
> >          > Hi-
> >          > I'm new to gdal and am trying to use gdalinfo to read a
> >         *.fits file
> >          > (astronomy files), specifically the header. When I list the
> >         formats
> >          > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS
> >         no longer
> >          > supported?
> > 
> >         It is, but you must build GDAL against the CFITSIO library:
> >         http://gdal.org/frmt_various.html#FITS
> > 
> >         On Debian and derivatives, this is the libcfitsio-dev package.
> > 
> >         --
> >         Spatialys - Geospatial professional services
> >         http://www.spatialys.com
> > 
> > 
> > 
> >     --
> >     Susan Borda
> >     Data Workflows Specialist
> >     Research Data Services
> >     University of Michigan Libraries
> >     3175 Shapiro Library
> >     734-764-9134 | sborda at umich.edu <mailto:sborda at umich.edu>
> > 
> > 
> --
> Jeff McKenna
> MapServer Consulting and Training Services
> https://gatewaygeomatics.com/
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev

-- 
Chiara Marmo
Ingénieur de Recherche GEOPS - Paris Sud-11
Bât 509
Tel: +33 (0)1 69 15 49 03 

From jmckenna at gatewaygeomatics.com  Wed Jul 11 09:09:40 2018
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Wed, 11 Jul 2018 13:09:40 -0300
Subject: [gdal-dev] Trac page on compiling GDAL with FITS support (was
 FITS format not listed in gdalinfo --formats)
In-Reply-To: <785777516.1729130.1531323621610.JavaMail.zimbra@u-psud.fr>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <2870428.kdFM3TiZ8S@even-i700>
 <CAKicayw2FsVdq=aywoYnWmUKXQfQfKeO3-DMZ-_Ct-w=PifWDw@mail.gmail.com>
 <CAB6t5t97-ZNsA4=b=MN2brZdeGgxffk4_xjHqrLOwr4mBhH_RA@mail.gmail.com>
 <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
 <785777516.1729130.1531323621610.JavaMail.zimbra@u-psud.fr>
Message-ID: <a69af76a-b78c-135a-2c30-2e820e1cca16@gatewaygeomatics.com>

Hi Chiara!

Absolutely, your edits are very welcomed.

If you need an account for Trac, just goto http://id.osgeo.org and 
request an account (small world: I'm one of the volunteers approving 
those accounts / due to spam attacks this is required).  I'll watch for 
your request.  thanks!  -jeff



On 2018-07-11 12:40 PM, Chiara Marmo wrote:
> Hi,
> I'm Chiara, as Trent said I'm working on FITS driver improvement in GDAL.
> 
> I have prepared a documentation page on the VESPA-Europlanet wiki [1]
> 
> I'm not an official contributor to GDAL code, but I will be happy to contribute to the Trac documentation if I may.
> May I? :)
> 
> Thanks for listening,
> Chiara
> 
> 
> [1] https://voparis-confluence.obspm.fr/display/VES/GDAL+with+FITS
> 
> ----- Original Message -----
>> From: "Jeff McKenna" <jmckenna at gatewaygeomatics.com>
>> To: gdal-dev at lists.osgeo.org
>> Sent: Thursday, July 5, 2018 8:18:50 PM
>> Subject: Re: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo --formats
>>
>> Trent, is it possible that you record all these steps and hints for
>> compiling FITS support at https://trac.osgeo.org/gdal/wiki/BuildHints
>> (i.e. create a new wiki page there and add a link to your build page in
>> the "External Library Issues" section)  That way the steps are recorded
>> and easy to find (instead of lost in the email archives)
>>
>> I'm happy to add a Windows section for compiling FITS as well.
>>
>> thanks!
>>
>> -jeff
>>
>>
>>
>> On 2018-07-05 2:12 PM, Trent Hare wrote:
>>> Susan,
>>>      Yes -  the FITS format is supported in GDAL once compilation has
>>> been linked to CFITSIO.
>>>
>>> Note this driver is currently being enhanced to (1) better support FITS
>>> files within GDAL and (2) the format FITS will have an extension added
>>> to it, which allows more typical GIS map projection support. That branch
>>> of GDAL is being worked on Chiara Marmo:
>>> https://github.com/epn-vespa/gdal/tree/fits_driver
>>>
>>> For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu)
>>> this should get you FITS support in GDAL (and also get QGIS with FITS
>>> also).
>>>
>>> _In order to have QGIS working with FITS_
>>>
>>>    * install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
>>>    * install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
>>>    * install QGIS
>>>
>>>
>>> *_Temporary workaround_: *
>>>     So a method Chiara created to test GDAL for FITS users is a simple
>>> Python script which creates a GDAL VRT header pointing into the FITS
>>> file. Once the VRT is created, any GDAL program can use it by pointing
>>> at the VRT file (gdal_translate, QGIS, ArcMap, ...). Perhaps that is
>>> worth a shot.
>>> https://github.com/epn-vespa/fits2vrt
>>>
>>> Lastly, once the FITS driver is updated we will try to support an
>>> anaconda version of GDAL with CFITSIO pre-built for users (should help
>>> Macs users too).
>>>
>>> Good luck,
>>> Trent
>>>
>>>
>>> P.S. maybe a little un-tested *build help* (linux again - sorry).
>>>
>>> Install CFITSIO
>>> Clone/download the GDAL repo.
>>> $ cd gdal/gdal
>>> you have compiled there the 'fits-driver' branch, using
>>> $ ./configure
>>> In that same repo you have a config.log file.
>>> If you grep cfitsio in config.log you must have (among others, and
>>> depending on your distro)
>>> EXTRA_INCLUDES='-I/usr/include/cfitsio '
>>> LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio
>>> -lz -lpthread -lm -lrt -ldl  -lpcre'
>>> now
>>> $ ./make
>>> more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
>>>
>>>
>>> On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu
>>> <mailto:sborda at umich.edu>> wrote:
>>>
>>>      Thanks Evan, I saw that mentioned in the formats list but I'm not
>>>      sure how to "build GDAL" with this library. I just downloaded GDAL
>>>      and it uses Python 3.6 but the version of CFITSIO I found uses
>>>      Python 2.x. I'm using a Mac but can easily run all of this on Linux
>>>      VM if need be.
>>>
>>>      -susan
>>>
>>>      On Thu, Jul 5, 2018 at 12:45 PM Even Rouault
>>>      <even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>> wrote:
>>>
>>>          On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
>>>           > Hi-
>>>           > I'm new to gdal and am trying to use gdalinfo to read a
>>>          *.fits file
>>>           > (astronomy files), specifically the header. When I list the
>>>          formats
>>>           > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS
>>>          no longer
>>>           > supported?
>>>
>>>          It is, but you must build GDAL against the CFITSIO library:
>>>          http://gdal.org/frmt_various.html#FITS
>>>
>>>          On Debian and derivatives, this is the libcfitsio-dev package.
>>>
>>>          --
>>>          Spatialys - Geospatial professional services
>>>          http://www.spatialys.com
>>>
>>>
>>>
>>>      --
>>>      Susan Borda
>>>      Data Workflows Specialist
>>>      Research Data Services
>>>      University of Michigan Libraries
>>>      3175 Shapiro Library
>>>      734-764-9134 | sborda at umich.edu <mailto:sborda at umich.edu>
>>>

From even.rouault at spatialys.com  Wed Jul 11 09:17:15 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 11 Jul 2018 18:17:15 +0200
Subject: [gdal-dev] Trac page on compiling GDAL with FITS support (was
	FITS format not listed in gdalinfo --formats)
In-Reply-To: <785777516.1729130.1531323621610.JavaMail.zimbra@u-psud.fr>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
 <785777516.1729130.1531323621610.JavaMail.zimbra@u-psud.fr>
Message-ID: <3819067.d9NXfK6fom@even-i700>

On mercredi 11 juillet 2018 17:40:21 CEST Chiara Marmo wrote:
> Hi,
> I'm Chiara, as Trent said I'm working on FITS driver improvement in GDAL.
> 
> I have prepared a documentation page on the VESPA-Europlanet wiki [1]
> 
> I'm not an official contributor to GDAL code, but I will be happy to
> contribute to the Trac documentation if I may. May I? :)

Sure. I'll send you in private message the "mantra" to create a OSGeo user id 
if you don't have one already, and you'll indicate me your id so I can grant 
you wiki page modification right.

Even

> 
> Thanks for listening,
> Chiara
> 
> 
> [1] https://voparis-confluence.obspm.fr/display/VES/GDAL+with+FITS
> 
> ----- Original Message -----
> 
> > From: "Jeff McKenna" <jmckenna at gatewaygeomatics.com>
> > To: gdal-dev at lists.osgeo.org
> > Sent: Thursday, July 5, 2018 8:18:50 PM
> > Subject: Re: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo
> > --formats
> > 
> > Trent, is it possible that you record all these steps and hints for
> > compiling FITS support at https://trac.osgeo.org/gdal/wiki/BuildHints
> > (i.e. create a new wiki page there and add a link to your build page in
> > the "External Library Issues" section)  That way the steps are recorded
> > and easy to find (instead of lost in the email archives)
> > 
> > I'm happy to add a Windows section for compiling FITS as well.
> > 
> > thanks!
> > 
> > -jeff
> > 
> > On 2018-07-05 2:12 PM, Trent Hare wrote:
> > > Susan,
> > > 
> > >     Yes -  the FITS format is supported in GDAL once compilation has
> > > 
> > > been linked to CFITSIO.
> > > 
> > > Note this driver is currently being enhanced to (1) better support FITS
> > > files within GDAL and (2) the format FITS will have an extension added
> > > to it, which allows more typical GIS map projection support. That branch
> > > of GDAL is being worked on Chiara Marmo:
> > > https://github.com/epn-vespa/gdal/tree/fits_driver
> > > 
> > > For Mac, I'm not sure this will work, but on Linux (Fedora and Ubuntu)
> > > this should get you FITS support in GDAL (and also get QGIS with FITS
> > > also).
> > > 
> > > _In order to have QGIS working with FITS_
> > > 
> > >   * install CFITSIO (Fedora : cfitsio-devel ; Ubuntu : libcfitsio-dev)
> > >   * install GDAL (Fedora : gdal-devel ; Ubuntu : libgdal-dev)
> > >   * install QGIS
> > > 
> > > *_Temporary workaround_: *
> > > 
> > >    So a method Chiara created to test GDAL for FITS users is a simple
> > > 
> > > Python script which creates a GDAL VRT header pointing into the FITS
> > > file. Once the VRT is created, any GDAL program can use it by pointing
> > > at the VRT file (gdal_translate, QGIS, ArcMap, ...). Perhaps that is
> > > worth a shot.
> > > https://github.com/epn-vespa/fits2vrt
> > > 
> > > Lastly, once the FITS driver is updated we will try to support an
> > > anaconda version of GDAL with CFITSIO pre-built for users (should help
> > > Macs users too).
> > > 
> > > Good luck,
> > > Trent
> > > 
> > > 
> > > P.S. maybe a little un-tested *build help* (linux again - sorry).
> > > 
> > > Install CFITSIO
> > > Clone/download the GDAL repo.
> > > $ cd gdal/gdal
> > > you have compiled there the 'fits-driver' branch, using
> > > $ ./configure
> > > In that same repo you have a config.log file.
> > > If you grep cfitsio in config.log you must have (among others, and
> > > depending on your distro)
> > > EXTRA_INCLUDES='-I/usr/include/cfitsio '
> > > LIBS='-lcrypto -lexpat -ljasper -ljpeg -lgeotiff -ltiff -lpng -lcfitsio
> > > -lz -lpthread -lm -lrt -ldl  -lpcre'
> > > now
> > > $ ./make
> > > more: https://trac.osgeo.org/gdal/wiki/BuildingOnUnix
> > > 
> > > 
> > > On Thu, Jul 5, 2018 at 9:59 AM Susan Borda <sborda at umich.edu
> > > 
> > > <mailto:sborda at umich.edu>> wrote:
> > >     Thanks Evan, I saw that mentioned in the formats list but I'm not
> > >     sure how to "build GDAL" with this library. I just downloaded GDAL
> > >     and it uses Python 3.6 but the version of CFITSIO I found uses
> > >     Python 2.x. I'm using a Mac but can easily run all of this on Linux
> > >     VM if need be.
> > >     
> > >     -susan
> > >     
> > >     On Thu, Jul 5, 2018 at 12:45 PM Even Rouault
> > >     
> > >     <even.rouault at spatialys.com <mailto:even.rouault at spatialys.com>> 
wrote:
> > >         On jeudi 5 juillet 2018 12:41:08 CEST Susan Borda wrote:
> > >          > Hi-
> > >          > I'm new to gdal and am trying to use gdalinfo to read a
> > >         
> > >         *.fits file
> > >         
> > >          > (astronomy files), specifically the header. When I list the
> > >         
> > >         formats
> > >         
> > >          > supported by gdalinfo, I'm only seeing FIT not FITS. Is FITS
> > >         
> > >         no longer
> > >         
> > >          > supported?
> > >         
> > >         It is, but you must build GDAL against the CFITSIO library:
> > >         http://gdal.org/frmt_various.html#FITS
> > >         
> > >         On Debian and derivatives, this is the libcfitsio-dev package.
> > >         
> > >         --
> > >         Spatialys - Geospatial professional services
> > >         http://www.spatialys.com
> > >     
> > >     --
> > >     Susan Borda
> > >     Data Workflows Specialist
> > >     Research Data Services
> > >     University of Michigan Libraries
> > >     3175 Shapiro Library
> > >     734-764-9134 | sborda at umich.edu <mailto:sborda at umich.edu>
> > 
> > --
> > Jeff McKenna
> > MapServer Consulting and Training Services
> > https://gatewaygeomatics.com/
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > https://lists.osgeo.org/mailman/listinfo/gdal-dev


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From atle at frenviksveen.net  Thu Jul 12 02:05:39 2018
From: atle at frenviksveen.net (Atle Frenvik Sveen)
Date: Thu, 12 Jul 2018 11:05:39 +0200
Subject: [gdal-dev] GDAL C# bindings, read from /vsimem/
Message-ID: <1531386339.1045069.1438249024.47117FBC@webmail.messagingengine.com>

Hi list, first time poster here.


I'm using the GDAL C# bindings in .net core via the Gdal.Core Nuget package (https://www.nuget.org/packages/Gdal.Core/)

Everyting seems to work fine, apart from the fact that I have to touch the file system in order to get my created GeoTiff as a memory stream

Sample code:

var outputRasterFileName = $"{Path.GetTempPath()}{Guid.NewGuid()}.tiff";

var driver = Gdal.GetDriverByName("GTiff");
var ds = driver.Create(outputRasterFileName, resolution.X, resolution.Y, 1, DataType.GDT_Byte, null);

SetSrsFromLayer(ds, layer);
var arg = new[] { envelope.MinX, pixelSize, 0, envelope.MinY, 0, pixelSize };
ds.SetGeoTransform(arg);
var band = ds.GetRasterBand(1);
band.SetNoDataValue(noDataValue);
band.FlushCache();
var rasterizeOptions = new[] { "ALL_TOUCHED=TRUE" }; 

Gdal.RasterizeLayer(ds, 1, new[] { 1 }, layer, IntPtr.Zero, IntPtr.Zero, 1, new[] { 10.0 }, rasterizeOptions, null, null);
ds.FlushCache();

var destination = new MemoryStream();

using (var source = File.Open(outputRasterFileName, FileMode.Open))
{
    source.CopyTo(destination);
    destination.Position = 0;
    return destination;
}

This works, but I do not like the idea of writing to disk when I don't have to. I then found these threads: 
http://osgeo-org.1560.x6.nabble.com/gdal-dev-NET-and-OGR-writing-to-stream-td3744067.html#a3744070
https://lists.osgeo.org/pipermail/gdal-dev/2016-August/045030.html

Which says I can use the memory file system handler, and the python sample code provided by Even seems easy enough to translate:

# Read /vsimem/output.png 
f = gdal.VSIFOpenL('/vsimem/output.png', 'rb')
gdal.VSIFSeekL(f, 0, 2) # seek to end
size = gdal.VSIFTellL(f)
gdal.VSIFSeekL(f, 0, 0) # seek to beginning
data = gdal.VSIFReadL(1, size, f)
gdal.VSIFCloseL(f)
# Cleanup
gdal.Unlink('/vsimem/output.png')


However, the C# bindings does not seem to include VSIFReadL, although Maksim Sestic seems to indicate that they are.

Is this an issue with the Nuget-package?

I then tried using C# Marshal.Copy, but this fails:

            var bufPtr = Gdal.VSIFOpenL(outputRasterFileName, "rb"); //outputRasterFileName is now "/vsimem/file.tiff"
            Gdal.VSIFSeekL(bufPtr, 0, 2); // seek to end
            var size = Gdal.VSIFTellL(bufPtr);
            Gdal.VSIFSeekL(bufPtr, 0, 0); // seek to beginning
            Gdal.VSIFCloseL(bufPtr);
            var data = new byte[size];
            Marshal.Copy(bufPtr, data, 0, size);           
            Gdal.Unlink(outputRasterFileName);   

I am by no means a C# expert, but I cannot see any reason this should fail? Given a memory pointer and size, read bytes, right?


As a last alternative I've tried to use the examples provided here: https://trac.osgeo.org/gdal/browser/trunk/gdal/swig/csharp/apps/GDALReadDirect.cs

This lets me read the bitmap of my raster, but all geotiff-metadata is lost. This also seems a bit overkill, as the actual GeoTiff is created and exists in memory!

So, to sum up a large mail:

1. Should Gdal.VSIFReadL be available in the C# bindings? If so, how do I get them?
2. If not 1, Should I be able to use Marshal.Copy in the manner described above? Or are there any other ways of getting these bytes?
3. If not 2, is using the sample code in https://trac.osgeo.org/gdal/browser/trunk/gdal/swig/csharp/apps/GDALReadDirect.cs a feasible way to create a stream of a geotiff-file`?


Thanks in advance for your replies, and thanks for a great library!

-a

-- 
  Atle Frenvik Sveen
  atle at frenviksveen.net
  45278689
  atlefren.net

From kchin at edrnet.com  Thu Jul 12 12:30:56 2018
From: kchin at edrnet.com (kch)
Date: Thu, 12 Jul 2018 12:30:56 -0700 (MST)
Subject: [gdal-dev] Use GDAL on AWS Lambda
Message-ID: <1531423856188-0.post@n6.nabble.com>

Hello, 

I am looking for any help from anyone who has experience with using GDAL on
AWS Lambda. I am trying to deploy a python function which uses GDAL onto AWS
Lambda. At the moment I am using Serverless to package and deploy my
function. I am at a roadblock because I can't figure out how to get all the
dependencies into my deployment package. My Serverless function packages the
dependencies listed in a requirements.txt using the
serverless-python-requirements plugin and dockerizePip: true option. At
deployment, I get the error: 

Serverless: Installing requirements of requirements.txt in .serverless…
Serverless: Docker Image: lambci/lambda:build-python3.6
Error --------------------------------------------------
The directory ‘/.cache/pip/http’ or its parent directory is not owned by the
current user and the cache has been disabled. Please check the permissions
and owner of that directory. If executing pip with sudo, you may want sudo’s
-H flag.
The directory ‘/.cache/pip’ or its parent directory is not owned by the
current user and caching wheels has been disabled. check the permissions and
owner of that directory. If executing pip with sudo, you may want sudo’s -H
flag.
Command “python setup.py egg_info” failed with error code 1 in
/tmp/pip-install-yo9exd91/pygdal/
For debugging logs, run again after setting the “SLS_DEBUG=*” environment
variable.

I have already updated setuptools to the latest version and even included
the latest version of setuptools in requirements.txt. I think the problem is
that at deployment, Serverless does not pick up all the non-python
dependencies of GDAL. I don't know how to work around this. 

I am running on Ubuntu 16.04 and Python3.6. Thank you in advance.




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From palmerjnz at gmail.com  Thu Jul 12 13:33:04 2018
From: palmerjnz at gmail.com (Jeremy Palmer)
Date: Fri, 13 Jul 2018 08:33:04 +1200
Subject: [gdal-dev] Use GDAL on AWS Lambda
In-Reply-To: <1531423856188-0.post@n6.nabble.com>
References: <1531423856188-0.post@n6.nabble.com>
Message-ID: <CAA5WJYnLmx+gRbdGivs0RFUXxQ5kxCKgsqEd_tbm16-HSSYkmg@mail.gmail.com>

I have no direct experience, but there are plenty of resources on the web
for how to install GDAL on Lambda:

https://github.com/mmcfarland/foss4g-lambda-demo (presentation
https://vimeo.com/234947418)
https://github.com/joshtkehoe/lambda-python-gdal

Both are using python 2.7, but the steps should be translatable to 3.6 as
your biggest issue is likely to be the size of linked binaries which should
be similar under both versions.

Cheers
Jeremy

On Fri, Jul 13, 2018 at 7:31 AM kch <kchin at edrnet.com> wrote:

> Hello,
>
> I am looking for any help from anyone who has experience with using GDAL on
> AWS Lambda. I am trying to deploy a python function which uses GDAL onto
> AWS
> Lambda. At the moment I am using Serverless to package and deploy my
> function. I am at a roadblock because I can't figure out how to get all the
> dependencies into my deployment package. My Serverless function packages
> the
> dependencies listed in a requirements.txt using the
> serverless-python-requirements plugin and dockerizePip: true option. At
> deployment, I get the error:
>
> Serverless: Installing requirements of requirements.txt in .serverless…
> Serverless: Docker Image: lambci/lambda:build-python3.6
> Error --------------------------------------------------
> The directory ‘/.cache/pip/http’ or its parent directory is not owned by
> the
> current user and the cache has been disabled. Please check the permissions
> and owner of that directory. If executing pip with sudo, you may want
> sudo’s
> -H flag.
> The directory ‘/.cache/pip’ or its parent directory is not owned by the
> current user and caching wheels has been disabled. check the permissions
> and
> owner of that directory. If executing pip with sudo, you may want sudo’s -H
> flag.
> Command “python setup.py egg_info” failed with error code 1 in
> /tmp/pip-install-yo9exd91/pygdal/
> For debugging logs, run again after setting the “SLS_DEBUG=*” environment
> variable.
>
> I have already updated setuptools to the latest version and even included
> the latest version of setuptools in requirements.txt. I think the problem
> is
> that at deployment, Serverless does not pick up all the non-python
> dependencies of GDAL. I don't know how to work around this.
>
> I am running on Ubuntu 16.04 and Python3.6. Thank you in advance.
>
>
>
>
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180713/d650fedf/attachment.html>

From Tim.Harris at digitalglobe.com  Thu Jul 12 14:58:59 2018
From: Tim.Harris at digitalglobe.com (Harris, Tim)
Date: Thu, 12 Jul 2018 21:58:59 +0000
Subject: [gdal-dev] Use GDAL on AWS Lambda
In-Reply-To: <1531423856188-0.post@n6.nabble.com>
References: <1531423856188-0.post@n6.nabble.com>
Message-ID: <79f8b78688004301820430d155755232@PW00INFMAI022.ent.ad.dg.local>

I haven't used Serverless, but I'm running GDAL in AWS Lambda using binary wheels:

https://github.com/youngpm/gdalmanylinux

This repo is based on Sean Gillies's wheel build for Fiona, Rasterio, and Shapely (https://github.com/sgillies/frs-wheel-builds). I believe it has instructions, but the general idea is that it uses an old linux Docker image to build GDAL wheels for a few different Python versions. Once those are built, I use the pip --target option to install my Lambda code, any required Python modules, and the GDAL wheel into a local directory. Then I just zip up that directory, upload to S3, and run my Lambda function. The zip ends up being about 30 MB.

For example, to install the GDAL wheel into the local directory, I would do something like this:
pip install --target ./lambda_zip_dir ./wheels/GDAL-2.3.0-cp36-cp36m-manylinux1_x86_64.whl

Same idea for any other dependencies and for my own Lambda code.

-----Original Message-----
From: gdal-dev [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of kch
Sent: Thursday, July 12, 2018 1:31 PM
To: gdal-dev at lists.osgeo.org
Subject: [gdal-dev] Use GDAL on AWS Lambda

Hello, 

I am looking for any help from anyone who has experience with using GDAL on
AWS Lambda. I am trying to deploy a python function which uses GDAL onto AWS
Lambda. At the moment I am using Serverless to package and deploy my
function. I am at a roadblock because I can't figure out how to get all the
dependencies into my deployment package. My Serverless function packages the
dependencies listed in a requirements.txt using the
serverless-python-requirements plugin and dockerizePip: true option. At
deployment, I get the error: 

Serverless: Installing requirements of requirements.txt in .serverless…
Serverless: Docker Image: lambci/lambda:build-python3.6
Error --------------------------------------------------
The directory ‘/.cache/pip/http’ or its parent directory is not owned by the
current user and the cache has been disabled. Please check the permissions
and owner of that directory. If executing pip with sudo, you may want sudo’s
-H flag.
The directory ‘/.cache/pip’ or its parent directory is not owned by the
current user and caching wheels has been disabled. check the permissions and
owner of that directory. If executing pip with sudo, you may want sudo’s -H
flag.
Command “python setup.py egg_info” failed with error code 1 in
/tmp/pip-install-yo9exd91/pygdal/
For debugging logs, run again after setting the “SLS_DEBUG=*” environment
variable.

I have already updated setuptools to the latest version and even included
the latest version of setuptools in requirements.txt. I think the problem is
that at deployment, Serverless does not pick up all the non-python
dependencies of GDAL. I don't know how to work around this. 

I am running on Ubuntu 16.04 and Python3.6. Thank you in advance.




--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/gdal-dev

From chiara.marmo at u-psud.fr  Fri Jul 13 02:59:31 2018
From: chiara.marmo at u-psud.fr (Chiara Marmo)
Date: Fri, 13 Jul 2018 11:59:31 +0200 (CEST)
Subject: [gdal-dev] Trac page on compiling GDAL with FITS support
In-Reply-To: <3819067.d9NXfK6fom@even-i700>
References: <CAKicayzNe1sFvO8V3TaA3qMRYnjzwJ36C3wofxmogfdPZ=FAcQ@mail.gmail.com>
 <53abc6ed-5453-e969-764f-a730460f47fa@gatewaygeomatics.com>
 <785777516.1729130.1531323621610.JavaMail.zimbra@u-psud.fr>
 <3819067.d9NXfK6fom@even-i700>
Message-ID: <1903189718.2870132.1531475971506.JavaMail.zimbra@u-psud.fr>

Hello,

Just to let you all know that a page describing how to link GDAL against CFITSIO is now available at
https://trac.osgeo.org/gdal/wiki/FITS

Best,
Chiara


----- Original Message -----
> From: "Even Rouault" <even.rouault at spatialys.com>
> To: gdal-dev at lists.osgeo.org
> Sent: Wednesday, July 11, 2018 6:17:15 PM
> Subject: Re: [gdal-dev] Trac page on compiling GDAL with FITS support (was	FITS format not listed in gdalinfo
> --formats)
> 
> On mercredi 11 juillet 2018 17:40:21 CEST Chiara Marmo wrote:
> > Hi,
> > I'm Chiara, as Trent said I'm working on FITS driver improvement in GDAL.
> > 
> > I have prepared a documentation page on the VESPA-Europlanet wiki [1]
> > 
> > I'm not an official contributor to GDAL code, but I will be happy to
> > contribute to the Trac documentation if I may. May I? :)
> 
> Sure. I'll send you in private message the "mantra" to create a OSGeo user id
> if you don't have one already, and you'll indicate me your id so I can grant
> you wiki page modification right.
> 
> Even
> 
> > 
> > Thanks for listening,
> > Chiara
> > 
> > 
> > [1] https://voparis-confluence.obspm.fr/display/VES/GDAL+with+FITS
> > 
> > ----- Original Message -----
> > 
> > > From: "Jeff McKenna" <jmckenna at gatewaygeomatics.com>
> > > To: gdal-dev at lists.osgeo.org
> > > Sent: Thursday, July 5, 2018 8:18:50 PM
> > > Subject: Re: [gdal-dev] [EXTERNAL] Re: FITS format not listed in gdalinfo
> > > --formats
> > > 
> > > Trent, is it possible that you record all these steps and hints for
> > > compiling FITS support at https://trac.osgeo.org/gdal/wiki/BuildHints
> > > (i.e. create a new wiki page there and add a link to your build page in
> > > the "External Library Issues" section)  That way the steps are recorded
> > > and easy to find (instead of lost in the email archives)
> > > 
> > > I'm happy to add a Windows section for compiling FITS as well.
> > > 
> > > thanks!
> > > 
> > > -jeff
> > > 

From kchin at edrnet.com  Fri Jul 13 11:16:57 2018
From: kchin at edrnet.com (kch)
Date: Fri, 13 Jul 2018 11:16:57 -0700 (MST)
Subject: [gdal-dev] Use GDAL on AWS Lambda
In-Reply-To: <79f8b78688004301820430d155755232@PW00INFMAI022.ent.ad.dg.local>
References: <1531423856188-0.post@n6.nabble.com>
 <79f8b78688004301820430d155755232@PW00INFMAI022.ent.ad.dg.local>
Message-ID: <1531505817169-0.post@n6.nabble.com>

Tim's solution worked for me. Thank you!



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From klassen.js at gmail.com  Fri Jul 13 12:08:17 2018
From: klassen.js at gmail.com (James Klassen)
Date: Fri, 13 Jul 2018 14:08:17 -0500
Subject: [gdal-dev] Esri JSON Curves
In-Reply-To: <1799257.XZN1n8Dzpk@even-i700>
References: <CAHqX796fb24M9yV9_PQ3A4C9BhJwyiB2wFs+KJ-9Sk+daY8ipQ@mail.gmail.com>
 <3910957.a1sd9sZLSe@even-i700>
 <ff96c5fc-a780-0a30-78bf-330dadea0be5@gmail.com>
 <1799257.XZN1n8Dzpk@even-i700>
Message-ID: <CAHqX794Em0Gjh+BOMRWWByXFQ2CfuK2c01haecJsFXzspb7iHw@mail.gmail.com>

Ok.  I made that change and it appears to work.

Latest code available here: https://github.com/klassenjs/
gdal/tree/esrijson-curves

On Mon, Jul 2, 2018 at 1:56 PM, Even Rouault <even.rouault at spatialys.com>
wrote:

> >
> > In the first two cases (without OLCCurveGeometries set) I see
> > curveToLineString is being called when there are curves in the data, but
> > not on every result page (again curves are relatively rare in the
> dataset).
>
> ok, then replace the call to OGRMemLayer::SetFeature() with
> OGRMemLayer::ISetFeature() in ogrgeojsonlayer.cpp to shortcut the
> linearization that is done by the generic OGRLayer::SetFeature()
>
> And you can then remove OLCCurveGeometries
>
>
> > In the last two cases (with OLCCurveGeometries set) I see
> > curveToLineString is being called with a different back trace (related
> > to OGRGeometryFactory::organizePolygons):
>
> That one is fine. It is an implementation detail of organizePolygons()
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180713/91ca1f30/attachment.html>

From arno at agerrius.nl  Sun Jul 15 05:40:36 2018
From: arno at agerrius.nl (Arno Gerretsen)
Date: Sun, 15 Jul 2018 14:40:36 +0200
Subject: [gdal-dev] WMS, blocksize and black lines
In-Reply-To: <9f04b1e46f4ced7cd86d04885233f796@agerrius.nl>
References: <a81dd60bee618a8ed091ae9752cd54cc@agerrius.nl>
 <E4954861B9544F5B8C45DCD07E3BD739@aquaveo.local>
 <9f04b1e46f4ced7cd86d04885233f796@agerrius.nl>
Message-ID: <11fdfe7f66f34bfad006797d07583716@agerrius.nl>

Just a little follow-up on this. I found another WMS server with the 
same images and it doesn't show these black lines. So I guess it is also 
something with this specific WMS server and not in GDAL.

Arno


On 2018-07-10 07:46, Arno Gerretsen wrote:
> Chris,
> 
> Thanks for the answer, if I put the window in the XML file it indeed
> also works for me.
> 
> But in my application I am sampling the GDAL dataset from code and
> setting a different window each time from code as well. So to modify
> the WMS XML every time in that case would not really be a work able
> solution.
> 
> This approach worked fine in the past with another WMS server, so I
> was hoping I missed some setting somewhere or so. I'll do some more
> experimentation.
> 
> Arno
> 
> 
> On 2018-07-10 07:04, Chris Smemoe wrote:
>> Arno,
>> 
>> I suspect the black lines has something to do with using the -projwin
>> argument to gdal_translate along with the DataWindow tag information 
>> in the
>> XML file.  The following XML works fine for me with the following 
>> command
>> line: "gdal_translate wms.xml test.tif"
>> 
>> <GDAL_WMS>
>>    <Service name="WMS">
>>      <Version>1.1.1</Version>
>> 
>> <ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServ
>> er/WMSServer</ServerUrl>
>>      <ImageFormat>tiff</ImageFormat>
>>      <Layers>0</Layers>
>>      <BBoxOrder>xyXY</BBoxOrder>
>>      <SRS>EPSG:4326</SRS>
>>    </Service>
>>    <DataWindow>
>>      <UpperLeftX>-89.0</UpperLeftX>
>>      <UpperLeftY>42.0</UpperLeftY>
>>      <LowerRightX>-88.0</LowerRightX>
>>      <LowerRightY>41.0</LowerRightY>
>>      <SizeX>1024</SizeX>
>>      <SizeY>1024</SizeY>
>>    </DataWindow>
>>    <UnsafeSSL>true</UnsafeSSL>
>> </GDAL_WMS>
>> 
>> Chris
>> 
>> -----Original Message-----
>> From: gdal-dev [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of 
>> Arno
>> Gerretsen
>> Sent: Monday, July 09, 2018 12:01 PM
>> To: gdal-dev at lists.osgeo.org
>> Subject: [gdal-dev] WMS, blocksize and black lines
>> 
>> Hi all,
>> 
>> I'm trying to create a WMS XML to access some WMS data in GDAL. But I
>> get black lines in the resulting image. I have found out that if I
>> reduce the size of the BlockSize in the WMS XML that the lines get 
>> more
>> narrow, but the download speed of the images also reduces a lot. Am I
>> missing some setting here to make it work?
>> 
>> This is the XML file I use:
>> 
>> <GDAL_WMS>
>>    <Service name="WMS">
>>      <Version>1.1.1</Version>
>> 
>> <ServerUrl>https://gis.apfo.usda.gov/arcgis/services/NAIP/Illinois/ImageServ
>> er/WMSServer?SERVICE=WMS</ServerUrl>
>>      <Layers>0</Layers>
>>      <SRS>EPSG:4326</SRS>
>>      <ImageFormat>image/tiff</ImageFormat>
>>      <Transparent>FALSE</Transparent>
>>      <BBoxOrder>xyXY</BBoxOrder>
>>    </Service>
>>    <DataWindow>
>>      <UpperLeftX>-91.562525</UpperLeftX>
>>      <UpperLeftY>42.562525</UpperLeftY>
>>      <LowerRightX>-87.437470</LowerRightX>
>>      <LowerRightY>36.937474</LowerRightY>
>> 	<SizeX>370834</SizeX>
>>      <SizeY>625056</SizeY>
>>    </DataWindow>
>>    <BandsCount>4</BandsCount>
>>    <UnsafeSSL>true</UnsafeSSL>
>>    <BlockSizeX>1024</BlockSizeX>
>>    <BlockSizeY>1024</BlockSizeY>
>> </GDAL_WMS>
>> 
>> And this is a sample call that shows the black lines:
>> 
>> gdal_translate -projwin -88.0 42.0 -87.99 41.99 wms.xml test.tif
>> 
>> With regards,

-- 
Arno

From bontepaarden at gmail.com  Mon Jul 16 01:53:30 2018
From: bontepaarden at gmail.com (Paul Meems)
Date: Mon, 16 Jul 2018 10:53:30 +0200
Subject: [gdal-dev] Dissolve large amount of geometries
In-Reply-To: <LOXP12301MB165651907BC0D9AA46123AAF824E0@LOXP12301MB1656.GBRP123.PROD.OUTLOOK.COM>
References: <CAHNf2YQ4K3uJ-aHEvVWPyLTKRQUe9wY8C8-4TnYqaR3CMkfOgg@mail.gmail.com>
 <1581772.x2kfsGyav9@even-i700>
 <CAHNf2YTbTo4NzWGWOX+9e7__f-tcO+CsZFU6drCNgoMKTM2fPg@mail.gmail.com>
 <LOXP12301MB165651907BC0D9AA46123AAF824E0@LOXP12301MB1656.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>

Thanks, Jon for your suggestion of GeoPandas.
Unfortunately, I'm not allowed to use new external dependencies.

I tried doing all steps in an SQLite file instead of using several
intermediate shapefiles. And I had some good results, so I created a script
dissolving an increasingly higher number of shapes.
Later I realized the performance increase was because in the new script I
forgot '-*explodecollections*'. This makes a huge difference. For now, I'll
keep the multipart polygons.

These commands I converted to a C# unit test:
// Convert fishnet shapefile to SQLite:
ogr2ogr -f SQLite taskmap.sqlite "Fishnet.shp" -nln fishnet -nlt POLYGON
-dsco SPATIALITE=YES -lco SPATIAL_INDEX=NO -gt unlimited --config
OGR_SQLITE_CACHE 4096 --config OGR_SQLITE_SYNCHRONOUS OFF
// Add field:
ogrinfo taskmap.sqlite -sql "ALTER TABLE fishnet ADD COLUMN randField real"
// Fill random values:
ogrinfo taskmap.sqlite -sql "UPDATE fishnet SET randField = ABS(RANDOM() %
10)"
// Create index:
ogrinfo taskmap.sqlite -sql "CREATE INDEX randfield_idx ON fishnet
(randField)"
// Combined dissolve and export:
ogr2ogr -f "ESRI Shapefile" -overwrite taskmap.shp taskmap.sqlite -sql
"SELECT ST_Union(geometry) as geom, randField FROM fishnet GROUP BY
randField" -gt unlimited --config OGR_SQLITE_CACHE 4096 --config
OGR_SQLITE_SYNCHRONOUS OFF

Some timing:
1,677 shapes --> 0.3s
4,810 shapes --> 1.8s
18,415 shapes --> 21.4s
72,288 shapes --> 5min, 54s
285,927 shapes --> 25m
1,139,424 shapes --> 6h, 47m
4,557,696 shapes --> Still running for 34h

4 million shapes are the amount my application needs to handle, but running
for days is not an option.

I noticed my script is using only a fraction of my resources: 30% RAM (of
12GB), 22-28% CPU (on 8 cores).
How can I let GDAL use more resources? Might it speed up the process?

I also read about CascadedUnion of GEOS. Can I also use it with GDAL/OGR?
If so how?
And would it help to enable GPU? If so, do I need a special build? I'm now
using the Windows-64bit of gisinternals.com

Thanks again for any pointers and/or suggestions.

Paul
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/63b07c2a/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 55474 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/63b07c2a/attachment-0001.png>

From ao at t-kartor.se  Mon Jul 16 02:30:35 2018
From: ao at t-kartor.se (Andreas Oxenstierna)
Date: Mon, 16 Jul 2018 11:30:35 +0200
Subject: [gdal-dev] Dissolve large amount of geometries
In-Reply-To: <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>
References: <CAHNf2YQ4K3uJ-aHEvVWPyLTKRQUe9wY8C8-4TnYqaR3CMkfOgg@mail.gmail.com>
 <1581772.x2kfsGyav9@even-i700>
 <CAHNf2YTbTo4NzWGWOX+9e7__f-tcO+CsZFU6drCNgoMKTM2fPg@mail.gmail.com>
 <LOXP12301MB165651907BC0D9AA46123AAF824E0@LOXP12301MB1656.GBRP123.PROD.OUTLOOK.COM>
 <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>
Message-ID: <2CAC6695-4A5C-47C8-84D9-25B9FAED26B3@t-kartor.se>

ST_Union in PostGIS should scale better than SQLite. 
ST_Dump gives you singlepart geometries. 

Best Regards

Andreas Oxenstierna



> 16 juli 2018 kl. 10:53 skrev Paul Meems <bontepaarden at gmail.com>:
> 
> Thanks, Jon for your suggestion of GeoPandas.
> Unfortunately, I'm not allowed to use new external dependencies.
> 
> I tried doing all steps in an SQLite file instead of using several intermediate shapefiles. And I had some good results, so I created a script dissolving an increasingly higher number of shapes.
> Later I realized the performance increase was because in the new script I forgot '-explodecollections'. This makes a huge difference. For now, I'll keep the multipart polygons.
> 
> These commands I converted to a C# unit test:
> // Convert fishnet shapefile to SQLite:
> ogr2ogr -f SQLite taskmap.sqlite "Fishnet.shp" -nln fishnet -nlt POLYGON -dsco SPATIALITE=YES -lco SPATIAL_INDEX=NO -gt unlimited --config OGR_SQLITE_CACHE 4096 --config OGR_SQLITE_SYNCHRONOUS OFF 
> // Add field:
> ogrinfo taskmap.sqlite -sql "ALTER TABLE fishnet ADD COLUMN randField real"
> // Fill random values:
> ogrinfo taskmap.sqlite -sql "UPDATE fishnet SET randField = ABS(RANDOM() % 10)"
> // Create index:
> ogrinfo taskmap.sqlite -sql "CREATE INDEX randfield_idx ON fishnet (randField)"
> // Combined dissolve and export:
> ogr2ogr -f "ESRI Shapefile" -overwrite taskmap.shp taskmap.sqlite -sql "SELECT ST_Union(geometry) as geom, randField FROM fishnet GROUP BY randField" -gt unlimited --config OGR_SQLITE_CACHE 4096 --config OGR_SQLITE_SYNCHRONOUS OFF
> 
> Some timing:
> 1,677 shapes --> 0.3s
> 4,810 shapes --> 1.8s
> 18,415 shapes --> 21.4s
> 72,288 shapes --> 5min, 54s
> 285,927 shapes --> 25m
> 1,139,424 shapes --> 6h, 47m
> 4,557,696 shapes --> Still running for 34h
> 
> 4 million shapes are the amount my application needs to handle, but running for days is not an option.
> 
> I noticed my script is using only a fraction of my resources: 30% RAM (of 12GB), 22-28% CPU (on 8 cores).
> How can I let GDAL use more resources? Might it speed up the process?
> 
> I also read about CascadedUnion of GEOS. Can I also use it with GDAL/OGR? If so how?
> And would it help to enable GPU? If so, do I need a special build? I'm now using the Windows-64bit of gisinternals.com
> 
> Thanks again for any pointers and/or suggestions.
> 
> Paul
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/01ab1eed/attachment.html>

From andrew at aitchison.me.uk  Mon Jul 16 02:27:28 2018
From: andrew at aitchison.me.uk (Andrew C Aitchison)
Date: Mon, 16 Jul 2018 10:27:28 +0100 (BST)
Subject: [gdal-dev] Dissolve large amount of geometries
In-Reply-To: <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>
References: <CAHNf2YQ4K3uJ-aHEvVWPyLTKRQUe9wY8C8-4TnYqaR3CMkfOgg@mail.gmail.com>
 <1581772.x2kfsGyav9@even-i700>
 <CAHNf2YTbTo4NzWGWOX+9e7__f-tcO+CsZFU6drCNgoMKTM2fPg@mail.gmail.com>
 <LOXP12301MB165651907BC0D9AA46123AAF824E0@LOXP12301MB1656.GBRP123.PROD.OUTLOOK.COM>
 <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>
Message-ID: <alpine.LRH.2.21.1807161017400.20017@warden.aitchison.me.uk>

On Mon, 16 Jul 2018, Paul Meems wrote:

> Thanks, Jon for your suggestion of GeoPandas.
> Unfortunately, I'm not allowed to use new external dependencies.

> Some timing:
> 1,677 shapes --> 0.3s
> 4,810 shapes --> 1.8s
> 18,415 shapes --> 21.4s
> 72,288 shapes --> 5min, 54s
> 285,927 shapes --> 25m
> 1,139,424 shapes --> 6h, 47m
> 4,557,696 shapes --> Still running for 34h
>
> 4 million shapes are the amount my application needs to handle, but running
> for days is not an option.
>
> I noticed my script is using only a fraction of my resources: 30% RAM (of
> 12GB), 22-28% CPU (on 8 cores).
> How can I let GDAL use more resources? Might it speed up the process?

If you aren't using most of your CPU or memory, I'd guess that reading 
from or writing to disk is the bottleneck. I'm not sure whether ogr uses
GDAL_CACHEMAX, but you could try
     export GDAL_CACHEMAX=12288
to make gdal use 12GB of cache (default is 40MB or 5% of RAM).
If the bottleneck is in sqlite you might be able to do something equivalent
there. If the bottleneck is writing the file, perhaps a ram disk might 
make sense ?

-- 
Andrew C. Aitchison					Cambridge, UK
 			andrew at aitchison.me.uk

From robert.coup at koordinates.com  Mon Jul 16 06:51:26 2018
From: robert.coup at koordinates.com (Robert Coup)
Date: Mon, 16 Jul 2018 14:51:26 +0100
Subject: [gdal-dev] Docker images for development/testing?
Message-ID: <CAFLLRpJVM2=VpJMikuzXb5huk+X6iNq9NNOLqaVYRK0daz=e0g@mail.gmail.com>

Hi All,

For me at least, maintaining working dev environments for GDAL can be
frustrating... there are a lot of dependencies, platforms, and a huge
number of config options. Let alone switching branches for backports/etc. I
typically use OSX as a desktop and linux environments running under that
via Docker & Virtualbox.

GDAL has really comprehensive CI, but I wonder if there's ways to improve
local dev & testing workflows? There is a Vagrant image from a while back,
but it runs Ubuntu Precise which is well EOL, so I assume it's not in
regular use.

What are other people doing? Does anyone have an elegant dev environment
they could share?

Suggestion:

1. docker images with all the build/test/library dependencies already
installed — publish them so getting the right dependencies & environment is
only a download.

2. docker-compose files with ccache and source trees mapped to the host
checkout. This should make builds & rebuilds comprehensive, and as quick as
possible (but won't be as fast as native builds). Could also be wrappers
around docker run.

I made a very rough proof of concept out of the trusty_clang travis
scripts...

https://github.com/koordinates/gdal/tree/docker-dev-poc/gdal/ci/docker

# build the base image with the dependencies
$ docker-compose -f gdal/ci/docker/docker-compose.yml build
# start the dev environment
$ docker-compose -f gdal/ci/docker/docker-compose.yml up -d

# repeat this bit as you develop
  # use the CI steps
  $ docker-compose -f gdal/ci/docker/docker-compose.yml exec /ci.sh all  #
build+test
  $ docker-compose -f gdal/ci/docker/docker-compose.yml exec /ci.sh build
  $ docker-compose -f gdal/ci/docker/docker-compose.yml exec /ci.sh test

  # or do it manually
  $ docker-compose -f gdal/ci/docker/docker-compose.yml exec bash

# tear it all down
$ docker-compose -f gdal/ci/docker/docker-compose.yml down

Thoughts? Comments?

Without other steering, I guess the next steps would be:

- do it for the best/cleanest/modern/featureful environment & compiler
rather than the venerable Trusty (which one?)
- don't run as root, make sure steps are fully repeatable, etc
- ideally a bunch of the stuff in the existing ci .sh files would be in
Makefiles or elsewhere I think?
- have a script that runs configure/etc with all the options + dependencies
that will work in the environment. (ie. extract more of install.sh)
- keep the .o files in the container instance rather than the source tree?
http://make.mad-scientist.net/papers/multi-architecture-builds/ via some
autotools voodoo?
- make it easier to extend for supporting other environments

Cheers,

Rob :)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/102a81e3/attachment.html>

From howard at hobu.co  Mon Jul 16 09:46:45 2018
From: howard at hobu.co (Howard Butler)
Date: Mon, 16 Jul 2018 11:46:45 -0500
Subject: [gdal-dev] Docker images for development/testing?
In-Reply-To: <CAFLLRpJVM2=VpJMikuzXb5huk+X6iNq9NNOLqaVYRK0daz=e0g@mail.gmail.com>
References: <CAFLLRpJVM2=VpJMikuzXb5huk+X6iNq9NNOLqaVYRK0daz=e0g@mail.gmail.com>
Message-ID: <74d1d868-f177-2ef1-477d-619be7be1efa@hobu.co>



On 7/16/18 8:51 AM, Robert Coup wrote:
> Suggestion:
>
> 1. docker images with all the build/test/library dependencies already
> installed — publish them so getting the right dependencies & environment is
> only a download.
>
>
> Thoughts? Comments?
PDAL uses Alpine+Docker for its TravisCI builds. The approach definitely
has some useful bug replication benefits, especially when we need to
take something locally for more intense debugging or we want someone to
reproduce a bug with a specific configuration. It is also convenient
that people can fetch the same base images from DockerHub and build
their own using our Travis configuration as a guide.

The downside of docker for CI testing is one more layer of stuff to go
wrong.

We switched from using Ubuntu to Alpine in an attempt to get smaller
images, with some painful success. Alpine images were definitely
smaller, but not always as convenient, and the packaging story is less
rigorous IMO. I'd say we're indifferent to Alpine vs. Ubuntu at this
time, and we'd probably just stick with Ubuntu given our experience.

See the PDAL tree's .travis.yml and scripts/ci directory for more
information https://github.com/PDAL/PDAL/

Howard






-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 528 bytes
Desc: OpenPGP digital signature
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/5db32389/attachment-0001.sig>

From bontepaarden at gmail.com  Mon Jul 16 12:27:52 2018
From: bontepaarden at gmail.com (Paul Meems)
Date: Mon, 16 Jul 2018 21:27:52 +0200
Subject: [gdal-dev] Dissolve large amount of geometries
In-Reply-To: <2CAC6695-4A5C-47C8-84D9-25B9FAED26B3@t-kartor.se>
References: <CAHNf2YQ4K3uJ-aHEvVWPyLTKRQUe9wY8C8-4TnYqaR3CMkfOgg@mail.gmail.com>
 <1581772.x2kfsGyav9@even-i700>
 <CAHNf2YTbTo4NzWGWOX+9e7__f-tcO+CsZFU6drCNgoMKTM2fPg@mail.gmail.com>
 <LOXP12301MB165651907BC0D9AA46123AAF824E0@LOXP12301MB1656.GBRP123.PROD.OUTLOOK.COM>
 <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>
 <2CAC6695-4A5C-47C8-84D9-25B9FAED26B3@t-kartor.se>
Message-ID: <CAHNf2YSh+aUCVe6p_ViJn-VnDEqrX+SaNkr09mWW8oQVjqLEsw@mail.gmail.com>

I took the advice of Andreas and converted my code to using PostGIS.
And the speed difference is enormous.

The commands I've used:
// Import shapefile into PostGIS:
ogr2ogr -f PostgreSQL PG:"host=localhost user=..." fishnet.shp -gt
unlimited -lco GEOMETRY_NAME=geom -a_srs "EPSG:28992"
// Add random data:
ogrinfo PG:"host=localhost user=..." -sql "ALTER TABLE fishnet ADD COLUMN
randField integer;UPDATE fishnet SET randField = ceil(RANDOM()*10);CREATE
INDEX randfield_idx ON fishnet (randField);
// Dissolve:
ogrinfo PG:"host=localhost user=..." -sql "CREATE TABLE dissolved AS SELECT
randfield, ST_Multi(ST_Union(f.geom)) AS geom FROM fishnet AS f GROUP BY
randfield"
// Export to shapefile
ogr2ogr -f "ESRI Shapefile" taskmap.shp PG:"host=localhost user=..." -sql
"SELECT randfield, (st_dump(geom)).geom AS geom FROM dissolved" -overwrite
-gt unlimited
// Clean up:
ogrinfo PG:"host=localhost user=..." -sql "DROP TABLE IF EXISTS fishnet
CASCADE;DROP TABLE IF EXISTS dissolved CASCADE"

The timing of the steps, after I converted the above commands to C#:
| #shapes |Import     |Add values |  Dissolve |    Export |
|1,677    |00:00:00.29|00:00:00.14|00:00:00.10|00:00:00.05|
|4,810    |00:00:00.28|00:00:00.20|00:00:01.11|00:00:00.15|
|18,415   |00:00:00.78|00:00:00.53|00:00:04.57|00:00:00.31|

|72,288   |00:00:02.07|00:00:02.13|00:00:22.56|00:00:01.02|
|285,927  |00:00:07.58|00:00:06.68|00:01:59.59|00:00:03.82|
|1,139,424|00:00:26.63|00:00:33.51|00:11:34.63|00:00:15.19|
|4,546,854|00:01:46.19|00:03:51.92|01:10:07.41|00:00:57.51|

4.5 million squares of 0.3m have a total area of about 40 ha.
That is good enough for me. The total time will be around 80 min, instead
of days using SQLite.

I'm assuming I can't speed up this command anymore, right?
ogrinfo PG:"host=localhost user=..." -sql "CREATE TABLE dissolved AS SELECT
randfield, ST_Multi(ST_Union(f.geom)) AS geom FROM fishnet AS f GROUP BY
randfield"

Thanks all for your valuable help.

Regards,

Paul

Op ma 16 jul. 2018 om 11:30 schreef Andreas Oxenstierna <ao at t-kartor.se>:

> ST_Union in PostGIS should scale better than SQLite.
> ST_Dump gives you singlepart geometries.
>
> Best Regards
>
> Andreas Oxenstierna
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/2ae345ce/attachment.html>

From even.rouault at spatialys.com  Mon Jul 16 14:07:42 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 16 Jul 2018 23:07:42 +0200
Subject: [gdal-dev] Docker images for development/testing?
In-Reply-To: <CAFLLRpJVM2=VpJMikuzXb5huk+X6iNq9NNOLqaVYRK0daz=e0g@mail.gmail.com>
References: <CAFLLRpJVM2=VpJMikuzXb5huk+X6iNq9NNOLqaVYRK0daz=e0g@mail.gmail.com>
Message-ID: <23579096.tv1iJP72mt@even-i700>

> 
> I made a very rough proof of concept out of the trusty_clang travis
> scripts...

> Thoughts? Comments?

Good initiative. As far as I'm concerned, the scripts/setdevenv.sh on my 
native Linux env does the job, but that indeed requires to have all the 
dependencies right.

> 
> Without other steering, I guess the next steps would be:
> 
> - do it for the best/cleanest/modern/featureful environment & compiler
> rather than the venerable Trusty (which one?)

Ubuntu 18.04 would probably be better. I've added it recently as one of the CI 
env, but using chroot instead of Docker (since I'm modestly familiate with it, 
and mixing root and non-root steps didn't seem to be immediately trivial)

> - don't run as root, make sure steps are fully repeatable, etc

I see you work arounded some things of the existing CI scripts. They can be 
adjusted if you need to.

> - ideally a bunch of the stuff in the existing ci .sh files would be in
> Makefiles or elsewhere I think?
> - have a script that runs configure/etc with all the options + dependencies
> that will work in the environment. (ie. extract more of install.sh)
> - keep the .o files in the container instance rather than the source tree?
> http://make.mad-scientist.net/papers/multi-architecture-builds/ via some
> autotools voodoo?

I didn't read the link but be aware that GDAL just uses autoconf and not 
automake.

Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From schwehr at gmail.com  Mon Jul 16 15:07:34 2018
From: schwehr at gmail.com (Kurt Schwehr)
Date: Mon, 16 Jul 2018 15:07:34 -0700
Subject: [gdal-dev] Docker images for development/testing?
In-Reply-To: <23579096.tv1iJP72mt@even-i700>
References: <CAFLLRpJVM2=VpJMikuzXb5huk+X6iNq9NNOLqaVYRK0daz=e0g@mail.gmail.com>
 <23579096.tv1iJP72mt@even-i700>
Message-ID: <CACmBxyvxAByD8tYDMUa=EdWMssxQMQZLVQXh-673m6hnkQjKBg@mail.gmail.com>

I might suggest going with debian testing to get reasonably new dependent
libs (if that matters to you).  I've been using it for 6 months for my
desktop and it has worked well for me.

On Mon, Jul 16, 2018 at 2:07 PM, Even Rouault <even.rouault at spatialys.com>
wrote:

> >
> > I made a very rough proof of concept out of the trusty_clang travis
> > scripts...
>
> > Thoughts? Comments?
>
> Good initiative. As far as I'm concerned, the scripts/setdevenv.sh on my
> native Linux env does the job, but that indeed requires to have all the
> dependencies right.
>
> >
> > Without other steering, I guess the next steps would be:
> >
> > - do it for the best/cleanest/modern/featureful environment & compiler
> > rather than the venerable Trusty (which one?)
>
> Ubuntu 18.04 would probably be better. I've added it recently as one of
> the CI
> env, but using chroot instead of Docker (since I'm modestly familiate with
> it,
> and mixing root and non-root steps didn't seem to be immediately trivial)
>
> > - don't run as root, make sure steps are fully repeatable, etc
>
> I see you work arounded some things of the existing CI scripts. They can
> be
> adjusted if you need to.
>
> > - ideally a bunch of the stuff in the existing ci .sh files would be in
> > Makefiles or elsewhere I think?
> > - have a script that runs configure/etc with all the options +
> dependencies
> > that will work in the environment. (ie. extract more of install.sh)
> > - keep the .o files in the container instance rather than the source
> tree?
> > http://make.mad-scientist.net/papers/multi-architecture-builds/ via some
> > autotools voodoo?
>
> I didn't read the link but be aware that GDAL just uses autoconf and not
> automake.
>
> Even
>
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev




-- 
--
http://schwehr.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180716/a6e5db8b/attachment.html>

From ao at t-kartor.se  Mon Jul 16 23:35:05 2018
From: ao at t-kartor.se (Andreas Oxenstierna)
Date: Tue, 17 Jul 2018 08:35:05 +0200
Subject: [gdal-dev] Dissolve large amount of geometries
In-Reply-To: <CAHNf2YSh+aUCVe6p_ViJn-VnDEqrX+SaNkr09mWW8oQVjqLEsw@mail.gmail.com>
References: <CAHNf2YQ4K3uJ-aHEvVWPyLTKRQUe9wY8C8-4TnYqaR3CMkfOgg@mail.gmail.com>
 <1581772.x2kfsGyav9@even-i700>
 <CAHNf2YTbTo4NzWGWOX+9e7__f-tcO+CsZFU6drCNgoMKTM2fPg@mail.gmail.com>
 <LOXP12301MB165651907BC0D9AA46123AAF824E0@LOXP12301MB1656.GBRP123.PROD.OUTLOOK.COM>
 <CAHNf2YR7hCo6O_RETtMSYBLJLUJYkzW2=jiADN+4WTqoK6vRXw@mail.gmail.com>
 <2CAC6695-4A5C-47C8-84D9-25B9FAED26B3@t-kartor.se>
 <CAHNf2YSh+aUCVe6p_ViJn-VnDEqrX+SaNkr09mWW8oQVjqLEsw@mail.gmail.com>
Message-ID: <ce6084c2-1ef2-8ca2-6aa0-55b2b2d6ae57@t-kartor.se>

If it is 20 mill. coordinates, it could be faster than 80 minutes, I 
guess in the region of 10 minutes.

I would:
1 Combine 3+4 to something like (I assume ST_Multi is not needed) - this 
avoids data duplication and one unnecessary transaction commit
    SELECT randfield, (st_dump(ST_Union(f.geom))).geom AS geom FROM 
fishnet AS f GROUP BY randfield

2 Remove the CREATE INDEX and/or add a spatial index - I do not really 
understand the random union logic

3 CLUSTER any index and ANALYZE (after CREATE INDEX)

4 Check PostgreSQL configs (work_mem, shared_buffers etc) - your stats 
shows a non-linear scaling above 100000 polys so db/hardware limits are hit

5 Disable autovacuum - may interfere during ST_Union execution

6 Execute on real hardware - no (cheap) laptop and Linux is faster - as 
an example this kind of PostGIS execution can be 2-3 times faster on 
iMac compared with "standard laptop"

7 Step 2 may be more efficient as well with
ADD COLUMN randField integer DEFAULT ceil(RANDOM()*10)

> I took the advice of Andreas and converted my code to using PostGIS.
> And the speed difference is enormous.
>
> The commands I've used:
> // Import shapefile into PostGIS:
> ogr2ogr -f PostgreSQL PG:"host=localhost user=..." fishnet.shp -gt 
> unlimited -lco GEOMETRY_NAME=geom -a_srs "EPSG:28992"
> // Add random data:
> ogrinfo PG:"host=localhost user=..." -sql "ALTER TABLE fishnet ADD 
> COLUMN randField integer;UPDATE fishnet SET randField = 
> ceil(RANDOM()*10);CREATE INDEX randfield_idx ON fishnet (randField);
> // Dissolve:
> ogrinfo PG:"host=localhost user=..." -sql "CREATE TABLE dissolved AS 
> SELECT randfield, ST_Multi(ST_Union(f.geom)) AS geom FROM fishnet AS f 
> GROUP BY randfield"
> // Export to shapefile
> ogr2ogr -f "ESRI Shapefile" taskmap.shp PG:"host=localhost user=..." 
> -sql "SELECT randfield, (st_dump(geom)).geom AS geom FROM dissolved" 
> -overwrite -gt unlimited
> // Clean up:
> ogrinfo PG:"host=localhost user=..." -sql "DROP TABLE IF EXISTS 
> fishnet CASCADE;DROP TABLE IF EXISTS dissolved CASCADE"
>
> The timing of the steps, after I converted the above commands to C#:
> | #shapes |Import     |Add values |  Dissolve | Export |
> |1,677 |00:00:00.29|00:00:00.14|00:00:00.10|00:00:00.05|
> |4,810 |00:00:00.28|00:00:00.20|00:00:01.11|00:00:00.15|
> |18,415  |00:00:00.78|00:00:00.53|00:00:04.57|00:00:00.31|
> |72,288  |00:00:02.07|00:00:02.13|00:00:22.56|00:00:01.02|
> |285,927 |00:00:07.58|00:00:06.68|00:01:59.59|00:00:03.82|
> |1,139,424|00:00:26.63|00:00:33.51|00:11:34.63|00:00:15.19|
> |4,546,854|00:01:46.19|00:03:51.92|01:10:07.41|00:00:57.51|
>
> 4.5 million squares of 0.3m have a total area of about 40 ha.
> That is good enough for me. The total time will be around 80 min, 
> instead of days using SQLite.
>
> I'm assuming I can't speed up this command anymore, right?
> ogrinfo PG:"host=localhost user=..." -sql "CREATE TABLE dissolved AS 
> SELECT randfield, ST_Multi(ST_Union(f.geom)) AS geom FROM fishnet AS f 
> GROUP BY randfield"
>
> Thanks all for your valuable help.
>
> Regards,
>
> Paul
>
> Op ma 16 jul. 2018 om 11:30 schreef Andreas Oxenstierna 
> <ao at t-kartor.se <mailto:ao at t-kartor.se>>:
>
>     ST_Union in PostGIS should scale better than SQLite.
>     ST_Dump gives you singlepart geometries.
>
>     Best Regards
>
>     Andreas Oxenstierna
>

-- 
Hälsningar

Andreas Oxenstierna
T-Kartor Geospatial AB
mobile: +46 733 206831
mailto: ao at t-kartor.se
http://www.t-kartor.com

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180717/21704952/attachment-0001.html>

From thibautvoirand at gmail.com  Tue Jul 17 05:01:13 2018
From: thibautvoirand at gmail.com (thibautvoirand)
Date: Tue, 17 Jul 2018 05:01:13 -0700 (MST)
Subject: [gdal-dev] gdal_merge unexpectedly setting nodata to zeros
Message-ID: <1531828873494-0.post@n6.nabble.com>

Hi all,

I am trying to merge 4 rasters containing nodata pixels using gdal_merge in
a single file with separate bands.
I use -9999 as nodata value.

In the output file, the first band has the correct nodata pixels (-9999) but
the following 3 bands have some zeros, in pixels that were nodata in the
input file.

My command line:
gdal_merge.py -o out.tif -separate -n -9999 -a_nodata -9999 -ot Float32
b1.tif b2.tif b3.tif b4.tif

My issue seems to resemble this issue:
https://gis.stackexchange.com/questions/190715/gdal-merge-stacking-files-nodata-value-wrong

Is this a bug or am I doing something wrong?

Thanks,
Thibaut



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From gane.prog at gmail.com  Tue Jul 17 05:34:15 2018
From: gane.prog at gmail.com (Gane R)
Date: Tue, 17 Jul 2018 18:04:15 +0530
Subject: [gdal-dev] gdal-1.11.3 to gdal-2.3.1 compatibility
Message-ID: <CALMrLdBno8S+-=PtviwwGZd=r4Tx1xBsbJHV3yb9=ucaKDLuRw@mail.gmail.com>

Hi all,

Is gdal-1.11.3, opening vector data set, reading OGR features code
compatible with gdal-2.3.1 code or any major changes in accessing OGR
features ?

Thanks
Gane
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180717/0474c164/attachment.html>

From gdal at zeidlers.de  Tue Jul 17 07:06:23 2018
From: gdal at zeidlers.de (Julian Zeidler)
Date: Tue, 17 Jul 2018 16:06:23 +0200
Subject: [gdal-dev] gdal-1.11.3 to gdal-2.3.1 compatibility
In-Reply-To: <CALMrLdBno8S+-=PtviwwGZd=r4Tx1xBsbJHV3yb9=ucaKDLuRw@mail.gmail.com>
References: <CALMrLdBno8S+-=PtviwwGZd=r4Tx1xBsbJHV3yb9=ucaKDLuRw@mail.gmail.com>
Message-ID: <c86f7f91-3e5c-0277-4095-484400b690b1@zeidlers.de>

Hi Gane,

it requires only minor modifications. In my Code I have a FLAG 
(HAVE_GDAL2) which makes it compile against both versions.
The changes are along the lines of:

#ifdef HAVE_GDAL2
      GDALDataset *ogrDataset;
#else
      OGRDataSource* ogrDataset;
#endif

#ifdef HAVE_GDAL2
         GDALAllRegister();
         unsigned int  nOpenFlags=GDAL_OF_VECTOR;
        GDALDriver 
*poDriver=GetGDALDriverManager()->GetDriverByName(driver);
         ogrDataset=(GDALDataset*) GDALOpenEx(filename,nOpenFlags, NULL, 
NULL, NULL);
  #else
         OGRRegisterAll();
          ogrDataset=OGRSFDriverRegistrar::Open(filename, FALSE );
  #endif


#ifdef HAVE_GDAL2
                 GDALClose(ogrDataset);
  #else
                 OGRDataSource::DestroyDataSource(ogrDataset);
   #endif


Cheers Julian

Am 17.07.2018 um 14:34 schrieb Gane R:
> Hi all,
>
> Is gdal-1.11.3, opening vector data set, reading OGR features code 
> compatible with gdal-2.3.1 code or any major changes in accessing OGR 
> features ?
>
> Thanks
> Gane
>
>
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180717/35a8f3a8/attachment.html>

From Jon.Morris at jbarisk.com  Tue Jul 17 07:33:42 2018
From: Jon.Morris at jbarisk.com (Jon Morris)
Date: Tue, 17 Jul 2018 14:33:42 +0000
Subject: [gdal-dev] Polygon intersection failure
Message-ID: <LO1P123MB11883FBF4A509B50B14113A4825C0@LO1P123MB1188.GBRP123.PROD.OUTLOOK.COM>

Hello all,

I'm having a problem with layer intersection and am not sure if I'm using the options correctly or if there is some functionality missing. I'm using GDAL 2.2.0 with Python 2.7.

I've got a layer of UK postcodes and a layer of UK buildings; when I run postcode_lyr.Intersection(building_lyr, out_lyr), I get RuntimeError: Attempt to write non-polygon (POINT) geometry to POLYGON type shapefile. With the option SKIP_FAILURES=YES, the intersection completes, but one postcode is left out. I get the same result when running the other way round - building_lyr.Intersection(postcode_lyr).

Is there a way of getting GDAL to only skip the bad geometry, but still add the remaining geometries for that feature? There should be three polygons in the result layer for that particular postcode. Or is there a way to find out which features have been skipped so I can go back and try and perform the intersection manually for just those features?

Thanks,

Jon

Jon Morris
Software Developer

Skype<sip:jon.morris at jbarisk.com>


T +44 (0) 1756 799919
www.jbarisk.com<http://www.jbarisk.com>

[Visit our website]<http://www.jbarisk.com> [http://www.jbagroup.co.uk/imgstore/JBA-Email-Sig-Icons-LINKEDIN.png] <https://www.linkedin.com/in/jon-morris-a2897b4/>  [Follow us on Twitter] <https://twitter.com/jbarisk>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180717/78cec77e/attachment.html>

From even.rouault at spatialys.com  Tue Jul 17 14:25:54 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 17 Jul 2018 23:25:54 +0200
Subject: [gdal-dev] Polygon intersection failure
In-Reply-To: <LO1P123MB11883FBF4A509B50B14113A4825C0@LO1P123MB1188.GBRP123.PROD.OUTLOOK.COM>
References: <LO1P123MB11883FBF4A509B50B14113A4825C0@LO1P123MB1188.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <23580442.FAoxhiy3Dk@even-i700>

On mardi 17 juillet 2018 14:33:42 CEST Jon Morris wrote:
> Hello all,
> 
> I'm having a problem with layer intersection and am not sure if I'm using
> the options correctly or if there is some functionality missing. I'm using
> GDAL 2.2.0 with Python 2.7.
> 
> I've got a layer of UK postcodes and a layer of UK buildings; when I run
> postcode_lyr.Intersection(building_lyr, out_lyr), I get RuntimeError:
> Attempt to write non-polygon (POINT) geometry to POLYGON type shapefile.
> With the option SKIP_FAILURES=YES, the intersection completes, but one
> postcode is left out. I get the same result when running the other way
> round - building_lyr.Intersection(postcode_lyr).
> 
> Is there a way of getting GDAL to only skip the bad geometry, but still add
> the remaining geometries for that feature? There should be three polygons
> in the result layer for that particular postcode. Or is there a way to find
> out which features have been skipped so I can go back and try and perform
> the intersection manually for just those features?

You could try the KEEP_LOWER_DIMENSION_GEOMETRIES=NO option for that to skip 
punctual intersections in polygon layers.
There is no debug traces currently on which features had failures. Something 
that could certainly be improved

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sebastien.guimmara.external at airbus.com  Wed Jul 18 01:49:47 2018
From: sebastien.guimmara.external at airbus.com (=?iso-8859-1?Q?GUIMMARA=2C_S=E9bastien_=28External=29_=5BFR=5D?=)
Date: Wed, 18 Jul 2018 08:49:47 +0000
Subject: [gdal-dev] Compile GDAL with OGDI support on Windows
Message-ID: <A1DABC8AB3291742B3D4C714F72B2F8E727F2627@tlswinmbx02.toulouse.spotimage.int>

Hi,

I am trying to compile GDAL 2.3.0 with OGDI 3.2.0 library on Windows, but the linking step fails because some libraries (zlib, proj) are present twice (in the OGDI lib, and also in the GDAL build).

In nmake.opt, if I remove the support for PROJ or zlib (to use the ones provided by OGDI), then the linker complains again because some symbols related to PROJ are missing. (e.g _pg_transform, _pg_init_plus...).

Moreover, nmake.opt does not seem up to date with OGDI 3.2.0 (notably the OGDI_INCLUDE path is slightly different).

The OGDI source was taken from GitHub (https://github.com/libogdi/ogdi), but the source taken from SourceForge is identical.

I also noted that GDAL continuous integration (appveyor) does not include OGDI support. Does that mean that OGDI is deprecated ? Is there an alternative for VPF support ?

Thank you,
Sébastien

Please consider the environment before printing this email message.

________________________________

Ce courriel (incluant ses éventuelles pièces jointes) peut contenir des informations confidentielles et/ou protégées ou dont la diffusion est restreinte. Si vous avez reçu ce courriel par erreur, vous ne devez ni le copier, ni l'utiliser, ni en divulguer le contenu à quiconque. Merci d'en avertir immédiatement l'expéditeur et d'effacer ce courriel de votre système. Airbus DS Geo décline toute responsabilité en cas de corruptionpar virus, d'altération ou de falsification de ce courriel lors de sa transmission par voie électronique.

This email (including any attachments) may contain confidential and/or privileged information or information otherwise protected from disclosure. If you are not the intended recipient, please notify the sender immediately, do not copy this message or any attachments and do not use it for any purpose or disclose its content to any person, but delete this message and any attachments from your system. Airbus DS Geo disclaims any and all liability if this email transmission was virus corrupted, altered or falsified.

________________________________

Airbus DS Geo SA (325 089 589 RCS Toulouse) - Siege social: 5, rue des Satellites, 31400 Toulouse, France.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180718/e9fc22a7/attachment.html>

From louis-philippe.rousseaulambert2 at canada.ca  Wed Jul 18 08:39:21 2018
From: louis-philippe.rousseaulambert2 at canada.ca (Rousseau Lambert2, Louis-Philippe (EC))
Date: Wed, 18 Jul 2018 15:39:21 +0000
Subject: [gdal-dev] GDAL multi bands files conversion to NetCDF
Message-ID: <7389ee9c3d1141efa87da6b7ed87352b@PELEPCDEXC006.birch.int.bell.ca>

Hi everyone!

I have s question regarding the conversion of a multiband file (like GeoTIFF) to NetCDF.

First my observations:

I used gdal_translate to convert a Geotiff to NetCDF:

gdal_translate -of input.tif result.nc

The gdalinfo result is:

Driver: netCDF/Network Common Data Format
Files: result.nc
Size is 512, 512
Coordinate System is `'
Metadata:
  NC_GLOBAL#Conventions=CF-1.5
  NC_GLOBAL#GDAL=GDAL 1.10.0, released 2013/04/24
  NC_GLOBAL#GDAL_AREA_OR_POINT=Area
  NC_GLOBAL#history=Wed Jul 18 15:33:16 2018: GDAL CreateCopy( result.nc, ... )
Subdatasets:
  SUBDATASET_1_NAME=NETCDF:"result.nc":Band1
  SUBDATASET_1_DESC=[1500x1650] Band1 (32-bit floating-point)
  SUBDATASET_2_NAME=NETCDF:"result.nc":Band2
  SUBDATASET_2_DESC=[1500x1650] Band2 (32-bit floating-point)
  SUBDATASET_3_NAME=NETCDF:"result.nc":Band3
  SUBDATASET_3_DESC=[1500x1650] Band3 (32-bit floating-point)
  SUBDATASET_4_NAME=NETCDF:"result.nc":Band4
  SUBDATASET_4_DESC=[1500x1650] Band4 (32-bit floating-point)
  SUBDATASET_5_NAME=NETCDF:"result.nc":Band5
  SUBDATASET_5_DESC=[1500x1650] Band5 (32-bit floating-point)
Corner Coordinates:
Upper Left  (    0.0,    0.0)
Lower Left  (    0.0,  512.0)
Upper Right (  512.0,    0.0)
Lower Right (  512.0,  512.0)
Center      (  256.0,  256.0)

As you can see, the different bands are written in different SUBDATASET. I would like the output to be only different bands, not different datasets. I don't think I saw a creation option that could do that...

I would like something like:

Driver: netCDF/Network Common Data Format
Files: output.nc
Size is 1068, 510
Coordinate System is `'
Origin = (-140.999964377091317,83.499994903744323)
Pixel Size = (0.083333295198278,-0.083333313348017)
Metadata:
  lat#axis=Y
  lat#long_name=latitude
  lat#standard_name=latitude
  lat#units=degrees_north
  lon#axis=X
  lon#long_name=longitude
  lon#standard_name=longitude
  lon#units=degrees_east
...Some metadata...
Corner Coordinates:
Upper Left  (-140.9999644,  83.4999949)
Lower Left  (-140.9999644,  41.0000051)
Upper Right ( -52.0000051,  83.4999949)
Lower Right ( -52.0000051,  41.0000051)
Center      ( -96.4999847,  62.2500000)
Band 1 Block=1068x1 Type=Float32, ColorInterp=Undefined
    Computed Min/Max=-29.841,11.720
  NoData Value=-99
  Metadata:
    long_name=Autumn mean temperature
    missing_value=-99
    NETCDF_DIM_time=17093376
    NETCDF_VARNAME=tm_son
    _FillValue=-99
Band 2 Block=1068x1 Type=Float32, ColorInterp=Undefined
    Computed Min/Max=-30.198,11.576
  NoData Value=-99
  Metadata:
    long_name=Autumn mean temperature
    missing_value=-99
    NETCDF_DIM_time=17102136
    NETCDF_VARNAME=tm_son
    _FillValue=-99
Band 3 Block=1068x1 Type=Float32, ColorInterp=Undefined
    Computed Min/Max=-30.479,11.854
  NoData Value=-99
  Metadata:
    long_name=Autumn mean temperature
    missing_value=-99
    NETCDF_DIM_time=17110920
    NETCDF_VARNAME=tm_son
    _FillValue=-99


Is there anything I missed ? Can you think of another way to do that ?

Thanks a lot!

LP
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180718/9f02f361/attachment.html>

From even.rouault at spatialys.com  Wed Jul 18 11:43:43 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 18 Jul 2018 20:43:43 +0200
Subject: [gdal-dev] GDAL multi bands files conversion to NetCDF
In-Reply-To: <7389ee9c3d1141efa87da6b7ed87352b@PELEPCDEXC006.birch.int.bell.ca>
References: <7389ee9c3d1141efa87da6b7ed87352b@PELEPCDEXC006.birch.int.bell.ca>
Message-ID: <3417632.TdiEgl6fGl@even-i700>

Louis Philippe

there's no one single step to do that, but you can do that in 2 steps:

- use gdal_translate -sds to export all the subdatasets in separate tif files
- use gdal_merge.py -separate to combine them in a single tif file (provided 
they have same resolution, extent, cordinate system), which seems to be your 
case here

Even

> Hi everyone!
> 
> I have s question regarding the conversion of a multiband file (like
> GeoTIFF) to NetCDF.
> 
> First my observations:
> 
> I used gdal_translate to convert a Geotiff to NetCDF:
> 
> gdal_translate -of input.tif result.nc
> 
> The gdalinfo result is:
> 
> Driver: netCDF/Network Common Data Format
> Files: result.nc
> Size is 512, 512
> Coordinate System is `'
> Metadata:
>   NC_GLOBAL#Conventions=CF-1.5
>   NC_GLOBAL#GDAL=GDAL 1.10.0, released 2013/04/24
>   NC_GLOBAL#GDAL_AREA_OR_POINT=Area
>   NC_GLOBAL#history=Wed Jul 18 15:33:16 2018: GDAL CreateCopy( result.nc,
> ... ) Subdatasets:
>   SUBDATASET_1_NAME=NETCDF:"result.nc":Band1
>   SUBDATASET_1_DESC=[1500x1650] Band1 (32-bit floating-point)
>   SUBDATASET_2_NAME=NETCDF:"result.nc":Band2
>   SUBDATASET_2_DESC=[1500x1650] Band2 (32-bit floating-point)
>   SUBDATASET_3_NAME=NETCDF:"result.nc":Band3
>   SUBDATASET_3_DESC=[1500x1650] Band3 (32-bit floating-point)
>   SUBDATASET_4_NAME=NETCDF:"result.nc":Band4
>   SUBDATASET_4_DESC=[1500x1650] Band4 (32-bit floating-point)
>   SUBDATASET_5_NAME=NETCDF:"result.nc":Band5
>   SUBDATASET_5_DESC=[1500x1650] Band5 (32-bit floating-point)
> Corner Coordinates:
> Upper Left  (    0.0,    0.0)
> Lower Left  (    0.0,  512.0)
> Upper Right (  512.0,    0.0)
> Lower Right (  512.0,  512.0)
> Center      (  256.0,  256.0)
> 
> As you can see, the different bands are written in different SUBDATASET. I
> would like the output to be only different bands, not different datasets. I
> don't think I saw a creation option that could do that...
> 
> I would like something like:
> 
> Driver: netCDF/Network Common Data Format
> Files: output.nc
> Size is 1068, 510
> Coordinate System is `'
> Origin = (-140.999964377091317,83.499994903744323)
> Pixel Size = (0.083333295198278,-0.083333313348017)
> Metadata:
>   lat#axis=Y
>   lat#long_name=latitude
>   lat#standard_name=latitude
>   lat#units=degrees_north
>   lon#axis=X
>   lon#long_name=longitude
>   lon#standard_name=longitude
>   lon#units=degrees_east
> ...Some metadata...
> Corner Coordinates:
> Upper Left  (-140.9999644,  83.4999949)
> Lower Left  (-140.9999644,  41.0000051)
> Upper Right ( -52.0000051,  83.4999949)
> Lower Right ( -52.0000051,  41.0000051)
> Center      ( -96.4999847,  62.2500000)
> Band 1 Block=1068x1 Type=Float32, ColorInterp=Undefined
>     Computed Min/Max=-29.841,11.720
>   NoData Value=-99
>   Metadata:
>     long_name=Autumn mean temperature
>     missing_value=-99
>     NETCDF_DIM_time=17093376
>     NETCDF_VARNAME=tm_son
>     _FillValue=-99
> Band 2 Block=1068x1 Type=Float32, ColorInterp=Undefined
>     Computed Min/Max=-30.198,11.576
>   NoData Value=-99
>   Metadata:
>     long_name=Autumn mean temperature
>     missing_value=-99
>     NETCDF_DIM_time=17102136
>     NETCDF_VARNAME=tm_son
>     _FillValue=-99
> Band 3 Block=1068x1 Type=Float32, ColorInterp=Undefined
>     Computed Min/Max=-30.479,11.854
>   NoData Value=-99
>   Metadata:
>     long_name=Autumn mean temperature
>     missing_value=-99
>     NETCDF_DIM_time=17110920
>     NETCDF_VARNAME=tm_son
>     _FillValue=-99
> 
> 
> Is there anything I missed ? Can you think of another way to do that ?
> 
> Thanks a lot!
> 
> LP


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Wed Jul 18 11:48:21 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 18 Jul 2018 20:48:21 +0200
Subject: [gdal-dev] Compile GDAL with OGDI support on Windows
In-Reply-To: <A1DABC8AB3291742B3D4C714F72B2F8E727F2627@tlswinmbx02.toulouse.spotimage.int>
References: <A1DABC8AB3291742B3D4C714F72B2F8E727F2627@tlswinmbx02.toulouse.spotimage.int>
Message-ID: <2562307.1YYZkp30Xu@even-i700>

Sébastien,

> 
> I am trying to compile GDAL 2.3.0 with OGDI 3.2.0 library on Windows, but
> the linking step fails because some libraries (zlib, proj) are present
> twice (in the OGDI lib, and also in the GDAL build).
> 
> In nmake.opt, if I remove the support for PROJ or zlib (to use the ones
> provided by OGDI), then the linker complains again because some symbols
> related to PROJ are missing. (e.g _pg_transform, _pg_init_plus...).
> 
> Moreover, nmake.opt does not seem up to date with OGDI 3.2.0 (notably the
> OGDI_INCLUDE path is slightly different).

You could have a look at the build recipees of the GDAL and OGDI packages of OSGeo4W:
https://download.osgeo.org/osgeo4w/x86_64/release/gdal/gdal-2.2.4-1-src.tar.bz2
https://download.osgeo.org/osgeo4w/x86_64/release/ogdi/ogdi-3.2.1-1-src.tar.bz2

> 
> The OGDI source was taken from GitHub (https://github.com/libogdi/ogdi), but
> the source taken from SourceForge is identical.

Actually the github is a bit more current since it has ogdi 3.2.1 whereas sourceforge
is now stucked to 3.2.0 since CVS support is no longer offered
> 
> I also noted that GDAL continuous integration (appveyor) does not include
> OGDI support. Does that mean that OGDI is deprecated ? 

No, it is actually tested on Linux. The Windows side is always more painful to setup,
so that given this is a somewhat marginal driver, nobody invested yet time to setup that.

> Is there an
> alternative for VPF support ?

Not that I'm aware of. At least on the C/C++ side of this world. I think GeoTools might
have a VPF reader

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From louis-philippe.rousseaulambert2 at canada.ca  Wed Jul 18 11:57:18 2018
From: louis-philippe.rousseaulambert2 at canada.ca (Rousseau Lambert2, Louis-Philippe (EC))
Date: Wed, 18 Jul 2018 18:57:18 +0000
Subject: [gdal-dev] GDAL multi bands files conversion to NetCDF
References: <7389ee9c3d1141efa87da6b7ed87352b@PELEPCDEXC006.birch.int.bell.ca>
 <3417632.TdiEgl6fGl@even-i700>
Message-ID: <8b4c01b002cf4296ab27de5a8cb0b89b@PELEPCDEXC006.birch.int.bell.ca>

Thanks for your answer Even,

I was looking at a one step solution because I wanted MapServer to
output the NetCDF with different bands instead of individual
Subdatasets... I should have mentioned that first in my question.

Basically, I have layers in MapServer which are served in WCS. Since we
can't use TIME= in WCS 2.0.1 and that I need to be able to output time
range and lists in a single WCS request, I'm using the band names and
the RANGESUBSET= feature to request multiple bands in the NetCDF output
format.

But the MapServer output NetCDF have many SUBDATASETs instead of many
bands... I was hoping to be able to add a FORMATOPTION in the NetCDF
OUTPUTFORMAT in MapServer to make it work, but from your answer I get
that it's not possible.

Thanks !

LP

On 07/18/2018 06:44 PM, Even Rouault wrote:
> Louis Philippe
>
> there's no one single step to do that, but you can do that in 2 steps:
>
> - use gdal_translate -sds to export all the subdatasets in separate tif files
> - use gdal_merge.py -separate to combine them in a single tif file (provided 
> they have same resolution, extent, cordinate system), which seems to be your 
> case here
>
> Even
>
>> Hi everyone!
>>
>> I have s question regarding the conversion of a multiband file (like
>> GeoTIFF) to NetCDF.
>>
>> First my observations:
>>
>> I used gdal_translate to convert a Geotiff to NetCDF:
>>
>> gdal_translate -of input.tif result.nc
>>
>> The gdalinfo result is:
>>
>> Driver: netCDF/Network Common Data Format
>> Files: result.nc
>> Size is 512, 512
>> Coordinate System is `'
>> Metadata:
>>   NC_GLOBAL#Conventions=CF-1.5
>>   NC_GLOBAL#GDAL=GDAL 1.10.0, released 2013/04/24
>>   NC_GLOBAL#GDAL_AREA_OR_POINT=Area
>>   NC_GLOBAL#history=Wed Jul 18 15:33:16 2018: GDAL CreateCopy( result.nc,
>> ... ) Subdatasets:
>>   SUBDATASET_1_NAME=NETCDF:"result.nc":Band1
>>   SUBDATASET_1_DESC=[1500x1650] Band1 (32-bit floating-point)
>>   SUBDATASET_2_NAME=NETCDF:"result.nc":Band2
>>   SUBDATASET_2_DESC=[1500x1650] Band2 (32-bit floating-point)
>>   SUBDATASET_3_NAME=NETCDF:"result.nc":Band3
>>   SUBDATASET_3_DESC=[1500x1650] Band3 (32-bit floating-point)
>>   SUBDATASET_4_NAME=NETCDF:"result.nc":Band4
>>   SUBDATASET_4_DESC=[1500x1650] Band4 (32-bit floating-point)
>>   SUBDATASET_5_NAME=NETCDF:"result.nc":Band5
>>   SUBDATASET_5_DESC=[1500x1650] Band5 (32-bit floating-point)
>> Corner Coordinates:
>> Upper Left  (    0.0,    0.0)
>> Lower Left  (    0.0,  512.0)
>> Upper Right (  512.0,    0.0)
>> Lower Right (  512.0,  512.0)
>> Center      (  256.0,  256.0)
>>
>> As you can see, the different bands are written in different SUBDATASET. I
>> would like the output to be only different bands, not different datasets. I
>> don't think I saw a creation option that could do that...
>>
>> I would like something like:
>>
>> Driver: netCDF/Network Common Data Format
>> Files: output.nc
>> Size is 1068, 510
>> Coordinate System is `'
>> Origin = (-140.999964377091317,83.499994903744323)
>> Pixel Size = (0.083333295198278,-0.083333313348017)
>> Metadata:
>>   lat#axis=Y
>>   lat#long_name=latitude
>>   lat#standard_name=latitude
>>   lat#units=degrees_north
>>   lon#axis=X
>>   lon#long_name=longitude
>>   lon#standard_name=longitude
>>   lon#units=degrees_east
>> ...Some metadata...
>> Corner Coordinates:
>> Upper Left  (-140.9999644,  83.4999949)
>> Lower Left  (-140.9999644,  41.0000051)
>> Upper Right ( -52.0000051,  83.4999949)
>> Lower Right ( -52.0000051,  41.0000051)
>> Center      ( -96.4999847,  62.2500000)
>> Band 1 Block=1068x1 Type=Float32, ColorInterp=Undefined
>>     Computed Min/Max=-29.841,11.720
>>   NoData Value=-99
>>   Metadata:
>>     long_name=Autumn mean temperature
>>     missing_value=-99
>>     NETCDF_DIM_time=17093376
>>     NETCDF_VARNAME=tm_son
>>     _FillValue=-99
>> Band 2 Block=1068x1 Type=Float32, ColorInterp=Undefined
>>     Computed Min/Max=-30.198,11.576
>>   NoData Value=-99
>>   Metadata:
>>     long_name=Autumn mean temperature
>>     missing_value=-99
>>     NETCDF_DIM_time=17102136
>>     NETCDF_VARNAME=tm_son
>>     _FillValue=-99
>> Band 3 Block=1068x1 Type=Float32, ColorInterp=Undefined
>>     Computed Min/Max=-30.479,11.854
>>   NoData Value=-99
>>   Metadata:
>>     long_name=Autumn mean temperature
>>     missing_value=-99
>>     NETCDF_DIM_time=17110920
>>     NETCDF_VARNAME=tm_son
>>     _FillValue=-99
>>
>>
>> Is there anything I missed ? Can you think of another way to do that ?
>>
>> Thanks a lot!
>>
>> LP
>


-- 
Louis-Philippe Rousseau Lambert, B.Sc.
Géomaticien / Geomatician
Section des Données, Performances et Standards
Data, Performance and Standards Section
Service Météorologique du Canada
Meteorological Service of Canada
Environnement et Changement Climatique Canada
Environment and Climate Change Canada
louis-philippe.rousseaulambert2 at canada.ca
(514) 421-5045


From cpaulik at vandersat.com  Thu Jul 19 03:44:50 2018
From: cpaulik at vandersat.com (Christoph Paulik)
Date: Thu, 19 Jul 2018 12:44:50 +0200
Subject: [gdal-dev] Writing geotiff with /vsigs in Python does not work
Message-ID: <87lga7fqsd.fsf@vandersat.com>


Hi,

I'm running the following code writing a geotiff and I've set the
GOOGLE_APPLICATION_CREDENTIALS environment variable for authentication:

from osgeo import gdal, gdal_array, osr
import numpy as np

file_name = '/vsigs/<my-bucket-name>/test.tif'

raster = np.arange(100*100, dtype=np.int32).reshape((100, 100))
data_type = gdal_array.NumericTypeCodeToGDALTypeCode(raster.dtype)

cols = raster.shape[1]
rows = raster.shape[0]
driver = gdal.GetDriverByName("GTiff")
create_options=['COMPRESS=LZW', 'TILED=YES']

ds = driver.Create(file_name, cols, rows, 1, data_type, create_options)
# (top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution)
ds.SetGeoTransform((10, 0.1, 0, 10, 0, -0.1))

srs = osr.SpatialReference()
srs.SetWellKnownGeogCS("WGS84")
projection = srs.ExportToWkt()
ds.SetProjection(projection)

# write the raster
band = ds.GetRasterBand(1)
band.SetScale(0.01)
band.SetOffset(0)
band.SetNoDataValue(255)
band.WriteArray(raster)
ds = None

It produces the following errors:

ERROR 6: Seek not supported on writable /vsigs/ files
ERROR 1: _tiffSeekProc:No such file or directory
ERROR 1: _tiffWriteProc:No such file or directory
ERROR 1: /vsigs/<my-bucket-name>/test.tif:Error writing TIFF header
ERROR 1: _tiffWriteProc:No such file or directory
ERROR 6: Seek not supported on writable /vsigs/ files
ERROR 1: _tiffSeekProc:No such file or directory
ERROR 1: _tiffWriteProc:No such file or directory
ERROR 1: /vsigs/<my-bucket-name>/test.tif:Error writing TIFF header
ERROR 6: Seek not supported on writable /vsigs/ files
ERROR 1: _tiffSeekProc:No such file or directory
ERROR 1: _tiffWriteProc:No such file or directory
ERROR 1: /vsigs/<my-bucket-name>/test.tif:Error updating TIFF header

Do I have to do things in a different order or way for this to work?

The result is an 8B file in my GCS bucket.

Thanks,
Christoph

-- 

-------------------------------------------------------
Christoph Paulik
VanderSat // Satellite observed water data. Globally. Daily.
Wilhelminastraat 43a, 2011 VK, Haarlem (NL), The Netherlands
W: www.vandersat.com
M: +31 (0) 6 1827 1928
PGP: 8CFC D7DF 2867 B2DC 749B  1B0A 6E3B A262 5186 A0AC
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 832 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180719/70ce7ff3/attachment.sig>

From even.rouault at spatialys.com  Fri Jul 20 02:54:49 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 20 Jul 2018 11:54:49 +0200
Subject: [gdal-dev] GDAL multi bands files conversion to NetCDF
In-Reply-To: <8b4c01b002cf4296ab27de5a8cb0b89b@PELEPCDEXC006.birch.int.bell.ca>
References: <7389ee9c3d1141efa87da6b7ed87352b@PELEPCDEXC006.birch.int.bell.ca>
 <3417632.TdiEgl6fGl@even-i700>
 <8b4c01b002cf4296ab27de5a8cb0b89b@PELEPCDEXC006.birch.int.bell.ca>
Message-ID: <2069806.9r5CAe2pGJ@even-i700>

On mercredi 18 juillet 2018 18:57:18 CEST Rousseau Lambert2, Louis-Philippe 
(EC) wrote:
> Thanks for your answer Even,
> 
> I was looking at a one step solution because I wanted MapServer to
> output the NetCDF with different bands instead of individual
> Subdatasets... I should have mentioned that first in my question.
> 
> Basically, I have layers in MapServer which are served in WCS. Since we
> can't use TIME= in WCS 2.0.1 and that I need to be able to output time
> range and lists in a single WCS request, I'm using the band names and
> the RANGESUBSET= feature to request multiple bands in the NetCDF output
> format.
> 
> But the MapServer output NetCDF have many SUBDATASETs instead of many
> bands... I was hoping to be able to add a FORMATOPTION in the NetCDF
> OUTPUTFORMAT in MapServer to make it work, but from your answer I get
> that it's not possible.

You are seing more an artifact of how the GDAL netCDF driver than a limitation 
of MapServer or the netCDF format itself.

When creating a netCDF dataset with multiple GDAL bands, it get reads back by 
GDAL as several subdatasets, but neither the concept of band or subdataset 
really exist in the netCDF format itself: you have variables in netCDF. As 
variables may be indexed by different dimensions, GDAL chooses to read them as 
subdatasets to be on the safe side. Readers that are closer to the netCDF data 
model will see those bands/subdatasets as different variables.
The GDAL netCDF driver could potentially be improved to (as an option ?) offer 
the possibility to expose those subdatasets as bands when this is possible 
(same indexing dimensions)

Even


> 
> Thanks !
> 
> LP
> 
> On 07/18/2018 06:44 PM, Even Rouault wrote:
> > Louis Philippe
> > 
> > there's no one single step to do that, but you can do that in 2 steps:
> > 
> > - use gdal_translate -sds to export all the subdatasets in separate tif
> > files - use gdal_merge.py -separate to combine them in a single tif file
> > (provided they have same resolution, extent, cordinate system), which
> > seems to be your case here
> > 
> > Even
> > 
> >> Hi everyone!
> >> 
> >> I have s question regarding the conversion of a multiband file (like
> >> GeoTIFF) to NetCDF.
> >> 
> >> First my observations:
> >> 
> >> I used gdal_translate to convert a Geotiff to NetCDF:
> >> 
> >> gdal_translate -of input.tif result.nc
> >> 
> >> The gdalinfo result is:
> >> 
> >> Driver: netCDF/Network Common Data Format
> >> Files: result.nc
> >> Size is 512, 512
> >> Coordinate System is `'
> >> 
> >> Metadata:
> >>   NC_GLOBAL#Conventions=CF-1.5
> >>   NC_GLOBAL#GDAL=GDAL 1.10.0, released 2013/04/24
> >>   NC_GLOBAL#GDAL_AREA_OR_POINT=Area
> >>   NC_GLOBAL#history=Wed Jul 18 15:33:16 2018: GDAL CreateCopy( result.nc,
> >> 
> >> ... ) Subdatasets:
> >>   SUBDATASET_1_NAME=NETCDF:"result.nc":Band1
> >>   SUBDATASET_1_DESC=[1500x1650] Band1 (32-bit floating-point)
> >>   SUBDATASET_2_NAME=NETCDF:"result.nc":Band2
> >>   SUBDATASET_2_DESC=[1500x1650] Band2 (32-bit floating-point)
> >>   SUBDATASET_3_NAME=NETCDF:"result.nc":Band3
> >>   SUBDATASET_3_DESC=[1500x1650] Band3 (32-bit floating-point)
> >>   SUBDATASET_4_NAME=NETCDF:"result.nc":Band4
> >>   SUBDATASET_4_DESC=[1500x1650] Band4 (32-bit floating-point)
> >>   SUBDATASET_5_NAME=NETCDF:"result.nc":Band5
> >>   SUBDATASET_5_DESC=[1500x1650] Band5 (32-bit floating-point)
> >> 
> >> Corner Coordinates:
> >> Upper Left  (    0.0,    0.0)
> >> Lower Left  (    0.0,  512.0)
> >> Upper Right (  512.0,    0.0)
> >> Lower Right (  512.0,  512.0)
> >> Center      (  256.0,  256.0)
> >> 
> >> As you can see, the different bands are written in different SUBDATASET.
> >> I
> >> would like the output to be only different bands, not different datasets.
> >> I
> >> don't think I saw a creation option that could do that...
> >> 
> >> I would like something like:
> >> 
> >> Driver: netCDF/Network Common Data Format
> >> Files: output.nc
> >> Size is 1068, 510
> >> Coordinate System is `'
> >> Origin = (-140.999964377091317,83.499994903744323)
> >> Pixel Size = (0.083333295198278,-0.083333313348017)
> >> 
> >> Metadata:
> >>   lat#axis=Y
> >>   lat#long_name=latitude
> >>   lat#standard_name=latitude
> >>   lat#units=degrees_north
> >>   lon#axis=X
> >>   lon#long_name=longitude
> >>   lon#standard_name=longitude
> >>   lon#units=degrees_east
> >> 
> >> ...Some metadata...
> >> Corner Coordinates:
> >> Upper Left  (-140.9999644,  83.4999949)
> >> Lower Left  (-140.9999644,  41.0000051)
> >> Upper Right ( -52.0000051,  83.4999949)
> >> Lower Right ( -52.0000051,  41.0000051)
> >> Center      ( -96.4999847,  62.2500000)
> >> Band 1 Block=1068x1 Type=Float32, ColorInterp=Undefined
> >> 
> >>     Computed Min/Max=-29.841,11.720
> >>   
> >>   NoData Value=-99
> >>   
> >>   Metadata:
> >>     long_name=Autumn mean temperature
> >>     missing_value=-99
> >>     NETCDF_DIM_time=17093376
> >>     NETCDF_VARNAME=tm_son
> >>     _FillValue=-99
> >> 
> >> Band 2 Block=1068x1 Type=Float32, ColorInterp=Undefined
> >> 
> >>     Computed Min/Max=-30.198,11.576
> >>   
> >>   NoData Value=-99
> >>   
> >>   Metadata:
> >>     long_name=Autumn mean temperature
> >>     missing_value=-99
> >>     NETCDF_DIM_time=17102136
> >>     NETCDF_VARNAME=tm_son
> >>     _FillValue=-99
> >> 
> >> Band 3 Block=1068x1 Type=Float32, ColorInterp=Undefined
> >> 
> >>     Computed Min/Max=-30.479,11.854
> >>   
> >>   NoData Value=-99
> >>   
> >>   Metadata:
> >>     long_name=Autumn mean temperature
> >>     missing_value=-99
> >>     NETCDF_DIM_time=17110920
> >>     NETCDF_VARNAME=tm_son
> >>     _FillValue=-99
> >> 
> >> Is there anything I missed ? Can you think of another way to do that ?
> >> 
> >> Thanks a lot!
> >> 
> >> LP


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Fri Jul 20 03:01:37 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 20 Jul 2018 12:01:37 +0200
Subject: [gdal-dev] Writing geotiff with /vsigs in Python does not work
In-Reply-To: <87lga7fqsd.fsf@vandersat.com>
References: <87lga7fqsd.fsf@vandersat.com>
Message-ID: <5905941.iWQyZfeIyy@even-i700>

Christoph,

> Do I have to do things in a different order or way for this to work?

/vsigs/ implementation (and other cloud virtual file systems) only supports 
sequential writing, but in the general case, writing a GeoTIFF file requires 
random writing capabilities, particularly for compressed datasets.
See the "streaming operations" paragraph of http://gdal.org/frmt_gtiff.html
So you have to create a on-disk file first and then copy it to the bucket.

Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From cpaulik at vandersat.com  Fri Jul 20 03:25:26 2018
From: cpaulik at vandersat.com (Christoph Paulik)
Date: Fri, 20 Jul 2018 12:25:26 +0200
Subject: [gdal-dev] Writing geotiff with /vsigs in Python does not work
In-Reply-To: <5905941.iWQyZfeIyy@even-i700>
References: <87lga7fqsd.fsf@vandersat.com> <5905941.iWQyZfeIyy@even-i700>
Message-ID: <87effyfbl5.fsf@vandersat.com>


Ok, thank you for the clarification.

Even Rouault writes:

> Christoph,
>
>> Do I have to do things in a different order or way for this to work?
>
> /vsigs/ implementation (and other cloud virtual file systems) only supports 
> sequential writing, but in the general case, writing a GeoTIFF file requires 
> random writing capabilities, particularly for compressed datasets.
> See the "streaming operations" paragraph of http://gdal.org/frmt_gtiff.html
> So you have to create a on-disk file first and then copy it to the bucket.
>
> Even


-- 

-------------------------------------------------------
Christoph Paulik
VanderSat // Satellite observed water data. Globally. Daily.
Wilhelminastraat 43a, 2011 VK, Haarlem (NL), The Netherlands
W: www.vandersat.com
M: +31 (0) 6 1827 1928
PGP: 8CFC D7DF 2867 B2DC 749B  1B0A 6E3B A262 5186 A0AC
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 832 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180720/fe6b8a74/attachment.sig>

From rykovd at gmail.com  Sat Jul 21 05:40:54 2018
From: rykovd at gmail.com (Denis Rykov)
Date: Sat, 21 Jul 2018 19:40:54 +0700
Subject: [gdal-dev] gdalwarp and internal transparency masks
Message-ID: <CAJbvKNoCgrJ7ws-Dt7EEtX4hCgs4TV72xXVE02WDZRYJfXPbNw@mail.gmail.com>

Hi,

I have a GeoTIFF raster with internal mask. Is it possible to retain this
mask while warping?

Mask is not retained now:

$ gdalinfo -json original.tif | jq .bands
[
  {
    "band": 1,
    "block": [
      3,
      2
    ],
    "type": "Byte",
    "colorInterpretation": "Gray",
    "mask": {
      "flags": [
        "PER_DATASET"
      ],
      "overviews": []
    },
    "metadata": {}
  }
]

$ gdalwarp --config GDAL_TIFF_INTERNAL_MASK YES original.tif destination.tif
Processing input file original.tif.
0...10...20...30...40...50...60...70...80...90...100 - done.

$ gdalinfo -json destination.tif | jq .bands
[
  {
    "band": 1,
    "block": [
      3,
      2
    ],
    "type": "Byte",
    "colorInterpretation": "Gray",
    "metadata": {}
  }
]
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180721/be7995f2/attachment.html>

From even.rouault at spatialys.com  Sat Jul 21 09:17:01 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 21 Jul 2018 18:17:01 +0200
Subject: [gdal-dev] gdalwarp and internal transparency masks
In-Reply-To: <CAJbvKNoCgrJ7ws-Dt7EEtX4hCgs4TV72xXVE02WDZRYJfXPbNw@mail.gmail.com>
References: <CAJbvKNoCgrJ7ws-Dt7EEtX4hCgs4TV72xXVE02WDZRYJfXPbNw@mail.gmail.com>
Message-ID: <5224853.KRhJRbbhDe@even-i700>

On samedi 21 juillet 2018 19:40:54 CEST Denis Rykov wrote:
> Hi,
> 
> I have a GeoTIFF raster with internal mask. Is it possible to retain this
> mask while warping?

Not as a mask with gdalwarp, but you can turn it as a an alpha band with
-dstalpha

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From landa.martin at gmail.com  Mon Jul 23 13:46:26 2018
From: landa.martin at gmail.com (Martin Landa)
Date: Mon, 23 Jul 2018 22:46:26 +0200
Subject: [gdal-dev] ERROR 1: In file cpl_vsil_gzip.cpp, at line 905, return 0
Message-ID: <CA+Ei1Ofpm4Y6UJnGK7yJ73LWT6PZmPtopSb4HbVU0bW8dpHx0w@mail.gmail.com>

Hi,

I have problem with reading some files provided by Czech State
Administration of Land Surveying and Cadastre in VFR format (supported
by GML driver). Some files seems to be incorrectly compressed.

Scanning layers seems to be OK:

$ ogrinfo -ro /vsicurl/http://vdp.cuzk.cz/vymenny_format/soucasna/20180630_OB_554464_UKSH.xml.gz
...
INFO: Open of `/vsicurl/http://vdp.cuzk.cz/vymenny_format/soucasna/20180630_OB_554464_UKSH.xml.gz'
      using driver `GML' successful.
1: Obce (Multi Point, Multi Polygon, Multi Polygon)
2: SpravniObvody (Point, Multi Polygon)
3: Mop (Point, Multi Polygon)
4: Momc (Point, Multi Polygon)
5: CastiObci (Point)
6: KatastralniUzemi (Multi Point, Multi Polygon, Multi Polygon)
7: Zsj (Multi Point, Multi Polygon)
8: Ulice (Multi Line String)
9: Parcely (Point, Polygon, Multi Polygon)
10: StavebniObjekty (Point, Multi Polygon, Multi Polygon)
11: AdresniMista (Point, Point, Point)

BUT reading features (GetNextFeature/GetFeature) fails:

$ ogrinfo -ro /vsicurl/http://vdp.cuzk.cz/vymenny_format/soucasna/20180630_OB_554464_UKSH.xml.gz
StavebniObjekty
...
INFO: Open of `/vsicurl/http://vdp.cuzk.cz/vymenny_format/soucasna/20180630_OB_554464_UKSH.xml.gz'
      using driver `GML' successful.
Layer name: StavebniObjekty
Geometry (DefinicniBod): Point
Geometry (OriginalniHranice): Multi Polygon
Geometry (OriginalniHraniceOmpv): Multi Polygon
ERROR 1: In file cpl_vsil_gzip.cpp, at line 905, return 0
Feature Count: 651
ERROR 1: In file cpl_vsil_gzip.cpp, at line 728, return -1
ERROR 1: In file cpl_vsil_gzip.cpp, at line 728, return -1
ERROR 1: In file cpl_vsil_gzip.cpp, at line 905, return 0
ERROR 1: In file cpl_vsil_gzip.cpp, at line 905, return 0
ERROR 1: XML parsing of GML file failed : no element found at line 1, column 0

NO features are printed. gzip says "unexpected end of file" and
refuses to extract the file. 7zip (and other programs) on Windows
reports similar error, but file is extracted. I am discussing issue
with the provider. By chance, do you have any tip how to read such
broken files by GDAL?

Thanks, Martin

-- 
Martin Landa
http://geo.fsv.cvut.cz/gwiki/Landa
http://gismentors.cz/mentors/landa

From rykovd at gmail.com  Tue Jul 24 01:51:55 2018
From: rykovd at gmail.com (Denis Rykov)
Date: Tue, 24 Jul 2018 15:51:55 +0700
Subject: [gdal-dev] gdalwarp and internal transparency masks
In-Reply-To: <5224853.KRhJRbbhDe@even-i700>
References: <CAJbvKNoCgrJ7ws-Dt7EEtX4hCgs4TV72xXVE02WDZRYJfXPbNw@mail.gmail.com>
 <5224853.KRhJRbbhDe@even-i700>
Message-ID: <CAJbvKNqUVeZFvWvLfVEeLqMa4VdiamXDHJZyw78TBGb2YqknmA@mail.gmail.com>

Even, thanks for the answer.

I have filed an issue at GitHub to track the possible progress on this
task: https://github.com/OSGeo/gdal/issues/794

On Sat, Jul 21, 2018 at 11:17 PM, Even Rouault <even.rouault at spatialys.com>
wrote:

> On samedi 21 juillet 2018 19:40:54 CEST Denis Rykov wrote:
> > Hi,
> >
> > I have a GeoTIFF raster with internal mask. Is it possible to retain this
> > mask while warping?
>
> Not as a mask with gdalwarp, but you can turn it as a an alpha band with
> -dstalpha
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180724/cbb2653d/attachment.html>

From Piyush.Agram at jpl.nasa.gov  Tue Jul 24 11:45:09 2018
From: Piyush.Agram at jpl.nasa.gov (Agram, Piyush S (334D))
Date: Tue, 24 Jul 2018 18:45:09 +0000
Subject: [gdal-dev] Complex valued NoData
Message-ID: <3CA22B17-4160-4145-9961-9771099D2979@jpl.nasa.gov>

Hi,
    We are working on use cases where we have to perform operations similar to gdal_translate / gdalwarp on complex valued datasets.

The last discussion that I could on this topic in the mailing archives is from 2010:
https://lists.osgeo.org/pipermail/gdal-dev/2010-September/025906.html

I’m willing to put in some effort to update the algorithms to handle nodata values for complex valued datasets properly (which it currently appears to ignore). Any pointers on where to start looking or focus on would help?

We would like to avoid using pixel functions and manipulating the real/imag parts independently and then putting them back together.

There are also different options for interpreting nodata. I believe we are limited to real values for this metadata field and adding new fields / changing the type could be pretty disruptive.

  1.  Compare real value only (seems easiest to implement)
  2.  Compare that both real and imaginary values are set to no data (probably better way of checking?)

If one were to implement nodata support for complex-valued datasets, which implementation would be preferred.

Thanks
Piyush
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180724/2bc55adb/attachment.html>

From jvenman at noggin.io  Tue Jul 24 17:48:17 2018
From: jvenman at noggin.io (jvenman)
Date: Tue, 24 Jul 2018 17:48:17 -0700 (MST)
Subject: [gdal-dev] Transform shapefile to specific WKT format
Message-ID: <1532479697032-0.post@n6.nabble.com>

Hi - I have an shapefile that has a .prj file with this format for GDA94
(4283):-

GEOGCS["GDA94",DATUM["D_GDA_1994",SPHEROID["GRS_1980",6378137,298.257222101]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]]

And the application that needs to read it complains that it's a different
projection from the representation of GDA94 (4283) that it understands which
is this:-

GEOGCS["GCS_GDA_1994",DATUM["D_GDA_1994",SPHEROID["GRS_1980",6378137.0,298.257222101]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]]

They're subtly different in the precision on the Degree value and the
presence of ".0" on the Spheroid which seems to be enough to make the target
application reject it. I'd like to ogr2ogr my way past this by being very
specific about the srs for the target shapefile. I've tried various
combinations of format for the -a_srs parameter and I always end up with
what I think is the definition of GDA94 (4283) that GDAL has in gdal_data
which is this:-

GEOGCS["GDA94",DATUM["D_GDA_1994",SPHEROID["GRS_1980",6378137,298.257222101]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]]

I have tried specifying the WKT like this:-

ogr2ogr --config GDAL_DATA "C:\Program Files\GDAL\gdal-data" -a_srs
"GEOGCS['GCS_GDA_1994',DATUM['D_GDA_1994',SPHEROID['GRS_1980',6378137.0,298.257222101]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]]"
-f "ESRI Shapefile" GDA94Test_TargetBRIMS1002.shp
Fire_Nr_Davidson_Point_1.shp

And I have tried specifying the a .prj file that is exactly the format I
want like this:-

ogr2ogr --config GDAL_DATA "C:\Program Files\GDAL\gdal-data" -a_srs
ESRI::BRIMS_Schema.prj -f "ESRI Shapefile" GDA94Test_TargetBRIMS1003.shp
Fire_Nr_Davidson_Point_1.shp

I know I could just overwrite the existing prj file with the one I want, but
I'd like to do it through ogr2ogr if it's possible. Can anyone point me in
the right direction or point out what I'm doing wrong?

Thanks,
Josh







--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From even.rouault at spatialys.com  Wed Jul 25 01:14:00 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 25 Jul 2018 10:14:00 +0200
Subject: [gdal-dev] Transform shapefile to specific WKT format
In-Reply-To: <1532479697032-0.post@n6.nabble.com>
References: <1532479697032-0.post@n6.nabble.com>
Message-ID: <2046030.fQISZH6OhG@even-i700>

Josh,

> I know I could just overwrite the existing prj file with the one I want, but
> I'd like to do it through ogr2ogr if it's possible.

There's no way to do it with OGR. The shapefile driver automatically 
transforms from OGC WKT to ESRI WKT. So your manual overwriting is the way to 
go.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Wed Jul 25 01:29:48 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 25 Jul 2018 10:29:48 +0200
Subject: [gdal-dev] Complex valued NoData
In-Reply-To: <3CA22B17-4160-4145-9961-9771099D2979@jpl.nasa.gov>
References: <3CA22B17-4160-4145-9961-9771099D2979@jpl.nasa.gov>
Message-ID: <2133415.tLkjNlcKkd@even-i700>

Piyush,

>     We are working on use cases where we have to perform operations similar
> to gdal_translate / gdalwarp on complex valued datasets.
 
> The last discussion that I could on this topic in the mailing archives is
> from 2010:
> https://lists.osgeo.org/pipermail/gdal-dev/2010-September/025906.html 
> I’m willing to put in some effort to update the algorithms to handle nodata
> values for complex valued datasets properly (which it currently appears to
> ignore). Any pointers on where to start looking or focus on would help?

gcore/overview.cpp
alg/gdalwarpkernel.cpp
 
> We would like to avoid using pixel functions and manipulating the real/imag
> parts independently and then putting them back together.
 
> There are also different options for interpreting nodata. I believe we are
> limited to real values for this metadata field and adding new fields /
> changing the type could be pretty disruptive.
 
>   1.  Compare real value only (seems easiest to implement)
>   2.  Compare that both real and imaginary values are set to no data
> (probably better way of checking?)
 
> If one were to implement nodata support for complex-valued datasets, which
> implementation would be preferred.

Probably that comparing the real value only would be the best way to go

Looking quickly, I see we have some inconsistency of behaviour. For example 
GDALRasterBand::GetHistogram() takes the norm of the value before comparing to 
nodata, whereas ComputeStatistics() only compares (and takes into account) the 
real value.

Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From matt.a.hanson at gmail.com  Wed Jul 25 07:52:16 2018
From: matt.a.hanson at gmail.com (Matt Hanson)
Date: Wed, 25 Jul 2018 10:52:16 -0400
Subject: [gdal-dev] Reading remote jp2k files
Message-ID: <CAGYeuZnRxN1AQSsGFndv9_4zqwhP-iDew+3nvyXvFxZOOpQXdQ@mail.gmail.com>

Hello,

I'm having trouble reading JP2K files remotely. I originally ran into this
problem when trying to use remote Sentinel-2 files as input to the GDAL
Warp API in C++. It works when I use a local version of the file.

I'm not sure if this is supported behavior, I thought it was, but to test I
tried gdal_translate on a remote file, and one with the local file.

$ gdal_translate
https://sentinel-s2-l1c.s3.amazonaws.com/tiles/32/T/QR/2018/1/21/0/B04.jp2
sentinel-test-remote.tif -f GTiff
$ gdal_translate B03.jp2 sentinel-test-local.tif -f GTiff

The local file works fine, but when using the remote file gdal_translate
just crashes with no error message.

I'm using GDAL 2.3.1 with openjpeg 2.3, I'm using a docker image
developmentseed/geolambda:1.0.0 and you can see the Dockerfile here:

https://github.com/developmentseed/geolambda/blob/master/Dockerfile

Is this supported behavior, should I be able to read these files remotely,
and do windowed reads on them?

matt
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180725/5edb9651/attachment.html>

From matt.a.hanson at gmail.com  Wed Jul 25 07:55:10 2018
From: matt.a.hanson at gmail.com (Matt Hanson)
Date: Wed, 25 Jul 2018 10:55:10 -0400
Subject: [gdal-dev] Use GDAL on AWS Lambda
In-Reply-To: <1531505817169-0.post@n6.nabble.com>
References: <1531423856188-0.post@n6.nabble.com>
 <79f8b78688004301820430d155755232@PW00INFMAI022.ent.ad.dg.local>
 <1531505817169-0.post@n6.nabble.com>
Message-ID: <CAGYeuZ=LSHrN37+7cx2QcogJYc4h1ejUH51CWjUSMQQHQZ68Pg@mail.gmail.com>

A bit late to the party, but there's also geolambda which works in a
similar manner as the above solutions. It's got the latest version of GDAL
and dependencies, Python 2.7 and 3.6 and packaging scripts for packaging up
your code for deployment to lambda:

https://github.com/developmentseed/geolambda

On Fri, Jul 13, 2018 at 2:17 PM kch <kchin at edrnet.com> wrote:

> Tim's solution worked for me. Thank you!
>
>
>
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180725/ac512c63/attachment.html>

From even.rouault at spatialys.com  Wed Jul 25 09:00:23 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 25 Jul 2018 18:00:23 +0200
Subject: [gdal-dev] Reading remote jp2k files
In-Reply-To: <CAGYeuZnRxN1AQSsGFndv9_4zqwhP-iDew+3nvyXvFxZOOpQXdQ@mail.gmail.com>
References: <CAGYeuZnRxN1AQSsGFndv9_4zqwhP-iDew+3nvyXvFxZOOpQXdQ@mail.gmail.com>
Message-ID: <1709869.hQjZ6NzhqS@even-i700>

Matt,

> 
> I'm having trouble reading JP2K files remotely. I originally ran into this
> problem when trying to use remote Sentinel-2 files as input to the GDAL
> Warp API in C++. It works when I use a local version of the file.
> 
> I'm not sure if this is supported behavior, I thought it was, but to test I
> tried gdal_translate on a remote file, and one with the local file.
> 
> $ gdal_translate
> https://sentinel-s2-l1c.s3.amazonaws.com/tiles/32/T/QR/2018/1/21/0/B04.jp2
> sentinel-test-remote.tif -f GTiff
> $ gdal_translate B03.jp2 sentinel-test-local.tif -f GTiff
> 
> The local file works fine, but when using the remote file gdal_translate
> just crashes with no error message.

A process crash ? Can you get a stack trace / valgrind output ?

I tried, and it failed in a regular way, since when you use http:// the HTTP 
driver triggers. This driver downloads the whole file in memory before passing 
it to the real driver, and it deleted the temp file, whereas the JP2OpenJPEG 
driver needs to be able to re-open it. Just fixed that issue

> 
> I'm using GDAL 2.3.1 with openjpeg 2.3, I'm using a docker image
> developmentseed/geolambda:1.0.0 and you can see the Dockerfile here:
> 
> https://github.com/developmentseed/geolambda/blob/master/Dockerfile
> 
> Is this supported behavior, should I be able to read these files remotely,
> and do windowed reads on them?

For windowed reads, you need to prefix with /vsicurl/, but I don't guarantee 
the efficiency of this with JPEG2000 in general, and with JP2OpenJPEG in 
particular.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Wed Jul 25 09:32:43 2018
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 25 Jul 2018 18:32:43 +0200
Subject: [gdal-dev] ERROR 1: In file cpl_vsil_gzip.cpp, at line 905,
	return 0
In-Reply-To: <CA+Ei1Ofpm4Y6UJnGK7yJ73LWT6PZmPtopSb4HbVU0bW8dpHx0w@mail.gmail.com>
References: <CA+Ei1Ofpm4Y6UJnGK7yJ73LWT6PZmPtopSb4HbVU0bW8dpHx0w@mail.gmail.com>
Message-ID: <1732779.4uyt12mOMa@even-i700>

On lundi 23 juillet 2018 22:46:26 CEST Martin Landa wrote:
> Hi,
> 
> I have problem with reading some files provided by Czech State
> Administration of Land Surveying and Cadastre in VFR format (supported
> by GML driver). Some files seems to be incorrectly compressed.
> 
[...]
> NO features are printed. gzip says "unexpected end of file" and
> refuses to extract the file. 7zip (and other programs) on Windows
> reports similar error, but file is extracted. I am discussing issue
> with the provider. By chance, do you have any tip how to read such
> broken files by GDAL?

The corruption in the compressed stream seems to occur just after the end of 
the closing XML tag, so indeed the file can be read. I've improved robustness 
of /vsigzip/ per
https://github.com/OSGeo/gdal/commit/d57006d94d94f8d365a20cbf14a0241f906f1706

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From cp2732 at gmail.com  Wed Jul 25 13:02:32 2018
From: cp2732 at gmail.com (Christopher Puda)
Date: Wed, 25 Jul 2018 16:02:32 -0400
Subject: [gdal-dev] Trouble Building GDAL with HDF5
Message-ID: <CAF27VCWdzzcxbzJ6yo8DaNpm3ybLkgsqLmYHeB4FS1QoDCVmjQ@mail.gmail.com>

I am trying to build GDAL with HDF5 usability on a Windows 7 64-bit
computer using Visual Studio Community Edition 2017. I have followed a
YouTube video (https://www.youtube.com/watch?v=Yf8rYOfvZjY) for getting the
vcxproj files, but get stuck when trying to build the main project. The
command I use is .\generate_vcxproj.bat 15.0 64 gdal_vs2017. Currently, I
am getting six errors and 11 warnings. I have attached the nmake.opt file I
use. I do not have a nmake.local file currently. The errors are as follows:

LNK1120 3 unresolved externals
LNK2019 unresolved external symbol SZ_BufftoBuffCompress referenced in
function H5Z_filter_szip
LNK2019 unresolved external symbol SZ_BufftoBuffDecompress referenced in
function H5Z_filter_szip
LNK2019 unresolved external symbol SZ_encoder_enabled referenced in
function H5Z_init_package
U1077 -> "C:\Program Files (x86)\Microsoft Visual
Studio\2017\Community\VC\Tools\MSVC\14.14.26428\bin\HostX86\x64\link.EXE"'
: return code '0x460'
MSB0373 The command "nmake -f makefile.vc MSVC_VER=1910 WIN64=1 DEBUG=1
WITH_PDB=1" exited with code 2.

This warning could also be a clue:
LNK4098 defaultlib 'MSVCRT' conflicts with use of other libs; use
/NODEFAULTLIB:library

More details for this issue can be found on the YouTube video link above
under the Comments section. Any help would be appreciated!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180725/60773c8c/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: nmake.opt
Type: application/octet-stream
Size: 35419 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180725/60773c8c/attachment-0001.obj>

From lucena_ivan at hotmail.com  Wed Jul 25 14:30:34 2018
From: lucena_ivan at hotmail.com (Ivan Lucena)
Date: Wed, 25 Jul 2018 21:30:34 +0000
Subject: [gdal-dev] Trouble Building GDAL with HDF5
In-Reply-To: <CAF27VCWdzzcxbzJ6yo8DaNpm3ybLkgsqLmYHeB4FS1QoDCVmjQ@mail.gmail.com>
References: <CAF27VCWdzzcxbzJ6yo8DaNpm3ybLkgsqLmYHeB4FS1QoDCVmjQ@mail.gmail.com>
Message-ID: <BN6PR2201MB1249F2234B3F1570A1CD5924F2540@BN6PR2201MB1249.namprd22.prod.outlook.com>

Christopher,

I believe that this problem has to do with how you build the HDF5 library. Are you building it yourself

I fight with that same problem on Linux a couple of months ago, after an HDF5 update.

The solution was to include Zlib into the HDF5 building configuration.

I don't have access to those machines anymore but on my OSX machine I am building HDF5 with those options:

$ ./configure --with-zlib=/usr/local/opt/zlib
$ make
$ make install

You can get Zlib source code from zlib.net and do the same or better yet, get the HDF5 Windows installer from HDFGroup.org. That works fine for me.

Regards,

Ivan

________________________________
From: gdal-dev <gdal-dev-bounces at lists.osgeo.org> on behalf of Christopher Puda <cp2732 at gmail.com>
Sent: Wednesday, July 25, 2018 4:02 PM
To: gdal-dev at lists.osgeo.org
Subject: [gdal-dev] Trouble Building GDAL with HDF5

I am trying to build GDAL with HDF5 usability on a Windows 7 64-bit computer using Visual Studio Community Edition 2017. I have followed a YouTube video (https://www.youtube.com/watch?v=Yf8rYOfvZjY) for getting the vcxproj files, but get stuck when trying to build the main project. The command I use is .\generate_vcxproj.bat 15.0 64 gdal_vs2017. Currently, I am getting six errors and 11 warnings. I have attached the nmake.opt file I use. I do not have a nmake.local file currently. The errors are as follows:

LNK1120 3 unresolved externals
LNK2019 unresolved external symbol SZ_BufftoBuffCompress referenced in function H5Z_filter_szip
LNK2019 unresolved external symbol SZ_BufftoBuffDecompress referenced in function H5Z_filter_szip
LNK2019 unresolved external symbol SZ_encoder_enabled referenced in function H5Z_init_package
U1077 -> "C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.14.26428\bin\HostX86\x64\link.EXE"' : return code '0x460'
MSB0373 The command "nmake -f makefile.vc<http://makefile.vc> MSVC_VER=1910 WIN64=1 DEBUG=1 WITH_PDB=1" exited with code 2.

This warning could also be a clue:
LNK4098 defaultlib 'MSVCRT' conflicts with use of other libs; use /NODEFAULTLIB:library

More details for this issue can be found on the YouTube video link above under the Comments section. Any help would be appreciated!

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180725/a9033fee/attachment.html>

From jvenman at noggin.io  Wed Jul 25 19:08:03 2018
From: jvenman at noggin.io (jvenman)
Date: Wed, 25 Jul 2018 19:08:03 -0700 (MST)
Subject: [gdal-dev] Transform shapefile to specific WKT format
In-Reply-To: <2046030.fQISZH6OhG@even-i700>
References: <1532479697032-0.post@n6.nabble.com> <2046030.fQISZH6OhG@even-i700>
Message-ID: <1532570883436-0.post@n6.nabble.com>

Thanks Even



--
Sent from: http://osgeo-org.1560.x6.nabble.com/GDAL-Dev-f3742093.html

From jvail at gmx.de  Wed Jul 25 23:02:19 2018
From: jvail at gmx.de (Jan Vaillant)
Date: Thu, 26 Jul 2018 08:02:19 +0200
Subject: [gdal-dev] Reading remote jp2k files
In-Reply-To: <1709869.hQjZ6NzhqS@even-i700>
References: <CAGYeuZnRxN1AQSsGFndv9_4zqwhP-iDew+3nvyXvFxZOOpQXdQ@mail.gmail.com>
 <1709869.hQjZ6NzhqS@even-i700>
Message-ID: <48c5702c-f22c-f7a1-dd09-e7d5bb89f70a@gmx.de>

Hi,

On 07/25/2018 06:00 PM, Even Rouault wrote:
>> Is this supported behavior, should I be able to read these files remotely,
>> and do windowed reads on them?
> 
> For windowed reads, you need to prefix with /vsicurl/, but I don't guarantee
> the efficiency of this with JPEG2000 in general, and with JP2OpenJPEG in
> particular.

Regarding "efficiency" I'd like to add two observations from a little 
investigation (not really in-depth) I did recently to compare /vsicurl/ 
with a tiny, experimental JS lib (fetch & decode single jp2 tiles in 
pure JS):

- If I try to fetch a window that is completely within one tile it 
*seems* vsicurl is iterating through all tiles and does not stop after 
reaching & fetching the "requested" tile.

- Instead of starting from the first tile it could make a guess and 
start at that offset and search backwards and forward till it finds the 
requested tile index. Although a good "guess" of an offset is difficult 
given that tile size might vary greatly.

I think this could probably make fetching parts slightly more efficient 
(in terms of no. of requests & data transfer). Certainly it would be 
much easier if tile offsets could be included in a jp2 header.

Jan


From giserliang at hotmail.com  Thu Jul 26 01:18:59 2018
From: giserliang at hotmail.com (? ??)
Date: Thu, 26 Jul 2018 08:18:59 +0000
Subject: [gdal-dev] Export label to dxf from postgresql by ogr2ogr
Message-ID: <SG2PR03MB1902A3BE5AE46053D6C003ADC82B0@SG2PR03MB1902.apcprd03.prod.outlook.com>

I need to export label to dxf from postgresql by ogr2ogr command, label information is text field in PG, but it is always unsuccessful, I always lose the text label information.

Those commands are here:

ogr2ogr -f "DXF" "demo.dxf" "PG:host=localhost user=postgres dbname=demo pas sword=xxxx port=5432" -sql "SELECT geom, 'LABEL(f:\'Times New Roman\',s:12pt,t:\'' || text || '\')' AS OGR_STYLE FROM demo"

ogr2ogr -select 'text' -f "DXF" "demo.dxf" "PG:host=localhost user=postgres dbname=demo pas sword=xxxx port=5432" "demo"

PG Fields are here:
 [PG Fields And Values] <https://i.stack.imgur.com/0g5h6.png>

What is wrong with those commands? Any Help? Thanks
________________________________
giserliang at hotmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180726/d613badf/attachment-0001.html>

From Maria.Ibarra at ign.fr  Thu Jul 26 06:42:15 2018
From: Maria.Ibarra at ign.fr (Maria Ibarra)
Date: Thu, 26 Jul 2018 13:42:15 +0000
Subject: [gdal-dev] Is it possible to optimize vector tiles time writing
 with MVT driver ?
Message-ID: <E7F574920EECF34CBCB30D379B14BEC5A8FABEC2@mailex1.ign.fr>

Hello,

I am using the GDAL 2.3.1 MVT driver  to build a vector tile basemap (multiple data layers, at different zoom levels). The process takes 14 hours. However, when I do the same thing using Tippecanoe, it takes one hour and a half.


I’m not sure if I am missing some configuration to reduce the time writing with GDAL.


This is the command I'm using :


ogr2ogr -f MVT <output-folder> PG:<connection to the database> -dsco CONF=<json_conf> -dim 2


where <json_conf> =

'{

    "layer_1": {

        "target_name": "layer_1" ,

        "description": "layer_1" ,

        "minzoom": 13 ,

        "maxzoom": 18

    },

    "layer_2":{

        "target_name": "layer_2" ,

        "description": "layer_2" ,

        "minzoom": 13 ,

        "maxzoom": 18 },

    <…>

}'


Any advice to optimize vector tile writing process would be helpful.


Thanks,


Maria


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180726/61c5e77f/attachment.html>

From tyler.burse at kitware.com  Thu Jul 26 07:02:13 2018
From: tyler.burse at kitware.com (Tyler Burse)
Date: Thu, 26 Jul 2018 10:02:13 -0400
Subject: [gdal-dev] Area from gdalinfo metadata on a .tif image
Message-ID: <CAPLLpK8OXdcxtDJqcgbpkGtogeh_5CzzJ1BCP9E0nWC1GY0=ZA@mail.gmail.com>

Hello,

I hope you all have had a great week so far. I am hoping you will be able
to provide some help because I have not been able to find a way to get the
area from the metadata returned by gdalinfo. What I get as the return of
gdalinfo appears to be a non-georeferenced figure such as:

C:\Temp>gdalinfo figure1.tif
Driver: GTiff/GeoTIFF
Files: figure1.tif
Size is 244, 210
Coordinate System is `'
Metadata:
  TIFFTAG_XRESOLUTION=96
  TIFFTAG_YRESOLUTION=96
  TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
Image Structure Metadata:
  INTERLEAVE=PIXEL
Corner Coordinates:
Upper Left  (    0.0,    0.0)
Lower Left  (    0.0,  210.0)
Upper Right (  244.0,    0.0)
Lower Right (  244.0,  210.0)
Center      (  122.0,  105.0)
Band 1 Block=244x11 Type=Byte, ColorInterp=Red
Band 2 Block=244x11 Type=Byte, ColorInterp=Green
Band 3 Block=244x11 Type=Byte, ColorInterp=Blue


Would you be able to help me with finding the best way to extract the area
in kilometers squared from this info using GDAL?

Best regards,

Tyler Burse
R&D Intern
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180726/da3d6d54/attachment.html>

From andrew at aitchison.me.uk  Thu Jul 26 07:23:57 2018
From: andrew at aitchison.me.uk (Andrew C Aitchison)
Date: Thu, 26 Jul 2018 15:23:57 +0100 (BST)
Subject: [gdal-dev] Area from gdalinfo metadata on a .tif image
In-Reply-To: <CAPLLpK8OXdcxtDJqcgbpkGtogeh_5CzzJ1BCP9E0nWC1GY0=ZA@mail.gmail.com>
References: <CAPLLpK8OXdcxtDJqcgbpkGtogeh_5CzzJ1BCP9E0nWC1GY0=ZA@mail.gmail.com>
Message-ID: <alpine.LRH.2.21.1807261508400.7863@warden.aitchison.me.uk>

On Thu, 26 Jul 2018, Tyler Burse wrote:
> I hope you all have had a great week so far. I am hoping you will be able
> to provide some help because I have not been able to find a way to get the
> area from the metadata returned by gdalinfo. What I get as the return of
> gdalinfo appears to be a non-georeferenced figure such as:
>
> C:\Temp>gdalinfo figure1.tif
> Driver: GTiff/GeoTIFF
> Files: figure1.tif
> Size is 244, 210
> Coordinate System is `'
> Metadata:
>  TIFFTAG_XRESOLUTION=96
>  TIFFTAG_YRESOLUTION=96
>  TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
> Image Structure Metadata:
>  INTERLEAVE=PIXEL
> Corner Coordinates:
> Upper Left  (    0.0,    0.0)
> Lower Left  (    0.0,  210.0)
> Upper Right (  244.0,    0.0)
> Lower Right (  244.0,  210.0)
> Center      (  122.0,  105.0)
> Band 1 Block=244x11 Type=Byte, ColorInterp=Red
> Band 2 Block=244x11 Type=Byte, ColorInterp=Green
> Band 3 Block=244x11 Type=Byte, ColorInterp=Blue
>
>
> Would you be able to help me with finding the best way to extract the area
> in kilometers squared from this info using GDAL?

The output includes
    Coordinate System is `'
so, formally, we do not know the relationship between the image and the
piece of the earth that it represents.

If the file specified the coordinate system,
then gdalinfo would report something like:
Coordinate System is:
PROJCS["OSGB 1936 / British National Grid",
     GEOGCS["OSGB 1936",
         DATUM["OSGB_1936",
             SPHEROID["Airy 1830",6377563.396,299.3249646,
                 AUTHORITY["EPSG","7001"]],
             TOWGS84[446.448,-125.157,542.06,0.15,0.247,0.842,-20.489],
             AUTHORITY["EPSG","6277"]],
         PRIMEM["Greenwich",0,
             AUTHORITY["EPSG","8901"]],
         UNIT["degree",0.0174532925199433,
             AUTHORITY["EPSG","9122"]],
         AUTHORITY["EPSG","4277"]],
     PROJECTION["Transverse_Mercator"],
     PARAMETER["latitude_of_origin",49],
     PARAMETER["central_meridian",-2],
     PARAMETER["scale_factor",0.9996012717],
     PARAMETER["false_easting",400000],
     PARAMETER["false_northing",-100000],
     UNIT["metre",1,
         AUTHORITY["EPSG","9001"]],
     AXIS["Easting",EAST],
     AXIS["Northing",NORTH],
     AUTHORITY["EPSG","27700"]]
Origin = (-649749.999999999883585,1449750.000000000465661)
Pixel Size = (500.000000000000000,-500.000000000000171)
Metadata:
  ... 
Corner Coordinates:
Upper Left  ( -649750.000, 1449750.000) ( 21d55'22.41"W, 61d27'54.60"N)
Lower Left  ( -649750.000, -150250.000) ( 16d 0'12.44"W, 47d41'10.18"N)
Upper Right ( 1350250.000, 1449750.000) ( 16d 9' 2.77"E, 61d43'17.34"N)
Lower Right ( 1350250.000, -150250.000) ( 10d42'41.48"E, 47d50'21.53"N)

Note the lines:
     UNIT["metre",1,
         AUTHORITY["EPSG","9001"]],
- so this coordinate system and file is in metres (other commone coordinate systems use US feet or degrees as units).

This file represents a space on the ground which is
   1320250 - -649750 = 2000000m = 2000km east to west, and
   1449750 - -150250 = 1600000m = 1600km north to south,
so has an area of 3.2million km^2.

-- 
Andrew C. Aitchison					Cambridge, UK
 			andrew at aitchison.me.uk

From SGONG at mdacorporation.com  Fri Jul 27 13:10:11 2018
From: SGONG at mdacorporation.com (Gong, Shawn)
Date: Fri, 27 Jul 2018 20:10:11 +0000
Subject: [gdal-dev] mosaiced SAR in geotiff
Message-ID: <7DCBC135929FF74E8A5488B1814AC6BC5388BDC2@exbermd02.ds.mda.ca>

Hi list,

I have simulated RCM Complex SLC in mosaiced geotiff format that I don't know how to deal with.
Is there a driver for it, similar to SPOT7 mosaiced product?

I tried to use gdalbuildvrt and gdal_merge but neither worked because the mosaiced geotiff are not georeferenced. Each chip has only 4 corner GCPs.

Should I use set_geotransform( ), then gdalbuildvrt ?

gdalinfo output:
Driver: GTiff/GeoTIFF
Files: PGS_TD_PR_GenIm_MRes30_1_PT_1_HH_0.tif
Size is 2407, 291
Coordinate System is `'
GCP Projection =
GEOGCS["WGS 84",
    DATUM["WGS_1984",
        SPHEROID["WGS 84",6378137,298.257223563,
            AUTHORITY["EPSG","7030"]],
        AUTHORITY["EPSG","6326"]],
    PRIMEM["Greenwich",0],
    UNIT["degree",0.0174532925199433],
    AUTHORITY["EPSG","4326"]]
GCP[  0]: Id=1, Info=
          (0.5,0.5) -> (-21.411272470412,-80.7062573860622,0)
GCP[  1]: Id=2, Info=
          (2406.5,0.5) -> (-21.4712880925672,-80.4068317341721,0)
GCP[  2]: Id=3, Info=
          (2406.5,290.5) -> (-21.1149325668978,-80.4046874263347,0)
GCP[  3]: Id=4, Info=
          (0.5,290.5) -> (-21.0437603692169,-80.7040392737628,0)
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_DATETIME=2018:04:05 17:40:44
  TIFFTAG_IMAGEDESCRIPTION=HH
Image Structure Metadata:
  INTERLEAVE=PIXEL
Corner Coordinates:
Upper Left  (    0.0,    0.0)
Lower Left  (    0.0,  291.0)
Upper Right ( 2407.0,    0.0)
Lower Right ( 2407.0,  291.0)
Center      ( 1203.5,  145.5)
Band 1 Block=2407x217 Type=Int16, ColorInterp=Gray
Band 2 Block=2407x217 Type=Int16, ColorInterp=Undefined

**.tif.tiffinfo:
TIFF Directory at offset 0x3fc280 (4178560)
  Image Width: 2407 Image Length: 291
  Bits/Sample: 16
  Sample Format: signed integer
  Compression Scheme: None
  Photometric Interpretation: min-is-black
  Orientation: row 0 top, col 0 lhs
  Samples/Pixel: 2
  Rows/Strip: 217
  Planar Configuration: single image plane
  ImageDescription: HH
  DateTime: 2018:04:05 17:40:44
--GeoTIFF Tags--
  Geo Tiepoints:
     ( 0.500000 0.500000 0.000000)->( -21.411272 -80.706257 0.000000)
 ( 2406.500000 0.500000 0.000000)->( -21.471288 -80.406832 0.000000)
 ( 2406.500000 290.500000 0.000000)->( -21.114933 -80.404687 0.000000)
 ( 0.500000 290.500000 0.000000)->( -21.043760 -80.704039 0.000000)
  GeoKey Directory:(present)
  GeoKey Double Params:(present)
  GeoKey ASCII Parameters:(present)

**.tif.listgeo:
Geotiff_Information:
   Version: 1
   Key_Revision: 1.0
   Tagged_Information:
      ModelTiepointTag (8,3):
         0.5              0.5              0
         -21.411272470412 -80.70625738606220
         2406.5           0.5              0
         -21.4712880925672-80.40683173417210
         2406.5           290.5            0
         -21.1149325668978-80.40468742633470
         0.5              290.5            0
         -21.0437603692169-80.70403927376280
      End_Of_Tags.
   Keyed_Information:
      GTModelTypeGeoKey (Short,1): ModelTypeGeographic
      GTRasterTypeGeoKey (Short,1): RasterPixelIsArea
      GTCitationGeoKey (Ascii,27): "Uncorrected Satellite Data"
      GeographicTypeGeoKey (Short,1): GCS_WGS_84
      GeogCitationGeoKey (Ascii,6): "WGS84"
      GeogGeodeticDatumGeoKey (Short,1): Datum_WGS84
      GeogLinearUnitsGeoKey (Short,1): Linear_Meter
      GeogAngularUnitsGeoKey (Short,1): Angular_Degree
      GeogEllipsoidGeoKey (Short,1): Ellipse_WGS_84
      GeogSemiMajorAxisGeoKey (Double,1): 6378137
      GeogSemiMinorAxisGeoKey (Double,1): 6356752.31424518
      End_Of_Keys.
   End_Of_Geotiff.
GCS: 4326/WGS 84
Datum: 6326/World Geodetic System 1984
Ellipsoid: 7030/WGS 84 (6378137.00,6356752.31)
Prime Meridian: 8901/Greenwich (0.000000/  0d 0' 0.00"E)
Corner Coordinates:
 ... unable to transform points between pixel/line and PCS space


Thanks,
Shawn

This electronic correspondence, including any attachments, is intended solely for the use of the intended recipient(s) and may contain legally privileged, proprietary and/or confidential information. If you are not the intended recipient, please immediately notify the sender by reply e-mail and permanently delete all copies of this electronic correspondence and associated attachments. Any use, disclosure, dissemination, distribution or copying of this electronic correspondence and any attachments for any purposes that have not been specifically authorized by the sender is strictly prohibited.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180727/f1ef59a2/attachment.html>

From athomas at thinkspatial.com.au  Sat Jul 28 08:16:46 2018
From: athomas at thinkspatial.com.au (Alan Thomas)
Date: Sun, 29 Jul 2018 01:16:46 +1000
Subject: [gdal-dev] Export label to dxf from postgresql by ogr2ogr
In-Reply-To: <SG2PR03MB1902A3BE5AE46053D6C003ADC82B0@SG2PR03MB1902.apcprd03.prod.outlook.com>
References: <SG2PR03MB1902A3BE5AE46053D6C003ADC82B0@SG2PR03MB1902.apcprd03.prod.outlook.com>
Message-ID: <CALhO07wendZt=4kc0SdmmOGrSe4FSk-TFneXPiSxGpR5qmtJ7w@mail.gmail.com>

Hi,

When I run your first command (with a couple of syntax fixes - it is
incorrect to delimit parts of the style string with single quotes) I
get a DXF file with two labels.

$ ogr2ogr -f "DXF" "demo.dxf" "PG:<connection string here>" -sql
"SELECT geom, 'LABEL(f:Times New Roman,s:12pt,t:' || text || ')' AS
OGR_STYLE FROM public.test"
ERROR 1: DXF layer does not support arbitrary field creation, field
'ogr_style' not created.

You can ignore that error message; the styling data does get used
correctly by the DXF writer.

Unfortunately I only have GDAL 2.2.4 to hand at the moment, which does
not contain any of the recent improvements to the DXF driver. It is
possible that the behaviour is different on GDAL 2.3. Can you confirm
whether this command works for you?

Alan

On Thu, 26 Jul 2018 at 18:19, ? ?? <giserliang at hotmail.com> wrote:
>
> I need to export label to dxf from postgresql by ogr2ogr command, label information is text field in PG, but it is always unsuccessful, I always lose the text label information.
>
> Those commands are here:
>
> ogr2ogr -f "DXF" "demo.dxf" "PG:host=localhost user=postgres dbname=demo pas sword=xxxx port=5432" -sql "SELECT geom, 'LABEL(f:\'Times New Roman\',s:12pt,t:\'' || text || '\')' AS OGR_STYLE FROM demo"
>
> ogr2ogr -select 'text' -f "DXF" "demo.dxf" "PG:host=localhost user=postgres dbname=demo pas sword=xxxx port=5432" "demo"
>
>
> PG Fields are here:
>
>
> What is wrong with those commands? Any Help? Thanks
> ________________________________
> giserliang at hotmail.com
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Alan Thomas
Software Developer
ThinkSpatial
http://www.thinkspatial.com.au

From jackynguyen.km at gmail.com  Tue Jul 31 22:02:34 2018
From: jackynguyen.km at gmail.com (Jacky Nguyen)
Date: Wed, 1 Aug 2018 13:02:34 +0800
Subject: [gdal-dev] Cannot call InvGeoTransform due to too many values to
	unpack
Message-ID: <CADHfsK2JJOA--fdncY8wPiBiG8DJCdCM65+i_E+6ADOHj4pyxw@mail.gmail.com>

I am learning Geo development. I am following the example from the book
'Geospatial Python Development'

I am stuck with the tutorial where it does the InvGeoTransform the raster
data (obtain the l10g here https://www.ngdc.noaa.gov/mgg/topo/gltiles.html
and the header file l10g.hdr from here
https://www.ngdc.noaa.gov/mgg/topo/elev/esri/hdr/)

The error that I received is: too many values to unpack at the line where
it does the InvGeoTransform()


The python code in the book is:

import sys, struct
from osgeo import gdal
from osgeo import gdalconst

minLat  = -48
maxLat  = -33
minLong = 165
maxLong = 179

dataset = gdal.Open("l10g")
band = dataset.GetRasterBand(1)

t = dataset.GetGeoTransform()
success,tInverse = gdal.InvGeoTransform(t)
if not success:
    print("Failed!")
    sys.exit(1)

x1,y1 = gdal.ApplyGeoTransform(tInverse, minLong, minLat)
x2,y2 = gdal.ApplyGeoTransform(tInverse, maxLong, maxLat)

minX = int(min(x1, x2))
maxX = int(max(x1, x2))
minY = int(min(y1, y2))
maxY = int(max(y1, y2))

width = (maxX - minX) + 1
fmt = "<" + ("h" * width)

histogram = {} # Maps elevation to number of occurrences.

for y in range(minY, maxY+1):
    scanline = band.ReadRaster(minX, y, width, 1,
                               width, 1,
                               gdalconst.GDT_Int16)
    values = struct.unpack(fmt, scanline)

    for value in values:
        try:
            histogram[value] += 1
        except KeyError:
            histogram[value] = 1

for height in sorted(histogram.keys()):
    print(height, histogram[height])


* when I do: gdalinfo l10g, i got this info:
Driver: EHdr/ESRI .hdr Labelled
Files: l10g
       l10g.hdr
Size is 10800, 6000
Coordinate System is `'
Origin = (90.000000000000497,-0.000000000000500)
Pixel Size = (0.008333333333000,-0.008333333333000)
Corner Coordinates:
Upper Left  (  90.0000000,  -0.0000000)
Lower Left  (  90.0000000, -50.0000000)
Upper Right ( 180.0000000,  -0.0000000)
Lower Right ( 180.0000000, -50.0000000)
Center      ( 135.0000000, -25.0000000)
Band 1 Block=10800x1 Type=Int16, ColorInterp=Undefined
  NoData Value=-500

* And my gdalinfo --version shows: GDAL 2.3.0dev, released 2017/99/99

Can anyone show me what the issue is?

Thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20180801/d0fb4876/attachment.html>

