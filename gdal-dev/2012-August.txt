From Jukka.Rahkonen at mmmtike.fi  Wed Aug  1 04:02:17 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 1 Aug 2012 11:02:17 +0000
Subject: [gdal-dev] OSM Driver and World Planet file (pbf format)
Message-ID: <84446DEF76453C439E9E97E438E13A634612DB@suutari.haapa.mmm.fi>

Even Rouault wrote:
> 
> 
> > Another set of tests with a brand new and quite powerful laptop.
> >  Specs for the
> > computer:
> > Intel i7-2760QM @2.4 GHz processor (8 threads) Hitachi Travelstar
> > Z7K320 7200 rpm SATA disk
> > 8 GB of memory
> > Windows 7, 64-bit
> >
> > GDAL-version r24717, Win64 build from gisinternals.com
> >
> > Timings for germany.osm.pbf (1.3 GB)
> > ====================================
> >
> > A) Default settings with command
> > ogr2ogr -f sqlite -dsco spatialite=yes germany.sqlite germany.osm.pbf
> > -gt 20000 -progress --config OGR_SQLITE_SYNCHRONOUS OFF
> >
> > - reading the data               67 minutes
> > - creating spatial indexes       38 minutes
> > - total                         105 minutes
> >
> > B) Using in-memory Spatialite db for the first step by giving SET
> > OSM_MAX_TMPFILE_SIZE=7000
> >
> > - reading the data              16 minutes
> > - creating spatial indexes      38 minutes
> > - total                         54 minutes
> >
> > Peak memory usage during this conversion was 4.4 GB.
> >
> > Conclusions
> > ===========
> > * The initial reading of data is heavily i/o bound. This phase is
> > really fast if there is enough memory for keeping the OSM tempfile in
> > memory but SSD disk seems to offer equally good performance.
> > * Creating spatial indexes for the Spatialite tables is also i/o
> > bound. The hardware sets the speed limit and there are no other tricks
> > for improving the performance. Multi-core CPU is quite idle during
> > this phase with 10-15% load.
> > * If user does not plan to do spatial queries then then it may be
> > handy to save some time and create the Spatialite db without spatial
> > indexes by using -lco SPATIAL_INDEX=NO option.
> > * Windows disk i/o may be a limiting factor.
> >
> > I consider that for small OSM datasets the speed starts to be good
> > enough. For me it is about the same if converting the Finnish OSM data
> > (137 MB in .pbf format) takes 160 or 140 seconds when using the
> > default settings or in-memory temporary database, respectively.
> 
> Interesting findings.
> 
> A SSD is of course the ideal hardware to get efficient random access to the
> nodes.
> 
> I've just introduced inr 24719 a new config. option OSM_COMPRESS_NODES
> that can be set to YES. The effect is to use a compression algorithm while
> storing the temporary node DB.  This can compress to a factor of 3 or 4, and
> help keeping the node DB to a size where it is below the RAM size and that
> the OS can dramatically cache it (at least on Linux). This can be efficient for
> OSM extracts of the size of the country, but probably not for a planet file. In
> the case of Germany and France, here's the effect on my PC (SATA disk) :
> 
> $ time ogr2ogr -f null null /home/even/gdal/data/osm/france_new.osm.pbf
> - progress --config OSM_COMPRESS_NODES YES [...]
> real    25m34.029s
> user    15m11.530s
> sys 0m36.470s
> 
> $ time ogr2ogr -f null null /home/even/gdal/data/osm/france_new.osm.pbf
> - progress --config OSM_COMPRESS_NODES NO [...]
> real    74m33.077s
> user    15m38.570s
> sys 1m31.720s
> 
> $ time ogr2ogr -f null null /home/even/gdal/data/osm/germany.osm.pbf -
> progress --config OSM_COMPRESS_NODES YES [...]
> real    7m46.594s
> user    7m24.990s
> sys 0m11.880s
> 
> $ time ogr2ogr -f null null /home/even/gdal/data/osm/germany.osm.pbf -
> progress --config OSM_COMPRESS_NODES NO [...]
> real    108m48.967s
> user    7m47.970s
> sys 2m9.310s
> 
> I didn't turn it to YES by default, because I'm unsure of the performance
> impact on SSD. Perhaps you have a chance to test.

I cannot test with SSD before weekend but otherwise the new configuration option really makes difference in some circumstances.

I have ended up to use the following base command  in speed tests:
ogr2ogr -f SQLite -dsco spatialite=yes germany.sqlite germany.osm.pbf -gt 20000 -progress --config OGR_SQLITE_SYNCHRONOUS -lco SPATIAL_INDEX=NO

Writing into Spatialite is pretty fast with these options and even your null driver does not seem to be very much faster. What happens after this step (like creating indexes) has nothing to do with OSM driver.

Test with  Intel i7-2760QM @2.4 GHz processor,  7200 rpm SATA disk and 1.3 GB input file 'germany.osm.pbf' 
--config OSM_COMPRESS_NODES NO
67 minutes
--config OSM_COMPRESS_NODES YES
15 minutes

It means 52 minutes less time or 4.5 times more speed.
Out of curiosity I tried what happens if I do the whole file input/output by using a 2.5" external USB 2.0 drive.
19 minutes! 

I made also a few tests with an old and much slower Windows computer.   Running osm2pgsql with Finnish OSM data with that machine takes nowadays about 3 hours.

Test with a single Intel Xeon @2.4 GHz processor and the same external USB 2.0 disk than in previous test
Input file 'finland.osm.pbf' 122 MB
Result: 7 minutes for both  OSM_COMPRESS_NODES NO and OSM_COMPRESS_NODES YES
Input file 'germany.osm.pbf' 1.3 GB
Result: 112 minutes with OSM_COMPRESS_NODES YES

Conclusions:
* When input file has reached the limit where disk i/o  cannot utilize cache properly, the compress_nodes setting can have a huge effect.
* When i/o works well the temporary database storage does not have great effect on overall speed. In-memory db, SSD drive and fast SATA drive are all equally fast and even external USB 2.0 drive is almost as fast.
* With small input data file size compress_node setting does not seem to have much effect on speed.
* Obviously CPU is now the limiting factor.
* OGR OSM driver runs pretty well also on older computers.
* While single processor PC runs at 100% CPU load the 8-core PC shows only 12%.  There seems to be 88% of computing power free for making the memory and SSD lines saturated sometimes in the future... 
* Instead of buying expensive hardware like SSD the lucky ones may meet someone like Even who wants and can write fast programs.

I found my first notes from less than two weeks  ago when I believed that OSM driver was fast.  Now I repeated those tests with same data and same computers and the progress I can see is non-negligible. Result in these tests is Spatialite db with spatial indexes.

finland.osm.pbf         40 minutes -> 7 minutes
germany.osm.pbf     15 hours     -> 50 minutes

-Jukka Rahkonen-



From even.rouault at mines-paris.org  Wed Aug  1 04:58:06 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 01 Aug 2012 13:58:06 +0200
Subject: [gdal-dev] OSM Driver and World Planet file (pbf format)
In-Reply-To: <84446DEF76453C439E9E97E438E13A634612DB@suutari.haapa.mmm.fi>
References: <84446DEF76453C439E9E97E438E13A634612DB@suutari.haapa.mmm.fi>
Message-ID: <1343822286.501919ce0f57a@imp.free.fr>

Selon Rahkonen Jukka <Jukka.Rahkonen at mmmtike.fi>:

Interesting results. I'll wait a bit for your tests with SSD to turn
OSM_COMPRESS_NODES to YES. Even if doesn't bring clear advantages, I don't think
it would hurt a lot, because the extra CPU load introduced by the
compression/decompression shouldn't be that high (the compression algorithm used
is just encoding in Protocol Buffer of the differences of longitude/latitude
between consecutive nodes, by chunk of 64 nodes)

Just a word of caution to remind you that the temporary node DB will be written
in the directory pointed by the CPL_TMPDIR config. option/env. variable if
defined, if not defined in TMPDIR, if not defined in TEMP, if not defined in the
current directory form which ogr2ogr is started. In Windows system, the TEMP
env. variable is generally defined, so when you test with your USB external
driver, it is very likely that the node DB is written in the temporary directory
associated with your Windows account.

As far as CPU load is concerned, the conversion is a single-threaded processus,
so on a 8 core system, it is expected that it tops at 100 / 8 = 12,5 % of the
global CPU power. With which hardware configuration and input PBF file do you
manage to reach 100% CPU ? Is that load constant during the process : I imagine
that it could change according to the stage of the conversion.
There might be a potential for parallelizing some stuff. What comes in mind for
now would be PBF decoding (when profiling only PBF decoding, the gzip
decompression is the major CPU user, but not sure if it matters that much in a
real-life ogr2ogr job) or way resolution (currently, we group ways into a batch
until 1 million nodes or 75 000 ways have to be resolved, which leads to more
efficient search in the node DB since we can sort nodes by increasing ids and
avoid useless seeks). But that's not obviously immediate which would lead to
increased efficiently. Parallelization may also generally requires more RAM if
you need work buffers for each thread.

> Even Rouault wrote:
> >
> >
> > > Another set of tests with a brand new and quite powerful laptop.
> > >  Specs for the
> > > computer:
> > > Intel i7-2760QM @2.4 GHz processor (8 threads) Hitachi Travelstar
> > > Z7K320 7200 rpm SATA disk
> > > 8 GB of memory
> > > Windows 7, 64-bit
> > >
> > > GDAL-version r24717, Win64 build from gisinternals.com
> > >
> > > Timings for germany.osm.pbf (1.3 GB)
> > > ====================================
> > >
> > > A) Default settings with command
> > > ogr2ogr -f sqlite -dsco spatialite=yes germany.sqlite germany.osm.pbf
> > > -gt 20000 -progress --config OGR_SQLITE_SYNCHRONOUS OFF
> > >
> > > - reading the data               67 minutes
> > > - creating spatial indexes       38 minutes
> > > - total                         105 minutes
> > >
> > > B) Using in-memory Spatialite db for the first step by giving SET
> > > OSM_MAX_TMPFILE_SIZE=7000
> > >
> > > - reading the data              16 minutes
> > > - creating spatial indexes      38 minutes
> > > - total                         54 minutes
> > >
> > > Peak memory usage during this conversion was 4.4 GB.
> > >
> > > Conclusions
> > > ===========
> > > * The initial reading of data is heavily i/o bound. This phase is
> > > really fast if there is enough memory for keeping the OSM tempfile in
> > > memory but SSD disk seems to offer equally good performance.
> > > * Creating spatial indexes for the Spatialite tables is also i/o
> > > bound. The hardware sets the speed limit and there are no other tricks
> > > for improving the performance. Multi-core CPU is quite idle during
> > > this phase with 10-15% load.
> > > * If user does not plan to do spatial queries then then it may be
> > > handy to save some time and create the Spatialite db without spatial
> > > indexes by using -lco SPATIAL_INDEX=NO option.
> > > * Windows disk i/o may be a limiting factor.
> > >
> > > I consider that for small OSM datasets the speed starts to be good
> > > enough. For me it is about the same if converting the Finnish OSM data
> > > (137 MB in .pbf format) takes 160 or 140 seconds when using the
> > > default settings or in-memory temporary database, respectively.
> >
> > Interesting findings.
> >
> > A SSD is of course the ideal hardware to get efficient random access to the
> > nodes.
> >
> > I've just introduced inr 24719 a new config. option OSM_COMPRESS_NODES
> > that can be set to YES. The effect is to use a compression algorithm while
> > storing the temporary node DB.  This can compress to a factor of 3 or 4,
> and
> > help keeping the node DB to a size where it is below the RAM size and that
> > the OS can dramatically cache it (at least on Linux). This can be efficient
> for
> > OSM extracts of the size of the country, but probably not for a planet
> file. In
> > the case of Germany and France, here's the effect on my PC (SATA disk) :
> >
> > $ time ogr2ogr -f null null /home/even/gdal/data/osm/france_new.osm.pbf
> > - progress --config OSM_COMPRESS_NODES YES [...]
> > real    25m34.029s
> > user    15m11.530s
> > sys 0m36.470s
> >
> > $ time ogr2ogr -f null null /home/even/gdal/data/osm/france_new.osm.pbf
> > - progress --config OSM_COMPRESS_NODES NO [...]
> > real    74m33.077s
> > user    15m38.570s
> > sys 1m31.720s
> >
> > $ time ogr2ogr -f null null /home/even/gdal/data/osm/germany.osm.pbf -
> > progress --config OSM_COMPRESS_NODES YES [...]
> > real    7m46.594s
> > user    7m24.990s
> > sys 0m11.880s
> >
> > $ time ogr2ogr -f null null /home/even/gdal/data/osm/germany.osm.pbf -
> > progress --config OSM_COMPRESS_NODES NO [...]
> > real    108m48.967s
> > user    7m47.970s
> > sys 2m9.310s
> >
> > I didn't turn it to YES by default, because I'm unsure of the performance
> > impact on SSD. Perhaps you have a chance to test.
>
> I cannot test with SSD before weekend but otherwise the new configuration
> option really makes difference in some circumstances.
>
> I have ended up to use the following base command  in speed tests:
> ogr2ogr -f SQLite -dsco spatialite=yes germany.sqlite germany.osm.pbf -gt
> 20000 -progress --config OGR_SQLITE_SYNCHRONOUS -lco SPATIAL_INDEX=NO
>
> Writing into Spatialite is pretty fast with these options and even your null
> driver does not seem to be very much faster. What happens after this step
> (like creating indexes) has nothing to do with OSM driver.
>
> Test with  Intel i7-2760QM @2.4 GHz processor,  7200 rpm SATA disk and 1.3 GB
> input file 'germany.osm.pbf'
> --config OSM_COMPRESS_NODES NO
> 67 minutes
> --config OSM_COMPRESS_NODES YES
> 15 minutes
>
> It means 52 minutes less time or 4.5 times more speed.
> Out of curiosity I tried what happens if I do the whole file input/output by
> using a 2.5" external USB 2.0 drive.
> 19 minutes!
>
> I made also a few tests with an old and much slower Windows computer.
> Running osm2pgsql with Finnish OSM data with that machine takes nowadays
> about 3 hours.
>
> Test with a single Intel Xeon @2.4 GHz processor and the same external USB
> 2.0 disk than in previous test
> Input file 'finland.osm.pbf' 122 MB
> Result: 7 minutes for both  OSM_COMPRESS_NODES NO and OSM_COMPRESS_NODES YES
> Input file 'germany.osm.pbf' 1.3 GB
> Result: 112 minutes with OSM_COMPRESS_NODES YES
>
> Conclusions:
> * When input file has reached the limit where disk i/o  cannot utilize cache
> properly, the compress_nodes setting can have a huge effect.
> * When i/o works well the temporary database storage does not have great
> effect on overall speed. In-memory db, SSD drive and fast SATA drive are all
> equally fast and even external USB 2.0 drive is almost as fast.
> * With small input data file size compress_node setting does not seem to have
> much effect on speed.
> * Obviously CPU is now the limiting factor.
> * OGR OSM driver runs pretty well also on older computers.
> * While single processor PC runs at 100% CPU load the 8-core PC shows only
> 12%.  There seems to be 88% of computing power free for making the memory and
> SSD lines saturated sometimes in the future...
> * Instead of buying expensive hardware like SSD the lucky ones may meet
> someone like Even who wants and can write fast programs.
>
> I found my first notes from less than two weeks  ago when I believed that OSM
> driver was fast.  Now I repeated those tests with same data and same
> computers and the progress I can see is non-negligible. Result in these tests
> is Spatialite db with spatial indexes.
>
> finland.osm.pbf         40 minutes -> 7 minutes
> germany.osm.pbf     15 hours     -> 50 minutes
>
> -Jukka Rahkonen-
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



From ramirogonzalez at suremptec.com.ar  Wed Aug  1 05:52:28 2012
From: ramirogonzalez at suremptec.com.ar (Ramiro Gonzalez)
Date: Wed, 1 Aug 2012 09:52:28 -0300
Subject: [gdal-dev] tool to create/edit srs wkts
Message-ID: <CAAb2t_k8Wu_0_UVbDw1r2b3JtaT_WTmU868SdnsgX0ynE1CA4A@mail.gmail.com>

Hi



I?m building a tool to create/edit projected srs, geographic srs, datums
and spheroids and save them as WKTs.  I?m already using
?ogr/SpatialReference?.



Then I?d like to use the new WKTs with gdal/ogr. Here are some questions:

 * Image/vector drivers construct WKT from information in the image/vector
or they also use information in gdal csv files (gcs.csv, datum.csv, ?) ?

   If they use the csv files:

    i. Is there any way to add the new WKTs to gdal data(even if I have to
add them every time I open my application)

    i. If someone wants to overwrite an existing srs(Same authority:code
but different content). Can I change the definition in GDAL.

 * What functionality may stop working with an image projected to a new srs.


Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120801/23869865/attachment.html>

From Jukka.Rahkonen at mmmtike.fi  Wed Aug  1 07:38:49 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 1 Aug 2012 14:38:49 +0000
Subject: [gdal-dev] OSM Driver and World Planet file (pbf format)
Message-ID: <84446DEF76453C439E9E97E438E13A63461CDE@suutari.haapa.mmm.fi>

Hi,

Right, temporary DB was written on system disk so I repeated the test. Now everything was for sure done on the same USB 2.0 disk (read pbf, write results to Spatialite and handle temporaty DB). It took a bit longer but difference was not very big: 26 minutes vs. 19 minutes when temporary DB was on the system disk.

CPU stays close to 100% on single processor XP throughout the conversion.  Same thing with a laptop having a two-core processor and running on 32-bit Vista, both cores seem burn at full power.

I made a rough parallelizing test by making 4 copies of finland.osm.pbf and running ogr2ogr in four separate windows.  This way the total CPU load of the 8 cores was staying around 50%. 
Result: All four conversions were ready after 3 minutes (45 seconds per conversion) while a single conversion takes 2 minutes.
Conclusion: 4 parellel  conversions in 3 minutes vs. within 8 minutes if performed as serial runs is much faster. 50% CPU load may tell that the speed of SATA disk is the limiting factor now.  Test with SSD drive should give more information about this.

I had a try also with 6 parellel runs but that was slower with all runs ready in 6 minutes which makes 60 seconds per conversion. With 8 runs computer jammed when all the progress bars were at 95%. 

Result was not a surprise because my experience about doing image processing with gdalwarp and gdal_translate with an 8-core server is that I can get the maximum throughput with our hardware by running processes in 4-6 windows.  If there are too many image conversions going on they start to disturb each other because disks cannot serve them all properly. However that computer behaves better when running conversions in 6 or more windows than this  laptop. Somehow it feels like the laptop has only 4 real processors/cores even the resource manager is showing eight.

I believe that by parallelizing the conversion program it is hard to take the juice as effectively from all the cores.

It may be difficult to feed rendering chain by having a bunch of source databases but it looks strongly that by splitting Germany into four distinct OSM source files it would be possible to import the whole country in 15 minutes with a good laptop.  Size of the OSM planet file is under 20 GB. Simple calculation suggests that importing the whole planet might be possible to do in 5 hours. With a laptop. Who will make a try?

-Jukka-

 Even Rouault wrote:
 
> Selon Rahkonen Jukka <Jukka.Rahkonen at mmmtike.fi>:
> 
> Interesting results. I'll wait a bit for your tests with SSD to turn
> OSM_COMPRESS_NODES to YES. Even if doesn't bring clear advantages, I
> don't think it would hurt a lot, because the extra CPU load introduced by the
> compression/decompression shouldn't be that high (the compression
> algorithm used is just encoding in Protocol Buffer of the differences of
> longitude/latitude between consecutive nodes, by chunk of 64 nodes)
> 
> Just a word of caution to remind you that the temporary node DB will be
> written in the directory pointed by the CPL_TMPDIR config. option/env.
> variable if defined, if not defined in TMPDIR, if not defined in TEMP, if not
> defined in the current directory form which ogr2ogr is started. In Windows
> system, the TEMP env. variable is generally defined, so when you test with
> your USB external driver, it is very likely that the node DB is written in the
> temporary directory associated with your Windows account.
> 
> As far as CPU load is concerned, the conversion is a single-threaded
> processus, so on a 8 core system, it is expected that it tops at 100 / 8 = 12,5 %
> of the global CPU power. With which hardware configuration and input PBF
> file do you manage to reach 100% CPU ? Is that load constant during the
> process : I imagine that it could change according to the stage of the
> conversion.
> There might be a potential for parallelizing some stuff. What comes in mind
> for now would be PBF decoding (when profiling only PBF decoding, the gzip
> decompression is the major CPU user, but not sure if it matters that much in
> a real-life ogr2ogr job) or way resolution (currently, we group ways into a
> batch until 1 million nodes or 75 000 ways have to be resolved, which leads to
> more efficient search in the node DB since we can sort nodes by increasing
> ids and avoid useless seeks). But that's not obviously immediate which would
> lead to increased efficiently. Parallelization may also generally requires more
> RAM if you need work buffers for each thread.
> 
> > Even Rouault wrote:
> > >
> > >
> > > > Another set of tests with a brand new and quite powerful laptop.
> > > >  Specs for the
> > > > computer:
> > > > Intel i7-2760QM @2.4 GHz processor (8 threads) Hitachi Travelstar
> > > > Z7K320 7200 rpm SATA disk
> > > > 8 GB of memory
> > > > Windows 7, 64-bit
> > > >
> > > > GDAL-version r24717, Win64 build from gisinternals.com
> > > >
> > > > Timings for germany.osm.pbf (1.3 GB)
> > > > ====================================
> > > >
> > > > A) Default settings with command
> > > > ogr2ogr -f sqlite -dsco spatialite=yes germany.sqlite
> > > > germany.osm.pbf -gt 20000 -progress --config
> > > > OGR_SQLITE_SYNCHRONOUS OFF
> > > >
> > > > - reading the data               67 minutes
> > > > - creating spatial indexes       38 minutes
> > > > - total                         105 minutes
> > > >
> > > > B) Using in-memory Spatialite db for the first step by giving SET
> > > > OSM_MAX_TMPFILE_SIZE=7000
> > > >
> > > > - reading the data              16 minutes
> > > > - creating spatial indexes      38 minutes
> > > > - total                         54 minutes
> > > >
> > > > Peak memory usage during this conversion was 4.4 GB.
> > > >
> > > > Conclusions
> > > > ===========
> > > > * The initial reading of data is heavily i/o bound. This phase is
> > > > really fast if there is enough memory for keeping the OSM tempfile
> > > > in memory but SSD disk seems to offer equally good performance.
> > > > * Creating spatial indexes for the Spatialite tables is also i/o
> > > > bound. The hardware sets the speed limit and there are no other
> > > > tricks for improving the performance. Multi-core CPU is quite idle
> > > > during this phase with 10-15% load.
> > > > * If user does not plan to do spatial queries then then it may be
> > > > handy to save some time and create the Spatialite db without
> > > > spatial indexes by using -lco SPATIAL_INDEX=NO option.
> > > > * Windows disk i/o may be a limiting factor.
> > > >
> > > > I consider that for small OSM datasets the speed starts to be good
> > > > enough. For me it is about the same if converting the Finnish OSM
> > > > data
> > > > (137 MB in .pbf format) takes 160 or 140 seconds when using the
> > > > default settings or in-memory temporary database, respectively.
> > >
> > > Interesting findings.
> > >
> > > A SSD is of course the ideal hardware to get efficient random access
> > > to the nodes.
> > >
> > > I've just introduced inr 24719 a new config. option
> > > OSM_COMPRESS_NODES that can be set to YES. The effect is to use a
> > > compression algorithm while storing the temporary node DB.  This can
> > > compress to a factor of 3 or 4,
> > and
> > > help keeping the node DB to a size where it is below the RAM size
> > > and that the OS can dramatically cache it (at least on Linux). This
> > > can be efficient
> > for
> > > OSM extracts of the size of the country, but probably not for a
> > > planet
> > file. In
> > > the case of Germany and France, here's the effect on my PC (SATA disk) :
> > >
> > > $ time ogr2ogr -f null null
> > > /home/even/gdal/data/osm/france_new.osm.pbf
> > > - progress --config OSM_COMPRESS_NODES YES [...]
> > > real    25m34.029s
> > > user    15m11.530s
> > > sys 0m36.470s
> > >
> > > $ time ogr2ogr -f null null
> > > /home/even/gdal/data/osm/france_new.osm.pbf
> > > - progress --config OSM_COMPRESS_NODES NO [...]
> > > real    74m33.077s
> > > user    15m38.570s
> > > sys 1m31.720s
> > >
> > > $ time ogr2ogr -f null null /home/even/gdal/data/osm/germany.osm.pbf
> > > - progress --config OSM_COMPRESS_NODES YES [...]
> > > real    7m46.594s
> > > user    7m24.990s
> > > sys 0m11.880s
> > >
> > > $ time ogr2ogr -f null null /home/even/gdal/data/osm/germany.osm.pbf
> > > - progress --config OSM_COMPRESS_NODES NO [...]
> > > real    108m48.967s
> > > user    7m47.970s
> > > sys 2m9.310s
> > >
> > > I didn't turn it to YES by default, because I'm unsure of the
> > > performance impact on SSD. Perhaps you have a chance to test.
> >
> > I cannot test with SSD before weekend but otherwise the new
> > configuration option really makes difference in some circumstances.
> >
> > I have ended up to use the following base command  in speed tests:
> > ogr2ogr -f SQLite -dsco spatialite=yes germany.sqlite germany.osm.pbf
> > -gt
> > 20000 -progress --config OGR_SQLITE_SYNCHRONOUS -lco
> SPATIAL_INDEX=NO
> >
> > Writing into Spatialite is pretty fast with these options and even
> > your null driver does not seem to be very much faster. What happens
> > after this step (like creating indexes) has nothing to do with OSM driver.
> >
> > Test with  Intel i7-2760QM @2.4 GHz processor,  7200 rpm SATA disk and
> > 1.3 GB input file 'germany.osm.pbf'
> > --config OSM_COMPRESS_NODES NO
> > 67 minutes
> > --config OSM_COMPRESS_NODES YES
> > 15 minutes
> >
> > It means 52 minutes less time or 4.5 times more speed.
> > Out of curiosity I tried what happens if I do the whole file
> > input/output by using a 2.5" external USB 2.0 drive.
> > 19 minutes!
> >
> > I made also a few tests with an old and much slower Windows computer.
> > Running osm2pgsql with Finnish OSM data with that machine takes
> > nowadays about 3 hours.
> >
> > Test with a single Intel Xeon @2.4 GHz processor and the same external
> > USB
> > 2.0 disk than in previous test
> > Input file 'finland.osm.pbf' 122 MB
> > Result: 7 minutes for both  OSM_COMPRESS_NODES NO and
> > OSM_COMPRESS_NODES YES Input file 'germany.osm.pbf' 1.3 GB
> > Result: 112 minutes with OSM_COMPRESS_NODES YES
> >
> > Conclusions:
> > * When input file has reached the limit where disk i/o  cannot utilize
> > cache properly, the compress_nodes setting can have a huge effect.
> > * When i/o works well the temporary database storage does not have
> > great effect on overall speed. In-memory db, SSD drive and fast SATA
> > drive are all equally fast and even external USB 2.0 drive is almost as fast.
> > * With small input data file size compress_node setting does not seem
> > to have much effect on speed.
> > * Obviously CPU is now the limiting factor.
> > * OGR OSM driver runs pretty well also on older computers.
> > * While single processor PC runs at 100% CPU load the 8-core PC shows
> > only 12%.  There seems to be 88% of computing power free for making
> > the memory and SSD lines saturated sometimes in the future...
> > * Instead of buying expensive hardware like SSD the lucky ones may
> > meet someone like Even who wants and can write fast programs.
> >
> > I found my first notes from less than two weeks  ago when I believed
> > that OSM driver was fast.  Now I repeated those tests with same data
> > and same computers and the progress I can see is non-negligible.
> > Result in these tests is Spatialite db with spatial indexes.
> >
> > finland.osm.pbf         40 minutes -> 7 minutes
> > germany.osm.pbf     15 hours     -> 50 minutes
> >
> > -Jukka Rahkonen-
> >
> >
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
> >
> 


From even.rouault at mines-paris.org  Wed Aug  1 08:36:11 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 01 Aug 2012 17:36:11 +0200
Subject: [gdal-dev] OSM Driver and World Planet file (pbf format)
In-Reply-To: <84446DEF76453C439E9E97E438E13A63461CDE@suutari.haapa.mmm.fi>
References: <84446DEF76453C439E9E97E438E13A63461CDE@suutari.haapa.mmm.fi>
Message-ID: <1343835371.50194ceb97f46@imp.free.fr>

>
> I made a rough parallelizing test by making 4 copies of finland.osm.pbf and
> running ogr2ogr in four separate windows.  This way the total CPU load of the
> 8 cores was staying around 50%.
> Result: All four conversions were ready after 3 minutes (45 seconds per
> conversion) while a single conversion takes 2 minutes.

In my opinion, "45 seconds per conversio"n isn't really a good summary : I'd say
that your computer could handle 4 conversions in parallel in 3 minutes. But the
fact of running conversions in parallel didn't make them *individually* faster
(that would be non-sense) that running a single one. We probably agree, that's
just the way of presenting the info that is a bit strange.

> Conclusion: 4 parellel  conversions in 3 minutes vs. within 8 minutes if
> performed as serial runs is much faster. 50% CPU load may tell that the speed
> of SATA disk is the limiting factor now.  Test with SSD drive should give
> more information about this.

Yes at some point the disk is the limiting factor whatever the number of CPUs
you have.

 Somehow it feels like the laptop has only 4 real processors/cores
> even the resource manager is showing eight.

I've not followed what the CPU state-of-the-art is currently, but perhaps it is
a quad-core with hyper-theading ? The hyper-threaded virtual cores wouldn't be
as efficient as normal cores.

>
> I believe that by parallelizing the conversion program it is hard to take the
> juice as effectively from all the cores.

Yes, if you parallelize I/O operations, then there's a risk that it makes it
slower actually. Only the CPU intensive operations should be parallelized to
limit that risk. But when reading OSM data, there isn't that much computation
involved. Way resolving is somehow stupid and mostly aobut I/O after all. Only
the resolving of multipolygons might involve CPU intensive operations to compute
the spatial relation between rings, but that's a tiny amount of the data of a
OSM file, and even if it is slow, it is perhaps 10 or 20% of the global
conversion time.

>
> It may be difficult to feed rendering chain by having a bunch of source
> databases but it looks strongly that by splitting Germany into four distinct
> OSM source files it would be possible to import the whole country in 15
> minutes with a good laptop.

I still maintain that splitting a file is a non trivial task. I strongly believe
that to do so, you must import the whole country and do spatial requests
afterwards. So, if the data producer doesn't do it for you, there's no point in
doing it at your end. However if you get it splitted , then it might indeed be
beneficial to operate on smaller extracts. (With a risk of some duplicated
and/or truncated and/or missing objects at the border of the tiles)









From even.rouault at mines-paris.org  Wed Aug  1 10:53:50 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 1 Aug 2012 19:53:50 +0200
Subject: [gdal-dev] reprojection of global rasters to mollweide
In-Reply-To: <CA+s71-wE4AVG5cLRoPashrMUU9_S7+a+uFGmmV2xc=FrpLA8HQ@mail.gmail.com>
References: <CA+s71-wE4AVG5cLRoPashrMUU9_S7+a+uFGmmV2xc=FrpLA8HQ@mail.gmail.com>
Message-ID: <201208011953.50179.even.rouault@mines-paris.org>

Le mardi 31 juillet 2012 11:32:35, Michael Schulz a ?crit :
> Dear GDAL'ers,
> 
> I have currently some issues with reprojecting global datasets in
> geographic coordinates to the Mollweide projection (GDAL 1.8.0). When using
> gdalwarp like:
> 
> gdalwarp -s_srs 'EPSG:4326' -t_srs '+proj=moll +lon_0=0 +x_0=0 +y_0=0
> +ellps=WGS84 +datum=WGS84 +units=m +no_defs' LatLon.2001.tree.nd.tif
> Mollweide.2001.tree.nd.tif
> 
> unpredictably, it sometimes works but other times I get the "Too many
> points (441 out of 441) failed to transform" error. I was wondering whether
> this could be a memory size issues (although the machine I'm working has
> 24GB RAM).

No, memory isn't the reason. The reason is that the algorithm used by gdalwarp 
doesn't manage to guess the extent of the raster once reprojected. It may or 
may not succeed depending on the extent of the source image and the 
reprojection involved. If you know the extent in the target coordinate system, 
specifying it with -te will solve that issue.

> 
> To overcome this adding the config option CHECK_WITH_INVERT_PROJ FALSE
> works, but now the projected raster shows wrapped values outside the actual
> valid coordinate range for Mollweide, e.g. the Aleutian Islands appear
> twice (once inside the outer ellipse. Is this due to
> the CHECK_WITH_INVERT_PROJ ?

The default value of CHECK_WITH_INVERT_PROJ (YES) checks that when a 
reprojection of a coordinate is done, the invert reprojection gives a result 
close to the original coordinate, which validates the fact that we are in the 
validity area of the reprojection. If you override with 
CHECK_WITH_INVERT_PROJ=FALSE, you can have indeed strange artifacts due to non 
invertible transformations.

> I haven't worked with the cutline option
> before, but should/could this be used here to solve this?

I don't think this will help.

> 
> Happy about any feedback on this issue. Thanks, Michael

From Jukka.Rahkonen at mmmtike.fi  Wed Aug  1 14:27:06 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 1 Aug 2012 21:27:06 +0000
Subject: [gdal-dev] OSM Driver and World Planet file (pbf format)
In-Reply-To: <1343835371.50194ceb97f46@imp.free.fr>
References: <84446DEF76453C439E9E97E438E13A63461CDE@suutari.haapa.mmm.fi>,
	<1343835371.50194ceb97f46@imp.free.fr>
Message-ID: <84446DEF76453C439E9E97E438E13A63461DD8@suutari.haapa.mmm.fi>

Even Rouault wrote:

>
>> I made a rough parallelizing test by making 4 copies of finland.osm.pbf and
>> running ogr2ogr in four separate windows.  This way the total CPU load of the
>> 8 cores was staying around 50%.
>> Result: All four conversions were ready after 3 minutes (45 seconds per
>> conversion) while a single conversion takes 2 minutes.

> In my opinion, "45 seconds per conversio"n isn't really a good summary : I'd say
> that your computer could handle 4 conversions in parallel in 3 minutes. But the
> fact of running conversions in parallel didn't make them *individually* faster
> (that would be non-sense) that running a single one. We probably agree, that's
> just the way of presenting the info that is a bit strange.

Ok, let's use other units. Some suggestions:
- data process rate as MB/sec or MB/minute (input sile size in pbf format)
- node conversion rate nodes/sec
- way or feature conversion rate as count/sec

None of them is a perfect speed unit. Nodes/sec feels most exact but practical speed 
depends on the nature of data, especially on the amount of relations and 
how complicated they are. Megabytes of pbf data per minute could be 
rather good measure too. In my single process vs. four parallel processes
example the conversion rates were 60 MB/minute vs. 160 MB/minute, 
respectively. By looking at file sizes in http://download.geofabrik.de/osm/europe/
one can make a fast estimate that converting 300 MB of data from Spain should
take about 5 minutes. With parallel runs Finland, Sweden and Norway would 
also be ready at the same time without any cost.

......
>> It may be difficult to feed rendering chain by having a bunch of source
>> databases but it looks strongly that by splitting Germany into four distinct
>> OSM source files it would be possible to import the whole country in 15
>> minutes with a good laptop.

> I still maintain that splitting a file is a non trivial task. I strongly believe
> that to do so, you must import the whole country and do spatial requests
> afterwards. So, if the data producer doesn't do it for you, there's no point in
> doing it at your end. However if you get it splitted , then it might indeed be
> beneficial to operate on smaller extracts. (With a risk of some duplicated
> and/or truncated and/or missing objects at the border of the tiles)

I agree. Splitting OSM data files on the client side was my ancient idea from more 
than a week ago. It does not make sense nowadays. Data should come splitted
from the data producer. It would need some thinking about how to split the
data so that there would not be troubles at the data set seams.  This GSoC 
project seems to aim at something similar
http://wiki.openstreetmap.org/wiki/Google_Summer_of_Code/2012/Data_Tile_Service

-Jukka-

From dlopezaspe at gmail.com  Wed Aug  1 14:42:51 2012
From: dlopezaspe at gmail.com (sigologo)
Date: Wed, 1 Aug 2012 14:42:51 -0700 (PDT)
Subject: [gdal-dev] setting nodata with gdalbuildvrt
Message-ID: <1343857371009-4992549.post@n6.nabble.com>

Hello GDALERS''!!!!

 Today I'm processing product MODIS MOD13A3 & MOD_Grid_monthly_1km_VI:1 km
monthly EVI,



gdalbuildvrt -hidenodata -vrtnodata "-1 1" mosaic_sinu.vrt
'HDF4_EOS:EOS_GRID:"MOD13A3.A2000032.h11v11.005.2006271173535.hdf":MOD_Grid_monthly_1km_VI:1
km monthly EVI' \
                                                           
'HDF4_EOS:EOS_GRID:"MOD13A3.A2000032.h11v12.005.2006271173529.hdf":MOD_Grid_monthly_1km_VI:1
km monthly EVI' \
                                                           
'HDF4_EOS:EOS_GRID:"MOD13A3.A2000032.h12v11.005.2006271173539.hdf":MOD_Grid_monthly_1km_VI:1
km monthly EVI' \
                                                           
'HDF4_EOS:EOS_GRID:"MOD13A3.A2000032.h12v12.005.2006271173558.hdf":MOD_Grid_monthly_1km_VI:1
km monthly EVI' 



 but my data in the vrt file is not in the same scale (-1 to 1) in
float-point, is possible specify scale y type in gdalbuildvrt......

Thanks in advanced!!!!






--
View this message in context: http://osgeo-org.1560.n6.nabble.com/setting-nodata-with-gdalbuildvrt-tp4992549.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From kedardeshpande87 at gmail.com  Wed Aug  1 17:05:10 2012
From: kedardeshpande87 at gmail.com (kedardeshpande87)
Date: Wed, 1 Aug 2012 17:05:10 -0700 (PDT)
Subject: [gdal-dev] Corrupted .shp error when reading shapefile from
	multiple threads
Message-ID: <1343865910500-4992566.post@n6.nabble.com>

Hi,

I am writing an application in Java with gdal's java bindings that reads a
zipcode layer shapefile.
I set a spatial filter of a point on the layer and get the zipcode by
reading from the layer.
...
DataSource ds = ogr.Open("path/to/shapefile");
Layer layer = ds.GetLayer(0);
...
public void getZipCode(double lat, double lon) {
  Geometry g = new Geometry(1); // Passing the geometry type. 1 for point.
  g.AddPoint(lon, lat);
  layer.SetSpatialFilter(g);
  Feature f = null;
  while((f = layer.GetNextFeature()) != null) {
     String zipcode = f.GetFieldAsString(0);   // 0th field is zipcode
  }
}

Above is a snippet of the code I am writing. Now, when call this
getZipCode() function for multiple times (like in a loop), it works fine.
But when I call this function from multiple parallel threads, I am getting
an error saying corrupted .shp file. This error is showing up only when I
make simultaneous reads on the shapefile from many threads.  The error is as
follows:

ERROR 1: Corrupted .shp file : shape 6, nPoints=677, nParts=1,
nEntitySize=5256.

Sometimes I get an error like this :

# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x000000379fa72faf, pid=26152, tid=1120618816
#
# JRE version: 6.0_32-b05
# Java VM: Java HotSpot(TM) 64-Bit Server VM (20.7-b02 mixed mode
linux-amd64 compressed oops)
# Problematic frame:
# C  [libc.so.6+0x72faf]  _dl_tls_get_addr_soft@@GLIBC_PRIVATE+0x72faf
#
# An error report file with more information is saved as:
# /rhel5pdi/home/kdeshpan/workspace/GDAL_Java_Cpp/hs_err_pid26152.log
#
# If you would like to submit a bug report, please visit:
#   http://java.sun.com/webapps/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#

I really want this to work in a multithreaded environment.

I am not modifying the shapefile, I am only reading the zip code information
from the shapefile. So I am getting why is the shapefile corrupted.
Moreover, if I use the same shapefile after getting this error and make
synchronous requests, it works. So I am guessing the shapefile is not
actually corrupted and it is showing the error because of something else.
Is this the expected bahavior from OGR library? Does it not support
multithreaded env ?
Or is it that there is some problem with the Java bindings ?
Can someone please suggest me how I can resolve this or get around this
issue ?

Thanks!
Kedar



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/Corrupted-shp-error-when-reading-shapefile-from-multiple-threads-tp4992566.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From luzhenyu1981 at gmail.com  Wed Aug  1 20:33:10 2012
From: luzhenyu1981 at gmail.com (Zhenyu Lu)
Date: Wed, 1 Aug 2012 20:33:10 -0700
Subject: [gdal-dev] Error in OSGeo.GDAL.Gdal.Open for .tif format
Message-ID: <CA+VK+ODC1EG8-a2Z4zA1ydNBOT750Y7V9v+ucwhoz6nc=geLww@mail.gmail.com>

Hi Group,

I just encountered an error in writting data to image in GTiff format using
the OSGeo.GDAL.Gdal.Open command. The error message showing is "****.tif
not recognised as a supported file format". The gdal librarary I am using
is gdal19dev.dll. The weird thing is the Gdal.Open command worked if the
image is in the format of HFA. The C# code I used to implement the writting
process is attached below (the sentence where error happened was
highlighted in red):
         /// <summary>
        /// Function of  WriteData2File
        /// </summary>
        /// <param name="LCx">the column index of left corner</param>
        /// <param name="LCy">the row index of left corner</param>
        /// <param name="width">the width of the rectangle</param>
        /// <param name="height">the length of the rectangle</param>
        /// <param name="fileName">the fileName where the data will be
saved</param>
        /// <returns>true, if the data is added correctly, false
otherwise.</returns>
        public bool WriteData2File(int LCx, int LCy, int width, int height,
int band, byte[] Data, string fileName)
        {
            OSGeo.GDAL.Driver imgDriver =
OSGeo.GDAL.Gdal.GetDriverByName("GTiff");
            string extension = System.IO.Path.GetExtension(fileName);
            if (extension == ".img")
                imgDriver = OSGeo.GDAL.Gdal.GetDriverByName("HFA");
            if (imgDriver == null)
                throw new Exception("The file type is not supported!");
            // OSGeo.GDAL.Gdal.AllRegister();
            OSGeo.GDAL.Dataset ds = OSGeo.GDAL.Gdal.Open(fileName,
OSGeo.GDAL.Access.GA_Update);
            int[] bandMap = new int[] { 1, 1, 1, 1 };
            try
            {
                ds.WriteRaster(LCx, LCy, width, height, Data, width,
height, 1, bandMap, 0, 0, 0);
                //ds.WriteRaster(LCx, LCy, width, height, Data, width,
height, band, 0, 0, 0);
                ds.Dispose();
                return true;
            }
            catch
            {
                return false;
            }
        }

Can anyone point out where the problem is? Thank you so much,


-- 
Zhenyu Lu
SUNY-ESF
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120801/80e34603/attachment.html>

From chapmanm at pixia.com  Wed Aug  1 21:12:39 2012
From: chapmanm at pixia.com (Martin Chapman)
Date: Thu, 02 Aug 2012 00:12:39 -0400 (EDT)
Subject: [gdal-dev] Corrupted .shp error when reading shapefile
	from	multiple threads
In-Reply-To: <1343865910500-4992566.post@n6.nabble.com>
References: <1343865910500-4992566.post@n6.nabble.com>
Message-ID: <8a4f2a7c.00001070.0000000a@CHAPMANM7S>

Kedar,

Think about it...how does GetNextFeature() know what feature is next?
It's because somewhere inside the datasource handle there is probably a
variable that is keeping track of what record is next.  If multiple
threads are all using the same datasource handle then this variable is
probably getting updated / read by different threads at the same time and
then all hell will break loose.

The answer to your problem is to open a separate datasource handle for
every thread you have so there is no sharing across threads.   Right now
your getZipCode() function is sharing a global datasource handle and the
code is not synchronized.  If you synchronize this code then it will be no
better than a single threaded application so if I was you I would either:

1. Open a datasource handle on each thread and pass it to the zipcode
function from each thread ... or

2. Create a class that encapsulates the getZipCode() function and has a
datasource member variable that opens the datasource on construction and
then create a separate instance of this class for each thread on startup
so each thread has its own copy of the class.   Or ....

3. See if there is a function on the handle that will get the next feature
given an index (like GetFeature(int index)) that you pass into the
function so there is no internal record keeping needed by the handle.
This is a risky way to do it though because even though it will work there
may be other global variables the handle is keeping so unless Frank can
vouch for that method I would go with curtain number 2. 

Best regards,
Marty



-----Original Message-----
From: gdal-dev-bounces at lists.osgeo.org
[mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of kedardeshpande87
Sent: Wednesday, August 01, 2012 6:05 PM
To: gdal-dev at lists.osgeo.org
Subject: [gdal-dev] Corrupted .shp error when reading shapefile from
multiple threads

Hi,

I am writing an application in Java with gdal's java bindings that reads a
zipcode layer shapefile.
I set a spatial filter of a point on the layer and get the zipcode by
reading from the layer.
...
DataSource ds = ogr.Open("path/to/shapefile"); Layer layer =
ds.GetLayer(0); ...
public void getZipCode(double lat, double lon) {
  Geometry g = new Geometry(1); // Passing the geometry type. 1 for point.
  g.AddPoint(lon, lat);
  layer.SetSpatialFilter(g);
  Feature f = null;
  while((f = layer.GetNextFeature()) != null) {
     String zipcode = f.GetFieldAsString(0);   // 0th field is zipcode
  }
}

Above is a snippet of the code I am writing. Now, when call this
getZipCode() function for multiple times (like in a loop), it works fine.
But when I call this function from multiple parallel threads, I am getting
an error saying corrupted .shp file. This error is showing up only when I
make simultaneous reads on the shapefile from many threads.  The error is
as
follows:

ERROR 1: Corrupted .shp file : shape 6, nPoints=677, nParts=1,
nEntitySize=5256.

Sometimes I get an error like this :

# A fatal error has been detected by the Java Runtime Environment:
#
#  SIGSEGV (0xb) at pc=0x000000379fa72faf, pid=26152, tid=1120618816 # #
JRE version: 6.0_32-b05 # Java VM: Java HotSpot(TM) 64-Bit Server VM
(20.7-b02 mixed mode
linux-amd64 compressed oops)
# Problematic frame:
# C  [libc.so.6+0x72faf]  _dl_tls_get_addr_soft@@GLIBC_PRIVATE+0x72faf
#
# An error report file with more information is saved as:
# /rhel5pdi/home/kdeshpan/workspace/GDAL_Java_Cpp/hs_err_pid26152.log
#
# If you would like to submit a bug report, please visit:
#   http://java.sun.com/webapps/bugreport/crash.jsp
# The crash happened outside the Java Virtual Machine in native code.
# See problematic frame for where to report the bug.
#

I really want this to work in a multithreaded environment.

I am not modifying the shapefile, I am only reading the zip code
information from the shapefile. So I am getting why is the shapefile
corrupted.
Moreover, if I use the same shapefile after getting this error and make
synchronous requests, it works. So I am guessing the shapefile is not
actually corrupted and it is showing the error because of something else.
Is this the expected bahavior from OGR library? Does it not support
multithreaded env ?
Or is it that there is some problem with the Java bindings ?
Can someone please suggest me how I can resolve this or get around this
issue ?

Thanks!
Kedar



--
View this message in context:
http://osgeo-org.1560.n6.nabble.com/Corrupted-shp-error-when-reading-shape
file-from-multiple-threads-tp4992566.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
http://lists.osgeo.org/mailman/listinfo/gdal-dev

From jukka.rahkonen at mmmtike.fi  Wed Aug  1 21:57:05 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Thu, 2 Aug 2012 04:57:05 +0000 (UTC)
Subject: [gdal-dev] 'Polygons as multipolygons' option for OSM driver
Message-ID: <loom.20120802T062948-717@post.gmane.org>

In OSM data same sort of polygon features are typically modelled either as
closed rings or as multipolygon relations if they happen to have holes or if the
length of the outer ring exceeds the limit of 2000 nodes.

For making rendering more simple the OGR driver might have an option for
skipping the polygon layer. In that case features which are found from the list
'closed_ways_are_polygons' in osmconf.ini would take attributes from the
[multipolygons] section instead of [polygons]. Results would be written into the
multipolygons table and geometry type of these features would be multipolygon. 

Place of the control could be just below the 'closed_ways_are_polygons' control.
It might have an understandable name like 'write_polygons_as_multipolygons' and
it could take values yes/no. As a comment there might be something like

# Uncomment to write also simple polygons into 'multipolygons' table
# If selected the 'polygons' table will not be created
# and all the polygons will take their attributes from the [multipolygons]
# section below

Does this feel reasonable?

-Jukka Rahkonen-






From even.rouault at mines-paris.org  Thu Aug  2 01:12:33 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 02 Aug 2012 10:12:33 +0200
Subject: [gdal-dev] Corrupted .shp error when reading shapefile from
	multiple threads
In-Reply-To: <8a4f2a7c.00001070.0000000a@CHAPMANM7S>
References: <1343865910500-4992566.post@n6.nabble.com>
	<8a4f2a7c.00001070.0000000a@CHAPMANM7S>
Message-ID: <1343895153.501a36715c3e7@imp.free.fr>

Selon Martin Chapman <chapmanm at pixia.com>:

> Kedar,
>
> Think about it...how does GetNextFeature() know what feature is next?
> It's because somewhere inside the datasource handle there is probably a
> variable that is keeping track of what record is next.  If multiple
> threads are all using the same datasource handle then this variable is
> probably getting updated / read by different threads at the same time and
> then all hell will break loose.
>
> The answer to your problem is to open a separate datasource handle for
> every thread you have so there is no sharing across threads.   Right now
> your getZipCode() function is sharing a global datasource handle and the
> code is not synchronized.  If you synchronize this code then it will be no
> better than a single threaded application so if I was you I would either:
>
> 1. Open a datasource handle on each thread and pass it to the zipcode
> function from each thread ... or
>
> 2. Create a class that encapsulates the getZipCode() function and has a
> datasource member variable that opens the datasource on construction and
> then create a separate instance of this class for each thread on startup
> so each thread has its own copy of the class.   Or ....
>
> 3. See if there is a function on the handle that will get the next feature
> given an index (like GetFeature(int index)) that you pass into the
> function so there is no internal record keeping needed by the handle.
> This is a risky way to do it though because even though it will work there
> may be other global variables the handle is keeping so unless Frank can
> vouch for that method I would go with curtain number 2.

Martin, I concur with your points.

About 3), (using GetFeature(index)), this won't work either. Because
GetFeature() needs to seek in the .shp and .dbf files. So if 2 threads use
GetFeature() on the same layer object, which has a single file pointer, the
seeks may conflict with each other and you might end up reading the wrong
content. The only safe solution is to use a datasource object for each thread.

From even.rouault at mines-paris.org  Thu Aug  2 01:50:24 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 02 Aug 2012 10:50:24 +0200
Subject: [gdal-dev] 'Polygons as multipolygons' option for OSM driver
In-Reply-To: <loom.20120802T062948-717@post.gmane.org>
References: <loom.20120802T062948-717@post.gmane.org>
Message-ID: <1343897424.501a3f501811b@imp.free.fr>

Selon Jukka Rahkonen <jukka.rahkonen at mmmtike.fi>:

> In OSM data same sort of polygon features are typically modelled either as
> closed rings or as multipolygon relations if they happen to have holes or if
> the
> length of the outer ring exceeds the limit of 2000 nodes.
>
> For making rendering more simple the OGR driver might have an option for
> skipping the polygon layer.

This is a topic that I've had in mind indeed. The problem is not just ease of
use on the generated result, but also a problem of "correctness", more exactly
of duplicates.

For example, let's imagine a forest with a clearing. You'll have 2 closed ways,
one to describe the outer ring of the forest, the other one for the clearing.
And a relation that binds the 2 ways. If the outer ring of the forest has tags,
and the clearing not, currently, the outer ring will be advertized in the
'polygons' layer, and the outer ring combined with the inner ring in the
'multipolygons' layer. So there is a duplicate, and the reported polygon in the
polygons layer has not the hole, which is not wanted for correct rendering.

(As far as the clearing itself, if it has tags, then it will be reported as
another feature, otherwise not : but this doesn't change from the current
situation)

> In that case features which are found from the
> list
> 'closed_ways_are_polygons' in osmconf.ini would take attributes from the
> [multipolygons] section instead of [polygons].

To be more exact, closed ways are identified as areas if they have a area=yes
tag, or if they have a tag which is listed in closed_ways_are_polygons

> Results would be written into
> the
> multipolygons table and geometry type of these features would be
> multipolygon.
>
> Place of the control could be just below the 'closed_ways_are_polygons'
> control.
> It might have an understandable name like 'write_polygons_as_multipolygons'
> and
> it could take values yes/no. As a comment there might be something like
>
> # Uncomment to write also simple polygons into 'multipolygons' table
> # If selected the 'polygons' table will not be created
> # and all the polygons will take their attributes from the [multipolygons]
> # section below
>
> Does this feel reasonable?

I agree with the idea, with the exception that I think that this should not be
configurable. So I'd just remove the polygons layer, to have only multipolygons.
That would simplify implementation (there are
already (too) many configurable stuff). And I don't think that the polygons
layer is currently very usefull, because it can advertize areas as just having
an outer ring, whereas they should be reported with a hole.

The behaviour of the driver would be that no simple polygons (polygons that are
described as ways) would be reported until the file has been completely
processed.

The algorithm would be something like that :
- store ways in the temporary way DB as currently, but don't advertize ways that
are identified as area for now
- when examining relations, when a polygon described as a way has been
"consumed" as being the outer way of a relation, it will be removed from the
temporary way DB (actually, probably just tagged as being no longer
advertizable, in case it would be needed by another relation afterwards)
- at the end, report all ways that are areas that remain in the temporary way DB
as being advertizable


>
> -Jukka Rahkonen-
>
>
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



From Jukka.Rahkonen at mmmtike.fi  Thu Aug  2 02:16:47 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Thu, 2 Aug 2012 09:16:47 +0000
Subject: [gdal-dev] 'Polygons as multipolygons' option for OSM driver
Message-ID: <84446DEF76453C439E9E97E438E13A63461F77@suutari.haapa.mmm.fi>

Hi,

Your plan is very reasonable. It should give correct results in most cases and I think that total solution is not possible before OSM project is able to develop 'the simplest approach that could possibly generate useful polygons' (adapted from http://wiki.openstreetmap.org/wiki/FAQ#Why_aren.27t_you_using_Open_Geospatial_Consortium_.28OGC.29_schemas_and_software_for_OpenStreetMap.3F

-Jukka-


Even Rouault wrote:
 
> Selon Jukka Rahkonen <jukka.rahkonen at mmmtike.fi>:
> 
> > In OSM data same sort of polygon features are typically modelled
> > either as closed rings or as multipolygon relations if they happen to
> > have holes or if the length of the outer ring exceeds the limit of
> > 2000 nodes.
> >
> > For making rendering more simple the OGR driver might have an option
> > for skipping the polygon layer.
> 
> This is a topic that I've had in mind indeed. The problem is not just ease of
> use on the generated result, but also a problem of "correctness", more
> exactly of duplicates.
> 
> For example, let's imagine a forest with a clearing. You'll have 2 closed ways,
> one to describe the outer ring of the forest, the other one for the clearing.
> And a relation that binds the 2 ways. If the outer ring of the forest has tags,
> and the clearing not, currently, the outer ring will be advertized in the
> 'polygons' layer, and the outer ring combined with the inner ring in the
> 'multipolygons' layer. So there is a duplicate, and the reported polygon in the
> polygons layer has not the hole, which is not wanted for correct rendering.
> 
> (As far as the clearing itself, if it has tags, then it will be reported as another
> feature, otherwise not : but this doesn't change from the current
> situation)
> 
> > In that case features which are found from the list
> > 'closed_ways_are_polygons' in osmconf.ini would take attributes from
> > the [multipolygons] section instead of [polygons].
> 
> To be more exact, closed ways are identified as areas if they have a area=yes
> tag, or if they have a tag which is listed in closed_ways_are_polygons
> 
> > Results would be written into
> > the
> > multipolygons table and geometry type of these features would be
> > multipolygon.
> >
> > Place of the control could be just below the 'closed_ways_are_polygons'
> > control.
> > It might have an understandable name like
> 'write_polygons_as_multipolygons'
> > and
> > it could take values yes/no. As a comment there might be something
> > like
> >
> > # Uncomment to write also simple polygons into 'multipolygons' table #
> > If selected the 'polygons' table will not be created # and all the
> > polygons will take their attributes from the [multipolygons] # section
> > below
> >
> > Does this feel reasonable?
> 
> I agree with the idea, with the exception that I think that this should not be
> configurable. So I'd just remove the polygons layer, to have only
> multipolygons.
> That would simplify implementation (there are already (too) many
> configurable stuff). And I don't think that the polygons layer is currently very
> usefull, because it can advertize areas as just having an outer ring, whereas
> they should be reported with a hole.
> 
> The behaviour of the driver would be that no simple polygons (polygons that
> are described as ways) would be reported until the file has been completely
> processed.
> 
> The algorithm would be something like that :
> - store ways in the temporary way DB as currently, but don't advertize ways
> that are identified as area for now
> - when examining relations, when a polygon described as a way has been
> "consumed" as being the outer way of a relation, it will be removed from the
> temporary way DB (actually, probably just tagged as being no longer
> advertizable, in case it would be needed by another relation afterwards)
> - at the end, report all ways that are areas that remain in the temporary way
> DB as being advertizable
> 
> 
> >
> > -Jukka Rahkonen-
> >
> >
> >
> >
> >
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
> >
> 


From mandschulz at googlemail.com  Thu Aug  2 03:40:49 2012
From: mandschulz at googlemail.com (Michael Schulz)
Date: Thu, 2 Aug 2012 12:40:49 +0200
Subject: [gdal-dev] reprojection of global rasters to mollweide
In-Reply-To: <201208011953.50179.even.rouault@mines-paris.org>
References: <CA+s71-wE4AVG5cLRoPashrMUU9_S7+a+uFGmmV2xc=FrpLA8HQ@mail.gmail.com>
	<201208011953.50179.even.rouault@mines-paris.org>
Message-ID: <CA+s71-z11-qsfsAPUa59CUv=pRMKWp5A9rxp_Y=j4Kuq0Pa2hA@mail.gmail.com>

Dear Even,

thanks for your response, finally I got it working. The main issue was that
the global dataset had an extent e.g. on the most western border of
-180.0044643 which caused the error (although strangely not always, because
I tried the same command with the same dataset and sometime it worked...)

Anyhow, clipping the data before and then specifying as you suggested the
target extent (-te) works now.

Cheers, Michael


2012/8/1 Even Rouault <even.rouault at mines-paris.org>

> Le mardi 31 juillet 2012 11:32:35, Michael Schulz a ?crit :
> > Dear GDAL'ers,
> >
> > I have currently some issues with reprojecting global datasets in
> > geographic coordinates to the Mollweide projection (GDAL 1.8.0). When
> using
> > gdalwarp like:
> >
> > gdalwarp -s_srs 'EPSG:4326' -t_srs '+proj=moll +lon_0=0 +x_0=0 +y_0=0
> > +ellps=WGS84 +datum=WGS84 +units=m +no_defs' LatLon.2001.tree.nd.tif
> > Mollweide.2001.tree.nd.tif
> >
> > unpredictably, it sometimes works but other times I get the "Too many
> > points (441 out of 441) failed to transform" error. I was wondering
> whether
> > this could be a memory size issues (although the machine I'm working has
> > 24GB RAM).
>
> No, memory isn't the reason. The reason is that the algorithm used by
> gdalwarp
> doesn't manage to guess the extent of the raster once reprojected. It may
> or
> may not succeed depending on the extent of the source image and the
> reprojection involved. If you know the extent in the target coordinate
> system,
> specifying it with -te will solve that issue.
>



>
> >
> > To overcome this adding the config option CHECK_WITH_INVERT_PROJ FALSE
> > works, but now the projected raster shows wrapped values outside the
> actual
> > valid coordinate range for Mollweide, e.g. the Aleutian Islands appear
> > twice (once inside the outer ellipse. Is this due to
> > the CHECK_WITH_INVERT_PROJ ?
>
> The default value of CHECK_WITH_INVERT_PROJ (YES) checks that when a
> reprojection of a coordinate is done, the invert reprojection gives a
> result
> close to the original coordinate, which validates the fact that we are in
> the
> validity area of the reprojection. If you override with
> CHECK_WITH_INVERT_PROJ=FALSE, you can have indeed strange artifacts due to
> non
> invertible transformations.
>
> > I haven't worked with the cutline option
> > before, but should/could this be used here to solve this?
>
> I don't think this will help.
>
> >
> > Happy about any feedback on this issue. Thanks, Michael
>



-- 
-----------------------------------------------------------
Michael Schulz

Via Cime Bianche 10
IT-21023 Besozzo (VA)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120802/fa415485/attachment.html>

From chapmanm at pixia.com  Thu Aug  2 06:56:08 2012
From: chapmanm at pixia.com (Martin Chapman)
Date: Thu, 02 Aug 2012 09:56:08 -0400 (EDT)
Subject: [gdal-dev] Corrupted .shp error when reading shapefile from
	multiple threads
In-Reply-To: <1343895153.501a36715c3e7@imp.free.fr>
References: <1343865910500-4992566.post@n6.nabble.com>
	<8a4f2a7c.00001070.0000000a@CHAPMANM7S>
	<1343895153.501a36715c3e7@imp.free.fr>
Message-ID: <49699f62.0000166c.00000002@CHAPMANM7S>

Even,

Thank you for your input on that.  I figured that was a risky idea and it
is good to know the definitive answer.

Best regards,
Martin

-----Original Message-----
From: Even Rouault [mailto:even.rouault at mines-paris.org] 
Sent: Thursday, August 02, 2012 2:13 AM
To: Martin Chapman
Cc: 'kedardeshpande87'; gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] Corrupted .shp error when reading shapefile from
multiple threads

Selon Martin Chapman <chapmanm at pixia.com>:

> Kedar,
>
> Think about it...how does GetNextFeature() know what feature is next?
> It's because somewhere inside the datasource handle there is probably 
> a variable that is keeping track of what record is next.  If multiple 
> threads are all using the same datasource handle then this variable is 
> probably getting updated / read by different threads at the same time 
> and then all hell will break loose.
>
> The answer to your problem is to open a separate datasource handle for
> every thread you have so there is no sharing across threads.   Right now
> your getZipCode() function is sharing a global datasource handle and 
> the code is not synchronized.  If you synchronize this code then it 
> will be no better than a single threaded application so if I was you I
would either:
>
> 1. Open a datasource handle on each thread and pass it to the zipcode 
> function from each thread ... or
>
> 2. Create a class that encapsulates the getZipCode() function and has 
> a datasource member variable that opens the datasource on construction 
> and then create a separate instance of this class for each thread on
startup
> so each thread has its own copy of the class.   Or ....
>
> 3. See if there is a function on the handle that will get the next 
> feature given an index (like GetFeature(int index)) that you pass into 
> the function so there is no internal record keeping needed by the
handle.
> This is a risky way to do it though because even though it will work 
> there may be other global variables the handle is keeping so unless 
> Frank can vouch for that method I would go with curtain number 2.

Martin, I concur with your points.

About 3), (using GetFeature(index)), this won't work either. Because
GetFeature() needs to seek in the .shp and .dbf files. So if 2 threads use
GetFeature() on the same layer object, which has a single file pointer,
the seeks may conflict with each other and you might end up reading the
wrong content. The only safe solution is to use a datasource object for
each thread.

From bluejp at gmail.com  Thu Aug  2 14:33:19 2012
From: bluejp at gmail.com (neojp)
Date: Thu, 2 Aug 2012 14:33:19 -0700 (PDT)
Subject: [gdal-dev] generating multipolygon from polygons
Message-ID: <1343943199338-4992794.post@n6.nabble.com>

Dear List,

I need to generate a multipolygon by adding all the polygons in a shapefile.
Based on a previous post I plan to use the addgeometry() to pass each
feature to the multipolygon layer. I have implemented this in python but I
cannot figure out what is going wrong.  Python says "'Geometry' object has
no attribute 'addGeometry'" that i can understand but not really know how to
fix. Below is the code, I would appreciate any help.


import ogr, os, sys
driver=ogr.GetDriverByName('ESRI Shapefile')

#open shape
shapefileName= 'c:\\test_multi\\polygonize_binary.shp'
dataset=driver.Open(shapefileName,0)
fn = 'c:\\test_multi\\multi_out.shp'
if os.path.exists(fn):
  driver.DeleteDataSource(fn)
outDS = driver.CreateDataSource(fn)
if outDS is None:
  print 'Could not create file'
  sys.exit(1)

#Create a layer to receive the multiple geometry 
#create a layer
outLayer = outDS.CreateLayer('multi_out', geom_type=ogr.wkbMultiPolygon)
# create new id and fields in the output shapefile
#add a new feature
# create an empty multipolygon geometry
m_poly = ogr.Geometry(ogr.wkbMultiPolygon)

layer=dataset.GetLayer()
for index in xrange(layer.GetFeatureCount()):
    feature = layer.GetFeature(index)
    geometry = feature.GetGeometryRef()
    #print geometry
    m_poly.addGeometry(geometry)



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/generating-multipolygon-from-polygons-tp4992794.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From warmerdam at pobox.com  Thu Aug  2 14:36:52 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Thu, 2 Aug 2012 14:36:52 -0700
Subject: [gdal-dev] Error in OSGeo.GDAL.Gdal.Open for .tif format
In-Reply-To: <CA+VK+ODC1EG8-a2Z4zA1ydNBOT750Y7V9v+ucwhoz6nc=geLww@mail.gmail.com>
References: <CA+VK+ODC1EG8-a2Z4zA1ydNBOT750Y7V9v+ucwhoz6nc=geLww@mail.gmail.com>
Message-ID: <CA+YzLBcgZ6whnzU-ZnWrpxhBoX12NBAJym=Ekm0P10XGiNHkXA@mail.gmail.com>

Zhenyu Lu,

Gdal.Open() with GA_Update mode cannot be used to create new files.  Instead
you will need to use the Create method on the driver object, and specify the
size, band count and other creation options.  GA_Update in Gdal.Open()
is intended for use with existing files that you want to update (replace
imagery, or metadata).

Best regards,
Frank

On Wed, Aug 1, 2012 at 8:33 PM, Zhenyu Lu <luzhenyu1981 at gmail.com> wrote:

>
> Hi Group,
>
> I just encountered an error in writting data to image in GTiff format
> using the OSGeo.GDAL.Gdal.Open command. The error message showing is
> "****.tif not recognised as a supported file format". The gdal librarary I
> am using is gdal19dev.dll. The weird thing is the Gdal.Open command worked
> if the image is in the format of HFA. The C# code I used to implement the
> writting process is attached below (the sentence where error happened was
> highlighted in red):
>          /// <summary>
>         /// Function of  WriteData2File
>         /// </summary>
>         /// <param name="LCx">the column index of left corner</param>
>         /// <param name="LCy">the row index of left corner</param>
>         /// <param name="width">the width of the rectangle</param>
>         /// <param name="height">the length of the rectangle</param>
>         /// <param name="fileName">the fileName where the data will be
> saved</param>
>         /// <returns>true, if the data is added correctly, false
> otherwise.</returns>
>         public bool WriteData2File(int LCx, int LCy, int width, int
> height, int band, byte[] Data, string fileName)
>         {
>             OSGeo.GDAL.Driver imgDriver =
> OSGeo.GDAL.Gdal.GetDriverByName("GTiff");
>             string extension = System.IO.Path.GetExtension(fileName);
>             if (extension == ".img")
>                 imgDriver = OSGeo.GDAL.Gdal.GetDriverByName("HFA");
>             if (imgDriver == null)
>                 throw new Exception("The file type is not supported!");
>             // OSGeo.GDAL.Gdal.AllRegister();
>             OSGeo.GDAL.Dataset ds = OSGeo.GDAL.Gdal.Open(fileName,
> OSGeo.GDAL.Access.GA_Update);
>             int[] bandMap = new int[] { 1, 1, 1, 1 };
>             try
>             {
>                 ds.WriteRaster(LCx, LCy, width, height, Data, width,
> height, 1, bandMap, 0, 0, 0);
>                 //ds.WriteRaster(LCx, LCy, width, height, Data, width,
> height, band, 0, 0, 0);
>                 ds.Dispose();
>                 return true;
>             }
>             catch
>             {
>                 return false;
>             }
>         }
>
> Can anyone point out where the problem is? Thank you so much,
>
>
> --
> Zhenyu Lu
> SUNY-ESF
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam,
warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120802/eb18aefc/attachment.html>

From warmerdam at pobox.com  Thu Aug  2 21:14:06 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Thu, 2 Aug 2012 21:14:06 -0700
Subject: [gdal-dev] generating multipolygon from polygons
In-Reply-To: <1343943199338-4992794.post@n6.nabble.com>
References: <1343943199338-4992794.post@n6.nabble.com>
Message-ID: <CA+YzLBfRwr2nZMEXWWh2rV-MAD6StVpYvaH9A3v3n-bGtbwM+Q@mail.gmail.com>

Neojp,

Try AddGeometry with a capital A.

Best regards,
Frank
On Aug 2, 2012 2:33 PM, "neojp" <bluejp at gmail.com> wrote:

> Dear List,
>
> I need to generate a multipolygon by adding all the polygons in a
> shapefile.
> Based on a previous post I plan to use the addgeometry() to pass each
> feature to the multipolygon layer. I have implemented this in python but I
> cannot figure out what is going wrong.  Python says "'Geometry' object has
> no attribute 'addGeometry'" that i can understand but not really know how
> to
> fix. Below is the code, I would appreciate any help.
>
>
> import ogr, os, sys
> driver=ogr.GetDriverByName('ESRI Shapefile')
>
> #open shape
> shapefileName= 'c:\\test_multi\\polygonize_binary.shp'
> dataset=driver.Open(shapefileName,0)
> fn = 'c:\\test_multi\\multi_out.shp'
> if os.path.exists(fn):
>   driver.DeleteDataSource(fn)
> outDS = driver.CreateDataSource(fn)
> if outDS is None:
>   print 'Could not create file'
>   sys.exit(1)
>
> #Create a layer to receive the multiple geometry
> #create a layer
> outLayer = outDS.CreateLayer('multi_out', geom_type=ogr.wkbMultiPolygon)
> # create new id and fields in the output shapefile
> #add a new feature
> # create an empty multipolygon geometry
> m_poly = ogr.Geometry(ogr.wkbMultiPolygon)
>
> layer=dataset.GetLayer()
> for index in xrange(layer.GetFeatureCount()):
>     feature = layer.GetFeature(index)
>     geometry = feature.GetGeometryRef()
>     #print geometry
>     m_poly.addGeometry(geometry)
>
>
>
> --
> View this message in context:
> http://osgeo-org.1560.n6.nabble.com/generating-multipolygon-from-polygons-tp4992794.html
> Sent from the GDAL - Dev mailing list archive at Nabble.com.
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120802/bccf2dc6/attachment.html>

From jukka.rahkonen at mmmtike.fi  Fri Aug  3 01:14:13 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Fri, 3 Aug 2012 08:14:13 +0000 (UTC)
Subject: [gdal-dev] Spatialite tables with multiple geometry columns
Message-ID: <loom.20120803T091825-188@post.gmane.org>

Hi,

A Mapserver user was trying to use a Spatialite db which had tables with
multiple geometry columns and I got interested in having a little try because
sometimes it could be handy to have both the polygons and their centroids
readily available from the same table.

However, it looks that currently there is no way to deal with the additional
geometry columns. I made a small database for testing and it is here
http://latuviitta.org/documents/multigeometry_db.sqlite

Table 'multigeom' has two geometry columns, one containing polygons and the
other containing centroid points. I made also two spatial views so that
view_geom1 is picking only polygon geometries and view_geom2 only points. I
believe I have made everything fine on the Spatialite side and Spatialite-gui
previews all the geometries correctly. However, it is only possible to handle
the first geometry column with OGR.

The ogrinfo report below shows that both geometries from the table are found and
geometry types are right. For view_geom2 wrong geometry type is reported.

C:\ohjelmat\GDAL_dev>ogrinfo multigeometry_db.sqlite
INFO: Open of `multigeometry_db.sqlite'
      using driver `SQLite' successful.
1: multigeom (Multi Polygon)
2: multigeom (Point)
3: view_geom1 (Multi Polygon)
4: view_geom2 (Multi Polygon)

I could not discover how I could select layer '2: multigeom (Point)' because it
has the same name 'multigeom' as the first layer. By doing 
ogrinfo multigeometry_db.sqlite multigeom 
the first geometry gets selected always. 

Spatial view for geom2 does not work either because OGR is looking at the first
geometry column of the main table

ogrinfo multigeometry_db.sqlite view_geom2
INFO: Open of `multigeometry_db.sqlite'
      using driver `SQLite' successful.
ERROR 1: Underlying layer multigeom for view view_geom2 has not
expected geometry column name (geom1 instead of geom2)

The Spatialite metadata is correct in views_geometry_columns

1	view_geom1	geom1	ROWID	multigeom	geom1
2	view_geom2	geom2	ROWID	multigeom	geom2

There seems to be something to improve both with tables and views. For tables it
looks that layers should just get individual layer names so they could be
selected, like 'multigeom(1)' and 'multigeom(2)' but I fear it is not that
simple. With views SQLite driver should be made to not expect the first geometry
column name it finds from the geometry_columns table but check other lines too.
If I delete the row for geom1 from geometry_colums of place row for geom2 before
it the view_geom2 comes usable for OGR (and view_geom1 unusable).

Regards,

-Jukka Rahkonen-




From even.rouault at mines-paris.org  Fri Aug  3 02:17:39 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Fri, 03 Aug 2012 11:17:39 +0200
Subject: [gdal-dev] Spatialite tables with multiple geometry columns
In-Reply-To: <loom.20120803T091825-188@post.gmane.org>
References: <loom.20120803T091825-188@post.gmane.org>
Message-ID: <1343985459.501b9733af310@imp.free.fr>

Selon Jukka Rahkonen <jukka.rahkonen at mmmtike.fi>:

Multi geometry support per table isn't really supported for now. For the PG
driver, we expose layer names as "table_name(geometry_column_name)". I think the
same convention could be used for sqlite. In your example, it would be
"multigeom(geom1)" and "multigeom(geom2)". The reasons for the view_geom2 view
to fail is exactly the same as why you didn't manage to query the multigeom with
geom2. The code of views does a GetLayerByName("multigeom"), and so only gets
the first layer.

> Hi,
>
> A Mapserver user was trying to use a Spatialite db which had tables with
> multiple geometry columns and I got interested in having a little try because
> sometimes it could be handy to have both the polygons and their centroids
> readily available from the same table.
>
> However, it looks that currently there is no way to deal with the additional
> geometry columns. I made a small database for testing and it is here
> http://latuviitta.org/documents/multigeometry_db.sqlite
>
> Table 'multigeom' has two geometry columns, one containing polygons and the
> other containing centroid points. I made also two spatial views so that
> view_geom1 is picking only polygon geometries and view_geom2 only points. I
> believe I have made everything fine on the Spatialite side and Spatialite-gui
> previews all the geometries correctly. However, it is only possible to handle
> the first geometry column with OGR.
>
> The ogrinfo report below shows that both geometries from the table are found
> and
> geometry types are right. For view_geom2 wrong geometry type is reported.
>
> C:\ohjelmat\GDAL_dev>ogrinfo multigeometry_db.sqlite
> INFO: Open of `multigeometry_db.sqlite'
>       using driver `SQLite' successful.
> 1: multigeom (Multi Polygon)
> 2: multigeom (Point)
> 3: view_geom1 (Multi Polygon)
> 4: view_geom2 (Multi Polygon)
>
> I could not discover how I could select layer '2: multigeom (Point)' because
> it
> has the same name 'multigeom' as the first layer. By doing
> ogrinfo multigeometry_db.sqlite multigeom
> the first geometry gets selected always.
>
> Spatial view for geom2 does not work either because OGR is looking at the
> first
> geometry column of the main table
>
> ogrinfo multigeometry_db.sqlite view_geom2
> INFO: Open of `multigeometry_db.sqlite'
>       using driver `SQLite' successful.
> ERROR 1: Underlying layer multigeom for view view_geom2 has not
> expected geometry column name (geom1 instead of geom2)
>
> The Spatialite metadata is correct in views_geometry_columns
>
> 1	view_geom1	geom1	ROWID	multigeom	geom1
> 2	view_geom2	geom2	ROWID	multigeom	geom2
>
> There seems to be something to improve both with tables and views. For tables
> it
> looks that layers should just get individual layer names so they could be
> selected, like 'multigeom(1)' and 'multigeom(2)' but I fear it is not that
> simple. With views SQLite driver should be made to not expect the first
> geometry
> column name it finds from the geometry_columns table but check other lines
> too.
> If I delete the row for geom1 from geometry_colums of place row for geom2
> before
> it the view_geom2 comes usable for OGR (and view_geom1 unusable).
>
> Regards,
>
> -Jukka Rahkonen-
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



From bluejp at gmail.com  Fri Aug  3 02:24:29 2012
From: bluejp at gmail.com (neojp)
Date: Fri, 3 Aug 2012 02:24:29 -0700 (PDT)
Subject: [gdal-dev] generating multipolygon from polygons
In-Reply-To: <CA+YzLBfRwr2nZMEXWWh2rV-MAD6StVpYvaH9A3v3n-bGtbwM+Q@mail.gmail.com>
References: <1343943199338-4992794.post@n6.nabble.com>
	<CA+YzLBfRwr2nZMEXWWh2rV-MAD6StVpYvaH9A3v3n-bGtbwM+Q@mail.gmail.com>
Message-ID: <1343985869375-4992895.post@n6.nabble.com>

Thanks Franks,

That was a newbie mistake.



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/generating-multipolygon-from-polygons-tp4992794p4992895.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From mathieu.coudert at gmail.com  Fri Aug  3 03:05:31 2012
From: mathieu.coudert at gmail.com (Mathieu Coudert)
Date: Fri, 3 Aug 2012 12:05:31 +0200
Subject: [gdal-dev] GDAL / Java bindings : Undefined symbol
	CPLLoggingErrorHandler in libgdaljni.so
Message-ID: <CAOWnZzaYTW29Fbi3p29GWc8w6ge62PyGr25zHbY_SGmCpEMXnA@mail.gmail.com>

Hi,

Running GDAL with Java binding I am facing an issue with an undefined
symbol: CPLLoggingErrorHandler in libgdaljni.so.

First I compiled GDAL 1.9.1 with Java support.
Then I followed the Java building instructions on Unix [1].
Everything seems to be correct, my ant build is successful.
However, running a make test or trying to execute the gdalinfo class I'm
facing an UnsatisfiedLinkError java exception due to the undefined
CPLLoggingErrorHandler symbol in libgdaljni.so

Any ideas how to deal with this issue would be appreciated.

I'm running GDAL 1.9.1 on top of Ubuntu 12.04 64bits (SWIG 2.0.4).

Oracle JDK 7 :
*java version "1.7.0_05"*
*Java(TM) SE Runtime Environment (build 1.7.0_05-b05)*
*Java HotSpot(TM) 64-Bit Server VM (build 23.1-b03, mixed mode)*

Please find below full traces of my errors :

*$ make test*
*rm -rf tmp_test*
*mkdir tmp_test*
*cp  test_data/byte.tif tmp_test*
*java -Djava.library.path=. -cp gdal.jar:build/apps GDALOverviews
tmp_test/byte.tif "NEAREST" 2 4*
*Native library load failed.*
*java.lang.UnsatisfiedLinkError:
/[myHome]/sources/gdal-1.9.1/swig/java/libgdaljni.so:
/[myHome]/sources/gdal-1.9.1/swig/java/libgdaljni.so: undefined symbol:
CPLLoggingErrorHandler*
*Exception in thread "main" java.lang.UnsatisfiedLinkError:
org.gdal.gdal.gdalJNI.AllRegister()V*
* at org.gdal.gdal.gdalJNI.AllRegister(Native Method)*
* at org.gdal.gdal.gdal.AllRegister(gdal.java:475)*
* at GDALOverviews.main(GDALOverviews.java:70)*
*make: *** [test] Error 1*


*$ echo $LD_LIBRARY_PATH*
*/[myHome]/sources/gdal-1.9.1/swig/java*
*
*
*$ java -classpath `pwd`/gdal.jar:`pwd`:`pwd`/build/apps gdalinfo*
*Native library load failed.*
*java.lang.UnsatisfiedLinkError:
/[myHome]/sources/gdal-1.9.1/swig/java/libgdaljni.so:
/[myHome]/sources/gdal-1.9.1/swig/java/libgdaljni.so:
undefined symbol: CPLLoggingErrorHandler*
*Exception in thread "main" java.lang.UnsatisfiedLinkError:
org.gdal.gdal.gdalJNI.AllRegister()V*
* at org.gdal.gdal.gdalJNI.AllRegister(Native Method)*
* at org.gdal.gdal.gdal.AllRegister(gdal.java:475)*
* at gdalinfo.main(gdalinfo.java:87)*

Cheers,
Mathieu

[1] http://trac.osgeo.org/gdal/wiki/GdalOgrInJavaBuildInstructionsUnix
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120803/e1d8ac73/attachment.html>

From even.rouault at mines-paris.org  Fri Aug  3 04:25:47 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Fri, 03 Aug 2012 13:25:47 +0200
Subject: [gdal-dev] GDAL / Java bindings : Undefined symbol
	CPLLoggingErrorHandler in libgdaljni.so
In-Reply-To: <CAOWnZzaYTW29Fbi3p29GWc8w6ge62PyGr25zHbY_SGmCpEMXnA@mail.gmail.com>
References: <CAOWnZzaYTW29Fbi3p29GWc8w6ge62PyGr25zHbY_SGmCpEMXnA@mail.gmail.com>
Message-ID: <1343993147.501bb53b14c82@imp.free.fr>

Selon Mathieu Coudert <mathieu.coudert at gmail.com>:

Your LD_LIBRARY_PATH should also include the path to libgdal.so

From jukka.rahkonen at mmmtike.fi  Fri Aug  3 04:30:06 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Fri, 3 Aug 2012 11:30:06 +0000 (UTC)
Subject: [gdal-dev] Any plans for a GDAL WMTS driver?
References: <loom.20120707T083755-135@post.gmane.org>
	<201207071258.33607.even.rouault@mines-paris.org>
Message-ID: <loom.20120803T130830-638@post.gmane.org>

Even Rouault <even.rouault <at> mines-paris.org> writes:

> 
> Le samedi 07 juillet 2012 08:45:33, Jukka Rahkonen a ?crit :
> > Hi,
> > 
> > National Land Survey of Finland has opened an experimental WMTS service.
> > GetCapabolities is found from
> > http://karttatiili.fi/dataset/taustakarttasarja/
capabilities/wmts.xml??REQU
> > EST=GetCapabilities Unfortunately GDAL does not have a WMTS driver 
yet. Are
> > there any plans for making such?
> 
> This is something I've also thought to. At first sight WMTS shouldn't be so 
> different of other tiled protocols (WMS-C, TMS, etc..), but there's an 
annoying 
> difficulty : in WMTS, the different overview levels have not necessarily
the same 
> spatial extent (in the server you are mentionning, this seems to be 
indeed the 
> case (*)), which doesn't fit natively into the GDAL model. An idea
would be to 
> take into account the tiling scheme and spatial extent of the most 
precise 
> level, and use perhaps a in-memory VRT to do on-the-fly clipping of the 
> overview levels. But that doesn't fit very well in the architecture 
of the 
> "minidrivers" of the WMS driver.
> 
> (*)
................
> 
> This indeed comes from the TileMatrix definition, where one can see 
that the 
> top of each level is not the same. And indeed, as 
> ScaleDenominator=7142.857142857143 is equivalent to 2 m and 
> ScaleDenominator=3571.4285714285716 is equivalent to 1 m, one can 
see that the 
> tile at row=0 at level 10 is at the half of tile at row = 0 at level 9.
> 
>     <TileMatrix>
>       <ows:Identifier>EPSG_3067_MML:9</ows:Identifier>
>       <ScaleDenominator>7142.857142857143</ScaleDenominator>
>       <TopLeftCorner>0.0 1.0000384E7</TopLeftCorner>
>       <TileWidth>256</TileWidth>
>       <TileHeight>256</TileHeight>
>       <MatrixWidth>19532</MatrixWidth>
>       <MatrixHeight>19532</MatrixHeight>
>     </TileMatrix>
>     <TileMatrix>
>       <ows:Identifier>EPSG_3067_MML:10</ows:Identifier>
>       <ScaleDenominator>3571.4285714285716</ScaleDenominator>
>       <TopLeftCorner>0.0 1.0000128E7</TopLeftCorner>
>       <TileWidth>256</TileWidth>
>       <TileHeight>256</TileHeight>
>       <MatrixWidth>39063</MatrixWidth>
>       <MatrixHeight>39063</MatrixHeight>
>     </TileMatrix>


There is another national TileMatrix in the same service which 
should be easier to handle ("JHS" matrix set is an official 
recommendation for national use in Finland while "MML" mastrix 
set must be something special for internal use at the National 
land survey of Finland.)  Perhaps it would be not too bad if the
WMTS driver would support first only the simple cases with same 
TopLeftCorner values at every zoom level and resolutions multiplied 
by factor of 2 at each step. That might encourage WMTS service 
providers to avoid using the advanced flexibility of the standard,
which after all would be just good for everybody.

<TileMatrix>
     <ows:Identifier>EPSG_3067_JHS:9</ows:Identifier>
     <ScaleDenominator>1.462857142857143E7</ScaleDenominator>
     <TopLeftCorner>-548576.0 8388608.0</TopLeftCorner>
     <TileWidth>256</TileWidth>
     <TileHeight>256</TileHeight>
     <MatrixWidth>2</MatrixWidth>
     <MatrixHeight>2</MatrixHeight>
</TileMatrix>
<TileMatrix>
     <ows:Identifier>EPSG_3067_JHS:10</ows:Identifier>
     <ScaleDenominator>7314285.714285715</ScaleDenominator>
     <TopLeftCorner>-548576.0 8388608.0</TopLeftCorner>
     <TileWidth>256</TileWidth>
     <TileHeight>256</TileHeight>
     <MatrixWidth>4</MatrixWidth>
     <MatrixHeight>4</MatrixHeight>
</TileMatrix>

-Jukka-


From mathieu.coudert at gmail.com  Fri Aug  3 04:43:26 2012
From: mathieu.coudert at gmail.com (Mathieu Coudert)
Date: Fri, 3 Aug 2012 13:43:26 +0200
Subject: [gdal-dev] GDAL / Java bindings : Undefined symbol
 CPLLoggingErrorHandler in libgdaljni.so
In-Reply-To: <1343993147.501bb53b14c82@imp.free.fr>
References: <CAOWnZzaYTW29Fbi3p29GWc8w6ge62PyGr25zHbY_SGmCpEMXnA@mail.gmail.com>
	<1343993147.501bb53b14c82@imp.free.fr>
Message-ID: <CAOWnZzYYetJUFCiqt4oa-_YhvfNYEcmuWQ6dO_gGDNT3WSscdw@mail.gmail.com>

Thanks Even, I tried to export /usr/local/lib as well in my LD_LIBRARY_PATH
but without success...
For instance, I did :

$ java -Djava.library.path=`pwd`:/usr/local/lib -classpath
`pwd`/gdal.jar:`pwd`:`pwd`/build/apps gdalinfo
$ java -Djava.library.path=`pwd`:/usr/local/lib/libgdal.so -classpath
`pwd`/gdal.jar:`pwd`:`pwd`/build/apps gdalinfo
$ export LD_LIBRARY_PATH=`pwd`:/usr/local/lib

Any idea please?

Mathieu


On Fri, Aug 3, 2012 at 1:25 PM, Even Rouault
<even.rouault at mines-paris.org>wrote:

> Selon Mathieu Coudert <mathieu.coudert at gmail.com>:
>
> Your LD_LIBRARY_PATH should also include the path to libgdal.so
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120803/47d9361f/attachment.html>

From Markus.Persson at vitec.se  Fri Aug  3 06:12:45 2012
From: Markus.Persson at vitec.se (Markus Persson)
Date: Fri, 3 Aug 2012 15:12:45 +0200
Subject: [gdal-dev] ogr2ogr - M-values?
Message-ID: <202996F51BA98644A1A71B8990FD3A426CE36335B9@su-mail.vitec.se>

Hello!

I have tried using ogr2ogr to get Oracle data to a .shp-file, this seems to work nice most of the times but not on my point objects. The .shp-file get X, Y and Z-values, but no M. And when I try to load this into DotSpatial so does it say that the .shp-file is wrong.
I tried another tool and created a .shp-file from the same data, and the only difference is that the .shp-file got some M-values and DotSpatial could load that.

So I think I have two options. Which one is the right one?


1)      Force ogr2ogr to output some M-values. How do I do this?

2)      Ogr2ogr works as intended and the fault is at DotSpatial? I have created an issue already and waiting for an answer.

/Markus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120803/03b7a526/attachment.html>

From even.rouault at mines-paris.org  Fri Aug  3 06:19:48 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Fri, 03 Aug 2012 15:19:48 +0200
Subject: [gdal-dev] ogr2ogr - M-values?
In-Reply-To: <202996F51BA98644A1A71B8990FD3A426CE36335B9@su-mail.vitec.se>
References: <202996F51BA98644A1A71B8990FD3A426CE36335B9@su-mail.vitec.se>
Message-ID: <1343999988.501bcff46cb76@imp.free.fr>

Selon Markus Persson <Markus.Persson at vitec.se>:

> Hello!
>
> I have tried using ogr2ogr to get Oracle data to a .shp-file, this seems to
> work nice most of the times but not on my point objects. The .shp-file get X,
> Y and Z-values, but no M. And when I try to load this into DotSpatial so does
> it say that the .shp-file is wrong.
> I tried another tool and created a .shp-file from the same data, and the only
> difference is that the .shp-file got some M-values and DotSpatial could load
> that.
>
> So I think I have two options. Which one is the right one?
>
>
> 1)      Force ogr2ogr to output some M-values. How do I do this?
>
> 2)      Ogr2ogr works as intended and the fault is at DotSpatial? I have
> created an issue already and waiting for an answer.

OGR data model doesn't support the M dimension. It will get ignored (not sure
what the Oracle driver does however with geometries with M). However it should
always produce valid shapefiles and that would be suprising if it produced wrong
shapefiles and that it wouldn't been detected before. So there's perhaps
something with DotSpatial.

>
> /Markus
>



From benjamin.lux at maxsea.fr  Fri Aug  3 06:46:00 2012
From: benjamin.lux at maxsea.fr (Benjamin)
Date: Fri, 3 Aug 2012 06:46:00 -0700 (PDT)
Subject: [gdal-dev]  Ogr remove multiples Polygones of a Multipolygone
Message-ID: <1344001560698-4992980.post@n6.nabble.com>

Hi,

I want to remove polygones who have a "little" area from a Mulipolygone.
My multipolygone may be verry complex.

I have write :

[code]
// geom OGRGEOMETRY of type wkbGeometryType.wkbMultiPolygone
// surfaceMin is an int

for (int i = 0; i < geom.GetGeometryCount(); i++)
{
    // If we have remove all polygone geometries of geom unless one 
    if (geom.GetGeometryType() != wkbGeometryType.wkbPolygon)
    return geom.Area() >= surfaceMin;

    // else if the polygone n?i is too little ...
    if (geom.GetGeometryRef(i).Area() < surfaceMin) 
    {
        // ... we remove it.
        geom = geom.Difference(geom.GetGeometryRef(i));
        i = 0;
    }
}
[/code]
Note : I can use Geometry::Difference because my polygones aren't stack
(poly1.Intersection(poly2) is all the time false).

There is a neater solution ?

1/
When you use Difference(Pi), the last polygon of the multipolygone go at the
indice i ?

ex : 
MP as a geometry with a multipolygone type
MP : P1, P2, P3, P4
MP.Difference(P2) : P1.Difference(P2), P3.Difference(P2), P4.Difference(P4)
?

if yes, i can write : 
"i--" and not "i=0", and not test every time sames first polygones ...

2/
Maybe there is an other way, and not use Difference(Pi) but a hidden methode
near "Remove(Pi)"  ?

3/
Do you think that create a new multipolygon is a better solution ?
And add just "big" Polygons with Geometry.AddGeometry(Geometry).
Then, AddGeometry() or AddGeometryDirectly() ?
This 2 methods aren't in the OGR API
(http://www.gdal.org/ogr/classOGRGeometry.html) but in my C# wrapper.


Best regards,
Benjamin



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/gdal-dev-Ogr-remove-multiples-Polygones-of-a-Multipolygone-tp4992980.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From giuseppe.amatulli at gmail.com  Fri Aug  3 09:09:14 2012
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Fri, 3 Aug 2012 11:09:14 -0500
Subject: [gdal-dev] spatial join using python ogr or shapely
Message-ID: <CAKoiDHLzoYGvRb9mpJ8yP4-GZi_nwEOAap7a4PTT4ScZGfr1TQ@mail.gmail.com>

HI,
I would like to make a spatial join of two shp using python ogr or shapely
Is this possible?
I do not have a common Item in the dbf so i can not make a table-join,
i have to do a spatial one.
I did not find any examples on the net.

so started ....

try:
    from osgeo import ogr
    import sys

shp00=ogr.Open("alabama.shp")
shp10=ogr.Open("tabblock2010_01_pophu.shp")

inPolyLshp00 = shp00.GetLayer(0)
inPolyLshp10 = shp10.GetLayer(0)

and then?

Any suggestion?
Thanks in advance
-- 
Giuseppe Amatulli
Web: www.spatial-ecology.net

From even.rouault at mines-paris.org  Fri Aug  3 14:56:33 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Fri, 3 Aug 2012 23:56:33 +0200
Subject: [gdal-dev] Spatialite tables with multiple geometry columns
In-Reply-To: <1343985459.501b9733af310@imp.free.fr>
References: <loom.20120803T091825-188@post.gmane.org>
	<1343985459.501b9733af310@imp.free.fr>
Message-ID: <201208032356.33345.even.rouault@mines-paris.org>

Andrea created http://trac.osgeo.org/gdal/ticket/4768 and I've just committed 
the code in trunk to add that support. I've tested it with a tiny sample just 
made for the unit test. No reason it should not work with more complex DBs, 
but testing appreciated.

From aperi2007 at gmail.com  Sat Aug  4 02:54:31 2012
From: aperi2007 at gmail.com (Andrea Peri)
Date: Sat, 4 Aug 2012 11:54:31 +0200
Subject: [gdal-dev] Spatialite tables with multiple geometry columns
Message-ID: <CABqTJk95yA83i+vhFF9r-ix0i+PNM418uLS7wZGi4bF6kz9mTw@mail.gmail.com>

Hi Roualt,

thx for patch,

I'm go to test it.
Just a question to understand how use it.

the sintax 'TABLE(GEOMETRY)' should return also the attributes from table
or only the geometry without attribute ?

regards,

-- 
-----------------
Andrea Peri
. . . . . . . . .
qwerty ?????
-----------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120804/b22fc353/attachment.html>

From jukka.rahkonen at mmmtike.fi  Sat Aug  4 08:33:49 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Sat, 4 Aug 2012 15:33:49 +0000 (UTC)
Subject: [gdal-dev] How to give additional WFS parameters right?
Message-ID: <loom.20120804T172335-967@post.gmane.org>

Hi,

I am trying to set MAXFEATURES to communication with WFS server.
In http://gdal.org/ogr/drv_wfs.html I can read

"Additionnal optional parameters can be specified such as TYPENAME, VERSION,
MAXFEATURES as specified in WFS specification.
It is also possible to specify the name of an XML file whose content matches the
following syntax (the <OGRWFSDataSource> element must be the first bytes of the
file):

<OGRWFSDataSource>
    <URL>http://path/to/WFS/service[?OPTIONAL_PARAMETER1=VALUE
[&OPTIONNAL_PARAMETER2=VALUE]]</URL>
</OGRWFSDataSource>"

I have tried now from command line
ogrinfo wfs:http://hip.latuviitta.org/cgi-bin/tinyows?
SERVICE=WFS&VERSION=1.1.0&TYPENAME=hki_parkkilippuautomaatit&MAXFEATURES=2

and also by writing an xml file containing the additional parameters. However I
cannot make it to work as supposed. The command line system does not send
GetFeature ever. With the XML file system GetFeature is sent without
MAXFEATURES. I can also see that ogrinfo adds GetCapabilities into the XML file
and at the same it overwrites my handwritten URL element and deletes the extra
parameters I tried to put there.

-Jukka Rahkonen-


From jukka.rahkonen at mmmtike.fi  Sat Aug  4 08:42:54 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Sat, 4 Aug 2012 15:42:54 +0000 (UTC)
Subject: [gdal-dev] How to give additional WFS parameters right?
References: <loom.20120804T172335-967@post.gmane.org>
Message-ID: <loom.20120804T173911-178@post.gmane.org>

Ok,
Inserting WFS source between "" helped with command line (I am on
Windows as usual").

ogr2ogr -f GML test2.txt "wfs:http://hip.latuviitta.org/cgi-bin/
tinyows?SERVICE=WFS&VERSION=1.1.0&TYPENAME=
lv:hki_parkkilippuautomaatit&MAXFEATURES=2"

The XML definition file overwrite problem is left.

-Jukka-




From aperi2007 at gmail.com  Sun Aug  5 00:49:48 2012
From: aperi2007 at gmail.com (Andrea Peri)
Date: Sun, 5 Aug 2012 09:49:48 +0200
Subject: [gdal-dev] Spatialite tables with multiple geometry columns
Message-ID: <CABqTJk99xL9CegvP06zRqtuoKL-2MRsKxVJV75UkRn-vbxmZxg@mail.gmail.com>

Hi EDven,
I try to use the your patch with gdal and mapserer.

Now I'm able to choose the right geometry from a multi-geometry table.
also I see that using this sintax

    CONNECTIONTYPE OGR
    CONNECTION '/path-to-splite/database.sqlite'
    DATA "select pk_uid,field1,field2,field3,geometry from table1"

I'm able to see with mapserver a map with geometries and labels.
I test it on a quite huge dataset with a spatial-index and it response
really fast.
All seem good.

But I experience just a secondary no good effect:
If I try to do an identify (a GetFeatureInfo request) on the map I'm having
always
a

>GetFeatureInfo results:
>
>  Search returned no results.

I have verify that the pk_uid field was a primary key.

So perhaps this could be a secondary effect of your patch ?

Thx,

-- 
-----------------
Andrea Peri
. . . . . . . . .
qwerty ?????
-----------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120805/001aff13/attachment.html>

From aperi2007 at gmail.com  Sun Aug  5 05:24:40 2012
From: aperi2007 at gmail.com (Andrea Peri)
Date: Sun, 5 Aug 2012 14:24:40 +0200
Subject: [gdal-dev] ogrinfo don't understand spatialiute multigeometry
Message-ID: <CABqTJk_pietfiAQp0Pzm==hEewgcuGgzhpe+qkmNDGwUMb8+Sg@mail.gmail.com>

Hi Even,

I finish the tests on your patch for spatilaite multigeometry.

There si some trouble with ogrinfo .
I guess is the same problem I just see on MapServer when I try a
GetFeatureInfo on a MultiGeometry layer.

I try this:

start a new db spatialite named "test.sqlite" and run this scripts:

-----------
create table prova(pk_uid integer primary key, nome varchar(10));
select AddGeometryColumn('prova','GEOMETRY',3003,'MULTIPOLYGON','XY');
select AddGeometryColumn('prova','BBOX',3003,'POLYGON','XY');

INSERT INTO PROVA (NOME,GEOMETRY,BBOX) VALUES (
    'A',
    ST_GeomFromText(
        'MULTIPOLYGON (((30 20, 10 40, 45 40, 30 20)),((15 5, 40 10, 10 20,
5 10, 15 5)))',
        3003
    ),
    ST_Envelope(
        ST_GeomFromText(
            'MULTIPOLYGON (((30 20, 10 40, 45 40, 30 20)),((15 5, 40 10, 10
20, 5 10, 15 5)))',
            3003
        )
    )
);
-------------

After ,
I try the

ogrinfo test.sqlite

It return:

INFO: Open of `test.sqlite'
      using driver `SQLite' successful.
1: prova(GEOMETRY) (Multi Polygon)
2: prova(BBOX) (Polygon)

So it is ok .

But when I try this other call:

ogrinfo test.sqlite prova

it return:

INFO: Open of `test.sqlite'
      using driver `SQLite' successful.
FAILURE: Couldn't fetch requested layer prova!

I'm not sure if this is the same problem I see with GetFeatureInfo of
MapServer.

Thx,


-- 
-----------------
Andrea Peri
. . . . . . . . .
qwerty ?????
-----------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120805/f164cdd5/attachment.html>

From jukka.rahkonen at mmmtike.fi  Sun Aug  5 07:09:15 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Sun, 5 Aug 2012 14:09:15 +0000 (UTC)
Subject: [gdal-dev] ogrinfo don't understand spatialiute multigeometry
References: <CABqTJk_pietfiAQp0Pzm==hEewgcuGgzhpe+qkmNDGwUMb8+Sg@mail.gmail.com>
Message-ID: <loom.20120805T160551-821@post.gmane.org>

Andrea Peri <aperi2007 <at> gmail.com> writes:

> But when I try this other call:
> ogrinfo test.sqlite prova
> it return:

> INFO: Open of `test.sqlite'
>       using driver `SQLite' successful.
> FAILURE: Couldn't fetch requested layer prova!
> I'm not sure if this is the same problem I see with GetFeatureInfo 
of MapServer.

Hi,

But Even wrote it should behave in the same way thatn PostGIS with multiple
geometries. Try
ogrinfo test.sqlite prova(GEOMETRY) and 
ogrinfo test.sqlite prova(BBOX)

-Jukka-



From osgeo.mailinglist at gmail.com  Sun Aug  5 13:58:29 2012
From: osgeo.mailinglist at gmail.com (Thomas Gratier)
Date: Sun, 5 Aug 2012 22:58:29 +0200
Subject: [gdal-dev] urn and geojson
Message-ID: <CACPZzQ1a9e2v6Q=hT5JN75VNri9+DQTx1y8iiJ=pMWLyvwgfcQ@mail.gmail.com>

Hello,

I'm playing around with geojson and I haven't found any clue on the doc e.g
http://www.gdal.org/ogr/drv_geojson.html about including urn in geojson
output.
I think it can be useful for sharing geojson and without urn, finding
projection isn't really possible.
Does I miss the feature? There is a roadmap about this?
The form I 'm expecting look like urn:ogc:def:crs:EPSG::26912 (following
this discussion
http://gis.stackexchange.com/questions/15953/whats-up-with-the-geojson-spec-and-crs-as-a-irmand
the official spec
http://www.geojson.org/geojson-spec.html#named-crs)<http://www.geojson.org/geojson-spec.html#named-crs>

Regards

ThomasG
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120805/d6bc3443/attachment.html>

From aperi2007 at gmail.com  Sun Aug  5 14:53:52 2012
From: aperi2007 at gmail.com (Andrea Peri)
Date: Sun, 5 Aug 2012 23:53:52 +0200
Subject: [gdal-dev] ogrinfo don't understand spatialiute multigeometry
Message-ID: <CABqTJk9gs-HQhdPvb+kon4CHGia7dEsvVk0dUbhC2M-b2yETyA@mail.gmail.com>

Hi Jukka,

you have right

ogrinfo test.sqlite "prova(GEOMETRY)"

work without problem.

Now just remain only the question of GetFeatureInfo request on MapServer
It seem don't work on my test.

Thx,

-- 
-----------------
Andrea Peri
. . . . . . . . .
qwerty ?????
-----------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120805/0b8f527f/attachment.html>

From mwtoews at gmail.com  Sun Aug  5 17:41:55 2012
From: mwtoews at gmail.com (Mike Toews)
Date: Mon, 6 Aug 2012 12:41:55 +1200
Subject: [gdal-dev] Capture stderr in interactive Python shell
Message-ID: <CAM2FmMox_WHQDh1WcYpkZkGT7nafpmkGy-r8Pfi2OF4s3cQXKw@mail.gmail.com>

I would like to capture or show GDAL error messages in an interactive
Python shell. For instance, if trying to open an non-existing raster:

from osgeo import gdal
ds = gdal.Open('noexist.tif')

shows nothing in an interactive shell (PythonWin, IDLE), but shows
messages when used in a shell (cmd.exe or Bash):

ERROR 4: `noexist.tif' does not exist in the file system, and is not
recognised as a supported dataset name.

It appears this output is sent to stderr. How can this output also
appear in an interactive Python shell, such as PythonWin or IDLE?

Thanks,
-Mike

From jzl5325 at psu.edu  Sun Aug  5 18:41:11 2012
From: jzl5325 at psu.edu (Jay L.)
Date: Sun, 5 Aug 2012 18:41:11 -0700
Subject: [gdal-dev] Capture stderr in interactive Python shell
In-Reply-To: <CAM2FmMox_WHQDh1WcYpkZkGT7nafpmkGy-r8Pfi2OF4s3cQXKw@mail.gmail.com>
References: <CAM2FmMox_WHQDh1WcYpkZkGT7nafpmkGy-r8Pfi2OF4s3cQXKw@mail.gmail.com>
Message-ID: <CA+bfmPuebweJ6sxM+trVib2SZpQLAyEZ+Q9Z4_wQV72J7mMDnw@mail.gmail.com>

try this:

from osgeo import gdal
gdal.UseExceptions()
gdal.Open('noexist.tif')

This is from: http://trac.osgeo.org/gdal/wiki/PythonGotchas


On Sun, Aug 5, 2012 at 5:41 PM, Mike Toews <mwtoews at gmail.com> wrote:

> I would like to capture or show GDAL error messages in an interactive
> Python shell. For instance, if trying to open an non-existing raster:
>
> from osgeo import gdal
> ds = gdal.Open('noexist.tif')
>
> shows nothing in an interactive shell (PythonWin, IDLE), but shows
> messages when used in a shell (cmd.exe or Bash):
>
> ERROR 4: `noexist.tif' does not exist in the file system, and is not
> recognised as a supported dataset name.
>
> It appears this output is sent to stderr. How can this output also
> appear in an interactive Python shell, such as PythonWin or IDLE?
>
> Thanks,
> -Mike
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120805/3210b718/attachment.html>

From newmanw10 at gmail.com  Sun Aug  5 19:47:34 2012
From: newmanw10 at gmail.com (Billy Newman)
Date: Sun, 5 Aug 2012 20:47:34 -0600
Subject: [gdal-dev] Windows 32 bit GDAL
Message-ID: <CAD34qgm+ze5=SwJAJdc5oCdN=7qyg3Va_izED_3ks6r2eCG-hQ@mail.gmail.com>

Anyone know where I can get windows 32 bit GDAL libs pre-compiled with Java
bindings?

Thanks,
Billy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120805/c83de696/attachment.html>

From chaitanya.ch at gmail.com  Sun Aug  5 20:24:41 2012
From: chaitanya.ch at gmail.com (Chaitanya kumar CH)
Date: Mon, 6 Aug 2012 08:54:41 +0530
Subject: [gdal-dev] Windows 32 bit GDAL
In-Reply-To: <CAD34qgm+ze5=SwJAJdc5oCdN=7qyg3Va_izED_3ks6r2eCG-hQ@mail.gmail.com>
References: <CAD34qgm+ze5=SwJAJdc5oCdN=7qyg3Va_izED_3ks6r2eCG-hQ@mail.gmail.com>
Message-ID: <CAMKgpOZ59Ha00ULnuSAoQXpwTaFVzNmVfUZHMqnBitSknhQxfQ@mail.gmail.com>

http://trac.osgeo.org/osgeo4w/

On Mon, Aug 6, 2012 at 8:17 AM, Billy Newman <newmanw10 at gmail.com> wrote:

> Anyone know where I can get windows 32 bit GDAL libs pre-compiled with
> Java bindings?
>
> Thanks,
> Billy
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



-- 
Best regards,
Chaitanya kumar CH.

+91-9494447584
17.2416N 80.1426E
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120806/7c039f76/attachment.html>

From ari.jolma at gmail.com  Mon Aug  6 01:27:26 2012
From: ari.jolma at gmail.com (Ari Jolma)
Date: Mon, 06 Aug 2012 11:27:26 +0300
Subject: [gdal-dev] RFC 39, layer algebra in trunk
Message-ID: <501F7FEE.6000801@gmail.com>

Folks,

I've committed the layer algebra stuff into trunk in changesets 24736 - 
24739. The last one is the initial test code.

I've also started a wiki page for describing the method set in more 
detail http://trac.osgeo.org/gdal/wiki/LayerAlgebra (linked to page 
http://trac.osgeo.org/gdal/wiki/CodeSnippets since that seemed to me as 
the best place).

Best regards,

Ari


From artur.redzko at tatukgis.com  Mon Aug  6 02:10:22 2012
From: artur.redzko at tatukgis.com (Artur Redzko)
Date: Mon, 6 Aug 2012 11:10:22 +0200
Subject: [gdal-dev] Detect if a format is raster or grid
Message-ID: <470319BA5986DB4EA76BDC16C2E062889EFA0D6E79@TEXAS.tatukgis.com>

Hi



I have a project where displaying rasters formats (e.g. bmp) is made in different way than displaying grid formats (e.g. dem). Using GDAL I have a problem with universal detecting whether file opened by GDAL is a grid or raster image. I thought that detecting color interpretation mixed with data type/size and band number would be enough to decide if IsGridImage=True|False but depending on format these values varies. A good example is srtm (16bit grid) and 16bit gray nitf. Do you know a good way to solve this task?



Regards

Artur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120806/e677612f/attachment.html>

From mathieu.coudert at gmail.com  Mon Aug  6 03:15:41 2012
From: mathieu.coudert at gmail.com (Mathieu Coudert)
Date: Mon, 6 Aug 2012 12:15:41 +0200
Subject: [gdal-dev] GDAL / Java bindings : Undefined symbol
 CPLLoggingErrorHandler in libgdaljni.so
In-Reply-To: <CAOWnZzYYetJUFCiqt4oa-_YhvfNYEcmuWQ6dO_gGDNT3WSscdw@mail.gmail.com>
References: <CAOWnZzaYTW29Fbi3p29GWc8w6ge62PyGr25zHbY_SGmCpEMXnA@mail.gmail.com>
	<1343993147.501bb53b14c82@imp.free.fr>
	<CAOWnZzYYetJUFCiqt4oa-_YhvfNYEcmuWQ6dO_gGDNT3WSscdw@mail.gmail.com>
Message-ID: <CAOWnZzZhpGY4eSdAcqqZiGPujErZKvrP6-NhqiESeQf9kD=QaA@mail.gmail.com>

Hi,

This error was due to the "--without-libtool" option compiling GDAL.

I found that I had to build GDAL *with* libtool to get java bindings
working (contrarily to what's written in section "Configure and Build GDAL"
from http://trac.osgeo.org/gdal/wiki/GdalOgrInJavaBuildInstructionsUnix)

Cheers,
Mathieu


Your LD_LIBRARY_PATH should also include the path to libgdal.so
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120806/870ab0b8/attachment-0001.html>

From jzl5325 at psu.edu  Mon Aug  6 09:53:11 2012
From: jzl5325 at psu.edu (Jay L.)
Date: Mon, 6 Aug 2012 09:53:11 -0700
Subject: [gdal-dev] GDAL - Python - ArcGIS10.1
Message-ID: <CA+bfmPt-=pgD7_2LizFPQMZPqd-kv=MVG455K-hBJi1MDCqhuQ@mail.gmail.com>

All,

I am trying to get the gdal python bindings working with an ArcGIS 10.1
installation.

I grabbed the core from gisinternals.com/sdk (thanks Tamas!) and installed
both the 1500 core files (MVS 2008) and the python 2.7 bindings.  I
appended the path as necessary and added the GDAL_DATA directory.  The gdal
installation appears to be working wonderfully with gdal_translate,
gdalinfo, and ogr2ogr all functioning as expected.

Any of the python scripts and a straigh import of gdal or ogr are failing.
Stack trace below.  Any ideas?  This is a new import error for me.

I attempted the import both from the root directory and the directory gdal
is in (thinking it still could have been a PATH issue).  I also tried both
the stable and the nightly builds to see if that was the issue.  Nada.

Thanks,
Jay

Microsoft Windows [Version 6.1.7601]
Copyright (c) 2009 Microsoft Corporation.  All rights reserved.

C:\Users\arc_user>python
Python 2.7.2 (default, Jun 12 2011, 15:08:59) [MSC v.1500 32 bit (Intel)]
on win
32
Type "help", "copyright", "credits" or "license" for more information.
>>> import gdal
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\Python27\ArcGIS10.1\lib\site-packages\gdal.py", line 2, in
<module>
    from osgeo.gdal import deprecation_warn
  File "C:\Python27\ArcGIS10.1\lib\site-packages\osgeo\__init__.py", line
21, in
 <module>
    _gdal = swig_import_helper()
  File "C:\Python27\ArcGIS10.1\lib\site-packages\osgeo\__init__.py", line
17, in
 swig_import_helper
    _mod = imp.load_module('_gdal', fp, pathname, description)
ImportError: DLL load failed: The device is not ready.
>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120806/f3713433/attachment.html>

From szekerest at gmail.com  Mon Aug  6 10:50:08 2012
From: szekerest at gmail.com (Tamas Szekeres)
Date: Mon, 6 Aug 2012 19:50:08 +0200
Subject: [gdal-dev] GDAL - Python - ArcGIS10.1
In-Reply-To: <CA+bfmPt-=pgD7_2LizFPQMZPqd-kv=MVG455K-hBJi1MDCqhuQ@mail.gmail.com>
References: <CA+bfmPt-=pgD7_2LizFPQMZPqd-kv=MVG455K-hBJi1MDCqhuQ@mail.gmail.com>
Message-ID: <CACALY+Ti6D1fw4FBV+NkB9oZq_m2GPWQwvp3DWdHA+yj+kmp1g@mail.gmail.com>

Jay,

Add the directory of the GDAL installation to the beginning of the system
PATH.
Or alternatively, you can run the GDAL console (to set the environment
correctly) and then start python.exe from this command prompt.

Best regards,

Tamas


2012/8/6 Jay L. <jzl5325 at psu.edu>

> All,
>
> I am trying to get the gdal python bindings working with an ArcGIS 10.1
> installation.
>
> I grabbed the core from gisinternals.com/sdk (thanks Tamas!) and
> installed both the 1500 core files (MVS 2008) and the python 2.7 bindings.
> I appended the path as necessary and added the GDAL_DATA directory.  The
> gdal installation appears to be working wonderfully with gdal_translate,
> gdalinfo, and ogr2ogr all functioning as expected.
>
> Any of the python scripts and a straigh import of gdal or ogr are
> failing.  Stack trace below.  Any ideas?  This is a new import error for me.
>
> I attempted the import both from the root directory and the directory gdal
> is in (thinking it still could have been a PATH issue).  I also tried both
> the stable and the nightly builds to see if that was the issue.  Nada.
>
> Thanks,
> Jay
>
> Microsoft Windows [Version 6.1.7601]
> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>
> C:\Users\arc_user>python
> Python 2.7.2 (default, Jun 12 2011, 15:08:59) [MSC v.1500 32 bit (Intel)]
> on win
> 32
> Type "help", "copyright", "credits" or "license" for more information.
> >>> import gdal
> Traceback (most recent call last):
>   File "<stdin>", line 1, in <module>
>   File "C:\Python27\ArcGIS10.1\lib\site-packages\gdal.py", line 2, in
> <module>
>     from osgeo.gdal import deprecation_warn
>   File "C:\Python27\ArcGIS10.1\lib\site-packages\osgeo\__init__.py", line
> 21, in
>  <module>
>     _gdal = swig_import_helper()
>   File "C:\Python27\ArcGIS10.1\lib\site-packages\osgeo\__init__.py", line
> 17, in
>  swig_import_helper
>     _mod = imp.load_module('_gdal', fp, pathname, description)
> ImportError: DLL load failed: The device is not ready.
> >>>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120806/32a17876/attachment.html>

From jzl5325 at psu.edu  Mon Aug  6 11:02:44 2012
From: jzl5325 at psu.edu (Jay L.)
Date: Mon, 6 Aug 2012 11:02:44 -0700
Subject: [gdal-dev] GDAL - Python - ArcGIS10.1
In-Reply-To: <CACALY+Ti6D1fw4FBV+NkB9oZq_m2GPWQwvp3DWdHA+yj+kmp1g@mail.gmail.com>
References: <CA+bfmPt-=pgD7_2LizFPQMZPqd-kv=MVG455K-hBJi1MDCqhuQ@mail.gmail.com>
	<CACALY+Ti6D1fw4FBV+NkB9oZq_m2GPWQwvp3DWdHA+yj+kmp1g@mail.gmail.com>
Message-ID: <CA+bfmPt7tDeXuMVqyz3cuOA5Q7C8bftc-np8Gd7rB2q-7J+E4g@mail.gmail.com>

Works wonderfully.

What causes this?  Is their another item in the path that is calling the
GDAL.dll earlier and locking the python bindings out?

Thanks,
Jay

On Mon, Aug 6, 2012 at 10:50 AM, Tamas Szekeres <szekerest at gmail.com> wrote:

> Jay,
>
> Add the directory of the GDAL installation to the beginning of the system
> PATH.
> Or alternatively, you can run the GDAL console (to set the environment
> correctly) and then start python.exe from this command prompt.
>
> Best regards,
>
> Tamas
>
>
> 2012/8/6 Jay L. <jzl5325 at psu.edu>
>
>> All,
>>
>> I am trying to get the gdal python bindings working with an ArcGIS 10.1
>> installation.
>>
>> I grabbed the core from gisinternals.com/sdk (thanks Tamas!) and
>> installed both the 1500 core files (MVS 2008) and the python 2.7 bindings.
>> I appended the path as necessary and added the GDAL_DATA directory.  The
>> gdal installation appears to be working wonderfully with gdal_translate,
>> gdalinfo, and ogr2ogr all functioning as expected.
>>
>> Any of the python scripts and a straigh import of gdal or ogr are
>> failing.  Stack trace below.  Any ideas?  This is a new import error for me.
>>
>> I attempted the import both from the root directory and the directory
>> gdal is in (thinking it still could have been a PATH issue).  I also tried
>> both the stable and the nightly builds to see if that was the issue.  Nada.
>>
>> Thanks,
>> Jay
>>
>> Microsoft Windows [Version 6.1.7601]
>> Copyright (c) 2009 Microsoft Corporation.  All rights reserved.
>>
>> C:\Users\arc_user>python
>> Python 2.7.2 (default, Jun 12 2011, 15:08:59) [MSC v.1500 32 bit (Intel)]
>> on win
>> 32
>> Type "help", "copyright", "credits" or "license" for more information.
>> >>> import gdal
>> Traceback (most recent call last):
>>   File "<stdin>", line 1, in <module>
>>   File "C:\Python27\ArcGIS10.1\lib\site-packages\gdal.py", line 2, in
>> <module>
>>     from osgeo.gdal import deprecation_warn
>>   File "C:\Python27\ArcGIS10.1\lib\site-packages\osgeo\__init__.py", line
>> 21, in
>>  <module>
>>     _gdal = swig_import_helper()
>>   File "C:\Python27\ArcGIS10.1\lib\site-packages\osgeo\__init__.py", line
>> 17, in
>>  swig_import_helper
>>     _mod = imp.load_module('_gdal', fp, pathname, description)
>> ImportError: DLL load failed: The device is not ready.
>> >>>
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120806/a915b400/attachment.html>

From sbahram at nc.rr.com  Mon Aug  6 17:50:57 2012
From: sbahram at nc.rr.com (Sina Bahram)
Date: Mon, 6 Aug 2012 20:50:57 -0400
Subject: [gdal-dev] Topology Exceptions on Non-Noded Intersections
Message-ID: <000001cd7436$b76ef290$264cd7b0$@nc.rr.com>

Hello,

I receive the following errors with the -wrapdateline argument.

ERROR 1: TopologyException: found non-noded intersection between LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING (0
-73.1221, -89.3211 -73.0542) at -59.8141 -73.0766
ERROR 1: TopologyException: found non-noded intersection between LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING
(180 -73.2589, -89.3211 -73.0542) at -59.8141 -73.0766

More details can be found on this question I asked:
http://gis.stackexchange.com/questions/30922/how-do-i-split-polygons-that-cross-the-dateline

any advice?

Thanks

Take care,
Sina

Website: www.SinaBahram.com
Twitter: @SinaBahram



From sbahram at nc.rr.com  Mon Aug  6 18:49:41 2012
From: sbahram at nc.rr.com (Sina Bahram)
Date: Mon, 6 Aug 2012 21:49:41 -0400
Subject: [gdal-dev] Topology Exceptions on Non-Noded Intersections
In-Reply-To: <CACqBkM8b2rjDOm+jwY=FbMxoGKjB3j5Sbkqf2288T3ERXHE7Pw@mail.gmail.com>
References: <000001cd7436$b76ef290$264cd7b0$@nc.rr.com>
	<CACqBkM8b2rjDOm+jwY=FbMxoGKjB3j5Sbkqf2288T3ERXHE7Pw@mail.gmail.com>
Message-ID: <000101cd743e$ea6822e0$bf3868a0$@nc.rr.com>

Eli,

Sounds like the same problem to me, yes. thank you for finding that.

However, now I'm still left wondering about implementing the fix.

As I said in the StackExchange question, I think wrapdateline should fix this, but if not is there an easy way to split polygons
along the dateline?

Thanks for the response to this.

Take care,
Sina


Website: www.SinaBahram.com
Twitter: @SinaBahram


-----Original Message-----
From: Eli Adam [mailto:eadam at co.lincoln.or.us] 
Sent: Monday, August 06, 2012 9:19 PM
To: Sina Bahram
Subject: Re: [gdal-dev] Topology Exceptions on Non-Noded Intersections

This is about Google Earth not Google Maps, but there may be something
relevant here, http://blog.opengeo.org/2010/08/10/shape-of-a-polygon/

Eli

On Mon, Aug 6, 2012 at 5:50 PM, Sina Bahram <sbahram at nc.rr.com> wrote:
> Hello,
>
> I receive the following errors with the -wrapdateline argument.
>
> ERROR 1: TopologyException: found non-noded intersection between LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING
(0
> -73.1221, -89.3211 -73.0542) at -59.8141 -73.0766
> ERROR 1: TopologyException: found non-noded intersection between LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING
> (180 -73.2589, -89.3211 -73.0542) at -59.8141 -73.0766
>
> More details can be found on this question I asked:
> http://gis.stackexchange.com/questions/30922/how-do-i-split-polygons-that-cross-the-dateline
>
> any advice?
>
> Thanks
>
> Take care,
> Sina
>
> Website: www.SinaBahram.com
> Twitter: @SinaBahram
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev


From anton.korosov at nersc.no  Tue Aug  7 02:10:34 2012
From: anton.korosov at nersc.no (Anton Korosov)
Date: Tue, 07 Aug 2012 11:10:34 +0200
Subject: [gdal-dev] Units of dimension variable in NetCDF is 'km'
Message-ID: <5020DB8A.1030700@nersc.no>

Dear Etienne,

I faced the following problem with the NetCDF driver:
Units of the dimension variables are 'km' and values in the SRS are in 
meters, of course (e.g. Earth radius). Hence the calculated GeoTransform 
is 1000 times less than should be and the calculate latlons are incorrect.
However 'units' attribute is given, besides AFAIK CF-conventions allow 
to have 'k' (kilo) preceding 'm' (meters) in the units.

Can you please give me a hint where to fix that in the driver so that it 
can adequately interpret units of the dimensions?

With best regards!
Anton


From etourigny.dev at gmail.com  Tue Aug  7 04:38:28 2012
From: etourigny.dev at gmail.com (Etienne Tourigny)
Date: Tue, 7 Aug 2012 08:38:28 -0300
Subject: [gdal-dev] Units of dimension variable in NetCDF is 'km'
In-Reply-To: <5020DB8A.1030700@nersc.no>
References: <5020DB8A.1030700@nersc.no>
Message-ID: <CA+TxYvOQZXF=uNZBLxx9zYhwLdUxYPW1ZVTZEyBFEN3d_A+6Jg@mail.gmail.com>

Hi,

km units are supposed to work...

Here is the code where "km" units are detected, which set the WKT
units to 1000m.

            /* add units to PROJCS */
            if ( pszUnits != NULL && ! EQUAL(pszUnits,"") ) {
                if ( EQUAL(pszUnits,"m") ) {
                    oSRS.SetLinearUnits( CF_UNITS_M, 1.0 );
                    oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
                }
                else if ( EQUAL(pszUnits,"km") ) {
                    oSRS.SetLinearUnits( CF_UNITS_M, 1000.0 );
                    oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
                }

What does the wkt actually look like?

Also running gdalinfo --debug ON <file.nc> can give a few hints.

It would be good for you to send me a link to the file or attach it to
a bug report (add me as cc).

Etienne

On Tue, Aug 7, 2012 at 6:10 AM, Anton Korosov <anton.korosov at nersc.no> wrote:
> Dear Etienne,
>
> I faced the following problem with the NetCDF driver:
> Units of the dimension variables are 'km' and values in the SRS are in
> meters, of course (e.g. Earth radius). Hence the calculated GeoTransform is
> 1000 times less than should be and the calculate latlons are incorrect.
> However 'units' attribute is given, besides AFAIK CF-conventions allow to
> have 'k' (kilo) preceding 'm' (meters) in the units.
>
> Can you please give me a hint where to fix that in the driver so that it can
> adequately interpret units of the dimensions?
>
> With best regards!
> Anton
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From etourigny.dev at gmail.com  Tue Aug  7 07:02:31 2012
From: etourigny.dev at gmail.com (Etienne Tourigny)
Date: Tue, 7 Aug 2012 11:02:31 -0300
Subject: [gdal-dev] Units of dimension variable in NetCDF is 'km'
In-Reply-To: <CAJ0mEz01atM6xYdNd+5u+21sxhJ+au_fRbLBZrPzeGHrZ1oq-w@mail.gmail.com>
References: <5020DB8A.1030700@nersc.no>
	<CA+TxYvOQZXF=uNZBLxx9zYhwLdUxYPW1ZVTZEyBFEN3d_A+6Jg@mail.gmail.com>
	<CAJ0mEz01atM6xYdNd+5u+21sxhJ+au_fRbLBZrPzeGHrZ1oq-w@mail.gmail.com>
Message-ID: <CA+TxYvOLFwapuCM71rXVRMB9EUOrTjWKcEBobs6RHi1jRtCCOQ@mail.gmail.com>

Hi Kyle,

Anton identified the problem, the driver assume that x dimension is
named "x", and in his dataset it is named "xc".  The fix you refer to
probably would not work in this case either.

Etienne

On Tue, Aug 7, 2012 at 10:59 AM, Kyle Shannon <kyle at pobox.com> wrote:
> What version are you using?  I seem to remember something like this in a
> ticket I filed.  I thought it was fixed in 1.9.1.
>
> kss
>
> On Tue, Aug 7, 2012 at 5:38 AM, Etienne Tourigny <etourigny.dev at gmail.com>
> wrote:
>>
>> Hi,
>>
>> km units are supposed to work...
>>
>> Here is the code where "km" units are detected, which set the WKT
>> units to 1000m.
>>
>>             /* add units to PROJCS */
>>             if ( pszUnits != NULL && ! EQUAL(pszUnits,"") ) {
>>                 if ( EQUAL(pszUnits,"m") ) {
>>                     oSRS.SetLinearUnits( CF_UNITS_M, 1.0 );
>>                     oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
>>                 }
>>                 else if ( EQUAL(pszUnits,"km") ) {
>>                     oSRS.SetLinearUnits( CF_UNITS_M, 1000.0 );
>>                     oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
>>                 }
>>
>> What does the wkt actually look like?
>>
>> Also running gdalinfo --debug ON <file.nc> can give a few hints.
>>
>> It would be good for you to send me a link to the file or attach it to
>> a bug report (add me as cc).
>>
>> Etienne
>>
>> On Tue, Aug 7, 2012 at 6:10 AM, Anton Korosov <anton.korosov at nersc.no>
>> wrote:
>> > Dear Etienne,
>> >
>> > I faced the following problem with the NetCDF driver:
>> > Units of the dimension variables are 'km' and values in the SRS are in
>> > meters, of course (e.g. Earth radius). Hence the calculated GeoTransform
>> > is
>> > 1000 times less than should be and the calculate latlons are incorrect.
>> > However 'units' attribute is given, besides AFAIK CF-conventions allow
>> > to
>> > have 'k' (kilo) preceding 'm' (meters) in the units.
>> >
>> > Can you please give me a hint where to fix that in the driver so that it
>> > can
>> > adequately interpret units of the dimensions?
>> >
>> > With best regards!
>> > Anton
>> >
>> > _______________________________________________
>> > gdal-dev mailing list
>> > gdal-dev at lists.osgeo.org
>> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>

From kyle at pobox.com  Tue Aug  7 06:59:31 2012
From: kyle at pobox.com (Kyle Shannon)
Date: Tue, 7 Aug 2012 07:59:31 -0600
Subject: [gdal-dev] Units of dimension variable in NetCDF is 'km'
In-Reply-To: <CA+TxYvOQZXF=uNZBLxx9zYhwLdUxYPW1ZVTZEyBFEN3d_A+6Jg@mail.gmail.com>
References: <5020DB8A.1030700@nersc.no>
	<CA+TxYvOQZXF=uNZBLxx9zYhwLdUxYPW1ZVTZEyBFEN3d_A+6Jg@mail.gmail.com>
Message-ID: <CAJ0mEz01atM6xYdNd+5u+21sxhJ+au_fRbLBZrPzeGHrZ1oq-w@mail.gmail.com>

What version are you using?  I seem to remember something like this in a
ticket I filed.  I thought it was fixed in 1.9.1.

kss

On Tue, Aug 7, 2012 at 5:38 AM, Etienne Tourigny <etourigny.dev at gmail.com>wrote:

> Hi,
>
> km units are supposed to work...
>
> Here is the code where "km" units are detected, which set the WKT
> units to 1000m.
>
>             /* add units to PROJCS */
>             if ( pszUnits != NULL && ! EQUAL(pszUnits,"") ) {
>                 if ( EQUAL(pszUnits,"m") ) {
>                     oSRS.SetLinearUnits( CF_UNITS_M, 1.0 );
>                     oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
>                 }
>                 else if ( EQUAL(pszUnits,"km") ) {
>                     oSRS.SetLinearUnits( CF_UNITS_M, 1000.0 );
>                     oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
>                 }
>
> What does the wkt actually look like?
>
> Also running gdalinfo --debug ON <file.nc> can give a few hints.
>
> It would be good for you to send me a link to the file or attach it to
> a bug report (add me as cc).
>
> Etienne
>
> On Tue, Aug 7, 2012 at 6:10 AM, Anton Korosov <anton.korosov at nersc.no>
> wrote:
> > Dear Etienne,
> >
> > I faced the following problem with the NetCDF driver:
> > Units of the dimension variables are 'km' and values in the SRS are in
> > meters, of course (e.g. Earth radius). Hence the calculated GeoTransform
> is
> > 1000 times less than should be and the calculate latlons are incorrect.
> > However 'units' attribute is given, besides AFAIK CF-conventions allow to
> > have 'k' (kilo) preceding 'm' (meters) in the units.
> >
> > Can you please give me a hint where to fix that in the driver so that it
> can
> > adequately interpret units of the dimensions?
> >
> > With best regards!
> > Anton
> >
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120807/7b25b920/attachment.html>

From anton.korosov at nersc.no  Tue Aug  7 08:23:35 2012
From: anton.korosov at nersc.no (Anton Korosov)
Date: Tue, 07 Aug 2012 17:23:35 +0200
Subject: [gdal-dev] Units of dimension variable in NetCDF is 'km'
In-Reply-To: <CA+TxYvMvAQtieXs=byaYV1aCFeEehLFXs6eA8Mi3ZuLySQ1Hiw@mail.gmail.com>
References: <5020DB8A.1030700@nersc.no>
	<CA+TxYvOQZXF=uNZBLxx9zYhwLdUxYPW1ZVTZEyBFEN3d_A+6Jg@mail.gmail.com>
	<50211F43.7040605@nersc.no>
	<CA+TxYvMvAQtieXs=byaYV1aCFeEehLFXs6eA8Mi3ZuLySQ1Hiw@mail.gmail.com>
Message-ID: <502132F7.9000405@nersc.no>

I could not find any. There is a similar bug in DODS driver (it assumes 
'lat' and 'lon' names for dimension variables), but fixing requires 
large update/debugging.

On 08/07/2012 04:01 PM, Etienne Tourigny wrote:
> yes please! are there any other areas which could require a similar fix?
>
> Etienne
>
> On Tue, Aug 7, 2012 at 10:59 AM, Anton Korosov <anton.korosov at nersc.no> wrote:
>> Hi!
>>
>> It seem to work fine with this patch. Should I make a ticket?
>>
>>
>> Index: frmts/netcdf/netcdfdataset.cpp
>> ===================================================================
>> --- frmts/netcdf/netcdfdataset.cpp      (revision 24746)
>> +++ frmts/netcdf/netcdfdataset.cpp      (working copy)
>> @@ -2603,14 +2603,14 @@
>>               const char *pszUnitsX = NULL;
>>               const char *pszUnitsY = NULL;
>>
>> -            strcpy( szTemp, "x" );
>> +            strcpy( szTemp, poDS->papszDimName[nXDimID] );
>>               strcat( szTemp, "#units" );
>>               pszValue = CSLFetchNameValue( poDS->papszMetadata,
>>                                             szTemp );
>>               if( pszValue != NULL )
>>                   pszUnitsX = pszValue;
>>
>> -            strcpy( szTemp, "y" );
>> +            strcpy( szTemp, poDS->papszDimName[nYDimID] );
>>               strcat( szTemp, "#units" );
>>               pszValue = CSLFetchNameValue( poDS->papszMetadata,
>>                                             szTemp );
>>
>>
>>
>> GDAL_netCDF:
>> =====
>> calling nc_open(
>> osisaf-nh_aggregated_ice_concentration_nh_polstere-100_200712010000.nc )
>> GDAL_netCDF: got cdfid=65536
>>
>> GDAL_netCDF: driver detected file type=1, libnetcdf detected type=1
>> GDAL_netCDF: dim_count = 4
>> GDAL_netCDF: var_count = 26
>> GDAL_netCDF: variable #2 [time_bounds] was ignored
>> GDAL_netCDF: variable #6 [lon] was ignored
>> GDAL_netCDF: variable #7 [lat] was ignored
>> GDAL_netCDF:
>> =====
>> SetProjectionFromVar( 10 )
>>
>> GDAL_netCDF: got grid_mapping Polar_Stereographic_Grid
>> GDAL_netCDF: bIsGdalFile=0 bIsGdalCfFile=0 bBottomUp=1
>> GDAL_netCDF: set bBottomUp = 0 from Y axis
>> GDAL_netCDF: setting WKT from CF
>> GDAL_netCDF: SetProjection, WKT = PROJCS["unnamed",GEOGCS["WGS
>> 84",DATUM["WGS_1984",SPHEROID["WGS
>> 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9108"]],AUTHORITY["EPSG","4326"]],PROJECTION["Polar_Stereographic"],PARAMETER["latitude_of_origin",70],PARAMETER["central_meridian",-45],PARAMETER["scale_factor",1],PARAMETER["false_easting",0],PARAMETER["false_northing",0],UNIT["metre",1000,AUTHORITY["EPSG","9001"]]]
>>
>> GDAL_netCDF:
>> SetGeoTransform(-3855.005000,10.000000,0.000000,5844.997000,0.000000,-10.000000)
>> GDAL_netCDF: using variables lon and lat for GEOLOCATION
>> GDAL_netCDF: bGotGeogCS=0 bGotCfSRS=1 bGotCfGT=1 bGotGdalSRS=0 bGotGdalGT=0
>> GDAL:
>> GDALOpen(NETCDF:osisaf-nh_aggregated_ice_concentration_nh_polstere-100_200712010000.nc:ice_conc_avg,
>> this=0x1924f30) succeeds as netCDF.
>>
>> Driver: netCDF/Network Common Data Format
>> GDAL: GDALDefaultOverviews::OverviewScan()
>> Files:
>> osisaf-nh_aggregated_ice_concentration_nh_polstere-100_200712010000.nc
>> Size is 760, 1120
>> Coordinate System is:
>> PROJCS["unnamed",
>>      GEOGCS["WGS 84",
>>          DATUM["WGS_1984",
>>              SPHEROID["WGS 84",6378137,298.257223563,
>>                  AUTHORITY["EPSG","7030"]],
>>              TOWGS84[0,0,0,0,0,0,0],
>>              AUTHORITY["EPSG","6326"]],
>>          PRIMEM["Greenwich",0,
>>              AUTHORITY["EPSG","8901"]],
>>          UNIT["degree",0.0174532925199433,
>>              AUTHORITY["EPSG","9108"]],
>>          AUTHORITY["EPSG","4326"]],
>>      PROJECTION["Polar_Stereographic"],
>>      PARAMETER["latitude_of_origin",70],
>>      PARAMETER["central_meridian",-45],
>>      PARAMETER["scale_factor",1],
>>      PARAMETER["false_easting",0],
>>      PARAMETER["false_northing",0],
>>      UNIT["metre",1000,
>>          AUTHORITY["EPSG","9001"]]]
>>
>> Origin = (-3855.005000000000109,5844.997000000000298)
>> Pixel Size = (10.000000000000000,-10.000000000000000)
>> Metadata:
>>    ice_conc_avg#_FillValue=-1e+10
>>    ice_conc_avg#cell_methods=time: mean
>>    ice_conc_avg#comment=as far as possible, interpolated values from input
>> files are avoided
>>    ice_conc_avg#coordinates=lon lat
>>    ice_conc_avg#grid_mapping=Polar_Stereographic_Grid
>>    ice_conc_avg#long_name=averaged total ice concentration
>>    ice_conc_avg#units=%
>>    ice_conc_avg#valid_max=100
>>    ice_conc_avg#valid_min=0
>>    NC_GLOBAL#abstract=Monthly sea ice concentration estimated from satellite
>> data
>> within the framework of EUMETSAT Ocean and Sea Ice SAF.
>>    NC_GLOBAL#activity_type=Space borne instrument
>>    NC_GLOBAL#area=Northern Hemisphere
>>    NC_GLOBAL#comment=For the OSI SAF daily product the Northern hemisphere
>> polar observation hole and other missing sectors are filled using
>> interpolation. If possible, the averaged monthly sea ice concentration is
>> based on nominal and corrected values only, avoiding the interpolated
>> values.
>>    NC_GLOBAL#contact=osisaf-dev at met.no
>>    NC_GLOBAL#Conventions=CF-1.0
>>    NC_GLOBAL#distribution_statement=Free
>>    NC_GLOBAL#easternmost_longitude=180
>>    NC_GLOBAL#gcmd_keywords=Cryosphere > Sea Ice > Sea Ice Concentration
>> Oceans > Sea Ice > Sea Ice Concentration
>> Cryosphere > Sea Ice > Sea Ice Extent
>> Oceans > Sea Ice > Sea Ice Extent
>> Cryosphere > Sea Ice > Sea Ice Edge
>> Oceans > Sea Ice > Sea Ice Edge
>> Geographical Region > Northern Hemisphere
>> Vertical Location > Sea Surface
>> NO/MET > Norwegian Meteorological Institute, Norway
>>    NC_GLOBAL#history=2010-04-26 creation
>>    NC_GLOBAL#institution=Norwegian Meteorological Institute
>>    NC_GLOBAL#keywords=Monthly Sea Ice Concentration,Monthly Sea Ice
>> Extent,Sea Ice,Oceanography,Meteorology,Climate,Remote Sensing
>>    NC_GLOBAL#northernmost_latitude=90
>>    NC_GLOBAL#PI_name=OSISAF HL Manager
>>    NC_GLOBAL#product_name=EUMETSAT OSISAF sea ice
>>    NC_GLOBAL#product_status=under development
>>    NC_GLOBAL#project_name=CryoClim
>>    NC_GLOBAL#projection=stere
>>    NC_GLOBAL#resolution=10.00 km
>>    NC_GLOBAL#source=EUMETSAT OSISAF ice concentration product
>>    NC_GLOBAL#southernmost_latitude=31.039446
>>    NC_GLOBAL#start_date=2007-12-01 00:00:00 UTC
>>    NC_GLOBAL#stop_date=2008-01-01 00:00:00 UTC
>>    NC_GLOBAL#title=Monthly aggregated sea ice concentration product
>>    NC_GLOBAL#topiccategory=Oceans ClimatologyMeteorologyAtmosphere
>>    NC_GLOBAL#url=http://saf.met.no/, http://cryoclim.met.no/metamod/sch/
>>    NC_GLOBAL#westernmost_longitude=-180
>>    NETCDF_DIM_EXTRA={time}
>>    NETCDF_DIM_time_DEF={1,6}
>>    NETCDF_DIM_time_VALUES=944006400
>>    Polar_Stereographic_Grid#earth_shape=elliptical
>>    Polar_Stereographic_Grid#false_easting=0
>>    Polar_Stereographic_Grid#false_northing=0
>>    Polar_Stereographic_Grid#grid_mapping_name=polar_stereographic
>>    Polar_Stereographic_Grid#latitude_of_projection_origin=90
>>    Polar_Stereographic_Grid#proj4_string=+proj=stere +a=6378273
>> +b=6356889.44891 +lat_0=90 +lat_ts=70 +lon_0=-45
>>    Polar_Stereographic_Grid#standard_parallel=70
>>    Polar_Stereographic_Grid#straight_vertical_longitude_from_pole=-45
>>    time#axis=T
>>    time#bounds=time_bounds
>>    time#comment=The time variable contains the start date of the averaging
>> period.
>>    time#long_name=reference time of product
>>    time#standard_name=time
>>    time#units=seconds since 1978-01-01 00:00:00
>>    xc#axis=X
>>    xc#grid_spacing=10.00 km
>>    xc#long_name=x coordinate of projection (eastings)
>>    xc#standard_name=projection_x_coordinate
>>    xc#units=km
>>    yc#axis=Y
>>    yc#grid_spacing=10.00 km
>>    yc#long_name=y coordinate of projection (northings)
>>    yc#standard_name=projection_y_coordinate
>>    yc#units=km
>> Geolocation:
>>    LINE_OFFSET=0
>>    LINE_STEP=1
>>    PIXEL_OFFSET=0
>>    PIXEL_STEP=1
>>    SRS=GEOGCS["WGS 84",DATUM["WGS_1984",SPHEROID["WGS
>> 84",6378137,298.257223563,AUTHORITY["EPSG","7030"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6326"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9108"]],AUTHORITY["EPSG","4326"]]
>>    X_BAND=1
>>
>> X_DATASET=NETCDF:"osisaf-nh_aggregated_ice_concentration_nh_polstere-100_200712010000.nc":lon
>>    Y_BAND=1
>>
>> Y_DATASET=NETCDF:"osisaf-nh_aggregated_ice_concentration_nh_polstere-100_200712010000.nc":lat
>> OGRCT: Source: +proj=stere +lat_0=90 +lat_ts=70 +lon_0=-45 +k=1 +x_0=0
>> +y_0=0 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=km +no_defs
>>
>> OGRCT: Target: +proj=longlat +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +no_defs
>> Corner Coordinates:
>> Upper Left  (   -3855.005,    5844.997) (168d24'23.11"E, 30d59'22.39"N)
>> Lower Left  (   -3855.005,   -5355.003) ( 80d44'58.84"W, 33d52'24.04"N)
>> Upper Right (    3744.995,    5844.997) (102d21' 5.69"E, 31d24'47.25"N)
>> Lower Right (    3744.995,   -5355.003) ( 10d 1'59.42"W, 34d20' 7.54"N)
>> Center      (     -55.005,     244.997) (147d39'13.75"E, 87d40'56.52"N)
>>
>> Band 1 Block=760x1 Type=Float32, ColorInterp=Undefined
>>    NoData Value=-10000000000
>>    Metadata:
>>      _FillValue=-1e+10
>>      cell_methods=time: mean
>>      comment=as far as possible, interpolated values from input files are
>> avoided
>>      coordinates=lon lat
>>      grid_mapping=Polar_Stereographic_Grid
>>      long_name=averaged total ice concentration
>>      NETCDF_DIM_time=944006400
>>      NETCDF_VARNAME=ice_conc_avg
>>      units=%
>>      valid_max=100
>>      valid_min=0
>> GDAL:
>> GDALClose(NETCDF:osisaf-nh_aggregated_ice_concentration_nh_polstere-100_200712010000.nc:ice_conc_avg,
>> this=0x1924f30)
>>
>>
>>
>>
>>
>> On 08/07/2012 01:38 PM, Etienne Tourigny wrote:
>>>
>>> Hi,
>>>
>>> km units are supposed to work...
>>>
>>> Here is the code where "km" units are detected, which set the WKT
>>> units to 1000m.
>>>
>>>               /* add units to PROJCS */
>>>               if ( pszUnits != NULL && ! EQUAL(pszUnits,"") ) {
>>>                   if ( EQUAL(pszUnits,"m") ) {
>>>                       oSRS.SetLinearUnits( CF_UNITS_M, 1.0 );
>>>                       oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
>>>                   }
>>>                   else if ( EQUAL(pszUnits,"km") ) {
>>>                       oSRS.SetLinearUnits( CF_UNITS_M, 1000.0 );
>>>                       oSRS.SetAuthority( "PROJCS|UNIT", "EPSG", 9001 );
>>>                   }
>>>
>>> What does the wkt actually look like?
>>>
>>> Also running gdalinfo --debug ON <file.nc> can give a few hints.
>>>
>>> It would be good for you to send me a link to the file or attach it to
>>> a bug report (add me as cc).
>>>
>>> Etienne
>>>
>>> On Tue, Aug 7, 2012 at 6:10 AM, Anton Korosov <anton.korosov at nersc.no>
>>> wrote:
>>>>
>>>> Dear Etienne,
>>>>
>>>> I faced the following problem with the NetCDF driver:
>>>> Units of the dimension variables are 'km' and values in the SRS are in
>>>> meters, of course (e.g. Earth radius). Hence the calculated GeoTransform
>>>> is
>>>> 1000 times less than should be and the calculate latlons are incorrect.
>>>> However 'units' attribute is given, besides AFAIK CF-conventions allow to
>>>> have 'k' (kilo) preceding 'm' (meters) in the units.
>>>>
>>>> Can you please give me a hint where to fix that in the driver so that it
>>>> can
>>>> adequately interpret units of the dimensions?
>>>>
>>>> With best regards!
>>>> Anton
>>>>
>>>> _______________________________________________
>>>> gdal-dev mailing list
>>>> gdal-dev at lists.osgeo.org
>>>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>>


From newmanw10 at gmail.com  Tue Aug  7 13:21:08 2012
From: newmanw10 at gmail.com (Billy Newman)
Date: Tue, 7 Aug 2012 14:21:08 -0600
Subject: [gdal-dev] GDAL 64 bit libs for windows
Message-ID: <CAD34qgnZ_i9Mba36OvWtZj0=BmLv-4qGFbk2TubpXv=zjjuzdA@mail.gmail.com>

I recently asked about 32 bit GDAL libs with Java bindings for windows.  I
really need both 32 and 64 bit binaries.

Thanks,
Billy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120807/d80288cd/attachment.html>

From jukka.rahkonen at mmmtike.fi  Tue Aug  7 13:33:43 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Tue, 7 Aug 2012 20:33:43 +0000 (UTC)
Subject: [gdal-dev] GDAL 64 bit libs for windows
References: <CAD34qgnZ_i9Mba36OvWtZj0=BmLv-4qGFbk2TubpXv=zjjuzdA@mail.gmail.com>
Message-ID: <loom.20120807T223317-70@post.gmane.org>

Billy Newman <newmanw10 <at> gmail.com> writes:

> 
> 
> I recently asked about 32 bit GDAL libs with Java bindings for windows. ?I
really need both 32 and 64 bit binaries.

Check http://www.gisinternals.com/sdk/

-Jukka Rahkonen-



From JARED.RUBIN at saic.com  Tue Aug  7 14:03:24 2012
From: JARED.RUBIN at saic.com (Jared Rubin)
Date: Tue, 07 Aug 2012 14:03:24 -0700
Subject: [gdal-dev] looking for GeoTIFF samples with RPC metadata
Message-ID: <CC46D0AC.6130%jared.rubin@saic.com>

I went to the below link and did not find any GeoTIFF with RPC
ftp://ftp.remotesensing.org/pub/geotiff/samples
Does anyone know where there are samples that can be downloaded?
thanks
Jared
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120807/1c801bd1/attachment.html>

From ivan.lucena at princeton-ma.us  Tue Aug  7 14:39:43 2012
From: ivan.lucena at princeton-ma.us (=?iso-8859-1?Q?Ivan=20Lucena?=)
Date: Tue, 07 Aug 2012 16:39:43 -0500
Subject: [gdal-dev]
	=?iso-8859-1?q?looking_for_GeoTIFF_samples_with_RPC_me?=
	=?iso-8859-1?q?tadata?=
In-Reply-To: <CC46D0AC.6130%jared.rubin@saic.com>
References: <CC46D0AC.6130%jared.rubin@saic.com>
Message-ID: <20120807213943.23346.qmail@s466.sureserver.com>

Jared,

You can find some images with RPC from Bolder Colorado USA here:

http://www.digitalglobe.com/product-samples

"Quickbird: Ortho Ready Standard Satellite Imagery"

Be aware of the license.

Regards,

Ivan

>  -------Original Message-------
>  From: Jared Rubin <JARED.RUBIN at saic.com>
>  To: gdal-dev at lists.osgeo.org
>  Subject: [gdal-dev] looking for GeoTIFF samples with RPC metadata
>  Sent: Aug 07 '12 16:03
>  
>  I went to the below link and did not find any GeoTIFF with RPC
>  [LINK: ftp://ftp.remotesensing.org/pub/geotiff/samples]
>  ftp://ftp.remotesensing.org/pub/geotiff/samples
>  Does anyone know where there are samples that can be downloaded?
>  thanks
>  Jared
>  --------------------
>  _______________________________________________
>  gdal-dev mailing list
>  [LINK: compose.php?to=gdal-dev at lists.osgeo.org] gdal-dev at lists.osgeo.org
>  [LINK: http://lists.osgeo.org/mailman/listinfo/gdal-dev]
>  http://lists.osgeo.org/mailman/listinfo/gdal-dev

From warmerdam at pobox.com  Tue Aug  7 16:10:30 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Tue, 7 Aug 2012 16:10:30 -0700
Subject: [gdal-dev] looking for GeoTIFF samples with RPC metadata
In-Reply-To: <20120807213943.23346.qmail@s466.sureserver.com>
References: <CC46D0AC.6130%jared.rubin@saic.com>
	<20120807213943.23346.qmail@s466.sureserver.com>
Message-ID: <CA+YzLBeN7-0RXZaD7Abfrt7e7BH5mq5ZVd8PA0FCFEXRG96=Aw@mail.gmail.com>

On Tue, Aug 7, 2012 at 2:39 PM, Ivan Lucena <ivan.lucena at princeton-ma.us>wrote:

> Jared,
>
> You can find some images with RPC from Bolder Colorado USA here:
>
> http://www.digitalglobe.com/product-samples
>
> "Quickbird: Ortho Ready Standard Satellite Imagery"
>
> Be aware of the license.


Ivan / Jared,

I fetched the dataset and isolated the following file
and it did not have RPCs internally:

05JUL04180116-P2AS-005554608080_01_P001.TIF

I see there is a parallel .RPB and .IMD file which GDAL
reads for metadata but this is *not* an example of the
RPC coefficients within the TIFF file if that is what you
were looking for.

I'm referring to:

  http://geotiff.maptools.org/rpc_prop.html

If that is what you need, let me know and I'll
try to prepare an example if there isn't one
already somewhere.  Note that to GDAL apps
this should look the same as working with the
quickbird image.

Best regards,
-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam,
warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120807/02c32f53/attachment.html>

From ivan.lucena at princeton-ma.us  Tue Aug  7 18:32:38 2012
From: ivan.lucena at princeton-ma.us (Ivan Lucena)
Date: Tue, 07 Aug 2012 21:32:38 -0400
Subject: [gdal-dev] looking for GeoTIFF samples with RPC metadata
In-Reply-To: <CA+YzLBeN7-0RXZaD7Abfrt7e7BH5mq5ZVd8PA0FCFEXRG96=Aw@mail.gmail.com>
References: <CC46D0AC.6130%jared.rubin@saic.com>
	<20120807213943.23346.qmail@s466.sureserver.com>
	<CA+YzLBeN7-0RXZaD7Abfrt7e7BH5mq5ZVd8PA0FCFEXRG96=Aw@mail.gmail.com>
Message-ID: <5021C1B6.4060306@princeton-ma.us>

Hi Frank,

The .RPB are perfect good example of RPC and GDAL reads it pretty well, 
although it is a little bit strange that gdalinfo reports the Reference 
System and GeoTransform matrix completely dissociated from the RPC but I 
think it does makes sense, since most of the applications will not 
process the RPC geometric transformation anyway.

I didn't know that Jared was looking specifically for *internal* RPC 
tags. He just said "GeoTIFF with RPC". If the GTIFF driver could write 
the RPC he could "gdal_translate" (a verb) the .TIF/.RPB to a GeoTiff 
with *internal* RPC. Would that work? By the way, does GDAL support RPC 
on any other file format as auxiliary xml?

Regards,

Ivan

On 8/7/12 7:10 PM, Frank Warmerdam wrote:
>
>
> On Tue, Aug 7, 2012 at 2:39 PM, Ivan Lucena 
> <ivan.lucena at princeton-ma.us <mailto:ivan.lucena at princeton-ma.us>> wrote:
>
>     Jared,
>
>     You can find some images with RPC from Bolder Colorado USA here:
>
>     http://www.digitalglobe.com/product-samples
>
>     "Quickbird: Ortho Ready Standard Satellite Imagery"
>
>     Be aware of the license.
>
>
> Ivan / Jared,
>
> I fetched the dataset and isolated the following file
> and it did not have RPCs internally:
>
> 05JUL04180116-P2AS-005554608080_01_P001.TIF
>
> I see there is a parallel .RPB and .IMD file which GDAL
> reads for metadata but this is *not* an example of the
> RPC coefficients within the TIFF file if that is what you
> were looking for.
>
> I'm referring to:
>
> http://geotiff.maptools.org/rpc_prop.html
>
> If that is what you need, let me know and I'll
> try to prepare an example if there isn't one
> already somewhere.  Note that to GDAL apps
> this should look the same as working with the
> quickbird image.
>
> Best regards,
> -- 
> ---------------------------------------+--------------------------------------
> I set the clouds in motion - turn up   | Frank Warmerdam, 
> warmerdam at pobox.com <mailto:warmerdam at pobox.com>
> light and sound - activate the windows | http://pobox.com/~warmerdam 
> <http://pobox.com/%7Ewarmerdam>
> and watch the world go round - Rush    | Geospatial Software Developer
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120807/304b236b/attachment.html>

From eborovenskiy at scanex.ru  Tue Aug  7 23:24:21 2012
From: eborovenskiy at scanex.ru (Evgeniy Borovenskiy)
Date: Wed, 8 Aug 2012 10:24:21 +0400
Subject: [gdal-dev] Luratech LuraWave JP2 Support in GDAL
Message-ID: <955BDE81516F04498F36F60B0570974979BAD203D3@vrum-exch2>

Good morning,

Could you tell us, please, do you plan the support of LuraWave JP2 in GDAL? And If you're familiar with this library, could you write us please about its advantages and disadvantages. Where does it lose to other libraries, for example KAKADU?

Thank you very much for your reply in advance.



> Best regards,

> Evgeniy Borovenskiy

> ScanEx software developer

> ___________________________________________

>

> RDC ScanEx

> Department of Software Development

> 5/22 Rossolimo Street, Moscow, 119021, Russia

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120808/2f45ba00/attachment-0001.html>

From jukka.rahkonen at mmmtike.fi  Wed Aug  8 01:14:43 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Wed, 8 Aug 2012 08:14:43 +0000 (UTC)
Subject: [gdal-dev] WFS driver does not do URL-encoding right
Message-ID: <loom.20120808T094949-411@post.gmane.org>

Hi,

It looks like it is not possible to use some special characters in filters with
OGR WFS driver.

This command works fine:
http://188.64.1.61/cgi-bin/tinyows -sql "select * from municipalities where
kunta_ni1='Helsinki'"

However, the WFS request fails if I use fore example 'Saarij?rvi' as an
attribute value. The reason is that character '?' does not get URL-encoded into
%C3%A4 as it should in the GetFeature request. This is the request that is sent
to WFS server. 

http://188.64.1.61/cgi-bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=%3CFilter%20xmlns=%22http://www.opengis.net/ogc%22%20xmlns:lv=%22http://latuviitta.fi/%22%20xmlns:gml=%22http://www.opengis.net/gml%22%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ekunta_ni1%3C/PropertyName%3E%3CLiteral%3ESaarij?rvi%3C/Literal%3E%3C/PropertyIsEqualTo%3E%3C/Filter%3E

Placing %C3%A4 into where it belongs makes the request to work.
I am on Windows XP with Finnish default settings.

Is this something worth filing a ticket or what?

-Jukka Rahkonen-


From luca.casagrande at gmail.com  Wed Aug  8 04:22:50 2012
From: luca.casagrande at gmail.com (Luca Casagrande)
Date: Wed, 8 Aug 2012 04:22:50 -0700 (PDT)
Subject: [gdal-dev] WMS description file from gdalinfo output
Message-ID: <1344424970614-4993841.post@n6.nabble.com>

Hello everybody,
using gdalinfo I can get information about a layer from a WMS server.

gdalinfo "WMS:http://localhost/cgi-bin/world/qgis_mapserv.fcgi" -sd 2

I wonder if there's a way to use this output to create a description file
for the WMS service without copying values by hand.

Thx
L. 



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/WMS-description-file-from-gdalinfo-output-tp4993841.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From jzl5325 at psu.edu  Wed Aug  8 09:01:33 2012
From: jzl5325 at psu.edu (Jay L.)
Date: Wed, 8 Aug 2012 09:01:33 -0700
Subject: [gdal-dev] Potential thrashing on Band #
Message-ID: <CA+bfmPuPmJW=OrcdUi5dJsF6nSz5Bt0DWoigh6LRcOgDbk87Lg@mail.gmail.com>

List,

I am receiving the "Potential thrashing on bans x of <image> message doing
some image manipulation using the python bindings.

I am manually setting the cache to 1GB and calling band.FlushCache().  I am
also reading the image at either the block size or multiples of the block
size.

What other techniques exist to reduce the potential to have band thrashing?
 The RasterIO call is the curent bottleneck and I thrashing is not helping
at all.

Best,
Jay
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120808/c7b84f51/attachment.html>

From JARED.RUBIN at saic.com  Wed Aug  8 13:14:40 2012
From: JARED.RUBIN at saic.com (Jared Rubin)
Date: Wed, 08 Aug 2012 13:14:40 -0700
Subject: [gdal-dev] looking for GeoTIFF samples with RPC metadata
In-Reply-To: <5021C1B6.4060306@princeton-ma.us>
Message-ID: <CC4816C0.614D%jared.rubin@saic.com>

Frank,
I was looking for a GeoTIFF file  that would have internal RPC tags without
relying up additional support files (.RPB and .IMD).
I was referring to
http://geotiff.maptools.org/rpc_prop.html
If the above was just a proposed extension to the GeoTIFF 1.0 specification
but did not become official then no need to generate a sample.
On a separate request,  with regards to the following
http://www.remotesensing.org/geotiff/spec/geotiff2.6.html#2.6
do you have any sample GeoTIFFs with the ModelTransformationTag GeoTIFF tag?
All GeoTIFFs that I have seen have the ModelTiepointTag GeoTIFF tag.
Thanks
Jared


On 8/7/12 6:32 PM, "Ivan Lucena" <ivan.lucena at princeton-ma.us> wrote:

>    
> Hi Frank,
>  
>  The .RPB are perfect good example of RPC and GDAL reads it pretty well,
> although it is a little bit strange that gdalinfo reports the Reference System
> and GeoTransform matrix completely dissociated from the RPC but I think it
> does makes sense, since most of the applications will not process the RPC
> geometric transformation anyway.
>  
>  I didn't know that Jared was looking specifically for *internal* RPC tags. He
> just said "GeoTIFF with RPC". If the GTIFF driver could write the RPC he could
> "gdal_translate" (a verb) the .TIF/.RPB to a GeoTiff with *internal* RPC.
> Would that work? By the way, does GDAL support RPC on any other file format as
> auxiliary xml?
>  
>  Regards,
>  
>  Ivan 
>  
>  On 8/7/12 7:10 PM, Frank Warmerdam wrote:
>  
>  
>> 
>>  
>>  
>> On Tue, Aug 7, 2012 at 2:39 PM, Ivan Lucena <ivan.lucena at princeton-ma.us>
>> wrote:
>>  
>>>  Jared,
>>>  
>>>  You can find some images with RPC from Bolder Colorado USA here:
>>>  
>>>  http://www.digitalglobe.com/product-samples
>>>  
>>>  "Quickbird: Ortho Ready Standard Satellite Imagery"
>>>  
>>>  Be aware of the license.
>>  
>> 
>>  
>>  
>> Ivan / Jared,
>>  
>> 
>>  
>>  
>> I fetched the dataset and isolated the following file
>>  
>> and it did not have RPCs internally:
>>  
>> 
>>  
>>  
>>  05JUL04180116-P2AS-005554608080_01_P001.TIF
>>  
>> 
>>  
>>  
>> I see there is a parallel .RPB and .IMD file which GDAL
>>  
>> reads for metadata but this is *not* an example of the
>>  
>> RPC coefficients within the TIFF file if that is what you
>>  
>> were looking for.
>>  
>> 
>>  
>>  
>> I'm referring to:
>>  
>> 
>>  
>>  
>>   http://geotiff.maptools.org/rpc_prop.html
>>  
>> 
>>  
>>  
>>  If that is what you need, let me know and I'll
>>  
>> try to prepare an example if there isn't one
>>  
>> already somewhere.  Note that to GDAL apps
>>  
>> this should look the same as working with the
>>  
>> quickbird image.
>>  
>> 
>>  
>>  
>> Best regards,
>>  
>>  -- 
>> 
---------------------------------------+------------------------------------->>
-
>>  I set the clouds in motion - turn up   | Frank Warmerdam,
>> warmerdam at pobox.com
>>  light and sound - activate the windows | http://pobox.com/~warmerdam
>> <http://pobox.com/%7Ewarmerdam>
>>  and watch the world go round - Rush    | Geospatial Software Developer
>>  
>>  
>  
>  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120808/4e7ee1dd/attachment.html>

From rveciana at gmail.com  Wed Aug  8 13:46:44 2012
From: rveciana at gmail.com (Roger Veciana i Rovira)
Date: Wed, 8 Aug 2012 22:46:44 +0200
Subject: [gdal-dev] Vaisala IRIS format driver
Message-ID: <CAJx2no=6L93sMP4eZOYMhp4iap88TJB1aikP6c7wqSUk64aesg@mail.gmail.com>

Hello,

I have almost finished a GDAL driver for the weather radar format
IRIS, from the VAISALA company.
The documentation about the IRIS system and format can be found here:
http://www.vaisala.com/en/meteorology/products/weatherradars/Pages/IRIS.aspx

I can submit the files with the X/MIT licence, and I've tested the
driver with both Linux and Windows.

By now, I have tested the driver with the following radar products:

PPI (reflectivity and speed)
CAPPI
RAIN1
RAINN
TOPS
VIL
MAX

The driver reads the ellipsoid (although the format doesn't provide
its name), and can work, currently, with Azimuthal Equidistant and
Mercator projections.

Does somebody else in the GDAL community finds this driver interesting?
I am looking for more sample files, since I've tested only the ones
from the radar network I work with. Could somebody provide me few to
test? I would appreciate specially checking other projections, not
implemented only because I haven't got the sample files.
Does somebody works with a product not listed above?

If somebody sends me some file or has some comment, I'll try to
implement it before uploading the files into the Trac.



Roger

From giuseppe.amatulli at gmail.com  Wed Aug  8 15:42:48 2012
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Wed, 8 Aug 2012 17:42:48 -0500
Subject: [gdal-dev] count unique combination in 2 tifs
Message-ID: <CAKoiDHKjhJFwxWJ3QfOQd-EnZQ_xfqY-25dhUodn3i5Wra1guA@mail.gmail.com>

Hi,
having 2 integer Tif file (Rast00 , Rast10)

Rast00= 1,2,4,4,5,4,1,4,1,1,4,0
Rast10= 0,2,3,5,4,4,1,4,2,1,3,4

I need to exclude the no-data (0) and calculate unique combination in
pairs and count the observations
in order to obtain  something like this?
(2,2,1)
(4,3,2)
(4,5,1)
(5,4,1)
(4,4,2)
(1,1,2)
(1,2,1)
and save to a txt file:

I identify two ways:

First option (faster)

Rast00=dsRast00.GetRasterBand(1).ReadAsArray()
Rast10=dsRast10.GetRasterBand(1).ReadAsArray()

mask=( Rast00 != 0 ) & ( Rast10 != 0  )

Rast00_mask= Rast00[mask]
Rast10_mask= Rast10[mask]

array2D = np.array(zip( Rast00_mask,Rast10_mask))

unique=dict()
for row in  array2D :
    row = tuple(row)
    if row in unique:
        unique[row] += 1
    else:
        unique[row] = 1

print unique
(how to save unique to a txt file without dictionary format? )

Second option (slower)

Rast00=dsRast00.GetRasterBand(1).ReadAsArray()
Rast10=dsRast10.GetRasterBand(1).ReadAsArray()

array2D=np.array(zip(np.concatenate(Rast00),np.concatenate(Rast10)))
Rast00
unique=dict()
for row in  array2D :
    row = tuple(row)
    if row[0] != 0 :
        if row[1] != 0 :
            if row in unique:
                unique[row] += 1
            else:
                unique[row] = 1
print unique
(how to save unique to a txt file without dictionary format? )

In reality i was suppose the second option faster than the first one
because the Rast00 & Rast10 array were read only ones in the second
option, but this is not the case.
Is there a way to speed up the process?
I also try
1) to read the tif row by row
2) and create array index rather than unique=dict()
but the speeding is not improve.
Any suggestions are well come?
Thanks
-- 
Giuseppe Amatulli
Web: www.spatial-ecology.net

From pwheeler at digitalglobe.com  Thu Aug  9 06:58:57 2012
From: pwheeler at digitalglobe.com (Paul Wheeler)
Date: Thu, 9 Aug 2012 07:58:57 -0600
Subject: [gdal-dev]  ogr_OCI plugin can't find OCI.dll
Message-ID: <C1BF1C58F42A304A899E2933C220F48A0BE1A12B@COMAIL02.digitalglobe.com>

How do I get the answer to this question, I am having the same problem

 

Paul Wheeler

ETL Developer  



Office: 303.684.1321

Mobile: 620.717.1015


 
www.digitalglobe.com <http://www.digitalglobe.com/> 

 


This electronic communication and any attachments may contain confidential and proprietary 
information of DigitalGlobe, Inc. If you are not the intended recipient, or an agent or employee 
responsible for delivering this communication to the intended recipient, or if you have received 
this communication in error, please do not print, copy, retransmit, disseminate or 
otherwise use the information. Please indicate to the sender that you have received this 
communication in error, and delete the copy you received. DigitalGlobe reserves the 
right to monitor any electronic communication sent or received by its employees, agents 
or representatives.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120809/b3ed3001/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 575 bytes
Desc: image001.png
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120809/b3ed3001/attachment.png>

From ivan.lucena at princeton-ma.us  Thu Aug  9 07:17:24 2012
From: ivan.lucena at princeton-ma.us (=?iso-8859-1?Q?Ivan=20Lucena?=)
Date: Thu, 09 Aug 2012 09:17:24 -0500
Subject: [gdal-dev]
	=?iso-8859-1?q?ogr=5FOCI_plugin_can=27t_find_OCI=2Edll?=
In-Reply-To: <C1BF1C58F42A304A899E2933C220F48A0BE1A12B@COMAIL02.digitalglobe.com>
References: <C1BF1C58F42A304A899E2933C220F48A0BE1A12B@COMAIL02.digitalglobe.com>
Message-ID: <20120809141725.6996.qmail@s466.sureserver.com>

Hi Paul,

I am not sure I understood the question but what I know is that your PATH variable should have the folder where OCI.DLL is installed. For example:

C:\> echo %PATH%
<some folder here>;C:\Oracle11\product\11.2.0\dbhome_1\bin\oci.dll;<some folder here>

You might *not* have an Oracle client, Instant Client or Server installed on your system.

That could be the problem too.

Regards,

Ivan


>  -------Original Message-------
>  From: Paul Wheeler <pwheeler at digitalglobe.com>
>  To: gdal-dev at lists.osgeo.org
>  Subject: [gdal-dev] ogr_OCI plugin can't find OCI.dll
>  Sent: Aug 09 '12 08:58
>  
>  How do I get the answer to this question, I am having the same problem
>  
>  
>  PAUL WHEELER
>  
>  ETL Developer
>  
>  
>  OFFICE: 303.684.1321
>  
>  MOBILE: 620.717.1015
>  
>  
>  [LINK: http://www.digitalglobe.com/] www.digitalglobe.com
>  
>  
>  This electronic communication and any attachments may contain confidential
>  and proprietary  information of DigitalGlobe, Inc. If you are not the
>  intended recipient, or an agent or employee  responsible for delivering
>  this communication to the intended recipient, or if you have received  this
>  communication in error, please do not print, copy, retransmit, disseminate
>  or  otherwise use the information. Please indicate to the sender that you
>  have received this  communication in error, and delete the copy you
>  received. DigitalGlobe reserves the  right to monitor any electronic
>  communication sent or received by its employees, agents  or
>  representatives.
>  --------------------
>  _______________________________________________
>  gdal-dev mailing list
>  [LINK: compose.php?to=gdal-dev at lists.osgeo.org] gdal-dev at lists.osgeo.org
>  [LINK: http://lists.osgeo.org/mailman/listinfo/gdal-dev]
>  http://lists.osgeo.org/mailman/listinfo/gdal-dev

From kassies at gmail.com  Fri Aug 10 06:34:21 2012
From: kassies at gmail.com (Rutger)
Date: Fri, 10 Aug 2012 06:34:21 -0700 (PDT)
Subject: [gdal-dev] count unique combination in 2 tifs
In-Reply-To: <CAKoiDHKjhJFwxWJ3QfOQd-EnZQ_xfqY-25dhUodn3i5Wra1guA@mail.gmail.com>
References: <CAKoiDHKjhJFwxWJ3QfOQd-EnZQ_xfqY-25dhUodn3i5Wra1guA@mail.gmail.com>
Message-ID: <1344605661791-4994407.post@n6.nabble.com>

Hey,

If youre example data is realistic, or if you know the range of values on
forehand, this might work:

/a = np.random.randint(0,5,(5,5)) # generate some example data between 0 and
5
b = np.random.randint(0,5,(5,5)) # generate some example data between 0 and
5

# create a new array with the unique combinations, if your maximum value is
above 10, raise the multiplier accordingly
c = np.where(np.logical_and(a!=0,b!=0),a * 10 + b,0)

bins, hist = np.histogram(c,bins=56, range=(0,56))/

View the results with something like:
/for i in np.arange(len(hist)):
    combo = str(i).rjust(2,'0')
    print combo[0],combo[1], hist[i]/

Regards,
Rutger



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/gdal-dev-count-unique-combination-in-2-tifs-tp4993978p4994407.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From jorgearevalo at libregis.org  Fri Aug 10 08:38:53 2012
From: jorgearevalo at libregis.org (Jorge Arevalo)
Date: Fri, 10 Aug 2012 17:38:53 +0200
Subject: [gdal-dev] What should I expect?
Message-ID: <CAMhtMNOtpTu_pJhe0rGOqv1XCrJAoPYXdMuyL3dvO+fE4wZ2Yw@mail.gmail.com>

Hello,

If while I'm executing gdalinfo against a raster layer I get a
positive value for pixel size Y, what of these scenarios is possible?

- The raster's map coordinate system sets the origin of the data in
the upper left corner.
- The raster is not georeferenced and its coordinates are interpreted
as image pixels, instead of map units.
- Any other situation (corrupt file?, other?)

I know this value is almost always negative. For example, in case of
UTM coordinate system. But, how common is to have a positive value for
Y coordinate?

Many thanks in advance

-- 
Jorge Arevalo
http://www.libregis.org

From chapmanm at pixia.com  Fri Aug 10 09:09:52 2012
From: chapmanm at pixia.com (Martin Chapman)
Date: Fri, 10 Aug 2012 12:09:52 -0400 (EDT)
Subject: [gdal-dev] What should I expect?
In-Reply-To: <CAMhtMNOtpTu_pJhe0rGOqv1XCrJAoPYXdMuyL3dvO+fE4wZ2Yw@mail.gmail.com>
References: <CAMhtMNOtpTu_pJhe0rGOqv1XCrJAoPYXdMuyL3dvO+fE4wZ2Yw@mail.gmail.com>
Message-ID: <54403820.000010f8.0000000a@CHAPMANM7S>

Jorge,

It's a south up image.  If the gsd x value is negative the image is an
east to west image.  Normally a north up image will have a positive gsd x
and a negative gsd y.

Marty

-----Original Message-----
From: gdal-dev-bounces at lists.osgeo.org
[mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of Jorge Arevalo
Sent: Friday, August 10, 2012 9:39 AM
To: gdal-dev at lists.osgeo.org
Subject: [gdal-dev] What should I expect?

Hello,

If while I'm executing gdalinfo against a raster layer I get a positive
value for pixel size Y, what of these scenarios is possible?

- The raster's map coordinate system sets the origin of the data in the
upper left corner.
- The raster is not georeferenced and its coordinates are interpreted as
image pixels, instead of map units.
- Any other situation (corrupt file?, other?)

I know this value is almost always negative. For example, in case of UTM
coordinate system. But, how common is to have a positive value for Y
coordinate?

Many thanks in advance

--
Jorge Arevalo
http://www.libregis.org
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
http://lists.osgeo.org/mailman/listinfo/gdal-dev

From jorgearevalo at libregis.org  Fri Aug 10 13:28:34 2012
From: jorgearevalo at libregis.org (Jorge Arevalo)
Date: Fri, 10 Aug 2012 22:28:34 +0200
Subject: [gdal-dev] What should I expect?
In-Reply-To: <54403820.000010f8.0000000a@CHAPMANM7S>
References: <CAMhtMNOtpTu_pJhe0rGOqv1XCrJAoPYXdMuyL3dvO+fE4wZ2Yw@mail.gmail.com>
	<54403820.000010f8.0000000a@CHAPMANM7S>
Message-ID: <CAMhtMNOv_qL2GpjomaN0rmtE9fkNp_CBmW911=13iKm8NcVjqw@mail.gmail.com>

Hi,

Many thanks for your response, Martin. So, it doesn't need to be a
mistake. Just a flipped image.

The doubt raised because, for example, gdalbuildvrt doesn't accept ns
positive resolution values. Looking at this old ticket
http://trac.osgeo.org/gdal/ticket/3432, seems that that kind of raster
data can't be mosaiced. You get an error. I don't understand why.

I know cartesian coordinate system sets the origin in the bottom left
corner, while images set the origin in the top left  corner. So, the
ns resolution of a georeferenced image is negative. Otherwise, you get
a south up image. But... if all the images you want to mosaic have
this "problem" (positive ns resolution), why I can't mosaic them using
gdalbuiltvrt?

Best regards,
Jorge

On Fri, Aug 10, 2012 at 6:09 PM, Martin Chapman <chapmanm at pixia.com> wrote:
> Jorge,
>
> It's a south up image.  If the gsd x value is negative the image is an
> east to west image.  Normally a north up image will have a positive gsd x
> and a negative gsd y.
>
> Marty
>
> -----Original Message-----
> From: gdal-dev-bounces at lists.osgeo.org
> [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of Jorge Arevalo
> Sent: Friday, August 10, 2012 9:39 AM
> To: gdal-dev at lists.osgeo.org
> Subject: [gdal-dev] What should I expect?
>
> Hello,
>
> If while I'm executing gdalinfo against a raster layer I get a positive
> value for pixel size Y, what of these scenarios is possible?
>
> - The raster's map coordinate system sets the origin of the data in the
> upper left corner.
> - The raster is not georeferenced and its coordinates are interpreted as
> image pixels, instead of map units.
> - Any other situation (corrupt file?, other?)
>
> I know this value is almost always negative. For example, in case of UTM
> coordinate system. But, how common is to have a positive value for Y
> coordinate?
>
> Many thanks in advance
>
> --
> Jorge Arevalo
> http://www.libregis.org
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Jorge Arevalo
http://www.libregis.org

From ari.jolma at gmail.com  Sat Aug 11 02:26:02 2012
From: ari.jolma at gmail.com (Ari Jolma)
Date: Sat, 11 Aug 2012 12:26:02 +0300
Subject: [gdal-dev] RFC 39, layer algebra in trunk
In-Reply-To: <501F7FEE.6000801@gmail.com>
References: <501F7FEE.6000801@gmail.com>
Message-ID: <5026252A.30506@gmail.com>

On 08/06/2012 11:27 AM, Ari Jolma wrote:
> I've also started a wiki page for describing the method set in more 
> detail http://trac.osgeo.org/gdal/wiki/LayerAlgebra (linked to page 
> http://trac.osgeo.org/gdal/wiki/CodeSnippets since that seemed to me 
> as the best place).

I've finished making a first version of this wiki page and while making 
it I found out that the Clip method was not doing at all what it was 
supposed to do. I've fixed that. Also, I found out that the Union method 
may produce features with empty geometries (#4772). I believe more 
testing is needed. Also, I guess the explanations and examples in the 
wiki page could be improved (ideas? complaints?).

Regards,

Ari


From even.rouault at mines-paris.org  Sat Aug 11 07:38:58 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 11 Aug 2012 16:38:58 +0200
Subject: [gdal-dev] urn and geojson
In-Reply-To: <CACPZzQ1a9e2v6Q=hT5JN75VNri9+DQTx1y8iiJ=pMWLyvwgfcQ@mail.gmail.com>
References: <CACPZzQ1a9e2v6Q=hT5JN75VNri9+DQTx1y8iiJ=pMWLyvwgfcQ@mail.gmail.com>
Message-ID: <201208111638.59179.even.rouault@mines-paris.org>

Le dimanche 05 ao?t 2012 22:58:29, Thomas Gratier a ?crit :
> Hello,
> 
> I'm playing around with geojson and I haven't found any clue on the doc e.g
> http://www.gdal.org/ogr/drv_geojson.html about including urn in geojson
> output.
> I think it can be useful for sharing geojson and without urn, finding
> projection isn't really possible.
> Does I miss the feature? There is a roadmap about this?
> The form I 'm expecting look like urn:ogc:def:crs:EPSG::26912 (following
> this discussion
> http://gis.stackexchange.com/questions/15953/whats-up-with-the-geojson-spec
> -and-crs-as-a-irmand the official spec
> http://www.geojson.org/geojson-spec.html#named-crs)<http://www.geojson.org/
> geojson-spec.html#named-crs>

Yes, indeed read support for CRS is there, but write support is missing. 
Please file a ticket in Trac about that.

> 
> Regards
> 
> ThomasG

From even.rouault at mines-paris.org  Sat Aug 11 07:42:15 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 11 Aug 2012 16:42:15 +0200
Subject: [gdal-dev] WMS description file from gdalinfo output
In-Reply-To: <1344424970614-4993841.post@n6.nabble.com>
References: <1344424970614-4993841.post@n6.nabble.com>
Message-ID: <201208111642.15181.even.rouault@mines-paris.org>

Le mercredi 08 ao?t 2012 13:22:50, Luca Casagrande a ?crit :
> Hello everybody,
> using gdalinfo I can get information about a layer from a WMS server.
> 
> gdalinfo "WMS:http://localhost/cgi-bin/world/qgis_mapserv.fcgi" -sd 2
> 
> I wonder if there's a way to use this output to create a description file
> for the WMS service without copying values by hand.

You can use the subdataset name as a valid connexion string, or you can 
generate a XML description file from the subdataset name with something like :

gdal_translate 
"WMS:http://demo.opengeo.org/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=og:0&SRS=EPSG:4326&BBOX=-180.0,-90.000000000036,180.000000000072,90.0" 
out.xml -of WMS

From even.rouault at mines-paris.org  Sat Aug 11 07:46:20 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 11 Aug 2012 16:46:20 +0200
Subject: [gdal-dev] What should I expect?
In-Reply-To: <CAMhtMNOv_qL2GpjomaN0rmtE9fkNp_CBmW911=13iKm8NcVjqw@mail.gmail.com>
References: <CAMhtMNOtpTu_pJhe0rGOqv1XCrJAoPYXdMuyL3dvO+fE4wZ2Yw@mail.gmail.com>
	<54403820.000010f8.0000000a@CHAPMANM7S>
	<CAMhtMNOv_qL2GpjomaN0rmtE9fkNp_CBmW911=13iKm8NcVjqw@mail.gmail.com>
Message-ID: <201208111646.20680.even.rouault@mines-paris.org>

Le vendredi 10 ao?t 2012 22:28:34, Jorge Arevalo a ?crit :
> Hi,
> 
> Many thanks for your response, Martin. So, it doesn't need to be a
> mistake. Just a flipped image.
> 
> The doubt raised because, for example, gdalbuildvrt doesn't accept ns
> positive resolution values. Looking at this old ticket
> http://trac.osgeo.org/gdal/ticket/3432, seems that that kind of raster
> data can't be mosaiced. You get an error. I don't understand why.
> 
> I know cartesian coordinate system sets the origin in the bottom left
> corner, while images set the origin in the top left  corner. So, the
> ns resolution of a georeferenced image is negative. Otherwise, you get
> a south up image. But... if all the images you want to mosaic have
> this "problem" (positive ns resolution), why I can't mosaic them using
> gdalbuiltvrt?

Jorge,

You could certainly remove this limitation of gdalbuildvrt. I put it because 
I'm lazy and don't usually deal with south-up images (and because images with 
postive ns resolution are in 99% of the cases in fact ungeoreferenced images, 
which you don't want to mosaic). I suspect that just removing the test might 
make things work. I let you experiment with that.

From even.rouault at mines-paris.org  Sat Aug 11 09:45:57 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 11 Aug 2012 18:45:57 +0200
Subject: [gdal-dev] Potential thrashing on Band #
In-Reply-To: <CA+bfmPuPmJW=OrcdUi5dJsF6nSz5Bt0DWoigh6LRcOgDbk87Lg@mail.gmail.com>
References: <CA+bfmPuPmJW=OrcdUi5dJsF6nSz5Bt0DWoigh6LRcOgDbk87Lg@mail.gmail.com>
Message-ID: <201208111845.57714.even.rouault@mines-paris.org>

Le mercredi 08 ao?t 2012 18:01:33, Jay L. a ?crit :
> List,
> 
> I am receiving the "Potential thrashing on bans x of <image> message doing
> some image manipulation using the python bindings.
> 
> I am manually setting the cache to 1GB and calling band.FlushCache().  I am
> also reading the image at either the block size or multiples of the block
> size.
> 
> What other techniques exist to reduce the potential to have band thrashing?
>  The RasterIO call is the curent bottleneck and I thrashing is not helping
> at all.

Unless you experiment severe performance problems, you can ignore this debug 
message. If your algorithm reads several times the whole image, even while 
being careful of aligning on blocks etc.., the warning will be emitted. It is 
just a hint, not something 100% reliable.

> 
> Best,
> Jay

From even.rouault at mines-paris.org  Sat Aug 11 09:58:15 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 11 Aug 2012 18:58:15 +0200
Subject: [gdal-dev] How to give additional WFS parameters right?
In-Reply-To: <loom.20120804T173911-178@post.gmane.org>
References: <loom.20120804T172335-967@post.gmane.org>
	<loom.20120804T173911-178@post.gmane.org>
Message-ID: <201208111858.15334.even.rouault@mines-paris.org>

Le samedi 04 ao?t 2012 17:42:54, Jukka Rahkonen a ?crit :
> Ok,
> Inserting WFS source between "" helped with command line (I am on
> Windows as usual").
> 
> ogr2ogr -f GML test2.txt "wfs:http://hip.latuviitta.org/cgi-bin/
> tinyows?SERVICE=WFS&VERSION=1.1.0&TYPENAME=
> lv:hki_parkkilippuautomaatit&MAXFEATURES=2"
> 
> The XML definition file overwrite problem is left.

I think the problem is just that you didn't XML-escaped the value of the URL 
element, namely the & character must be written as &amp; 

I've updated the doc to make that more obvious (and fix the example where it 
wasn't done before OPTIONNAL_PARAMETER2 ) 

> 
> -Jukka-
> 
> 
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120811/81a8d92c/attachment.html>

From even.rouault at mines-paris.org  Sat Aug 11 11:05:49 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 11 Aug 2012 20:05:49 +0200
Subject: [gdal-dev] Topology Exceptions on Non-Noded Intersections
In-Reply-To: <000101cd743e$ea6822e0$bf3868a0$@nc.rr.com>
References: <000001cd7436$b76ef290$264cd7b0$@nc.rr.com>
	<CACqBkM8b2rjDOm+jwY=FbMxoGKjB3j5Sbkqf2288T3ERXHE7Pw@mail.gmail.com>
	<000101cd743e$ea6822e0$bf3868a0$@nc.rr.com>
Message-ID: <201208112005.49833.even.rouault@mines-paris.org>

Le mardi 07 ao?t 2012 03:49:41, Sina Bahram a ?crit :
> Eli,
> 
> Sounds like the same problem to me, yes. thank you for finding that.
> 
> However, now I'm still left wondering about implementing the fix.
> 
> As I said in the StackExchange question, I think wrapdateline should fix
> this, but if not is there an easy way to split polygons along the
> dateline?
> 
> Thanks for the response to this.

The TopologyException error comes from the GEOS library. You might need to 
upgrade your GEOS to a newer version and see if it helps.

I've downloaded the 
http://thematicmapping.org/downloads/TM_WORLD_BORDERS-0.3.zip dataset and 
tried -wrapdateline on it. It works great. Except that it is not needed at all 
since the longitudes of the dataset are between -180 and 180, so there's 
nothing to wrap at all...

> 
> Take care,
> Sina
> 
> 
> Website: www.SinaBahram.com
> Twitter: @SinaBahram
> 
> 
> -----Original Message-----
> From: Eli Adam [mailto:eadam at co.lincoln.or.us]
> Sent: Monday, August 06, 2012 9:19 PM
> To: Sina Bahram
> Subject: Re: [gdal-dev] Topology Exceptions on Non-Noded Intersections
> 
> This is about Google Earth not Google Maps, but there may be something
> relevant here, http://blog.opengeo.org/2010/08/10/shape-of-a-polygon/
> 
> Eli
> 
> On Mon, Aug 6, 2012 at 5:50 PM, Sina Bahram <sbahram at nc.rr.com> wrote:
> > Hello,
> > 
> > I receive the following errors with the -wrapdateline argument.
> > 
> > ERROR 1: TopologyException: found non-noded intersection between
> > LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING
> 
> (0
> 
> > -73.1221, -89.3211 -73.0542) at -59.8141 -73.0766
> > ERROR 1: TopologyException: found non-noded intersection between
> > LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING (180
> > -73.2589, -89.3211 -73.0542) at -59.8141 -73.0766
> > 
> > More details can be found on this question I asked:
> > http://gis.stackexchange.com/questions/30922/how-do-i-split-polygons-that
> > -cross-the-dateline
> > 
> > any advice?
> > 
> > Thanks
> > 
> > Take care,
> > Sina
> > 
> > Website: www.SinaBahram.com
> > Twitter: @SinaBahram
> > 
> > 
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From sbahram at nc.rr.com  Sat Aug 11 12:33:06 2012
From: sbahram at nc.rr.com (Sina Bahram)
Date: Sat, 11 Aug 2012 15:33:06 -0400
Subject: [gdal-dev] Topology Exceptions on Non-Noded Intersections
In-Reply-To: <201208112005.49833.even.rouault@mines-paris.org>
References: <000001cd7436$b76ef290$264cd7b0$@nc.rr.com>
	<CACqBkM8b2rjDOm+jwY=FbMxoGKjB3j5Sbkqf2288T3ERXHE7Pw@mail.gmail.com>
	<000101cd743e$ea6822e0$bf3868a0$@nc.rr.com>
	<201208112005.49833.even.rouault@mines-paris.org>
Message-ID: <000b01cd77f8$25593350$700b99f0$@nc.rr.com>

Then maybe I am explaining this problem wrong. If a polygon contains points that are close to -180 and 180 then things like MapKit
on IOS don't paint it correctly, instead taking the portion that crosses the line and stretching it around the world. In other
words, the shortest distance between something like -178 and 178 is not of length 4 but greater than 300 as it wraps around.

Is there a different solution that I can try to fix this problem?

Thank you for letting me know about GEOS possibly being out of date. I suppose I'll need to build that from source to get any newer,
as that's the latest in Ubuntu 12.04s repository.

Also, thank you for taking the time to download that dataset and try it out.

I've updated the StackExchange question with your findings:
http://gis.stackexchange.com/questions/30922/how-do-i-split-polygons-that-cross-the-dateline

any thoughts on how to fix this problem?

Take care,
Sina

Website: www.SinaBahram.com
Twitter: @SinaBahram

-----Original Message-----
From: Even Rouault [mailto:even.rouault at mines-paris.org] 
Sent: Saturday, August 11, 2012 2:06 PM
To: gdal-dev at lists.osgeo.org
Cc: Sina Bahram
Subject: Re: [gdal-dev] Topology Exceptions on Non-Noded Intersections

Le mardi 07 ao?t 2012 03:49:41, Sina Bahram a ?crit :
> Eli,
> 
> Sounds like the same problem to me, yes. thank you for finding that.
> 
> However, now I'm still left wondering about implementing the fix.
> 
> As I said in the StackExchange question, I think wrapdateline should fix
> this, but if not is there an easy way to split polygons along the
> dateline?
> 
> Thanks for the response to this.

The TopologyException error comes from the GEOS library. You might need to 
upgrade your GEOS to a newer version and see if it helps.

I've downloaded the 
http://thematicmapping.org/downloads/TM_WORLD_BORDERS-0.3.zip dataset and 
tried -wrapdateline on it. It works great. Except that it is not needed at all 
since the longitudes of the dataset are between -180 and 180, so there's 
nothing to wrap at all...

> 
> Take care,
> Sina
> 
> 
> Website: www.SinaBahram.com
> Twitter: @SinaBahram
> 
> 
> -----Original Message-----
> From: Eli Adam [mailto:eadam at co.lincoln.or.us]
> Sent: Monday, August 06, 2012 9:19 PM
> To: Sina Bahram
> Subject: Re: [gdal-dev] Topology Exceptions on Non-Noded Intersections
> 
> This is about Google Earth not Google Maps, but there may be something
> relevant here, http://blog.opengeo.org/2010/08/10/shape-of-a-polygon/
> 
> Eli
> 
> On Mon, Aug 6, 2012 at 5:50 PM, Sina Bahram <sbahram at nc.rr.com> wrote:
> > Hello,
> > 
> > I receive the following errors with the -wrapdateline argument.
> > 
> > ERROR 1: TopologyException: found non-noded intersection between
> > LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING
> 
> (0
> 
> > -73.1221, -89.3211 -73.0542) at -59.8141 -73.0766
> > ERROR 1: TopologyException: found non-noded intersection between
> > LINESTRING (-59.7742 -72.9003, -59.8494 -73.2331) and LINESTRING (180
> > -73.2589, -89.3211 -73.0542) at -59.8141 -73.0766
> > 
> > More details can be found on this question I asked:
> > http://gis.stackexchange.com/questions/30922/how-do-i-split-polygons-that
> > -cross-the-dateline
> > 
> > any advice?
> > 
> > Thanks
> > 
> > Take care,
> > Sina
> > 
> > Website: www.SinaBahram.com
> > Twitter: @SinaBahram
> > 
> > 
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev


From ari.jolma at gmail.com  Sat Aug 11 13:19:00 2012
From: ari.jolma at gmail.com (Ari Jolma)
Date: Sat, 11 Aug 2012 23:19:00 +0300
Subject: [gdal-dev] [GDAL] callback.i missing
In-Reply-To: <201208111700.09094.even.rouault@mines-paris.org>
References: <201208111700.09094.even.rouault@mines-paris.org>
Message-ID: <5026BE34.9000002@gmail.com>

On 08/11/2012 06:00 PM, Even Rouault wrote:
> Hi Ari,
>
> I think you have not committed swig/include/python/callback.i , which might
> explain why Tamas buildbot currently fail when regenerating the python
> bindings : http://www.gisinternals.com/sdk/build-
> output/vc7-20120811-4-12-56-09-vc7-dev-err.txt

Sorry. Committed now.

Ari

>
> Best regards,
>
> Even


From even.rouault at mines-paris.org  Sun Aug 12 13:04:15 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sun, 12 Aug 2012 22:04:15 +0200
Subject: [gdal-dev] 'Polygons as multipolygons' option for OSM driver
In-Reply-To: <1343897424.501a3f501811b@imp.free.fr>
References: <loom.20120802T062948-717@post.gmane.org>
	<1343897424.501a3f501811b@imp.free.fr>
Message-ID: <201208122204.15595.even.rouault@mines-paris.org>


> The behaviour of the driver would be that no simple polygons (polygons that
> are described as ways) would be reported until the file has been
> completely processed.
> 
> The algorithm would be something like that :
> - store ways in the temporary way DB as currently, but don't advertize ways
> that are identified as area for now
> - when examining relations, when a polygon described as a way has been
> "consumed" as being the outer way of a relation, it will be removed from
> the temporary way DB (actually, probably just tagged as being no longer
> advertizable, in case it would be needed by another relation afterwards) -
> at the end, report all ways that are areas that remain in the temporary
> way DB as being advertizable

I've implemented the above in r24774. It might have an impact of performance 
(not benchmarked, and hopefully not too big) and if you turn -progress, it 
will seem to be stuck at 100% for longer as before, since there is now the 
post processing of closed ways that are not referenced by relations to do.

Best regards,

Even

From jukka.rahkonen at mmmtike.fi  Mon Aug 13 01:26:41 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Mon, 13 Aug 2012 08:26:41 +0000 (UTC)
Subject: [gdal-dev] How to give additional WFS parameters right?
References: <loom.20120804T172335-967@post.gmane.org>
	<loom.20120804T173911-178@post.gmane.org>
	<201208111858.15334.even.rouault@mines-paris.org>
Message-ID: <loom.20120813T095232-879@post.gmane.org>

Even Rouault <even.rouault <at> mines-paris.org> writes:

> 
> 
> Le samedi 04 ao?t 2012 17:42:54, Jukka Rahkonen a ?crit :
> > Ok,
> > Inserting WFS source between "" helped with command line (I am on
> > Windows as usual").
> > 
> > ogr2ogr -f GML test2.txt "wfs:http://hip.latuviitta.org/cgi-bin/
> > tinyows?SERVICE=WFS&VERSION=1.1.0&TYPENAME=
> > lv:hki_parkkilippuautomaatit&MAXFEATURES=2"
> > 
> > The XML definition file overwrite problem is left.
> 
> I think the problem is just that you didn't XML-escaped the value of the URL
element, namely the & character must be written as & 
> 
> I've updated the doc to make that more obvious (and fix the example where it
wasn't done before OPTIONNAL_PARAMETER2 ) 

Great. It was not obvious for me but by using the & format the extra
parameters in XML definition file works fine.

I found also another not totally obvious demand when writing the XML file. The
value of TYPENAME must include the namespace part.
This setting works
<URL>http://hip.latuviitta.org/cgi-bin/tinyows?
TYPENAME=lv:municipalities&MAXFEATURES=2</URL>

But this lazy written definition without namespace does not
<URL>http://hip.latuviitta.org/cgi-bin/tinyows?
TYPENAME=municipalities&MAXFEATURES=2</URL>

What makes it not obvious is that namespace is not needed if command is sent
directly without using the XML definition file
ogrinfo "wfs:http://hip.latuviitta.org/cgi-bin/tinyows?maxfeatures=2" 
municipalities

If behaviour cannot be changed (or is not wise to change) so that namespace is
not necessary then it would be good to edit documentation a little bit:
Note: the URL must be XML-escaped, for example the & character must be written
as & and the TYPENAME parameter must be written with the namespase as
ns:typename

Finally, could it be so that a list of values is not properly supported as
TYPENAME or am I writing it somehow wrong again? Ogrinfo does not find any
layers if I write the following into XML file, instead of two layers as I 
expected.

<URL>http://hip.latuviitta.org/cgi-bin/tinyows?TYPENAME=lv:mml_railway,lv:municipalities</URL>

-Jukka Rahkonen-


From Jukka.Rahkonen at mmmtike.fi  Mon Aug 13 01:50:55 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Mon, 13 Aug 2012 08:50:55 +0000
Subject: [gdal-dev] 'Polygons as multipolygons' option for OSM driver
Message-ID: <84446DEF76453C439E9E97E438E13A6346390A@suutari.haapa.mmm.fi>


Even Rouault wrote: 

> > The behaviour of the driver would be that no simple polygons (polygons
> > that are described as ways) would be reported until the file has been
> > completely processed.
> >
> > The algorithm would be something like that :
> > - store ways in the temporary way DB as currently, but don't advertize
> > ways that are identified as area for now
> > - when examining relations, when a polygon described as a way has been
> > "consumed" as being the outer way of a relation, it will be removed
> > from the temporary way DB (actually, probably just tagged as being no
> > longer advertizable, in case it would be needed by another relation
> > afterwards) - at the end, report all ways that are areas that remain
> > in the temporary way DB as being advertizable
> 
> I've implemented the above in r24774. It might have an impact of
> performance (not benchmarked, and hopefully not too big) and if you turn -
> progress, it will seem to be stuck at 100% for longer as before, since there is
> now the post processing of closed ways that are not referenced by relations
> to do.

I made a quick test with command
ogr2ogr -f SQLite -dsco spatialite=yes germany.sqlite germany.osm.pbf -gt 20000 -progress --config OGR_SQLITE_SYNCHRONOUS OFF --config OSM_COMPRESS_NODES YES -lco SPATIAL_INDEX=NO

With previous version the conversion took 880 seconds vs. 985 seconds with the new one (r24776) thus it was 12 percent slower in this phase.  I consider that it is not bad at all because for most use cases the OSM polygons (closed rings presenting areas) and multipolygons (coming from OSM multipolygon relations) must be combined anyway and it would probably be much slower as a separate process.

The timings above include only the raw conversion into Spatialite. Creating spatial indexes for the tables take so much time that the whole process that gives indexed tables as end result is only 4 percent slower with the new OSM driver version.

-Jukka Rahkonen-



From j.l.h.hartmann at uva.nl  Mon Aug 13 04:03:12 2012
From: j.l.h.hartmann at uva.nl (Jan Hartmann)
Date: Mon, 13 Aug 2012 13:03:12 +0200
Subject: [gdal-dev] Python programs on multi-core machines
In-Reply-To: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B89@MAILBOXSERVER.rf.local>
References: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B89@MAILBOXSERVER.rf.local>
Message-ID: <5028DEF0.7020903@uva.nl>

I'm working on multi-core VMss in a Cloud environment, that access their 
data on a central dataserver via NFS. Parallellizing jobs for different 
map sheets gives huge accelerations for C-programs like gdaladdo, but 
there seems to be a problem with Python-based programs like rgb2pct.py. 
Consider the following:

(
     rgb2pct.py file1.tif file1_256.tif
     gdaladdo file1_256.tif 2 4 8 16
)&
(
     rgb2pct.py file1.tif file1_256.tif
     gdaladdo file1_256.tif 2 4 8 16
)&
.. etc, for all available cores
wait

When running this on a 16-core VM I see first 16 python processes, each 
with CPU-loads around 20% for each processor, and then 16 gdaladdo 
processes, with CPU-loads around 95%. When I replace the tif-input-files 
for rgb2pct.py by equivalent jpg-files, the loads for the 16 rgb2pct.py 
processes increase to about 80% and the overall computing time more than 
halves.

So my impression is that one Python I/O process blocks  all others. I 
have read something about Python's GIL (Global Interpreter Lock, 
http://docs.python.org/faq/library#can-t-we-get-rid-of-the-global-interpreter-lock) 
and the multi-processing module, but I don't see an easy way to 
implement this for my setup.  Does anyone have a simple solution for 
this problem?

Jan

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120813/4ef7f4e6/attachment.html>

From bontepaarden at gmail.com  Mon Aug 13 04:12:01 2012
From: bontepaarden at gmail.com (Paul Meems)
Date: Mon, 13 Aug 2012 13:12:01 +0200
Subject: [gdal-dev] Compiling libCurl with GDAL v1.9
Message-ID: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>

Hi all,

I'm trying (again) to compile GDAL with libCurl support.
I'm on Windows using VS2008Pro.
I'm using GDALv1.9.

I went to this page http://trac.osgeo.org/gdal/wiki/LibCurl
On this page a link is provided to a package.
That link is no longer working.

So I tried looking for the package myself.
I've downloaded curl-7.27.0-ssl-sspi-zlib-static-bin-w32.zip from
fossies.org and curl-7.27.0-devel-mingw32.zip from haxx.se both both don't
have the needed lib files.

So my question is:
How to obtain the correct libCurl package?

Thanks,

Paul

 *Paul Meems *
Release manager, configuration manager
and forum moderator of MapWindow GIS.
www.mapwindow.org

Owner of MapWindow.nl - Support for
Dutch speaking users.
www.mapwindow.nl

*
*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120813/fd7f6d44/attachment.html>

From jukka.rahkonen at mmmtike.fi  Mon Aug 13 04:31:56 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Mon, 13 Aug 2012 11:31:56 +0000 (UTC)
Subject: [gdal-dev] Compiling libCurl with GDAL v1.9
References: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
Message-ID: <loom.20120813T131900-405@post.gmane.org>

Paul Meems <bontepaarden <at> gmail.com> writes:

> 
> 
> Hi all,I'm trying (again) to compile GDAL with libCurl support.I'm on Windows
using VS2008Pro.I'm using GDALv1.9.I went to this page
http://trac.osgeo.org/gdal/wiki/LibCurl

If you do not have a special need for compiling yourself you can perhaps use
ready made stuff from http://gisinternals.com/sdk/
Information and buildlog links may give some hints too.

-Jukka Rahkonen-




From szekerest at gmail.com  Mon Aug 13 05:13:58 2012
From: szekerest at gmail.com (Tamas Szekeres)
Date: Mon, 13 Aug 2012 14:13:58 +0200
Subject: [gdal-dev] Compiling libCurl with GDAL v1.9
In-Reply-To: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
References: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
Message-ID: <CACALY+R0g3svUSsGz8Ura-zzXTBs00N9YP7ZQvwNYQQ3-0=RAA@mail.gmail.com>

Paul,

If you want to recompile libcurl, I'd suggest to utilize the provided cmake
approach to create a working solution file. All other approaches (on
windows) lead to various mysterious issues which are better to avoid.

Best regards,

Tamas



2012/8/13 Paul Meems <bontepaarden at gmail.com>

> Hi all,
>
> I'm trying (again) to compile GDAL with libCurl support.
> I'm on Windows using VS2008Pro.
> I'm using GDALv1.9.
>
> I went to this page http://trac.osgeo.org/gdal/wiki/LibCurl
> On this page a link is provided to a package.
> That link is no longer working.
>
> So I tried looking for the package myself.
> I've downloaded curl-7.27.0-ssl-sspi-zlib-static-bin-w32.zip from
> fossies.org and curl-7.27.0-devel-mingw32.zip from haxx.se both both
> don't have the needed lib files.
>
> So my question is:
> How to obtain the correct libCurl package?
>
> Thanks,
>
> Paul
>
>  *Paul Meems *
> Release manager, configuration manager
> and forum moderator of MapWindow GIS.
> www.mapwindow.org
>
> Owner of MapWindow.nl - Support for
> Dutch speaking users.
> www.mapwindow.nl
>
> *
> *
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120813/d3a83ce5/attachment.html>

From jmckenna at gatewaygeomatics.com  Mon Aug 13 05:26:33 2012
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Mon, 13 Aug 2012 09:26:33 -0300
Subject: [gdal-dev] Compiling libCurl with GDAL v1.9
In-Reply-To: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
References: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
Message-ID: <5028F279.4040101@gatewaygeomatics.com>

Hi Paul,

I compile libCurl with the MSVC compiler, and I follow the "MSVC from
command line" instructions at http://curl.haxx.se/docs/install.html

I set the ZLIB and OPENSSL paths as suggested as well.

-jeff



-- 
Jeff McKenna
MapServer Consulting and Training Services
http://www.gatewaygeomatics.com/



On 12-08-13 8:12 AM, Paul Meems wrote:
> Hi all,
> 
> I'm trying (again) to compile GDAL with libCurl support.
> I'm on Windows using VS2008Pro.
> I'm using GDALv1.9.
> 
> I went to this page http://trac.osgeo.org/gdal/wiki/LibCurl
> On this page a link is provided to a package.
> That link is no longer working.
> 
> So I tried looking for the package myself.
> I've downloaded curl-7.27.0-ssl-sspi-zlib-static-bin-w32.zip from
> fossies.org <http://fossies.org> and curl-7.27.0-devel-mingw32.zip from
> haxx.se <http://haxx.se> both both don't have the needed lib files.
> 
> So my question is:
> How to obtain the correct libCurl package?
> 




From szekerest at gmail.com  Mon Aug 13 05:38:21 2012
From: szekerest at gmail.com (Tamas Szekeres)
Date: Mon, 13 Aug 2012 14:38:21 +0200
Subject: [gdal-dev] Compiling libCurl with GDAL v1.9
In-Reply-To: <5028F279.4040101@gatewaygeomatics.com>
References: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
	<5028F279.4040101@gatewaygeomatics.com>
Message-ID: <CACALY+RNAx+3g+B-N22tS-RrMdOE5V8RkNJzDfoPLGbQESotUQ@mail.gmail.com>

I recently used this option (curl 7.27.0), but a client reported
performance problems with this approach. May be I would have been trying to
disable one or more services which are compiled by default causing this
side effect, but I rather went back to the original cmake approach
instead. I've never experienced issues like this by using the cmake builds.

Best regards,

Tamas



2012/8/13 Jeff McKenna <jmckenna at gatewaygeomatics.com>

> Hi Paul,
>
> I compile libCurl with the MSVC compiler, and I follow the "MSVC from
> command line" instructions at http://curl.haxx.se/docs/install.html
>
> I set the ZLIB and OPENSSL paths as suggested as well.
>
> -jeff
>
>
>
> --
> Jeff McKenna
> MapServer Consulting and Training Services
> http://www.gatewaygeomatics.com/
>
>
>
> On 12-08-13 8:12 AM, Paul Meems wrote:
> > Hi all,
> >
> > I'm trying (again) to compile GDAL with libCurl support.
> > I'm on Windows using VS2008Pro.
> > I'm using GDALv1.9.
> >
> > I went to this page http://trac.osgeo.org/gdal/wiki/LibCurl
> > On this page a link is provided to a package.
> > That link is no longer working.
> >
> > So I tried looking for the package myself.
> > I've downloaded curl-7.27.0-ssl-sspi-zlib-static-bin-w32.zip from
> > fossies.org <http://fossies.org> and curl-7.27.0-devel-mingw32.zip from
> > haxx.se <http://haxx.se> both both don't have the needed lib files.
> >
> > So my question is:
> > How to obtain the correct libCurl package?
> >
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120813/cc426d73/attachment.html>

From bontepaarden at gmail.com  Mon Aug 13 05:46:47 2012
From: bontepaarden at gmail.com (Paul Meems)
Date: Mon, 13 Aug 2012 14:46:47 +0200
Subject: [gdal-dev] Compiling libCurl with GDAL v1.9
In-Reply-To: <CACALY+RNAx+3g+B-N22tS-RrMdOE5V8RkNJzDfoPLGbQESotUQ@mail.gmail.com>
References: <CAHNf2YT6-az779E4AU-r1gJHg6aYMTSa=hPfw7wBg_c8bPKd3Q@mail.gmail.com>
	<5028F279.4040101@gatewaygeomatics.com>
	<CACALY+RNAx+3g+B-N22tS-RrMdOE5V8RkNJzDfoPLGbQESotUQ@mail.gmail.com>
Message-ID: <CAHNf2YSEpGTgjO3orEnLvGzrysmGPsOzdZgt-zm_m8xjb+ZWdQ@mail.gmail.com>

Thanks all for your help.

@Jeff: I've tried that approach last year (with GDAL v1.8) and it gave me
nothing but trouble.
That is the reason I wanted to use precompiled curl libraries this time.

@Jukka, Tamas: I've successfully downloaded the zip files from
http://gisinternals.com/sdk/ and extracted the necessary files for Curl.
I didn't know that was possible.
This gave me the possibility to compile GDAL with our own settings AND use
the precompiled curl libraries.

As said I can compile now. I will now test if it is really working ;)
Perhaps the web page http://trac.osgeo.org/gdal/wiki/LibCurl should be
updated?

Thanks,

Paul

 *Paul Meems *
Release manager, configuration manager
and forum moderator of MapWindow GIS.
www.mapwindow.org

Owner of MapWindow.nl - Support for
Dutch speaking users.
www.mapwindow.nl

*
*



2012/8/13 Tamas Szekeres <szekerest at gmail.com>

> I recently used this option (curl 7.27.0), but a client reported
> performance problems with this approach. May be I would have been trying to
> disable one or more services which are compiled by default causing this
> side effect, but I rather went back to the original cmake approach
> instead. I've never experienced issues like this by using the cmake builds.
>
> Best regards,
>
> Tamas
>
>
>
> 2012/8/13 Jeff McKenna <jmckenna at gatewaygeomatics.com>
>
>> Hi Paul,
>>
>> I compile libCurl with the MSVC compiler, and I follow the "MSVC from
>> command line" instructions at http://curl.haxx.se/docs/install.html
>>
>> I set the ZLIB and OPENSSL paths as suggested as well.
>>
>> -jeff
>>
>>
>>
>> --
>> Jeff McKenna
>> MapServer Consulting and Training Services
>> http://www.gatewaygeomatics.com/
>>
>>
>>
>> On 12-08-13 8:12 AM, Paul Meems wrote:
>> > Hi all,
>> >
>> > I'm trying (again) to compile GDAL with libCurl support.
>> > I'm on Windows using VS2008Pro.
>> > I'm using GDALv1.9.
>> >
>> > I went to this page http://trac.osgeo.org/gdal/wiki/LibCurl
>> > On this page a link is provided to a package.
>> > That link is no longer working.
>> >
>> > So I tried looking for the package myself.
>> > I've downloaded curl-7.27.0-ssl-sspi-zlib-static-bin-w32.zip from
>> > fossies.org <http://fossies.org> and curl-7.27.0-devel-mingw32.zip from
>> > haxx.se <http://haxx.se> both both don't have the needed lib files.
>> >
>> > So my question is:
>> > How to obtain the correct libCurl package?
>> >
>>
>>
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120813/ea7edeac/attachment.html>

From pwheeler at digitalglobe.com  Tue Aug 14 10:02:11 2012
From: pwheeler at digitalglobe.com (Paul Wheeler)
Date: Tue, 14 Aug 2012 11:02:11 -0600
Subject: [gdal-dev] use of ogr2ogr with SAP Data Services
Message-ID: <C1BF1C58F42A304A899E2933C220F48A0BF2575E@COMAIL02.digitalglobe.com>

Using ogr2ogr with data services, running batch file, from data services
job.

 

It will work on 3.2 not on 4.0, batch files run to completion from
command prompt on both servers, however, when bat file is ran for 4.0
fails to execute, 4.0 will run any other batch file we have.

 

Paul 

 


This electronic communication and any attachments may contain confidential and proprietary 
information of DigitalGlobe, Inc. If you are not the intended recipient, or an agent or employee 
responsible for delivering this communication to the intended recipient, or if you have received 
this communication in error, please do not print, copy, retransmit, disseminate or 
otherwise use the information. Please indicate to the sender that you have received this 
communication in error, and delete the copy you received. DigitalGlobe reserves the 
right to monitor any electronic communication sent or received by its employees, agents 
or representatives.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120814/848bd132/attachment.html>

From mike at stamen.com  Tue Aug 14 12:00:20 2012
From: mike at stamen.com (Michal Migurski)
Date: Tue, 14 Aug 2012 12:00:20 -0700
Subject: [gdal-dev] Possible bug: hard limit to the number of Datasets
	creatable in a Python process?
Message-ID: <FB5572DE-1DD9-4D84-BFB7-772A4A1C719F@stamen.com>

I'm experiencing a reproducible bug.

I create new 258x258 pixel datasets like this:

	driver = gdal.GetDriverByName('GTiff')
	handle, filename = mkstemp(dir=tmpdir, prefix='dem-tools-hillup-data-render-', suffix='.tif')
	ds = driver.Create(filename, width, height, 1, gdal.GDT_Float32)

I also open a number of datasets in the same process using gdal.Open() and warp them together with gdal.ReprojectImage().

When I have created 1,020 new datasets / opened 2,041 total datasets, I get a None back from driver.Create(). This number is stable, and appears unrelated to the specific datasets that I'm creating. Datasets are being flushed and falling out of scope, so I believe that they're correctly being closed when they should. Do these numbers sound like known, hard internal limits to anyone?

I'm using the 1.6 Python bindings on Ubuntu 10.04 LTS.

-mike.

----------------------------------------------------------------
michal migurski- mike at stamen.com
                 415.558.1610




From even.rouault at mines-paris.org  Tue Aug 14 12:37:13 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 14 Aug 2012 21:37:13 +0200
Subject: [gdal-dev] Possible bug: hard limit to the number of Datasets
	creatable in a Python process?
In-Reply-To: <FB5572DE-1DD9-4D84-BFB7-772A4A1C719F@stamen.com>
References: <FB5572DE-1DD9-4D84-BFB7-772A4A1C719F@stamen.com>
Message-ID: <201208142137.13179.even.rouault@mines-paris.org>

Le mardi 14 ao?t 2012 21:00:20, Michal Migurski a ?crit :
> I'm experiencing a reproducible bug.
> 
> I create new 258x258 pixel datasets like this:
> 
> 	driver = gdal.GetDriverByName('GTiff')
> 	handle, filename = mkstemp(dir=tmpdir,
> prefix='dem-tools-hillup-data-render-', suffix='.tif') ds =
> driver.Create(filename, width, height, 1, gdal.GDT_Float32)
> 
> I also open a number of datasets in the same process using gdal.Open() and
> warp them together with gdal.ReprojectImage().
> 
> When I have created 1,020 new datasets / opened 2,041 total datasets, I get
> a None back from driver.Create(). This number is stable, and appears
> unrelated to the specific datasets that I'm creating. Datasets are being
> flushed and falling out of scope, so I believe that they're correctly
> being closed when they should. Do these numbers sound like known, hard
> internal limits to anyone?

I don't think it is a bug in GDAL, but an issue in your script. This sounds 
like you hit the default limit of 1024 files opened simultaneously by a Linux 
process. So I suspect that your datasets are not properly closed.

Calling ds.FlushCache() is not sufficient. In principle, if the dataset handle 
goes out of scope, it should be destroyed, so I suspect that it is not the 
case. Assigning None to the dataset will force its closing.

> 
> I'm using the 1.6 Python bindings on Ubuntu 10.04 LTS.
> 
> -mike.
> 
> ----------------------------------------------------------------
> michal migurski- mike at stamen.com
>                  415.558.1610
> 
> 
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From mike at stamen.com  Tue Aug 14 13:00:32 2012
From: mike at stamen.com (Michal Migurski)
Date: Tue, 14 Aug 2012 13:00:32 -0700
Subject: [gdal-dev] Possible bug: hard limit to the number of Datasets
	creatable in a Python process?
In-Reply-To: <201208142137.13179.even.rouault@mines-paris.org>
References: <FB5572DE-1DD9-4D84-BFB7-772A4A1C719F@stamen.com>
	<201208142137.13179.even.rouault@mines-paris.org>
Message-ID: <0CD5394C-1C83-407F-BCBB-7FE690EE6394@stamen.com>

On Aug 14, 2012, at 12:37 PM, Even Rouault wrote:

> Le mardi 14 ao?t 2012 21:00:20, Michal Migurski a ?crit :
>> I'm experiencing a reproducible bug.
>> 
>> I create new 258x258 pixel datasets like this:
>> 
>> 	driver = gdal.GetDriverByName('GTiff')
>> 	handle, filename = mkstemp(dir=tmpdir,
>> prefix='dem-tools-hillup-data-render-', suffix='.tif') ds =
>> driver.Create(filename, width, height, 1, gdal.GDT_Float32)
>> 
>> I also open a number of datasets in the same process using gdal.Open() and
>> warp them together with gdal.ReprojectImage().
>> 
>> When I have created 1,020 new datasets / opened 2,041 total datasets, I get
>> a None back from driver.Create(). This number is stable, and appears
>> unrelated to the specific datasets that I'm creating. Datasets are being
>> flushed and falling out of scope, so I believe that they're correctly
>> being closed when they should. Do these numbers sound like known, hard
>> internal limits to anyone?
> 
> I don't think it is a bug in GDAL, but an issue in your script. This sounds 
> like you hit the default limit of 1024 files opened simultaneously by a Linux 
> process. So I suspect that your datasets are not properly closed.
> 
> Calling ds.FlushCache() is not sufficient. In principle, if the dataset handle 
> goes out of scope, it should be destroyed, so I suspect that it is not the 
> case. Assigning None to the dataset will force its closing.


Great, thank you Even.

I have a place to look now. When I watch the output of lsof as the script runs, I can see that the failure occurs near the moment where the number of open file handles approaches 1024.

I've added `ds = None` to the relevant parts of my script, but I don't think the file handles are actually being closed. Here's an excerpt of lsof output for the specific pid, which shows correctly that the TIF files have each been deleted but handles remain open:

	python  4719 migurski  127u   REG    8,1   267898  65148403 /tmp/dem-tools-hillup-data-render-KvUA8d.tif (deleted)
	python  4719 migurski  128u   REG    8,1   267898  65148404 /tmp/dem-tools-hillup-data-render-MAwCVw.tif (deleted)
	python  4719 migurski  129u   REG    8,1   267898  65148405 /tmp/dem-tools-hillup-data-render-M_NvT_.tif (deleted)
	python  4719 migurski  130u   REG    8,1   267898  65148406 /tmp/dem-tools-hillup-data-render-dV1p7h.tif (deleted)
	python  4719 migurski  131u   REG    8,1   267898  65148407 /tmp/dem-tools-hillup-data-render-rmuD4b.tif (deleted)
	python  4719 migurski  132u   REG    8,1   267898  65148408 /tmp/dem-tools-hillup-data-render-KGtcFD.tif (deleted)
	python  4719 migurski  133u   REG    8,1   267898  65148409 /tmp/dem-tools-hillup-data-render-EI4Jkz.tif (deleted)
	python  4719 migurski  134u   REG    8,1   267898  65148410 /tmp/dem-tools-hillup-data-render-MnHVKl.tif (deleted)
	python  4719 migurski  135u   REG    8,1   267898  65148411 /tmp/dem-tools-hillup-data-render-oGd6_b.tif (deleted)
	python  4719 migurski  136u   REG    8,1   267898  65148412 /tmp/dem-tools-hillup-data-render-8p0cew.tif (deleted)
	python  4719 migurski  137u   REG    8,1   267898  65148413 /tmp/dem-tools-hillup-data-render-CZTPWc.tif (deleted)

I'm going to try switching to vsimem, maybe that will help.

-mike.

----------------------------------------------------------------
michal migurski- mike at stamen.com
                 415.558.1610




From mike at stamen.com  Tue Aug 14 13:05:20 2012
From: mike at stamen.com (Michal Migurski)
Date: Tue, 14 Aug 2012 13:05:20 -0700
Subject: [gdal-dev] Possible bug: hard limit to the number of Datasets
	creatable in a Python process?
In-Reply-To: <0CD5394C-1C83-407F-BCBB-7FE690EE6394@stamen.com>
References: <FB5572DE-1DD9-4D84-BFB7-772A4A1C719F@stamen.com>
	<201208142137.13179.even.rouault@mines-paris.org>
	<0CD5394C-1C83-407F-BCBB-7FE690EE6394@stamen.com>
Message-ID: <27AF5353-DFE9-4B11-A013-D49FA0503895@stamen.com>

On Aug 14, 2012, at 1:00 PM, Michal Migurski wrote:

> On Aug 14, 2012, at 12:37 PM, Even Rouault wrote:
> 
>> Calling ds.FlushCache() is not sufficient. In principle, if the dataset handle 
>> goes out of scope, it should be destroyed, so I suspect that it is not the 
>> case. Assigning None to the dataset will force its closing.
> 
> 
> Great, thank you Even.
> 
> I have a place to look now. When I watch the output of lsof as the script runs, I can see that the failure occurs near the moment where the number of open file handles approaches 1024.
> 
> I've added `ds = None` to the relevant parts of my script, but I don't think the file handles are actually being closed.

Ah, found the bug - I was neglecting to close a handle returned from mkstemp. Not a GDAL bug at all, pure Python badness on my part.

-mike.

----------------------------------------------------------------
michal migurski- mike at stamen.com
                 415.558.1610




From maitai at virtual-winds.com  Tue Aug 14 23:22:27 2012
From: maitai at virtual-winds.com (maitai at virtual-winds.com)
Date: Wed, 15 Aug 2012 08:22:27 +0200
Subject: [gdal-dev] bsb/kap files
Message-ID: <1345011747-dc359e7e37773a45e75f5f5a024078f5@virtual-winds.com>

Hello all, I am new to this list.

We have tried recently to use gdal for reading kap (bsb) files, and in many cases it seems that gdal is not able to convert image coordinates to lat/lon. For instance this file (a kap file from NOAA)

http://www.virtual-winds.com/maitai/14782_1.KAP


This map is correctly converted by bsbLib, but gdalInfo fails to find the coordinates of the corners. bsbLib uses WPx/WPy if present and it seems gdal does not.

I have submitted this problem to Franck Warmerdam, and here is an extract of his answer:

---------------------------------------------------------------------------------------

It may be helpful to raise the issue on the gdal-dev list where other
BSB users can also comment.

It's been a while since I did much work on the BSB/KAP driver, so my
answers may not be completely accurate.  The source is always the
final reference.

I see for the file you provided GDAL identies the reference points
(GCPs) properly, so that is good. And the gdalwarp utility should be
able to warp to WGS84 if needed using the GCPs.  Gdalinfo does not use
the GCPs to transform from pixel/line to georeferenced though it could
be improved to do so.

Later in the code (see ScanForGCPs()) we attempt to transform the GCPs
to the projection defined for the file in the KNP line (POLYCONIC in
this case) and then attempts to use the transformed GCPs to compute an
affine transformation (a GeoTransform in GDAL-speak).  It would appear
this fails - presumably because they aren't regular enough.

I've never tried using the WPX/WPY/PWX/PWY lines.  I gather they are
in fact the suggested coefficients for an affine transform between
pixel/line and POLYCONIC meters?  It might be interesting to try and
use these.

Best regards,
---------------------------------------------------------------------------------------

Maybe someone has already faced this issue or has a solution?

Thanks

Philippe.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120815/51467ea9/attachment.html>

From eborovenskiy at scanex.ru  Tue Aug 14 23:48:51 2012
From: eborovenskiy at scanex.ru (Evgeniy Borovenskiy)
Date: Wed, 15 Aug 2012 10:48:51 +0400
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
Message-ID: <955BDE81516F04498F36F60B0570974979BDADB1A5@vrum-exch2>

Hello,

tell me please, can i write JPEG2000 file with codek KAKADU without create intermediate file .tif.

Evgeniy.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120815/f2771ee1/attachment.html>

From jukka.rahkonen at mmmtike.fi  Wed Aug 15 04:50:02 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Wed, 15 Aug 2012 11:50:02 +0000 (UTC)
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
References: <955BDE81516F04498F36F60B0570974979BDADB1A5@vrum-exch2>
Message-ID: <loom.20120815T134335-551@post.gmane.org>

Evgeniy Borovenskiy <eborovenskiy <at> scanex.ru> writes:

> 
> 
> Hello,
> ?
> tell me please, can i write JPEG2000 file with codek KAKADU without create
intermediate file .tif.

Yes you can. Gdal_translate -of JP2KAK input.png output.jp2 will make you a
JPEG2000 image.

-Jukka Rahkonen-




From even.rouault at mines-paris.org  Wed Aug 15 05:08:23 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 15 Aug 2012 14:08:23 +0200
Subject: [gdal-dev] How to give additional WFS parameters right?
In-Reply-To: <loom.20120813T095232-879@post.gmane.org>
References: <loom.20120804T172335-967@post.gmane.org>
	<201208111858.15334.even.rouault@mines-paris.org>
	<loom.20120813T095232-879@post.gmane.org>
Message-ID: <201208151408.23920.even.rouault@mines-paris.org>

> I found also another not totally obvious demand when writing the XML file.
> The value of TYPENAME must include the namespace part.
> This setting works
> <URL>http://hip.latuviitta.org/cgi-bin/tinyows?
> TYPENAME=lv:municipalities&MAXFEATURES=2</URL>
> 
> But this lazy written definition without namespace does not
> <URL>http://hip.latuviitta.org/cgi-bin/tinyows?
> TYPENAME=municipalities&MAXFEATURES=2</URL>
> 
> What makes it not obvious is that namespace is not needed if command is
> sent directly without using the XML definition file
> ogrinfo "wfs:http://hip.latuviitta.org/cgi-bin/tinyows?maxfeatures=2"
> municipalities
> 
> If behaviour cannot be changed (or is not wise to change) so that namespace
> is not necessary then it would be good to edit documentation a little bit:

Added to the doc : "The name provided to the TYPENAME parameter must be 
exactly the layer name reported by OGR,
in particular with its namespace prefix when its exists."

The fact that you can use the short name in GetLayerByName() (which is what is 
invoked by 'ogrinfo datasource layername') is just some syntaxic sugar that 
you happened to discover. But it is already a bit difficult to manage it in the 
code (For example if you had foo:some_name and bar:some_name, it will be 
disabled), so I almost regret it to have added it and I would prefer not 
extending it to other places of the driver, in particular in TYPENAME which is 
an advanced use of the driver.

> 
> Finally, could it be so that a list of values is not properly supported as
> TYPENAME or am I writing it somehow wrong again? Ogrinfo does not find any
> layers if I write the following into XML file, instead of two layers as I
> expected.

Specifying several names wasn't supported actually, but it is an easy and 
natural addition compliant with the WFS spec, so it is now. Added to the doc : 
"Note: starting with GDAL 2.0, several type names can be provided and 
separated by comma."


From jukka.rahkonen at mmmtike.fi  Wed Aug 15 12:28:22 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Wed, 15 Aug 2012 19:28:22 +0000 (UTC)
Subject: [gdal-dev] WFS driver does not do URL-encoding right
References: <loom.20120808T094949-411@post.gmane.org>
Message-ID: <loom.20120815T212329-456@post.gmane.org>

Jukka Rahkonen <jukka.rahkonen <at> mmmtike.fi> writes:

> 
> Hi,
> 
> It looks like it is not possible to use some special characters in filters with
> OGR WFS driver.

GvSIG is also sending GetFeatures with http GET and filters and it had same kind
of problems with special characters. Now the developers say that they have fixed
URL encoding. I hope that the solution is somehow re-usable
https://devel.gvsig.org/redmine/issues/984

-Jukka-



From even.rouault at mines-paris.org  Wed Aug 15 12:45:08 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 15 Aug 2012 21:45:08 +0200
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <loom.20120815T212329-456@post.gmane.org>
References: <loom.20120808T094949-411@post.gmane.org>
	<loom.20120815T212329-456@post.gmane.org>
Message-ID: <201208152145.08749.even.rouault@mines-paris.org>

Le mercredi 15 ao?t 2012 21:28:22, Jukka Rahkonen a ?crit :
> GvSIG is also sending GetFeatures with http GET and filters and it had same
> kind of problems with special characters. Now the developers say that they
> have fixed URL encoding. I hope that the solution is somehow re-usable

I'm not sure this is a problem with URL encoding, but more a problem with the 
fact that the Windows console is not using UTF-8. So even if the OGR WFS 
driver did escape the special character, this wouldn't solve anything, since 
it would get a non UTF8 character and would escape it wrongly...

Some seraching would suggest that typing "chcp 65001" before might help, but 
I'm not sure...

I'm wondering if the GDAL command line utilities shouldn't use special 
instructions under Windows to better deal with Unicode characters. Some search 
would suggest that using wmain() and/or SetConsoleOutputCP() might help. Are 
there Windows programmers around that might give advice on how to get 
arguments in UTF-8 from the Windows command line ?

Anyway, with Linux, it works fine :

$ ogrinfo "WFS:http://188.64.1.61/cgi-bin/tinyows" -sql "select * from 
municipalities where kunta_ni1='Saarij?rvi'" ro --debug on
WFS: http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&REQUEST=GetCapabilities&ACCEPTVERSIONS=1.1.0,1.0.0
HTTP: Fetch(http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&REQUEST=GetCapabilities&ACCEPTVERSIONS=1.1.0,1.0.0)
WFS: GetFeature operation supports hits
WFS: Transaction support !
OGR: OGROpen(WFS:http://188.64.1.61/cgi-bin/tinyows/0x1eaf190) succeeded as 
WFS.
INFO: Open of `WFS:http://188.64.1.61/cgi-bin/tinyows'
      using driver `WFS' successful.
layer names ignored in combination with -sql.
HTTP: Fetch(http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=DescribeFeatureType&TYPENAME=lv:municipalities,lv:mml_kunta10k_2011_l,lv:mml_kunta10k_2011_p,lv:mml_kunta100k_2011_l,lv:mml_kunta100k_2011_p,lv:mml_kunta250k_2011_l,lv:mml_kunta250k_2011_p,lv:mml_kunta1000k_2011_l,lv:mml_kunta1000k_2011_p,lv:mml_kunta4500k_2011_l,lv:mml_kunta4500k_2011_p,lv:mml_airport,lv:mml_asemat,lv:mml_avi1_l,lv:mml_avi1_p,lv:mml_cityp,lv:mml_coast_l,lv:mml_coast_p,lv:mml_dcont_l,lv:mml_dcont_p,lv:mml_forest,lv:mml_hcont_l,lv:mml_hcont_p,lv:mml_hpoint,lv:mml_kunta1_l,lv:mml_kunta1_p,lv:mml_kunta1_maa_alue,lv:mml_lake_l,lv:mml_lake_p,lv:mml_maaku1_l,lv:mml_maaku1_p,lv:mml_namep,lv:mml_pelto,lv:mml_railway,lv:mml_river,lv:mml_rivera_l,lv:mml_rivera_p,lv:mml_road,lv:mml_suot,lv:mml_taajama,lv:mml_paikannimet20,lv:peltolohkot_2011,lv:pks_pienalue,lv:pks_suuralue,lv:pks_tilastoalue,lv:pks_asuinalueet,lv:pks_teollisuusalueet,lv:pks_viheralueet,lv:pks_maankaytto,lv:pks_jarvet)

Layer name: municipalities
Geometry: Multi Polygon
WFS: http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=<Filter 
xmlns="http://www.opengis.net/ogc" xmlns:lv="http://latuviitta.fi/" 
xmlns:gml="http://www.opengis.net/gml"><PropertyIsEqualTo><PropertyName>kunta_ni1</PropertyName><Literal>Saarij?rvi</Literal></PropertyIsEqualTo></Filter>&RESULTTYPE=hits
HTTP: Fetch(http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=%3CFilter%20xmlns=%22http://www.opengis.net/ogc%22%20xmlns:lv=%22http://latuviitta.fi/%22%20xmlns:gml=%22http://www.opengis.net/gml%22%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ekunta_ni1%3C/PropertyName%3E%3CLiteral%3ESaarij?rvi%3C/Literal%3E%3C/PropertyIsEqualTo%3E%3C/Filter%3E&RESULTTYPE=hits)
Feature Count: 1
WFS: http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=<Filter 
xmlns="http://www.opengis.net/ogc" xmlns:lv="http://latuviitta.fi/" 
xmlns:gml="http://www.opengis.net/gml"><PropertyIsEqualTo><PropertyName>kunta_ni1</PropertyName><Literal>Saarij?rvi</Literal></PropertyIsEqualTo></Filter>
VSICURL: Start download for http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=%3CFilter%20xmlns=%22http://www.opengis.net/ogc%22%20xmlns:lv=%22http://latuviitta.fi/%22%20xmlns:gml=%22http://www.opengis.net/gml%22%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ekunta_ni1%3C/PropertyName%3E%3CLiteral%3ESaarij?rvi%3C/Literal%3E%3C/PropertyIsEqualTo%3E%3C/Filter%3E
GML: Using Expat reader
GML: Global SRS = EPSG:3067
GML: Using /vsimem/tempwfs_0x1f38d60/file.xsd
GML: ResetReading()
GML: ResetReading()
GML: ResetReading()
Extent: (372349.750000, 6933225.500000) - (433496.625000, 6976330.000000)
Layer SRS WKT:
PROJCS["ETRS89 / TM35FIN(E,N)",
    GEOGCS["ETRS89",
        DATUM["European_Terrestrial_Reference_System_1989",
            SPHEROID["GRS 1980",6378137,298.257222101,
                AUTHORITY["EPSG","7019"]],
            TOWGS84[0,0,0,0,0,0,0],
            AUTHORITY["EPSG","6258"]],
        PRIMEM["Greenwich",0,
            AUTHORITY["EPSG","8901"]],
        UNIT["degree",0.0174532925199433,
            AUTHORITY["EPSG","9122"]],
        AXIS["Latitude",NORTH],
        AXIS["Longitude",EAST],
        AUTHORITY["EPSG","4258"]],
    PROJECTION["Transverse_Mercator"],
    PARAMETER["latitude_of_origin",0],
    PARAMETER["central_meridian",27],
    PARAMETER["scale_factor",0.9996],
    PARAMETER["false_easting",500000],
    PARAMETER["false_northing",0],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AXIS["Easting",EAST],
    AXIS["Northing",NORTH],
    AUTHORITY["EPSG","3067"]]
gml_id: String (0.0)
suuralue: String (0.0)
avi: String (0.0)
maakunta: String (0.0)
seutukunta: String (0.0)
kunta: String (0.0)
suural_ni1: String (0.0)
suural_ni2: String (0.0)
avi_ni1: String (0.0)
avi_ni2: String (0.0)
maaku_ni1: String (0.0)
maaku_ni2: String (0.0)
seutuk_ni1: String (0.0)
seutuk_ni2: String (0.0)
kunta_ni1: String (0.0)
kunta_ni2: String (0.0)
kieli_ni1: String (0.0)
kieli_ni2: String (0.0)
kaupunki: Integer (0.0)
shape_leng: Real (0.0)
shape_area: Real (0.0)
OGRFeature(municipalities):257
  gml_id (String) = municipalities.257
  suuralue (String) = 2
  avi (String) = 4
  maakunta (String) = 13
  seutukunta (String) = 138
  kunta (String) = 729
  suural_ni1 (String) = L?nsi-Suomi
  suural_ni2 (String) = V?stra Finland
  avi_ni1 (String) = L?nsi- ja Sis?-Suomen aluehallintovirasto
  avi_ni2 (String) = Regionf?rvaltningsverket i V?stra och Inre Finland
  maaku_ni1 (String) = Keski-Suomi
  maaku_ni2 (String) = Mellersta Finland
  seutuk_ni1 (String) = Saarij?rven-Viitasaaren seutukunta
  seutuk_ni2 (String) = N_A
  kunta_ni1 (String) = Saarij?rvi
  kunta_ni2 (String) = N_A
  kieli_ni1 (String) = Suomi
  kieli_ni2 (String) = N_A
  kaupunki (Integer) = 2
  shape_leng (Real) = 217890.793269
  shape_area (Real) = 1421634392.31
  MULTIPOLYGON (((431175.55 6965415.6,433032.45 6963484.87,433496.63 
6961995.55,432351.54 6959161.48,423520.98 6956704.84,423422.06 
6956644.06,422918.06 6955962.73,423083.85 6953557.94,423181.66 
6951635.51,423025.36 6951041.19,422504.5 6949076.54,421988.79 
6947131.72,421846.05 6946593.06,421657.17 6946136.92,421882.76 
6945904.69,422882.4 6944892.62,423357.37 6944492.15,424116.56 
6942683.6,424083.41 6942465.44,422808.01 6941696.47,421855.79 
6941095.75,422017.19 6936052.02,419804.12 6935199.87,420152.42 
6933980.52,418004.53 6933225.62,415856.59 6934154.51,415563.71 
6934940.76,413443.2 6935260.62,410080.95 6935303.47,406732.4 
6940340.15,405283.66 6940446.34,400536.73 6940067.59,395580.16 
6939666.46,394920.71 6939627.43,393296.99 6941629.18,392178.08 
6943009.1,388880.05 6940383.58,386820.25 6937431.16,385498.39 
6936754.31,382380.61 6935463.93,376786.52 6949235.01,376220.86 
6950627.73,376127.46 6950563.76,373019.66 6953049.78,372702.42 
6954380.45,372603.1 6954765.57,372349.76 6955805.15,374454.19 
6956467.94,375402.84 6957483.21,376693.11 6960172.06,379308.83 
6958442.84,380233.69 6959786.94,383043.44 6959588.0,385260.54 
6963460.37,386126.71 6962687.56,386482.41 6962309.48,387933.7 
6963064.38,389326.9 6964863.98,390205.83 6963726.52,390485.8 
6962642.8,390546.02 6960626.33,391081.01 6959431.29,391143.47 
6959390.35,391247.55 6959388.43,391380.73 6959410.82,391483.09 
6959414.66,391583.13 6959410.82,393919.24 6958183.8,394190.41 
6958043.06,395000.48 6959552.22,394025.91 6959996.84,394595.75 
6960744.06,395576.83 6962623.63,395307.5 6963381.72,394986.46 
6964198.03,394633.88 6964200.59,393400.07 6962755.4,393178.08 
6962814.9,392425.42 6963368.27,391563.51 6965746.83,396502.43 
6969234.09,399764.51 6971565.33,400074.27 6971787.96,402446.56 
6970262.82,403456.64 6967897.06,403516.58 6967892.58,403593.19 
6967903.45,403666.52 6967884.26,403770.08 6967819.65,403906.26 
6967769.75,404062.24 6967713.45,404584.71 6967312.34,405728.86 
6966534.41,406338.33 6965860.77,406816.11 6964471.25,413353.47 
6965814.09,413366.98 6966519.73,415997.31 6969484.31,419935.19 
6973875.52,421809.07 6975976.44,422135.82 6976320.62,423614.26 
6976330.22,426661.92 6976295.05,427289.53 6970722.89,429386.49 
6969247.65,431175.55 6965415.6)))

GenSQL: 1 features read on layer 'municipalities'.
GML: ResetReading()
VSICURL: Stop download for http://188.64.1.61/cgi-
bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=%3CFilter%20xmlns=%22http://www.opengis.net/ogc%22%20xmlns:lv=%22http://latuviitta.fi/%22%20xmlns:gml=%22http://www.opengis.net/gml%22%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ekunta_ni1%3C/PropertyName%3E%3CLiteral%3ESaarij?rvi%3C/Literal%3E%3C/PropertyIsEqualTo%3E%3C/Filter%3E

From Jukka.Rahkonen at mmmtike.fi  Wed Aug 15 14:14:53 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 15 Aug 2012 21:14:53 +0000
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <201208152145.08749.even.rouault@mines-paris.org>
References: <loom.20120808T094949-411@post.gmane.org>
	<loom.20120815T212329-456@post.gmane.org>,
	<201208152145.08749.even.rouault@mines-paris.org>
Message-ID: <84446DEF76453C439E9E97E438E13A634663AD@suutari.haapa.mmm.fi>


Even Rouault wrote:


Le mercredi 15 ao?t 2012 21:28:22, Jukka Rahkonen a ?crit :
>> GvSIG is also sending GetFeatures with http GET and filters and it had same
>> kind of problems with special characters. Now the developers say that they
>> have fixed URL encoding. I hope that the solution is somehow re-usable

> I'm not sure this is a problem with URL encoding, but more a problem with the
> fact that the Windows console is not using UTF-8. So even if the OGR WFS
> driver did escape the special character, this wouldn't solve anything, since
> it would get a non UTF8 character and would escape it wrongly...

> Some seraching would suggest that typing "chcp 65001" before might help, but
> I'm not sure...

> I'm wondering if the GDAL command line utilities shouldn't use special
> instructions under Windows to better deal with Unicode characters. Some search
> would suggest that using wmain() and/or SetConsoleOutputCP() might help. Are
> there Windows programmers around that might give advice on how to get
> arguments in UTF-8 from the Windows command line ?

> Anyway, with Linux, it works fine :
........

If it happens to help, this is the only reliable method I have discovered so far for 
creating GetFeatures on Windows so that they work.

1) Create a complete plain text request 
2) Split it into two pieces and copy the part before XML filter to a safe place.
http://188.64.1.61/cgi-bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFeature&TYPENAME=lv:municipalities&FILTER=
3) Copy the filter part and drop into some URL encoding service like http://www.albionresearch.com/misc/urlencode.php. 

For example this goes to the URL-encoding service
<Filter xmlns="http://www.opengis.net/ogc" xmlns:lv="http://latuviitta.fi/" xmlns:gml="http://www.opengis.net/gml"><PropertyIsEqualTo><PropertyName>kunta_ni1</PropertyName><Literal>Saarij?rvi</Literal></PropertyIsEqualTo></Filter>

and this comes back
%3CFilter%20xmlns%3D%22http%3A%2F%2Fwww.opengis.net%2Fogc%22%20xmlns%3Alv%3D%22http%3A%2F%2Flatuviitta.fi%2F%22%20xmlns%3Agml%3D%22http%3A%2F%2Fwww.opengis.net%2Fgml%22%3E%3CPropertyIsEqualTo%3E%3CPropertyName%3Ekunta_ni1%3C%2FPropertyName%3E%3CLiteral%3ESaarij%C3%A4rvi%3C%2FLiteral%3E%3C%2FPropertyIsEqualTo%3E%3C%2FFilter%3E

4) Combine the starting part of GetFeature from step 2) and URL-encoded filter from step 3)
This new GetFeature can be sent with a browser or with wget or curl.

You can guess that I do not really use this method for any real work.  Instead I am either using Kosmo
GIS as WFS client because it is using http POST (and has a query builder), or then I send requests 
from browser with POST method by using Poster add-on.  However, using WFS through OGR offers 
so nice possibilities that it would be great to learn some way for making also attribute filters with special characters to work - on Windows and in Finland.

-Jukka-


From even.rouault at mines-paris.org  Wed Aug 15 14:24:34 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 15 Aug 2012 23:24:34 +0200
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <84446DEF76453C439E9E97E438E13A634663AD@suutari.haapa.mmm.fi>
References: <loom.20120808T094949-411@post.gmane.org>
	<201208152145.08749.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A634663AD@suutari.haapa.mmm.fi>
Message-ID: <201208152324.35045.even.rouault@mines-paris.org>

Le mercredi 15 ao?t 2012 23:14:53, Rahkonen Jukka a ?crit :
> Even Rouault wrote:
> 
> Le mercredi 15 ao?t 2012 21:28:22, Jukka Rahkonen a ?crit :
> >> GvSIG is also sending GetFeatures with http GET and filters and it had
> >> same kind of problems with special characters. Now the developers say
> >> that they have fixed URL encoding. I hope that the solution is somehow
> >> re-usable
> > 
> > I'm not sure this is a problem with URL encoding, but more a problem with
> > the fact that the Windows console is not using UTF-8. So even if the OGR
> > WFS driver did escape the special character, this wouldn't solve
> > anything, since it would get a non UTF8 character and would escape it
> > wrongly...
> > 
> > Some seraching would suggest that typing "chcp 65001" before might help,
> > but I'm not sure...
> > 
> > I'm wondering if the GDAL command line utilities shouldn't use special
> > instructions under Windows to better deal with Unicode characters. Some
> > search would suggest that using wmain() and/or SetConsoleOutputCP()
> > might help. Are there Windows programmers around that might give advice
> > on how to get arguments in UTF-8 from the Windows command line ?
> 
> > Anyway, with Linux, it works fine :
> ........
> 
> If it happens to help, this is the only reliable method I have discovered
> so far for creating GetFeatures on Windows so that they work.
> 
> 1) Create a complete plain text request
> 2) Split it into two pieces and copy the part before XML filter to a safe
> place.
> http://188.64.1.61/cgi-bin/tinyows?SERVICE=WFS&VERSION=1.1.0&REQUEST=GetFe
> ature&TYPENAME=lv:municipalities&FILTER= 3) Copy the filter part and drop
> into some URL encoding service like
> http://www.albionresearch.com/misc/urlencode.php.

Looks a bit complicated. Actually, I'm thinking you could avoid those encoding 
problems with using :

ogrinfo "WFS:http://188.64.1.61/cgi-bin/tinyows" -sql --optfile sql.txt

where sql.txt contains (with a UTF-8 text editor, such as Notepad++ correctly 
configured) :

"select * from municipalities where kunta_ni1='Saarij?rvi'"

(The double-quote at the beginning and trailing of the file are necessary)

From Jukka.Rahkonen at mmmtike.fi  Wed Aug 15 22:04:06 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Thu, 16 Aug 2012 05:04:06 +0000
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <201208152324.35045.even.rouault@mines-paris.org>
References: <loom.20120808T094949-411@post.gmane.org>
	<201208152145.08749.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A634663AD@suutari.haapa.mmm.fi>,
	<201208152324.35045.even.rouault@mines-paris.org>
Message-ID: <84446DEF76453C439E9E97E438E13A63466403@suutari.haapa.mmm.fi>

Even Rouault wrote:

> Looks a bit complicated. Actually, I'm thinking you could avoid those encoding
> problems with using :

> ogrinfo "WFS:http://188.64.1.61/cgi-bin/tinyows" -sql --optfile sql.txt

> where sql.txt contains (with a UTF-8 text editor, such as Notepad++ correctly
> configured) :

> "select * from municipalities where kunta_ni1='Saarij?rvi'"

> (The double-quote at the beginning and trailing of the file are necessary)

Yes, that works. It is a bit tricky but totally usable. I tried to save the whole command into Windows batch file as UTF-8 encoded but that does not work, it must be done exactly as you wrote. Hardest thing will be to learn other people to do it this way.

-Jukka-

From Roger.bivand at nhh.no  Thu Aug 16 00:50:27 2012
From: Roger.bivand at nhh.no (Roger Bivand)
Date: Thu, 16 Aug 2012 07:50:27 +0000 (UTC)
Subject: [gdal-dev] Access SVN revision number from runtime?
Message-ID: <loom.20120816T093648-858@post.gmane.org>

gcore/gdal_version.h gives us the hard-wired compile-time version string.
GDALVersionInfo("--version") gives us the version known by the runtime. We can
use GDALCheckVersion() to check that the two match (in rgdal/R). But is the SVN
revision number exposed in the same way? A rgdal user on OpenSUSE has reported
problems writing GTiff which turned out to stem from updates to the shared
object having moved things leading to "Failure during IO":
http://ssrebelious.blogspot.no/2012/08/rgdal-crash-solved.html. I think that the
packagers may have been rolling their updates forward, so I'd like to provide a
more fine-grained GDALCheckVersion() which also accesses the SVN revision. Is
this possible (or sensible)?

Thanks,

Roger


From even.rouault at mines-paris.org  Thu Aug 16 01:15:15 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 10:15:15 +0200
Subject: [gdal-dev] Access SVN revision number from runtime?
In-Reply-To: <loom.20120816T093648-858@post.gmane.org>
References: <loom.20120816T093648-858@post.gmane.org>
Message-ID: <1345104915.502cac1313543@imp.free.fr>

Selon Roger Bivand <Roger.bivand at nhh.no>:

> gcore/gdal_version.h gives us the hard-wired compile-time version string.
> GDALVersionInfo("--version") gives us the version known by the runtime. We
> can
> use GDALCheckVersion() to check that the two match (in rgdal/R). But is the
> SVN
> revision number exposed in the same way?

No, the revision number is not exposed in any way.

> A rgdal user on OpenSUSE has
> reported
> problems writing GTiff which turned out to stem from updates to the shared
> object having moved things leading to "Failure during IO":
> http://ssrebelious.blogspot.no/2012/08/rgdal-crash-solved.html. I think that
> the
> packagers may have been rolling their updates forward,

Not sure what happened there. Sounds like some weird packaging/installation
problem against which you cannot do much.

> so I'd like to provide
> a
> more fine-grained GDALCheckVersion() which also accesses the SVN revision. Is
> this possible (or sensible)?

I would advise against that. I'd go further : you should not even call
GDALCheckVersion() if RGDAL is only using the C API, which (in the GDAL 1.x
series) is forward compatible. I read your comment on the above blog that you
would refuse at runtime to run against GDAL 1.9.1 if RGDAL was compiled against
GDAL 1.9.0, but I don't think you want that. You want people to be able to
install bugfixes release of GDAL without requiring a rebuild of all packages
depending on GDAL. GDALCheckVersion() is mainly usefull for authors of plugins
to detect situations where they have compiled their plugin against GDAL 1.x and
at runtime are linking against GDAL 1.y, which for plugins using the C++ API
will not potentially work due to C++ ABI changes.

>
> Thanks,
>
> Roger
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>





















From jukka.rahkonen at mmmtike.fi  Thu Aug 16 01:37:55 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Thu, 16 Aug 2012 08:37:55 +0000 (UTC)
Subject: [gdal-dev] WFS driver does not do URL-encoding right
References: <loom.20120808T094949-411@post.gmane.org>
	<201208152145.08749.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A634663AD@suutari.haapa.mmm.fi>,
	<201208152324.35045.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A63466403@suutari.haapa.mmm.fi>
Message-ID: <loom.20120816T092524-3@post.gmane.org>

I think this is my last question about WFS and URL-encoding this time.

I had a look how the WFS requests look in hexadecimals.

My TinyOWS and Mapserver WFS both accepts two ways to express letter "?" inside
ogc:Filter with http GET. First of those alternatives is an UTF-8 letter "?" in
URL-encoded format which looks as text like %C3%A4. Corresponding hex values in
the GetFeature request seem to be 25-43-33-25-41-34. Another alternative that
works also it to give letter "?" in UTF-8 without URL-encoding it and then the
hex values are C3-A4.

My question is that are both alternatives correct to use in http GET? I have
thought that URLs should use URL-encoding. OGR WFS driver is itself doing URL
encoding for <,>," and [space]. Could it be so that expressing "?" as plain
C3-A4 in a filter works only because the http GET route is passing them on as
raw, and WFS server by accident interprets them back to "?" because it is
internally using UTF-8?

There seem to be more to puzzle ordinary people like me. What looks like
character "?" to me is also an extended ASCII character #228 and some
URL-encoders are translating it to %E4 (probably the reason for gvSIG WFS filter
error).
http://www.blooberry.com/indexdot/html/topics/urlencoding.htm
Some others are considering "?" as a two-byte UTF-8 character and URL-encode 
that into %C3%A4 
http://www.w3schools.com/tags/ref_urlencode.asp

It must be funny to be a coder.

-Jukka-


From zoltans at geograph.co.za  Thu Aug 16 02:14:22 2012
From: zoltans at geograph.co.za (Zoltan Szecsei)
Date: Thu, 16 Aug 2012 11:14:22 +0200
Subject: [gdal-dev] reprojecting SRTM data
Message-ID: <502CB9EE.2090204@geograph.co.za>

Hi,
I've downloaded srtm_41_19 both in tiff and ASCII formats.

I reproject the tiif image such:
gdalwarp -t_srs '+proj=tmerc +lat_0=0 +lon_0=21 +k=1 +x_0=0 +y_0=0
+ellps=WGS84 +datum=WGS84 +units=m +no_defs' srtm_41_19.tif srtm_lo21.tif

and gdalinfo produces realistic values.

But the software I want to use this tif-DEM in complains:
Error encountered while reading GeoTIFF file:  Elevation data must
be specified as 32-bit floating point samples.

The software however does read the ASCII version, but I need to
re-project the ASCII file to Lo19 (see above proj string).

How can I do this?


Thanks & regards,
Zoltan



-- 

===========================================
Zoltan Szecsei PrGISc [PGP0031]
Geograph (Pty) Ltd.
P.O. Box 7, Muizenberg 7950, South Africa.

65 Main Road, Muizenberg 7945
Western Cape, South Africa.

34? 6'16.35"S 18?28'5.62"E

Tel: +27-21-7884897  Mobile: +27-83-6004028
Fax: +27-86-6115323     www.geograph.co.za
===========================================


From Roger.Bivand at nhh.no  Thu Aug 16 02:28:38 2012
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 16 Aug 2012 11:28:38 +0200 (CEST)
Subject: [gdal-dev] Access SVN revision number from runtime?
In-Reply-To: <1345104915.502cac1313543@imp.free.fr>
References: <loom.20120816T093648-858@post.gmane.org>
	<1345104915.502cac1313543@imp.free.fr>
Message-ID: <alpine.LRH.2.02.1208161117020.25857@reclus.nhh.no>

On Thu, 16 Aug 2012, Even Rouault wrote:

> Selon Roger Bivand <Roger.bivand at nhh.no>:
>
>> gcore/gdal_version.h gives us the hard-wired compile-time version string.
>> GDALVersionInfo("--version") gives us the version known by the runtime. We
>> can
>> use GDALCheckVersion() to check that the two match (in rgdal/R). But is the
>> SVN
>> revision number exposed in the same way?
>
> No, the revision number is not exposed in any way.
>
>> A rgdal user on OpenSUSE has reported problems writing GTiff which 
>> turned out to stem from updates to the shared object having moved 
>> things leading to "Failure during IO": 
>> http://ssrebelious.blogspot.no/2012/08/rgdal-crash-solved.html. I think 
>> that the packagers may have been rolling their updates forward,
>
> Not sure what happened there. Sounds like some weird packaging/installation
> problem against which you cannot do much.

Right, this was my basic feeling, but given the tone of his blog, I 
thought I'd ask. Thanks gor responding so fast!

>
>> so I'd like to provide a more fine-grained GDALCheckVersion() which 
>> also accesses the SVN revision. Is this possible (or sensible)?
>
> I would advise against that. I'd go further : you should not even call 
> GDALCheckVersion() if RGDAL is only using the C API, which (in the GDAL 
> 1.x series) is forward compatible. I read your comment on the above blog 
> that you would refuse at runtime to run against GDAL 1.9.1 if RGDAL was 
> compiled against GDAL 1.9.0, but I don't think you want that. You want 
> people to be able to install bugfixes release of GDAL without requiring 
> a rebuild of all packages depending on GDAL. GDALCheckVersion() is 
> mainly usefull for authors of plugins to detect situations where they 
> have compiled their plugin against GDAL 1.x and at runtime are linking 
> against GDAL 1.y, which for plugins using the C++ API will not 
> potentially work due to C++ ABI changes.

The rgdal source is part C (for proj), part C++ for OGR/GDAL, but C++ 
written by C-minded people, so no new classes, but using C++ OGR/GDAL 
classes, things like: pDataset->~GDALDataset();. As I understand you, 
1.x.a and 1.x.b share the C++ ABI, but say 1.x.b and 1.y.a will probably 
not.

This suggests that I may use GDALCheckVersion(GDAL_VERSION_MAJOR, 
GDAL_VERSION_MINOR, NULL); to get something that might help users debug 
performance failures, but that GDAL_VERSION_REV is too fine-grained.

Best wishes,

Roger

>
>>
>> Thanks,
>>
>> Roger
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-- 
Roger Bivand
Department of Economics, NHH Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From schut at sarvision.nl  Thu Aug 16 02:43:32 2012
From: schut at sarvision.nl (Vincent Schut)
Date: Thu, 16 Aug 2012 11:43:32 +0200
Subject: [gdal-dev] reprojecting SRTM data
In-Reply-To: <502CB9EE.2090204@geograph.co.za>
References: <502CB9EE.2090204@geograph.co.za>
Message-ID: <502CC0C4.4050005@sarvision.nl>

On 08/16/12 11:14, Zoltan Szecsei wrote:
> Hi,
> I've downloaded srtm_41_19 both in tiff and ASCII formats.
>
> I reproject the tiif image such:
> gdalwarp -t_srs '+proj=tmerc +lat_0=0 +lon_0=21 +k=1 +x_0=0 +y_0=0
> +ellps=WGS84 +datum=WGS84 +units=m +no_defs' srtm_41_19.tif srtm_lo21.tif
>
> and gdalinfo produces realistic values.
>
> But the software I want to use this tif-DEM in complains:
> Error encountered while reading GeoTIFF file:  Elevation data must
> be specified as 32-bit floating point samples.

Hi Zoltan,

you can add "-ot Float32" to your gdalwarp command to produce a 32-bit 
floating point file (which your software seems to want).

Best,
Vincent.
>
> The software however does read the ASCII version, but I need to
> re-project the ASCII file to Lo19 (see above proj string).
>
> How can I do this?
>
>
> Thanks & regards,
> Zoltan
>
>
>


From zoltans at geograph.co.za  Thu Aug 16 03:39:59 2012
From: zoltans at geograph.co.za (Zoltan Szecsei)
Date: Thu, 16 Aug 2012 12:39:59 +0200
Subject: [gdal-dev] reprojecting SRTM data
In-Reply-To: <502CC0C4.4050005@sarvision.nl>
References: <502CB9EE.2090204@geograph.co.za> <502CC0C4.4050005@sarvision.nl>
Message-ID: <502CCDFF.5000404@geograph.co.za>

On 2012/08/16 11:43, Vincent Schut wrote:
> On 08/16/12 11:14, Zoltan Szecsei wrote:
>>
>>
>> But the software I want to use this tif-DEM in complains:
>> Error encountered while reading GeoTIFF file:  Elevation data must
>> be specified as 32-bit floating point samples.
>
> Hi Zoltan,
>
> you can add "-ot Float32" to your gdalwarp command to produce a 32-bit 
> floating point file (which your software seems to want).
>
> Best,
> Vincent.
>

Muahahaha - works like a dream - Thanks!

You know, one of the unsaid benefits of open source, is that the 
programmer actually is also a user.
THAT is why we have all these practical and useful  little parameters. :-)

Well done to the developer of this one.

Regards,
Zoltan


-- 

===========================================
Zoltan Szecsei PrGISc [PGP0031]
Geograph (Pty) Ltd.
P.O. Box 7, Muizenberg 7950, South Africa.

65 Main Road, Muizenberg 7945
Western Cape, South Africa.

34? 6'16.35"S 18?28'5.62"E

Tel: +27-21-7884897  Mobile: +27-83-6004028
Fax: +27-86-6115323     www.geograph.co.za
===========================================


From even.rouault at mines-paris.org  Thu Aug 16 03:57:59 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 12:57:59 +0200
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <loom.20120816T092524-3@post.gmane.org>
References: <loom.20120808T094949-411@post.gmane.org>
	<201208152145.08749.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A634663AD@suutari.haapa.mmm.fi>,
	<201208152324.35045.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A63466403@suutari.haapa.mmm.fi>
	<loom.20120816T092524-3@post.gmane.org>
Message-ID: <1345114679.502cd23786cd4@imp.free.fr>

Selon Jukka Rahkonen <jukka.rahkonen at mmmtike.fi>:

> I think this is my last question about WFS and URL-encoding this time.
>
> I had a look how the WFS requests look in hexadecimals.
>
> My TinyOWS and Mapserver WFS both accepts two ways to express letter "?"
> inside
> ogc:Filter with http GET. First of those alternatives is an UTF-8 letter "?"
> in
> URL-encoded format which looks as text like %C3%A4. Corresponding hex values
> in
> the GetFeature request seem to be 25-43-33-25-41-34. Another alternative that
> works also it to give letter "?" in UTF-8 without URL-encoding it and then
> the
> hex values are C3-A4.
>
> My question is that are both alternatives correct to use in http GET?

This is a good question. My guess would be that there might be a old HTTP RFC
that only allowed ASCII characters and thus mandated URL-encoding, and perhaps a
newer RFC that accept all characters. Most servers seem to accept both.

> I have
> thought that URLs should use URL-encoding. OGR WFS driver is itself doing URL
> encoding for <,>," and [space]. Could it be so that expressing "?" as plain
> C3-A4 in a filter works only because the http GET route is passing them on as
> raw, and WFS server by accident interprets them back to "?" because it is
> internally using UTF-8?

Yes. But passing the character as 25-43-33-25-41-34 (URL-encoded) or C3-A4
(plain UTF8) requires the WFS driver to interpret it as UTF-8 in both cases. In
XML, UTF-8 is the default encoding, unless otherwise specified. But for other
parameters passed in the GET, this is indeed a good question to know how the
server is supposed which encoding it is...

Note: yesterday after your emails, I've revised substantially how escaping was
done in the WFS driver, because there were cases where URL-escaping would have
been needed (for example if you passed '&' or '%'), so now for '?', you should
see 25-43-33-25-41-34 (but that won't solve anything for Windows command line).
There was also missing XML-escaping in some cases (yes, you need to XML-escape
stuff, and then URL-escape it...).


From eborovenskiy at scanex.ru  Thu Aug 16 04:09:56 2012
From: eborovenskiy at scanex.ru (Evgeniy Borovenskiy)
Date: Thu, 16 Aug 2012 15:09:56 +0400
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
Message-ID: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>

The thing is when I try to save the buffer with an image that is being saved in the operative memory when my program is working and when the KAKADU's driver tries to create JPEG2000 for the file recording the driver isn't created. It's because there's no function 'Create' in JP2KAKDataset. But there's the function 'JP2KAKCreateCopy' in which the recording of JPEG2000 format happens from the file with the format .tif. The driver GTiffDataset is created when it's impossible to create the driver for KAKADU. The question is this: is it possible to make a record JPEG2000 directly? Is it possible to create the driver KAKADU directly, to write the function 'Create' for KAKADU and why has it happened before?


Evgeniy
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120816/af5c312b/attachment.html>

From even.rouault at mines-paris.org  Thu Aug 16 04:11:59 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 13:11:59 +0200
Subject: [gdal-dev] Access SVN revision number from runtime?
In-Reply-To: <alpine.LRH.2.02.1208161117020.25857@reclus.nhh.no>
References: <loom.20120816T093648-858@post.gmane.org>
	<1345104915.502cac1313543@imp.free.fr>
	<alpine.LRH.2.02.1208161117020.25857@reclus.nhh.no>
Message-ID: <1345115519.502cd57ff3b58@imp.free.fr>


> The rgdal source is part C (for proj), part C++ for OGR/GDAL, but C++
> written by C-minded people, so no new classes, but using C++ OGR/GDAL
> classes, things like: pDataset->~GDALDataset();.

Ah ok, so rgdal uses the GDAL C++ API (when feasable, the use of the C API is
encouraged to avoid ABI issues).

By the way pDataset->~GDALDataset() is a weird syntax. I've never used that in
any C++ code, so I am wondering if this completely destroys the object. I
suspect that the code of the destructor is called, but potentially not its super
destructor, so there must be a small memory leak. Why not using delete pDataset,
or better, to avoid cross-heap issues on Windows,
GDALClose((GDALDatasetH)pDataset) ?

> As I understand you,
> 1.x.a and 1.x.b share the C++ ABI, but say 1.x.b and 1.y.a will probably
> not.

Yes, 1.x.a and 1.x.b share the same C++ ABI, but other combinations might not.

>
> This suggests that I may use GDALCheckVersion(GDAL_VERSION_MAJOR,
> GDAL_VERSION_MINOR, NULL); to get something that might help users debug
> performance failures, but that GDAL_VERSION_REV is too fine-grained.

Yes.

















From even.rouault at mines-paris.org  Thu Aug 16 04:15:28 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 13:15:28 +0200
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
In-Reply-To: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>
References: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>
Message-ID: <1345115728.502cd6500375c@imp.free.fr>

Selon Evgeniy Borovenskiy <eborovenskiy at scanex.ru>:

> The thing is when I try to save the buffer with an image that is being saved
> in the operative memory when my program is working and when the KAKADU's
> driver tries to create JPEG2000 for the file recording the driver isn't
> created. It's because there's no function 'Create' in JP2KAKDataset. But
> there's the function 'JP2KAKCreateCopy' in which the recording of JPEG2000
> format happens from the file with the format .tif. The driver GTiffDataset is
> created when it's impossible to create the driver for KAKADU. The question is
> this: is it possible to make a record JPEG2000 directly? Is it possible to
> create the driver KAKADU directly, to write the function 'Create' for KAKADU
> and why has it happened before?

Realitvely few drivers that have write capabilities support the Create() method
(because this requires to be able to do random write in the file), and support
only CreateCopy() which needs an existing source dataset.

If I understand well your use case, you have a memory buffer that you want to
save as a JPEG2000 image with the Kakadu driver. You could create a MEM dataset
(see the doc of the MEM driver), and use it as the source dataset for the call
of CreateCopy() on the Kakadu driver.


>
>
> Evgeniy
>



From Jukka.Rahkonen at mmmtike.fi  Thu Aug 16 04:17:11 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Thu, 16 Aug 2012 11:17:11 +0000
Subject: [gdal-dev] WFS driver does not do URL-encoding right
Message-ID: <84446DEF76453C439E9E97E438E13A634665A3@suutari.haapa.mmm.fi>

Even Rouault wrote:
 
> Note: yesterday after your emails, I've revised substantially how escaping
> was done in the WFS driver, because there were cases where URL-escaping
> would have been needed (for example if you passed '&' or '%'), so now for
> '?', you should see 25-43-33-25-41-34 (but that won't solve anything for
> Windows command line).
> There was also missing XML-escaping in some cases (yes, you need to XML-
> escape stuff, and then URL-escape it...).

I have heard that things are getting quite a bit harder to handle with WPS
when you may need to include the WFS request with its filters inside the
WPS request and escape everything correctly... Should things be escaped 
once, twice or not at all...

-Jukka-

From Roger.Bivand at nhh.no  Thu Aug 16 04:17:35 2012
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 16 Aug 2012 13:17:35 +0200 (CEST)
Subject: [gdal-dev] Access SVN revision number from runtime?
In-Reply-To: <1345115519.502cd57ff3b58@imp.free.fr>
References: <loom.20120816T093648-858@post.gmane.org>
	<1345104915.502cac1313543@imp.free.fr>
	<alpine.LRH.2.02.1208161117020.25857@reclus.nhh.no>
	<1345115519.502cd57ff3b58@imp.free.fr>
Message-ID: <alpine.LRH.2.02.1208161313440.25857@reclus.nhh.no>

On Thu, 16 Aug 2012, Even Rouault wrote:

>
>> The rgdal source is part C (for proj), part C++ for OGR/GDAL, but C++
>> written by C-minded people, so no new classes, but using C++ OGR/GDAL
>> classes, things like: pDataset->~GDALDataset();.
>
> Ah ok, so rgdal uses the GDAL C++ API (when feasable, the use of the C API is
> encouraged to avoid ABI issues).

This was Tim Keitt's design choice in 2002. On reflection, the C API might 
be an improvement, when time permits. Maybe a GSoC project next year!

>
> By the way pDataset->~GDALDataset() is a weird syntax. I've never used 
> that in any C++ code, so I am wondering if this completely destroys the 
> object. I suspect that the code of the destructor is called, but 
> potentially not its super destructor, so there must be a small memory 
> leak. Why not using delete pDataset, or better, to avoid cross-heap 
> issues on Windows, GDALClose((GDALDatasetH)pDataset) ?

Once again, Tim's choice. Thanks for the tip about alternatives!

>
>> As I understand you,
>> 1.x.a and 1.x.b share the C++ ABI, but say 1.x.b and 1.y.a will probably
>> not.
>
> Yes, 1.x.a and 1.x.b share the same C++ ABI, but other combinations 
> might not.
>
>>
>> This suggests that I may use GDALCheckVersion(GDAL_VERSION_MAJOR,
>> GDAL_VERSION_MINOR, NULL); to get something that might help users debug
>> performance failures, but that GDAL_VERSION_REV is too fine-grained.
>
> Yes.
>

Good, implemented and committed to SVN.

-- 
Roger Bivand
Department of Economics, NHH Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mateusz at loskot.net  Thu Aug 16 04:19:24 2012
From: mateusz at loskot.net (Mateusz Loskot)
Date: Thu, 16 Aug 2012 12:19:24 +0100
Subject: [gdal-dev] Access SVN revision number from runtime?
In-Reply-To: <1345115519.502cd57ff3b58@imp.free.fr>
References: <loom.20120816T093648-858@post.gmane.org>
	<1345104915.502cac1313543@imp.free.fr>
	<alpine.LRH.2.02.1208161117020.25857@reclus.nhh.no>
	<1345115519.502cd57ff3b58@imp.free.fr>
Message-ID: <CABUeae9p+AHZPTqmc_HPeArodKHbRvkAdDhDJPwem5gyhiWRSA@mail.gmail.com>

On 16 August 2012 12:11, Even Rouault <even.rouault at mines-paris.org> wrote:
>
> By the way pDataset->~GDALDataset() is a weird syntax. I've never used that in
> any C++ code, so I am wondering if this completely destroys the object

The only and typical situation when destructor is called explicitly is when
object is allocated and created using "placement new" [1].
In other situations, the destructor will be called and will perform the clean-up
according to its definition, but the memory allocated for the object
itself won't be released.


[1] http://en.wikipedia.org/wiki/Placement_syntax

Best regards,
-- 
Mateusz Loskot, http://mateusz.loskot.net

From benjamin.lux at maxsea.fr  Thu Aug 16 04:43:20 2012
From: benjamin.lux at maxsea.fr (Benjamin)
Date: Thu, 16 Aug 2012 04:43:20 -0700 (PDT)
Subject: [gdal-dev]  Ogr: Is an OGR::Geometry::InteriorPoint() method ?
Message-ID: <1345117400183-4995621.post@n6.nabble.com>

Hi,

Is an OGR::Geometry method which compute an interior point exist ?
I have just found a Centroid() method but "The centroid is not necessarily
within the geometry".

So the centroid of:
POLYGON ((0 0,0 5, 5 5, 5 4, 1 4, 1 1, 5 1, 5 0, 0 0)) is near to (2 2.5),
it's within the polygon.
 _____
|   ___|
|  |___
|_____|

(ASCII fan-art \o/)

For example, with JTS (Java Topologie Suite) we can obtain an interior point
(0.5 2.5).


Thanks in advance for any reply.

Best regards,
Benjamin.



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/gdal-dev-Ogr-Is-an-OGR-Geometry-InteriorPoint-method-tp4995621.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From eborovenskiy at scanex.ru  Thu Aug 16 04:53:18 2012
From: eborovenskiy at scanex.ru (Evgeniy Borovenskiy)
Date: Thu, 16 Aug 2012 15:53:18 +0400
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
In-Reply-To: <1345115728.502cd6500375c@imp.free.fr>
References: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>
	<1345115728.502cd6500375c@imp.free.fr>
Message-ID: <955BDE81516F04498F36F60B0570974979BDADB250@vrum-exch2>

No, at the moment I use the variant in which the file '.tif' with the use of the driver GTiffDataset is created. And then through CreateCopy() JPEG2000 is created.
I'd like to create a JPEG2000 file straigh away because the size of images are very big and the intermediate file '.tif' can be more than 20GB. In one of the examples of KAKADU compressor it said that it's possible to record not the whole picture at once but to record the pictures in parts. Am I write or it's impossible to record the pictures in parts?

Is it possible to write the function 'create' for KAKADU that will create the driver for the direct record of JPEG2000 for the buffer (it's desirable to record the picture in parts)?


Evgeniy



-----Original Message-----
From: Even Rouault [mailto:even.rouault at mines-paris.org] 
Sent: Thursday, August 16, 2012 3:15 PM
To: Evgeniy Borovenskiy
Cc: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] write JPEG2000 with codek KAKADU without .tif

Selon Evgeniy Borovenskiy <eborovenskiy at scanex.ru>:

> The thing is when I try to save the buffer with an image that is being 
> saved in the operative memory when my program is working and when the 
> KAKADU's driver tries to create JPEG2000 for the file recording the 
> driver isn't created. It's because there's no function 'Create' in 
> JP2KAKDataset. But there's the function 'JP2KAKCreateCopy' in which 
> the recording of JPEG2000 format happens from the file with the format 
> .tif. The driver GTiffDataset is created when it's impossible to 
> create the driver for KAKADU. The question is
> this: is it possible to make a record JPEG2000 directly? Is it 
> possible to create the driver KAKADU directly, to write the function 
> 'Create' for KAKADU and why has it happened before?

Realitvely few drivers that have write capabilities support the Create() method (because this requires to be able to do random write in the file), and support only CreateCopy() which needs an existing source dataset.

If I understand well your use case, you have a memory buffer that you want to save as a JPEG2000 image with the Kakadu driver. You could create a MEM dataset (see the doc of the MEM driver), and use it as the source dataset for the call of CreateCopy() on the Kakadu driver.


>
>
> Evgeniy
>



From even.rouault at mines-paris.org  Thu Aug 16 05:09:25 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 14:09:25 +0200
Subject: [gdal-dev] Ogr: Is an OGR::Geometry::InteriorPoint() method ?
In-Reply-To: <1345117400183-4995621.post@n6.nabble.com>
References: <1345117400183-4995621.post@n6.nabble.com>
Message-ID: <1345118965.502ce2f568a30@imp.free.fr>

Selon Benjamin <benjamin.lux at maxsea.fr>:

> Hi,
>
> Is an OGR::Geometry method which compute an interior point exist ?

To my knowledge there is no such method. If you don't have particular
constraints on the point except that it must be at the interior of the polygon,
you could take a random vertex of the boundary, compute the distance D to the
next point, and then compute various points located on a circle centered on that
vertex and of radius D/2 until the IsPointOnSurface() returns TRUE. Not very
efficient, there are likely better methods...

> I have just found a Centroid() method but "The centroid is not necessarily
> within the geometry".
>
> So the centroid of:
> POLYGON ((0 0,0 5, 5 5, 5 4, 1 4, 1 1, 5 1, 5 0, 0 0)) is near to (2 2.5),
> it's within the polygon.
>  _____
> |   ___|
> |  |___
> |_____|
>
> (ASCII fan-art o/)
>
> For example, with JTS (Java Topologie Suite) we can obtain an interior point
> (0.5 2.5).

Do you know the name of the JTS method ? It might also exist in GEOS, the C++
port of JTS that GDAL relies on to do geometry related computations.

From ari.jolma at gmail.com  Thu Aug 16 05:20:53 2012
From: ari.jolma at gmail.com (Ari Jolma)
Date: Thu, 16 Aug 2012 15:20:53 +0300
Subject: [gdal-dev] Ogr: Is an OGR::Geometry::InteriorPoint() method ?
In-Reply-To: <1345118965.502ce2f568a30@imp.free.fr>
References: <1345117400183-4995621.post@n6.nabble.com>
	<1345118965.502ce2f568a30@imp.free.fr>
Message-ID: <502CE5A5.8000204@gmail.com>

On 08/16/2012 03:09 PM, Even Rouault wrote:
> Selon Benjamin <benjamin.lux at maxsea.fr>:
>
> > For example, with JTS (Java Topologie Suite) we can obtain an interior point (0.5 2.5).
> Do you know the name of the JTS method ? It might also exist in GEOS, the C++
> port of JTS that GDAL relies on to do geometry related computations.

http://geos.osgeo.org/doxygen/classgeos_1_1algorithm_1_1InteriorPointArea.html 
describes geos::algorithm::InteriorPointArea Class, which can be used to 
obtain an interior point of an area.

Ari


From even.rouault at mines-paris.org  Thu Aug 16 05:20:57 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 14:20:57 +0200
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
In-Reply-To: <955BDE81516F04498F36F60B0570974979BDADB250@vrum-exch2>
References: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>
	<1345115728.502cd6500375c@imp.free.fr>
	<955BDE81516F04498F36F60B0570974979BDADB250@vrum-exch2>
Message-ID: <1345119657.502ce5a9b5d5e@imp.free.fr>

Selon Evgeniy Borovenskiy <eborovenskiy at scanex.ru>:

> No, at the moment I use the variant in which the file '.tif' with the use of
> the driver GTiffDataset is created. And then through CreateCopy() JPEG2000 is
> created.
> I'd like to create a JPEG2000 file straigh away because the size of images
> are very big and the intermediate file '.tif' can be more than 20GB. In one
> of the examples of KAKADU compressor it said that it's possible to record not
> the whole picture at once but to record the pictures in parts. Am I write or
> it's impossible to record the pictures in parts?

The Kakadu API allows that, but not the GDAL JP2KAK driver. Well, internally to
the CreateCopy() method, it does actually rely on the capability to write the
picture by pieces. It is just that it is not exposed, because there might be
restrictions that would not respect the contract of Create(), which allows
random writes of blocks, and even re-write of them. Perhaps that GDAL could have
a relaxed Create(), which would advertize restricted write capability, that
would at least allow sequential write of the data, but that doesn't exist
currently.

>
> Is it possible to write the function 'create' for KAKADU that will create the
> driver for the direct record of JPEG2000 for the buffer (it's desirable to
> record the picture in parts)?

One option that could satisfy your need is to take inspiration of what is done
in the gdaldem utility to make the color-relief option works even with drivers
that have only CreateCopy() capability. See the GDALColorReliefDataset and
GDALColorReliefRasterBand classes in
http://trac.osgeo.org/gdal/browser/trunk/gdal/apps/gdaldem.cpp . Basically you
must create a intermediate dataset class and rasterband class, the later
implementing IReadBlock(), and you would pass the intermediate dataset as the
source dataset to the CreateCopy() of the JP2KAK driver. The IReadBlock() will
be called by JP2KAKCreateCopy() each time it needs data, which would allow you
to generate it on-the-fly from whatever data you have.

It is certainly less flexible that the full random write capabilities offered by
Create(), but that's the only method I can see that doesn't require extending
the JP2KAK driver.

From etourigny.dev at gmail.com  Thu Aug 16 05:25:43 2012
From: etourigny.dev at gmail.com (Etienne Tourigny)
Date: Thu, 16 Aug 2012 09:25:43 -0300
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
In-Reply-To: <955BDE81516F04498F36F60B0570974979BDADB250@vrum-exch2>
References: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>
	<1345115728.502cd6500375c@imp.free.fr>
	<955BDE81516F04498F36F60B0570974979BDADB250@vrum-exch2>
Message-ID: <CA+TxYvMcTXdKrS3_=1puu3BPOj7kTyO6x8LnG7L+FSV9gW8nEg@mail.gmail.com>

On Thu, Aug 16, 2012 at 8:53 AM, Evgeniy Borovenskiy
<eborovenskiy at scanex.ru> wrote:
> No, at the moment I use the variant in which the file '.tif' with the use of the driver GTiffDataset is created. And then through CreateCopy() JPEG2000 is created.
> I'd like to create a JPEG2000 file straigh away because the size of images are very big and the intermediate file '.tif' can be more than 20GB. In one of the examples of KAKADU compressor it said that it's possible to record not the whole picture at once but to record the pictures in parts. Am I write or it's impossible to record the pictures in parts?

If size is an issue (and not computation time), you could create your
gtiff with some type of compression (DEFLATE,LZW, etc.). Depending on
data and compression method this can dramatically reduce file size,
perhaps at the expense of computation time.

>
> Is it possible to write the function 'create' for KAKADU that will create the driver for the direct record of JPEG2000 for the buffer (it's desirable to record the picture in parts)?
>
>
> Evgeniy
>
>
>
> -----Original Message-----
> From: Even Rouault [mailto:even.rouault at mines-paris.org]
> Sent: Thursday, August 16, 2012 3:15 PM
> To: Evgeniy Borovenskiy
> Cc: gdal-dev at lists.osgeo.org
> Subject: Re: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
>
> Selon Evgeniy Borovenskiy <eborovenskiy at scanex.ru>:
>
>> The thing is when I try to save the buffer with an image that is being
>> saved in the operative memory when my program is working and when the
>> KAKADU's driver tries to create JPEG2000 for the file recording the
>> driver isn't created. It's because there's no function 'Create' in
>> JP2KAKDataset. But there's the function 'JP2KAKCreateCopy' in which
>> the recording of JPEG2000 format happens from the file with the format
>> .tif. The driver GTiffDataset is created when it's impossible to
>> create the driver for KAKADU. The question is
>> this: is it possible to make a record JPEG2000 directly? Is it
>> possible to create the driver KAKADU directly, to write the function
>> 'Create' for KAKADU and why has it happened before?
>
> Realitvely few drivers that have write capabilities support the Create() method (because this requires to be able to do random write in the file), and support only CreateCopy() which needs an existing source dataset.
>
> If I understand well your use case, you have a memory buffer that you want to save as a JPEG2000 image with the Kakadu driver. You could create a MEM dataset (see the doc of the MEM driver), and use it as the source dataset for the call of CreateCopy() on the Kakadu driver.
>
>
>>
>>
>> Evgeniy
>>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From diregola at gmail.com  Thu Aug 16 06:49:11 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Thu, 16 Aug 2012 15:49:11 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous band
	characteristics
In-Reply-To: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
References: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
Message-ID: <CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>

Hi All,

On Mon, Jul 30, 2012 at 7:31 PM, Casper B?rgesen (CABO) <CABO at niras.dk>wrote:

>  Hi! ****
>
> ** **
>
> I?m trying to create a VRT file from 4 GeoTIFFs using gdalbuildvrt. Three
> of the GeoTIFFs are created using OrthoVista and the last one created with
> an earlier version of the same program. When I run gdalbuildvrt I get the
> following error message when I try to add the file created by the early
> version: ****
>
> ** **
>
> Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping...****
>
> ** **
>
> I get the same error message, so may be related... I've tried to make a
virtual mosaic, using SRTM DEMs,

gdalbuildvrt -input_file_list list.txt STM_CP-DEMS_EU_mosaic.vrt

and got:

0...Warning 6: gdalbuildvrt does not support heterogenous band
characteristics. Skipping STM_CP-DEMS_2500015000.tif
10.Warning 6: gdalbuildvrt does not support heterogenous band
characteristics. Skipping STM_CP-DEMS_2500025000.tif
..Warning 6: gdalbuildvrt does not support heterogenous band
characteristics. Skipping STM_CP-DEMS_2500035000.tif
[....]

Hence, I made my mosaic using:
 gdalwarp --optfile list.txt STM_CP-DEMS_EU_mosaic.tif
It took a bit more time obviously, but it didn't complain.

So.. Could it be a bug of gdalbuildvrt, or.. ?

Thanks and regards,


-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120816/aa2b6e69/attachment.html>

From even.rouault at mines-paris.org  Thu Aug 16 07:32:40 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 16 Aug 2012 16:32:40 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous band
	characteristics
In-Reply-To: <CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>
References: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
	<CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>
Message-ID: <1345127560.502d04883ce9f@imp.free.fr>

Selon Margherita Di Leo <diregola at gmail.com>:

> Hi All,
>
> On Mon, Jul 30, 2012 at 7:31 PM, Casper B?rgesen (CABO) <CABO at niras.dk>wrote:
>
> >  Hi! ****
> >
> > ** **
> >
> > I?m trying to create a VRT file from 4 GeoTIFFs using gdalbuildvrt. Three
> > of the GeoTIFFs are created using OrthoVista and the last one created with
> > an earlier version of the same program. When I run gdalbuildvrt I get the
> > following error message when I try to add the file created by the early
> > version: ****
> >
> > ** **
> >
> > Warning 6: gdalbuildvrt does not support heterogenous band
> > characteristics. Skipping...****
> >
> > ** **
> >
> > I get the same error message, so may be related... I've tried to make a
> virtual mosaic, using SRTM DEMs,
>
> gdalbuildvrt -input_file_list list.txt STM_CP-DEMS_EU_mosaic.vrt
>
> and got:
>
> 0...Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping STM_CP-DEMS_2500015000.tif
> 10.Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping STM_CP-DEMS_2500025000.tif
> ..Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping STM_CP-DEMS_2500035000.tif
> [....]
>
> Hence, I made my mosaic using:
>  gdalwarp --optfile list.txt STM_CP-DEMS_EU_mosaic.tif
> It took a bit more time obviously, but it didn't complain.
>
> So.. Could it be a bug of gdalbuildvrt, or.. ?

I don't think it is a bug. gdalbuildvrt is a "lightweight" but restrictive
mosaicing solution, whereas gdalwarp is "heavier" but more capable.

gdalbuildvrt makes various checks to ensure that the tiles to be mosaiced are
very similar. Perhaps some of the tests are too restrictive. You should try to
compare the output of gdalinfo between a file that is integrated into the VRT
and one that is skipped to see which differences there are (band data type,
presence/absence of color table, color interpretation, etc...)

>
> Thanks and regards,
>
>
> --
> Dr. Margherita Di Leo
>



From benjamin.lux at maxsea.fr  Thu Aug 16 08:03:59 2012
From: benjamin.lux at maxsea.fr (Benjamin)
Date: Thu, 16 Aug 2012 08:03:59 -0700 (PDT)
Subject: [gdal-dev] Ogr: Is an OGR::Geometry::InteriorPoint() method ?
In-Reply-To: <502CE5A5.8000204@gmail.com>
References: <1345117400183-4995621.post@n6.nabble.com>
	<1345118965.502ce2f568a30@imp.free.fr> <502CE5A5.8000204@gmail.com>
Message-ID: <1345129439278-4995701.post@n6.nabble.com>

Hi,



Even Rouault wrote
> 
> To my knowledge there is no such method. If you don't have particular
> constraints on the point except that it must be at the interior of the
> polygon,
> you could take a random vertex of the boundary, compute the distance D to
> the
> next point, and then compute various points located on a circle centered
> on that
> vertex and of radius D/2 until the IsPointOnSurface() returns TRUE. Not
> very
> efficient, there are likely better methods...
> 

I don't want a totally random point.



Ari Jolma-2 wrote
> 
> On 08/16/2012 03:09 PM, Even Rouault wrote:
>> Selon Benjamin &lt;benjamin.lux@&gt;:
>>
>> > For example, with JTS (Java Topologie Suite) we can obtain an interior
>> point (0.5 2.5).
>> Do you know the name of the JTS method ? It might also exist in GEOS, the
>> C++
>> port of JTS that GDAL relies on to do geometry related computations.
> 
> http://geos.osgeo.org/doxygen/classgeos_1_1algorithm_1_1InteriorPointArea.html 
> describes geos::algorithm::InteriorPointArea Class, which can be used to 
> obtain an interior point of an area.
> 
> Ari
> 

I had a look to JTS sources and write again the InteriorPointArea in C#.
If someone want it I take it at the end of this email (and for others .NET
users who google it).

Thank to Even and Ari for theirs answers.


<code>
// A copie from JTS InteriorPointArea Class (Java) for C#
// See also : http://www.vividsolutions.com/jts/jtshome.htm

using OSGeo.OGR;
/// <summary>
/// Computes a point in the interior of an area geometry.
/// 
/// Algorithm :
/// 1/ Find the intersections between the geometry 
/// and the horizontal bisector of the area's envelope
/// 2/Pick the midpoint of the largest intersection 
/// (the intersections will be lines and points)
/// </summary>
/// <remarks>
/// Note: If a fixed precision model is used,
/// in some cases this method may return a point
/// which does not lie in the interior.
/// </remarks>
public class InteriorPointArea
{

    private static double Avg(double a, double b)
    {
        return (a + b) / 2.0;
    }

    //private Geometry _factory;
    private double[] _interiorPoint = null;
    private double _maxWidth = 0.0;

    public InteriorPointArea(Geometry g)
    {
        //_factory = g;
        Add(g);
    }

    public double[] GetInteriorPoint()
    {
        return _interiorPoint;
    }

    /// <summary>
    /// Tests the interior vertices (if any)
    /// defined by a linear Geometry for the best inside point.
    /// If a Geometry is not of dimension 1 it is not tested.
    /// </summary>
    /// geom the geometry to add.
    private void Add(Geometry geom)
    {
        if (geom.GetGeometryType() == wkbGeometryType.wkbPolygon)
        {
            AddPolygon(geom);
        }
        else if (geom.GetGeometryType() ==
wkbGeometryType.wkbGeometryCollection
            || geom.GetGeometryType() == wkbGeometryType.wkbMultiPolygon)
        {
            for (int i = 0; i < geom.GetGeometryCount(); i++)
            {
                Add(geom.GetGeometryRef(i));
            }
        }
    }



    /// <summary>
    ///  Finds a reasonable point at which to label a Geometry.
    /// @param geometry the geometry to analyze
    /// </summary>
    /// the geometry to analyze.
    /// <returns>the midpoint of the largest intersection between the
geometry and
    ///  a line halfway down its envelope</returns>
    public void AddPolygon(Geometry geometry)
    {
        Geometry bisector = HorizontalBisector(geometry);

        Geometry intersections = bisector.Intersection(geometry);
        Geometry widestIntersection = WidestGeometry(intersections);

        double width = widestIntersection.Length();
        if (_interiorPoint == null || width > _maxWidth)
        {
            _interiorPoint = CentreOfEnveloppe(widestIntersection);
            _maxWidth = width;
        }
    }



    /// <summary>
    /// return the widests geometry.
    /// </summary>
    /// The geometry.
    /// <returns>
    /// if geometry is a collection, the widest sub-geometry; otherwise,
    /// the geometry itself
    /// </returns>
    protected Geometry WidestGeometry(Geometry geometry)
    {
        if (geometry.GetGeometryType() != wkbGeometryType.wkbMultiLineString
&&
            geometry.GetGeometryType() !=
wkbGeometryType.wkbGeometryCollection)
        {
            return geometry;
        }

        if (geometry.IsEmpty())
        {
            return geometry;
        }

        Geometry widestGeometry = geometry.GetGeometryRef(0);

        for (int i = 1; i < geometry.GetGeometryCount(); i++)
        { //Start at 1
            if (geometry.GetGeometryRef(i).Length() >
widestGeometry.Length())
            {
                widestGeometry = geometry.GetGeometryRef(i);
            }
        }
        return widestGeometry;
    }

    protected Geometry HorizontalBisector(Geometry geometry)
    {

        Envelope envelope = new Envelope();
        geometry.GetEnvelope(envelope);

        // Assert: for areas, minx <> maxx
        double avgY = Avg(envelope.MinY, envelope.MaxY);
        Geometry result = new Geometry(wkbGeometryType.wkbLineString);
        result.AddPoint(envelope.MinX, avgY, 0);
        result.AddPoint(envelope.MaxX, avgY, 0);
        return result;
    }

    /// <summary>
    /// Returns the centre point of the envelope.
    /// </summary>
    /// envelope the envelope to analyze.
    /// <returns>Returns the centre point of the envelope.</returns>
    public double[] Centre(Envelope envelope)
    {
        return new double[] { Avg(envelope.MinX, envelope.MaxX),
Avg(envelope.MinY, envelope.MaxY) };
    }


    public double[] CentreOfEnveloppe(Geometry geom)
    {
        Envelope env = new Envelope();
        geom.GetEnvelope(env);
        return Centre(env);
    }

}
</code>







--
View this message in context: http://osgeo-org.1560.n6.nabble.com/gdal-dev-Ogr-Is-an-OGR-Geometry-InteriorPoint-method-tp4995621p4995701.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From mateusz at loskot.net  Thu Aug 16 08:06:22 2012
From: mateusz at loskot.net (Mateusz Loskot)
Date: Thu, 16 Aug 2012 16:06:22 +0100
Subject: [gdal-dev] Ogr: Is an OGR::Geometry::InteriorPoint() method ?
In-Reply-To: <1345129439278-4995701.post@n6.nabble.com>
References: <1345117400183-4995621.post@n6.nabble.com>
	<1345118965.502ce2f568a30@imp.free.fr>
	<502CE5A5.8000204@gmail.com> <1345129439278-4995701.post@n6.nabble.com>
Message-ID: <CABUeae-32DkdVRJW9tsdOpz=n1vOD9WQOQUu6yYvAg+iE=+rmQ@mail.gmail.com>

On 16 August 2012 16:03, Benjamin <benjamin.lux at maxsea.fr> wrote:
> I had a look to JTS sources and write again the InteriorPointArea in C#.
> If someone want it I take it at the end of this email (and for others .NET
> users who google it).

http://code.google.com/p/nettopologysuite/source/browse/trunk/NetTopologySuite/Algorithm/InteriorPointArea.cs

Best regards,
-- 
Mateusz Loskot, http://mateusz.loskot.net

From diregola at gmail.com  Thu Aug 16 08:14:48 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Thu, 16 Aug 2012 17:14:48 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous band
	characteristics
In-Reply-To: <1345127560.502d04883ce9f@imp.free.fr>
References: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
	<CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>
	<1345127560.502d04883ce9f@imp.free.fr>
Message-ID: <CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>

On Thu, Aug 16, 2012 at 4:32 PM, Even Rouault
<even.rouault at mines-paris.org>wrote:

> Selon Margherita Di Leo <diregola at gmail.com>:
>
> > Hi All,
> >
> > On Mon, Jul 30, 2012 at 7:31 PM, Casper B?rgesen (CABO) <CABO at niras.dk
> >wrote:
> >
> > >  Hi! ****
> > >
> > > ** **
> > >
> > > I?m trying to create a VRT file from 4 GeoTIFFs using gdalbuildvrt.
> Three
> > > of the GeoTIFFs are created using OrthoVista and the last one created
> with
> > > an earlier version of the same program. When I run gdalbuildvrt I get
> the
> > > following error message when I try to add the file created by the early
> > > version: ****
> > >
> > > ** **
> > >
> > > Warning 6: gdalbuildvrt does not support heterogenous band
> > > characteristics. Skipping...****
> > >
> > > ** **
> > >
> > > I get the same error message, so may be related... I've tried to make a
> > virtual mosaic, using SRTM DEMs,
> >
> > gdalbuildvrt -input_file_list list.txt STM_CP-DEMS_EU_mosaic.vrt
> >
> > and got:
> >
> > 0...Warning 6: gdalbuildvrt does not support heterogenous band
> > characteristics. Skipping STM_CP-DEMS_2500015000.tif
> > 10.Warning 6: gdalbuildvrt does not support heterogenous band
> > characteristics. Skipping STM_CP-DEMS_2500025000.tif
> > ..Warning 6: gdalbuildvrt does not support heterogenous band
> > characteristics. Skipping STM_CP-DEMS_2500035000.tif
> > [....]
> >
> > Hence, I made my mosaic using:
> >  gdalwarp --optfile list.txt STM_CP-DEMS_EU_mosaic.tif
> > It took a bit more time obviously, but it didn't complain.
> >
> > So.. Could it be a bug of gdalbuildvrt, or.. ?
>
> I don't think it is a bug. gdalbuildvrt is a "lightweight" but restrictive
> mosaicing solution, whereas gdalwarp is "heavier" but more capable.
>
> gdalbuildvrt makes various checks to ensure that the tiles to be mosaiced
> are
> very similar. Perhaps some of the tests are too restrictive. You should
> try to
> compare the output of gdalinfo between a file that is integrated into the
> VRT
> and one that is skipped to see which differences there are (band data type,
> presence/absence of color table, color interpretation, etc...)
>

Even, thank you for replying. Actually the files are all skipped, except
the first one of course. About this file, gdalinfo says:

gdalinfo STM_CP-DEMS_1790010475.tif
Driver: GTiff/GeoTIFF
Files: STM_CP-DEMS_1790010475.tif
Size is 5000, 2250
Coordinate System is:
PROJCS["ETRS89 / LAEA Europe",
    GEOGCS["ETRS89",
        DATUM["European_Terrestrial_Reference_System_1989",
            SPHEROID["GRS 1980",6378137,298.2572221000027,
                AUTHORITY["EPSG","7019"]],
            AUTHORITY["EPSG","6258"]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4258"]],
    PROJECTION["Lambert_Azimuthal_Equal_Area"],
    PARAMETER["latitude_of_center",52],
    PARAMETER["longitude_of_center",10],
    PARAMETER["false_easting",4321000],
    PARAMETER["false_northing",3210000],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AUTHORITY["EPSG","3035"]]
Origin = (1540000.000000000000000,1160000.000000000000000)
Pixel Size = (100.000000000000000,-100.000000000000000)
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_DATETIME=2010:08:09 09:37:53
  TIFFTAG_DOCUMENTNAME=STM_CP-DEMS_1790010475.tif
  TIFFTAG_IMAGEDESCRIPTION=File written by egcs_wrgtif 2.1
  TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
  TIFFTAG_SOFTWARE=IDL 7.1.1, ITT Visual Information Solutions
  TIFFTAG_XRESOLUTION=100
  TIFFTAG_YRESOLUTION=100
Image Structure Metadata:
  COMPRESSION=LZW
  INTERLEAVE=BAND
Corner Coordinates:
Upper Left  ( 1540000.000, 1160000.000) ( 18d35'52.39"W, 28d46'34.65"N)
Lower Left  ( 1540000.000,  935000.000) ( 17d57'14.30"W, 26d50'46.78"N)
Upper Right ( 2040000.000, 1160000.000) ( 13d41'27.23"W, 30d17'11.28"N)
Lower Right ( 2040000.000,  935000.000) ( 13d 8'11.03"W, 28d19' 3.39"N)
Center      ( 1790000.000, 1047500.000) ( 15d51'19.76"W, 28d35'33.72"N)
Band 1 Block=5000x1 Type=Int16, ColorInterp=Gray

So I take a skipped file for comparison:

gdalinfo STM_CP-DEMS_2500015000.tif
Driver: GTiff/GeoTIFF
Files: STM_CP-DEMS_2500015000.tif
Size is 10000, 10000
Coordinate System is:
PROJCS["ETRS89 / LAEA Europe",
    GEOGCS["ETRS89",
        DATUM["European_Terrestrial_Reference_System_1989",
            SPHEROID["GRS 1980",6378137,298.2572221000027,
                AUTHORITY["EPSG","7019"]],
            AUTHORITY["EPSG","6258"]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4258"]],
    PROJECTION["Lambert_Azimuthal_Equal_Area"],
    PARAMETER["latitude_of_center",52],
    PARAMETER["longitude_of_center",10],
    PARAMETER["false_easting",4321000],
    PARAMETER["false_northing",3210000],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AUTHORITY["EPSG","3035"]]
Origin = (2000000.000000000000000,2000000.000000000000000)
Pixel Size = (100.000000000000000,-100.000000000000000)
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_DATETIME=2010:08:06 10:58:28
  TIFFTAG_DOCUMENTNAME=STM_CP-DEMS_2500015000.tif
  TIFFTAG_IMAGEDESCRIPTION=File written by egcs_wrgtif 2.1
  TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
  TIFFTAG_SOFTWARE=IDL 7.1.1, ITT Visual Information Solutions
  TIFFTAG_XRESOLUTION=100
  TIFFTAG_YRESOLUTION=100
Image Structure Metadata:
  COMPRESSION=LZW
  INTERLEAVE=BAND
Corner Coordinates:
Upper Left  ( 2000000.000, 2000000.000) ( 16d36'13.25"W, 37d23'21.20"N)
Lower Left  ( 2000000.000, 1000000.000) ( 13d41' 3.88"W, 28d46'45.49"N)
Upper Right ( 3000000.000, 2000000.000) (  5d28'46.07"W, 39d52'33.70"N)
Lower Right ( 3000000.000, 1000000.000) (  3d40'26.43"W, 30d56'55.67"N)
Center      ( 2500000.000, 1500000.000) (  9d49'34.83"W, 34d25'40.17"N)
Band 1 Block=10000x1 Type=Float32, ColorInterp=Gray

I can't see anything obvious why these two files can't be mosaiced..

Thanks,



-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120816/0e188a55/attachment-0001.html>

From nicolas.simon at spw.wallonie.be  Thu Aug 16 08:24:55 2012
From: nicolas.simon at spw.wallonie.be (Nicolas Simon)
Date: Thu, 16 Aug 2012 17:24:55 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous
	bandcharacteristics
In-Reply-To: <CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>
Message-ID: <94D09947F0049948855245E630E6FA4E01181866@si0140.mrw.wallonie.int>

Hello,
    The problem comes from the data type: Int16 for the first file, Float32 for the second file.
 
Nicolas
-----Message d'origine-----
De : gdal-dev-bounces at lists.osgeo.org [mailto:gdal-dev-bounces at lists.osgeo.org]De la part de Margherita Di Leo
Envoy? : jeudi 16 ao?t 2012 17:15
? : Even Rouault
Cc : gdal-dev at lists.osgeo.org
Objet : Re: [gdal-dev] gdalbuildvrt problem with heterogenous bandcharacteristics




On Thu, Aug 16, 2012 at 4:32 PM, Even Rouault < even.rouault at mines-paris.org> wrote:


Selon Margherita Di Leo < diregola at gmail.com>:


> Hi All,
>
> On Mon, Jul 30, 2012 at 7:31 PM, Casper B?rgesen (CABO) < CABO at niras.dk>wrote:
>

> >  Hi! ****
> >
> > ** **

> >
> > I?m trying to create a VRT file from 4 GeoTIFFs using gdalbuildvrt. Three
> > of the GeoTIFFs are created using OrthoVista and the last one created with
> > an earlier version of the same program. When I run gdalbuildvrt I get the
> > following error message when I try to add the file created by the early

> > version: ****
> >
> > ** **

> >
> > Warning 6: gdalbuildvrt does not support heterogenous band

> > characteristics. Skipping...****
> >
> > ** **

> >
> > I get the same error message, so may be related... I've tried to make a
> virtual mosaic, using SRTM DEMs,
>
> gdalbuildvrt -input_file_list list.txt STM_CP-DEMS_EU_mosaic.vrt
>
> and got:
>
> 0...Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping STM_CP-DEMS_2500015000.tif
> 10.Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping STM_CP-DEMS_2500025000.tif
> ..Warning 6: gdalbuildvrt does not support heterogenous band
> characteristics. Skipping STM_CP-DEMS_2500035000.tif
> [....]
>
> Hence, I made my mosaic using:
>  gdalwarp --optfile list.txt STM_CP-DEMS_EU_mosaic.tif
> It took a bit more time obviously, but it didn't complain.
>
> So.. Could it be a bug of gdalbuildvrt, or.. ?


I don't think it is a bug. gdalbuildvrt is a "lightweight" but restrictive
mosaicing solution, whereas gdalwarp is "heavier" but more capable.

gdalbuildvrt makes various checks to ensure that the tiles to be mosaiced are
very similar. Perhaps some of the tests are too restrictive. You should try to
compare the output of gdalinfo between a file that is integrated into the VRT
and one that is skipped to see which differences there are (band data type,
presence/absence of color table, color interpretation, etc...)



Even, thank you for replying. Actually the files are all skipped, except the first one of course. About this file, gdalinfo says:

gdalinfo STM_CP-DEMS_1790010475.tif
Driver: GTiff/GeoTIFF
Files: STM_CP-DEMS_1790010475.tif
Size is 5000, 2250
Coordinate System is:
PROJCS["ETRS89 / LAEA Europe",
    GEOGCS["ETRS89",
        DATUM["European_Terrestrial_Reference_System_1989",
            SPHEROID["GRS 1980",6378137,298.2572221000027,
                AUTHORITY["EPSG","7019"]],
            AUTHORITY["EPSG","6258"]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4258"]],
    PROJECTION["Lambert_Azimuthal_Equal_Area"],
    PARAMETER["latitude_of_center",52],
    PARAMETER["longitude_of_center",10],
    PARAMETER["false_easting",4321000],
    PARAMETER["false_northing",3210000],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AUTHORITY["EPSG","3035"]]
Origin = (1540000.000000000000000,1160000.000000000000000)
Pixel Size = (100.000000000000000,-100.000000000000000)
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_DATETIME=2010:08:09 09:37:53
  TIFFTAG_DOCUMENTNAME=STM_CP-DEMS_1790010475.tif
  TIFFTAG_IMAGEDESCRIPTION=File written by egcs_wrgtif 2.1
  TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
  TIFFTAG_SOFTWARE=IDL 7.1.1, ITT Visual Information Solutions
  TIFFTAG_XRESOLUTION=100
  TIFFTAG_YRESOLUTION=100
Image Structure Metadata:
  COMPRESSION=LZW
  INTERLEAVE=BAND
Corner Coordinates:
Upper Left  ( 1540000.000, 1160000.000) ( 18d35'52.39"W, 28d46'34.65"N)
Lower Left  ( 1540000.000,  935000.000) ( 17d57'14.30"W, 26d50'46.78"N)
Upper Right ( 2040000.000, 1160000.000) ( 13d41'27.23"W, 30d17'11.28"N)
Lower Right ( 2040000.000,  935000.000) ( 13d 8'11.03"W, 28d19' 3.39"N)
Center      ( 1790000.000, 1047500.000) ( 15d51'19.76"W, 28d35'33.72"N)
Band 1 Block=5000x1 Type=Int16, ColorInterp=Gray

So I take a skipped file for comparison:

gdalinfo STM_CP-DEMS_2500015000.tif
Driver: GTiff/GeoTIFF
Files: STM_CP-DEMS_2500015000.tif
Size is 10000, 10000
Coordinate System is:
PROJCS["ETRS89 / LAEA Europe",
    GEOGCS["ETRS89",
        DATUM["European_Terrestrial_Reference_System_1989",
            SPHEROID["GRS 1980",6378137,298.2572221000027,
                AUTHORITY["EPSG","7019"]],
            AUTHORITY["EPSG","6258"]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4258"]],
    PROJECTION["Lambert_Azimuthal_Equal_Area"],
    PARAMETER["latitude_of_center",52],
    PARAMETER["longitude_of_center",10],
    PARAMETER["false_easting",4321000],
    PARAMETER["false_northing",3210000],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AUTHORITY["EPSG","3035"]]
Origin = (2000000.000000000000000,2000000.000000000000000)
Pixel Size = (100.000000000000000,-100.000000000000000)
Metadata:
  AREA_OR_POINT=Area
  TIFFTAG_DATETIME=2010:08:06 10:58:28
  TIFFTAG_DOCUMENTNAME=STM_CP-DEMS_2500015000.tif
  TIFFTAG_IMAGEDESCRIPTION=File written by egcs_wrgtif 2.1
  TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
  TIFFTAG_SOFTWARE=IDL 7.1.1, ITT Visual Information Solutions
  TIFFTAG_XRESOLUTION=100
  TIFFTAG_YRESOLUTION=100
Image Structure Metadata:
  COMPRESSION=LZW
  INTERLEAVE=BAND
Corner Coordinates:
Upper Left  ( 2000000.000, 2000000.000) ( 16d36'13.25"W, 37d23'21.20"N)
Lower Left  ( 2000000.000, 1000000.000) ( 13d41' 3.88"W, 28d46'45.49"N)
Upper Right ( 3000000.000, 2000000.000) (  5d28'46.07"W, 39d52'33.70"N)
Lower Right ( 3000000.000, 1000000.000) (  3d40'26.43"W, 30d56'55.67"N)
Center      ( 2500000.000, 1500000.000) (  9d49'34.83"W, 34d25'40.17"N)
Band 1 Block=10000x1 Type=Float32, ColorInterp=Gray

I can't see anything obvious why these two files can't be mosaiced.. 

Thanks,




-- 
Dr. Margherita Di Leo



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120816/2c72c3ef/attachment.html>

From diregola at gmail.com  Thu Aug 16 08:32:46 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Thu, 16 Aug 2012 17:32:46 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous
	bandcharacteristics
In-Reply-To: <94D09947F0049948855245E630E6FA4E01181866@si0140.mrw.wallonie.int>
References: <CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>
	<94D09947F0049948855245E630E6FA4E01181866@si0140.mrw.wallonie.int>
Message-ID: <CABa=8QqSSCPqcH2dGUGTz9cMNo9rcJ25wrrhBx4Pkvp7zN5-2w@mail.gmail.com>

On Thu, Aug 16, 2012 at 5:24 PM, Nicolas Simon <
nicolas.simon at spw.wallonie.be> wrote:

> **
> Hello,
>     The problem comes from the data type: Int16 for the first file,
> Float32 for the second file.
>
> Nicolas
>
>
> Thanks!


-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120816/1b483b2d/attachment.html>

From eadam at co.lincoln.or.us  Thu Aug 16 14:02:02 2012
From: eadam at co.lincoln.or.us (Eli Adam)
Date: Thu, 16 Aug 2012 14:02:02 -0700
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous band
	characteristics
In-Reply-To: <CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>
References: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
	<CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>
	<1345127560.502d04883ce9f@imp.free.fr>
	<CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>
Message-ID: <CACqBkM8yNT7cHCqE6D6EQvc-Dtcy1xx+=Z7kUAqzRMQbXhsfPw@mail.gmail.com>

> Band 1 Block=5000x1 Type=Int16, ColorInterp=Gray
...
> Band 1 Block=10000x1 Type=Float32, ColorInterp=Gray
>
> I can't see anything obvious why these two files can't be mosaiced..
>

It looks like one is 16 bit and the other 32.  gdalbuildvrt probably
can't determine the type of output to create.

What is the output type of gdalwarp on the same files? Did gdalwarp do
anything to make the input files match in the output?

HTH, Eli

From jukka.rahkonen at mmmtike.fi  Thu Aug 16 23:28:24 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Fri, 17 Aug 2012 06:28:24 +0000 (UTC)
Subject: [gdal-dev] Ogr: Is an OGR::Geometry::InteriorPoint() method ?
References: <1345117400183-4995621.post@n6.nabble.com>
	<1345118965.502ce2f568a30@imp.free.fr> <502CE5A5.8000204@gmail.com>
	<1345129439278-4995701.post@n6.nabble.com>
Message-ID: <loom.20120817T082424-599@post.gmane.org>

Benjamin <benjamin.lux <at> maxsea.fr> writes:

....
> Thank to Even and Ari for theirs answers.
> 
> <code>
> // A copie from JTS InteriorPointArea Class (Java) for C#
> // See also : http://www.vividsolutions.com/jts/jtshome.htm
> 

Perhaps it does not matter in this case but JTS home is nowadays at
http://tsusiatsoftware.net/jts/main.html and the latest version there seems to
be 1.12. 

-Jukka Rahkonen-


From diregola at gmail.com  Thu Aug 16 23:56:26 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Fri, 17 Aug 2012 08:56:26 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous band
	characteristics
In-Reply-To: <CACqBkM8yNT7cHCqE6D6EQvc-Dtcy1xx+=Z7kUAqzRMQbXhsfPw@mail.gmail.com>
References: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
	<CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>
	<1345127560.502d04883ce9f@imp.free.fr>
	<CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>
	<CACqBkM8yNT7cHCqE6D6EQvc-Dtcy1xx+=Z7kUAqzRMQbXhsfPw@mail.gmail.com>
Message-ID: <CABa=8QoD7SMfm27EGs9nDPAPRUnXxN9M3QnYCDxE1FSwq6pLOw@mail.gmail.com>

Hi,

On Thu, Aug 16, 2012 at 11:02 PM, Eli Adam <eadam at co.lincoln.or.us> wrote:

> > Band 1 Block=5000x1 Type=Int16, ColorInterp=Gray
> ...
> > Band 1 Block=10000x1 Type=Float32, ColorInterp=Gray
> >
> > I can't see anything obvious why these two files can't be mosaiced..
> >
>
> It looks like one is 16 bit and the other 32.  gdalbuildvrt probably
> can't determine the type of output to create.
>
> What is the output type of gdalwarp on the same files? Did gdalwarp do
> anything to make the input files match in the output?
>

This is the output of the mosaic made by gdalwarp:

gdalinfo STM_CP-DEMS_EU_mosaic.tif
Driver: GTiff/GeoTIFF
Files: /home/leomarg/DATA/SRTM_DEMs/_ALL/STM_CP-DEMS_EU_mosaic.tif
Size is 64600, 50650
Coordinate System is:
PROJCS["ETRS89 / LAEA Europe",
    GEOGCS["ETRS89",
        DATUM["European_Terrestrial_Reference_System_1989",
            SPHEROID["GRS 1980",6378137,298.2572221010002,
                AUTHORITY["EPSG","7019"]],
            AUTHORITY["EPSG","6258"]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433],
        AUTHORITY["EPSG","4258"]],
    PROJECTION["Lambert_Azimuthal_Equal_Area"],
    PARAMETER["latitude_of_center",52],
    PARAMETER["longitude_of_center",10],
    PARAMETER["false_easting",4321000],
    PARAMETER["false_northing",3210000],
    UNIT["metre",1,
        AUTHORITY["EPSG","9001"]],
    AUTHORITY["EPSG","3035"]]
Origin = (1540000.000000000000000,6000000.000000000000000)
Pixel Size = (100.000000000000000,-100.000000000000000)
Metadata:
  AREA_OR_POINT=Area
Image Structure Metadata:
  INTERLEAVE=BAND
Corner Coordinates:
Upper Left  ( 1540000.000, 6000000.000) ( 57d31'59.79"W, 63d25'17.15"N)
Lower Left  ( 1540000.000,  935000.000) ( 17d57'14.30"W, 26d50'46.78"N)
Upper Right ( 8000000.000, 6000000.000) ( 86d 0'31.83"E, 56d26'45.47"N)
Lower Right ( 8000000.000,  935000.000) ( 46d17'14.56"E, 23d32'41.83"N)
Center      ( 4770000.000, 3467500.000) ( 16d52'39.75"E, 54d 7'19.36"N)
Band 1 Block=64600x1 Type=Int16, ColorInterp=Gray

Thanks,


-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120817/64f43905/attachment.html>

From ari.jolma at gmail.com  Fri Aug 17 00:49:54 2012
From: ari.jolma at gmail.com (Ari Jolma)
Date: Fri, 17 Aug 2012 10:49:54 +0300
Subject: [gdal-dev] Ogr: Is an OGR::Geometry::InteriorPoint() method ?
In-Reply-To: <1345129439278-4995701.post@n6.nabble.com>
References: <1345117400183-4995621.post@n6.nabble.com>
	<1345118965.502ce2f568a30@imp.free.fr> <502CE5A5.8000204@gmail.com>
	<1345129439278-4995701.post@n6.nabble.com>
Message-ID: <502DF7A2.30102@gmail.com>

I wrote:

 >http://geos.osgeo.org/doxygen/classgeos_1_1algorithm_1_1InteriorPointArea.html describes >geos::algorithm::InteriorPointArea Class, which can be used to obtain an interior point of an area.

In fact, I would be interested in having this exposed through GDAL 
because of the addPolygon method for labeling geometries. My current 
labeling algorithm (for visualizing GDAL vector data) is not very good.

Ari


From jukka.rahkonen at mmmtike.fi  Fri Aug 17 00:55:05 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Fri, 17 Aug 2012 07:55:05 +0000 (UTC)
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
References: <955BDE81516F04498F36F60B0570974979BDADB248@vrum-exch2>
	<1345115728.502cd6500375c@imp.free.fr>
	<955BDE81516F04498F36F60B0570974979BDADB250@vrum-exch2>
Message-ID: <loom.20120817T090326-349@post.gmane.org>

Evgeniy Borovenskiy <eborovenskiy <at> scanex.ru> writes:

> 
> No, at the moment I use the variant in which the file '.tif' with the use of
the driver GTiffDataset is
> created. And then through CreateCopy() JPEG2000 is created.
> I'd like to create a JPEG2000 file straigh away because the size of images are
very big and the intermediate
> file '.tif' can be more than 20GB. In one of the examples of KAKADU compressor
it said that it's possible to
> record not the whole picture at once but to record the pictures in parts. Am I
write or it's impossible to
> record the pictures in parts?
> 
> Is it possible to write the function 'create' for KAKADU that will create the
driver for the direct record of
> JPEG2000 for the buffer (it's desirable to record the picture in parts)?
> 
> Evgeniy

If you are creating big images and if you want to get them ready fast you may
consider not to use GDAL for JPEG2000 compression at all. Have a try by writing
an intermediate geotiff with GDAL and compress it with native Kakadu tools. GDAL
is fast with tiffs but not so optimal with JPEG2000.

I have some fresh timings available about compressing a biggish raster map
mosaic. I created first an intermediate tiff file from .vrt mosaic with GDAL.
Resulting image had 288000 x 480000 pixels and it compressed extremely well with
deflate into 5.1 GB while as uncompressed it would have been 400 GB. Compressing
this image into JPEG2000 took 78 minutes with Kakadu tools. 

Parameters were adjusted to give a good visual quality and image file that fits
on DVD. If somebody gets interested in doing something similar, please do not
copy my -slope parameter but use -rate instead. Using slopes is faster than
using rate and it leads to constant quality instead of constant bit rate but
parameters must suit the input data.

Computer specs:
- AMD Phenom(tm) II X2 545 Processor
- 6 GB RAM
- SATA-disk, same disk for input and output
- Windows ,7 64-bit
 
Kdu_compress-version
- 7.0 compiled from sources with libtiff support
 
Kdu_compress -command
 
kdu_compress -i 50t_single.tif -o 50t_kdu70_slopes.jp2
-slope 47000,44170 
Clayers=10 
Clevels=9 
Corder=RPCL 
ORGgen_plt=yes
Cprecincts={256,256},{256,256},{128,128},{64,64} 
Stiles={32768,32768} 
-flush_period 32768

I did not have fresh GDAL with JP2KAK driver for doing a speed comparison. I am
not totally sure if GDAL could even compress this image at all because JP2KAK
driver does not support tiles and using incremental flushing in a GDAL way could
lead to error because it may try to create more than 256 tile parts. But 20 GB
is not a big image and you won't see this to happen.

-Jukka Rahkonen-




From lhomme.xavier at gmail.com  Fri Aug 17 02:35:40 2012
From: lhomme.xavier at gmail.com (xavier lhomme)
Date: Fri, 17 Aug 2012 11:35:40 +0200
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <84446DEF76453C439E9E97E438E13A634665A3@suutari.haapa.mmm.fi>
References: <84446DEF76453C439E9E97E438E13A634665A3@suutari.haapa.mmm.fi>
Message-ID: <CACqzBMx2GWO7bLxPO_vGdDqaBkXLTqYQoqkjvvLqzMhJmLJvaQ@mail.gmail.com>

Hi
 I tried to add to the function SetAttributeFirlter the following  filter :
 nam = 'MY#FIRST TEST ON'   but it doesn't work.
 then I tried    HttpUtility.UrlEncode( ) but it doesn't work too.

 If I encode my string like this  nam = 'MY%23 FIRST+TEST+ON ' it works;

 Could you explain a bit more what we need to encode ?

xav
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120817/86e16072/attachment.html>

From even.rouault at mines-paris.org  Fri Aug 17 02:47:20 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Fri, 17 Aug 2012 11:47:20 +0200
Subject: [gdal-dev] WFS driver does not do URL-encoding right
In-Reply-To: <CACqzBMx2GWO7bLxPO_vGdDqaBkXLTqYQoqkjvvLqzMhJmLJvaQ@mail.gmail.com>
References: <84446DEF76453C439E9E97E438E13A634665A3@suutari.haapa.mmm.fi>
	<CACqzBMx2GWO7bLxPO_vGdDqaBkXLTqYQoqkjvvLqzMhJmLJvaQ@mail.gmail.com>
Message-ID: <1345196840.502e1328aa488@imp.free.fr>

Selon xavier lhomme <lhomme.xavier at gmail.com>:

> Hi
>  I tried to add to the function SetAttributeFirlter the following  filter :
>  nam = 'MY#FIRST TEST ON'   but it doesn't work.
>  then I tried    HttpUtility.UrlEncode( ) but it doesn't work too.
>
>  If I encode my string like this  nam = 'MY%23 FIRST+TEST+ON ' it works;
>
>  Could you explain a bit more what we need to encode ?

You shouldn't to have to do any encoding on the side of the user using the OGR
API (and if you do so, then the WFS driver might again URL-encode what you would
have already encoded... definitely not what you want). This must be done by the
WFS driver when composing the request to the WFS server. I've pushed a few fixes
to trunk 2 days ago to improve the URL encoding. Perhaps they will fix your
issue.

>
> xav
>



From jukka.rahkonen at mmmtike.fi  Sat Aug 18 06:12:18 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Sat, 18 Aug 2012 13:12:18 +0000 (UTC)
Subject: [gdal-dev] Gdalinfo slow with big Rasterlite tables
Message-ID: <loom.20120818T142851-271@post.gmane.org>

Hi,

I converted 153600 x 249600 pixels of rasterdata into a
Rasterlite table. After creating overviews the result
behaves well in Quantum GIS once the table is opened.
Unfortunatly opening the table with QGis installed on a
mini PC takes ages.

I do not know what QGis is really doing but I guessed that
perhaps it wants to know some metadata and makes a
gdalinfo request or something equivalent. Therefore I made
a test with bit more powerful computer and running
gdalinfo with that took about 3 minutes. That feels rather
slow.

Is gdalinfo perhaps walking through every single tile in the
rasterlite table for gathering the image layer info? Could
there be any other way to do it in more effective way on the
GDAL side?

I have a feeling that this may not be really a GDAL
problem. Doing plain SELECT count(*) from test_rasters
with Spatialite-gui is also very slow and took about the
same 3 minutes in my rapid test. That makes me think that
for getting more speed Rasterlite should store more info
about tiles into raster_metadata tables for providing an
instant access to data. Perhaps this is something to talk
with Alessandro who is developing a new Rasterlite 2 which
should be ready by the end of this year.

When it comes to GDAL, could it make any sense to cache
gdalinfo from Rasterlite layers? Three minutes is rather a
long time and my 153600 x 249600 pixel sized layer with
780270 rows/tiles in 5 meter resolution in the table is
not exceptionally big. If time is increasing with tile
count it would mean 12 minutes for getting gdalinfo from
2.5 meter resolution and 48 minutes from 1.25 minutes
layer...

Test with gdal_translate makes me feel that it is also
reading the layer info first and spending about 3 minutes for
that before starting the real work. Timing is very uncertain
though, I could only take the time before the progress bar
appears on the screen.

-Jukka Rahkonen-




From even.rouault at mines-paris.org  Sat Aug 18 07:43:34 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 18 Aug 2012 16:43:34 +0200
Subject: [gdal-dev] Gdalinfo slow with big Rasterlite tables
In-Reply-To: <loom.20120818T142851-271@post.gmane.org>
References: <loom.20120818T142851-271@post.gmane.org>
Message-ID: <201208181643.34423.even.rouault@mines-paris.org>

Jukka,

> 
> Is gdalinfo perhaps walking through every single tile in the
> rasterlite table for gathering the image layer info? Could
> there be any other way to do it in more effective way on the
> GDAL side?

The Rasterlite driver needs to fetch the extent of the "XXXX_metadata" layers 
to establish the extent of the raster XXXX, which might take a long time when 
there are a lot of tiles.

> 
> When it comes to GDAL, could it make any sense to cache
> gdalinfo from Rasterlite layers? Three minutes is rather a
> long time and my 153600 x 249600 pixel sized layer with
> 780270 rows/tiles in 5 meter resolution in the table is
> not exceptionally big. If time is increasing with tile
> count it would mean 12 minutes for getting gdalinfo from
> 2.5 meter resolution and 48 minutes from 1.25 minutes
> layer...
> 

Funny because independantly of the issue you raise here, I was working on 
improving the performance of GetFeatureCount() and GetExtent() on Spatialite 
DBs. In Spatialite 3.0, there is a SQL function triggered by "SELECT 
UpdateLayerStatistics()" that creates a "layer_statistics" table that cache 
those both row count and extent.

I've just pushed an improvement (r24800) in which the SQLite driver can use 
those cached values, if they are up-to-date. The up-to-dateness is determined 
by checking that the timestamp of the last 'UpdateLayerStatistics' event 
recorded in the 'spatialite_history' table matches the timestamp of the file. 
When creating a new Spatialite DB or updating it with the OGR API, the SQLite 
driver makes sure that the statistics are kept up-to-date automatically. 
However, if a third-party tool edits the DB, it is then necessary to run : 
ogrinfo the.db -sql "SELECT UpdateLayerStatistics()". (The driver plays on the 
safe side, and will not use old statistics to avoid getting false results.)

I've just made marginal changes (r24801) in the Rasterlite driver so that the 
above caching mechanism works automatically in simple gdal_translate and 
gdaladdo scenario. I would expect that it might solve your performance 
problem, although I have not checked that.

You can check that statistics are used by issuing :

$ gdalinfo byte.sqlite --debug on

SQLITE: SpatiaLite-style SQLite DB found !
SQLITE: File timestamp matches layer statistics timestamp. Loading statistics 
for byte_metadata
SQLite: Layer byte_metadata feature count : 2
SQLite: Layer byte_metadata extent : 440720.0,3750120.0,441920.0,3751320.0
OGR: OGROpen(byte.sqlite/0x1ad6390) succeeded as SQLite.
[...]

Best regards,

Even

From even.rouault at mines-paris.org  Sat Aug 18 10:03:56 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sat, 18 Aug 2012 19:03:56 +0200
Subject: [gdal-dev] [Proposed new feature] A '"SQLite" SQL dialect for OGR
Message-ID: <201208181903.56368.even.rouault@mines-paris.org>

Hi folks,

I've attached in 
http://trac.osgeo.org/gdal/attachment/ticket/4782/sqlite_dialect.patch a patch 
that adds a SQLite alternate SQL dialect that can be used with any OGR 
datasource (only available if GDAL/OGR is configured with SQLite support of 
course)

To remind you the concept of SQL dialects, for non-RDBMS OGR drivers, OGR uses 
its own SQL engine, which is the called the OGRSQL dialect. Whereas for RDBMS 
OGR drivers, their own SQL engine will be used, unless otherwise specified.

This patchs adds the capability to use a SQLite dialect (through the -dialect 
option of ogrinfo or ogr2ogr for example). When doing so, the SQLite SQL 
engine is used, and when Spatialite is available, all the Spatialite functions 
( see http://www.gaia-gis.it/gaia-sins/spatialite-sql-3.0.0.html ) can also be 
used.

Technically, this works thanks to a temporary in-memory SQLite DB and a module 
(ogr/ogrsf_frmts/sqlite/ogrsqlitevirtualogr.cpp) that exposes OGR layers to 
SQLite through its Virtual Table mechanism ( http://www.sqlite.org/vtab.html 
). When the datasource you operate on is opened in update mode and that the 
corresponding OGR driver supports CreateFeature()/SetFeature()/DeleteFeature() 
operations, SQL INSERT/UPDATE/DELETE operations will work too.

What do you think about it ?

A few non-exhaustive examples of things you can do :

# Initial CSV file :

$ cat my.csv
id,foo,bar,long,lat
1,"foo","bar",2,49
1,"foo","bar",3,50
2,"foo2","bar2",-2,49
2,"foo2","bar2",-3,51

# Creates a Geometry field from each (long,lat) tuple :

$ ogrinfo my.csv -dialect sqlite -sql "SELECT *, MakePoint(CAST(long AS 
FLOAT), CAST(lat AS FLOAT)) as geometry FROM my" -q

Layer name: SELECT
OGRFeature(SELECT):0
  id (String) = 1
  foo (String) = foo
  bar (String) = bar
  long (String) = 2
  lat (String) = 49
  POINT (2 49)

OGRFeature(SELECT):1
  id (String) = 1
  foo (String) = foo
  bar (String) = bar
  long (String) = 3
  lat (String) = 50
  POINT (3 50)

OGRFeature(SELECT):2
  id (String) = 2
  foo (String) = foo2
  bar (String) = bar2
  long (String) = -2
  lat (String) = 49
  POINT (-2 49)

OGRFeature(SELECT):3
  id (String) = 2
  foo (String) = foo2
  bar (String) = bar2
  long (String) = -3
  lat (String) = 51
  POINT (-3 51)


# Merge all the points that have the same id into a line :

$ ogrinfo my.csv -dialect sqlite -sql "SELECT id, foo,bar, 
MakeLine(MakePoint(CAST(long AS FLOAT), CAST(lat AS FLOAT))) FROM my GROUP BY 
id" -q

Layer name: SELECT
OGRFeature(SELECT):0
  id (String) = 1
  foo (String) = foo
  bar (String) = bar
  LINESTRING (2 49,3 50)

OGRFeature(SELECT):1
  id (String) = 2
  foo (String) = foo2
  bar (String) = bar2
  LINESTRING (-2 49,-3 51)

# Compute the geodesic length of each line :

$ ogrinfo my.csv -dialect sqlite -sql "SELECT id,  
GeodesicLength(SetSRID(MakeLine(MakePoint(CAST(long AS FLOAT), CAST(lat AS 
FLOAT))),4326)) AS total_length FROM my GROUP BY id" -q

Layer name: SELECT
OGRFeature(SELECT):0
  id (String) = 1
  total_length (Real) = 132725.477910869

OGRFeature(SELECT):1
  id (String) = 2
  total_length (Real) = 233720.037020965

# Appends a new entry in the CSV :

$ ogrinfo my.csv -dialect sqlite -sql "insert into my (id,foo,bar,long,lat) 
values (3,'foo3','bar3',2.5,49.5)"

$ cat my.csv
id,foo,bar,long,lat
1,"foo","bar",2,49
1,"foo","bar",3,50
2,"foo2","bar2",-2,49
2,"foo2","bar2",-3,51
3,foo3,bar3,2.5,49.5

# Reprojection from EPSG:32631 to EPSG:4326 :

$ ogrinfo poly.shp -dialect sqlite -sql "SELECT 
ST_Transform(SetSRID(GEOMETRY,32631),4326) AS GEOMETRY, * FROM poly WHERE 
EAS_ID = 170"
INFO: Open of `poly.shp'
      using driver `ESRI Shapefile' successful.

Layer name: SELECT
Geometry: Unknown (any)
Feature Count: 1
Extent: (2.750069, 43.034444) - (2.751428, 43.035184)
Layer SRS WKT:
GEOGCS["WGS 84",
    DATUM["WGS_1984",
        SPHEROID["WGS 84",6378137,298.257223563,
            AUTHORITY["EPSG","7030"]],
        AUTHORITY["EPSG","6326"]],
    PRIMEM["Greenwich",0,
        AUTHORITY["EPSG","8901"]],
    UNIT["degree",0.0174532925199433,
        AUTHORITY["EPSG","9122"]],
    AUTHORITY["EPSG","4326"]]
Geometry Column = GEOMETRY
AREA: Real (0.0)
EAS_ID: Real (0.0)
PRFEDEA: String (0.0)
OGRFeature(SELECT):0
  AREA (Real) = 5268.813
  EAS_ID (Real) = 170
  PRFEDEA (String) = 35043413
  POLYGON ((2.751427625469495 43.034734578878634,2.750298298604006 
43.034443959553869,2.75006933958772 43.03490271631064,2.75124435992688 
43.035184432169061,2.751427625469495 43.034734578878634))

Note: a similar capability was already available in OGR 1.9 for Shapefiles, 
through the use of the VirtualShape module that is embedded in Spatialite. See 
the http://gdal.org/ogr/drv_sqlite.html page.

Best regards,

Even


From Michael.Smith at erdc.dren.mil  Sat Aug 18 10:28:09 2012
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Sat, 18 Aug 2012 17:28:09 +0000
Subject: [gdal-dev] [Proposed new feature] A '"SQLite" SQL dialect for
 OGR
In-Reply-To: <201208181903.56368.even.rouault@mines-paris.org>
Message-ID: <CC5548C9.339E4%michael.smith@erdc.dren.mil>

This is "wicked cool".

Mike

-- 
Michael Smith

US Army Corps
Remote Sensing GIS/Center



On 8/18/12 1:03 PM, "Even Rouault" <even.rouault at mines-paris.org> wrote:

>Hi folks,
>
>I've attached in 
>http://trac.osgeo.org/gdal/attachment/ticket/4782/sqlite_dialect.patch a
>patch 
>that adds a SQLite alternate SQL dialect that can be used with any OGR
>datasource (only available if GDAL/OGR is configured with SQLite support
>of 
>course)
>
>To remind you the concept of SQL dialects, for non-RDBMS OGR drivers, OGR
>uses 
>its own SQL engine, which is the called the OGRSQL dialect. Whereas for
>RDBMS 
>OGR drivers, their own SQL engine will be used, unless otherwise
>specified.
>
>This patchs adds the capability to use a SQLite dialect (through the
>-dialect 
>option of ogrinfo or ogr2ogr for example). When doing so, the SQLite SQL
>engine is used, and when Spatialite is available, all the Spatialite
>functions 
>( see http://www.gaia-gis.it/gaia-sins/spatialite-sql-3.0.0.html ) can
>also be 
>used.
>
>Technically, this works thanks to a temporary in-memory SQLite DB and a
>module 
>(ogr/ogrsf_frmts/sqlite/ogrsqlitevirtualogr.cpp) that exposes OGR layers
>to 
>SQLite through its Virtual Table mechanism (
>http://www.sqlite.org/vtab.html
>). When the datasource you operate on is opened in update mode and that
>the 
>corresponding OGR driver supports
>CreateFeature()/SetFeature()/DeleteFeature()
>operations, SQL INSERT/UPDATE/DELETE operations will work too.
>
>What do you think about it ?
>
>A few non-exhaustive examples of things you can do :
>
># Initial CSV file :
>
>$ cat my.csv
>id,foo,bar,long,lat
>1,"foo","bar",2,49
>1,"foo","bar",3,50
>2,"foo2","bar2",-2,49
>2,"foo2","bar2",-3,51
>
># Creates a Geometry field from each (long,lat) tuple :
>
>$ ogrinfo my.csv -dialect sqlite -sql "SELECT *, MakePoint(CAST(long AS
>FLOAT), CAST(lat AS FLOAT)) as geometry FROM my" -q
>
>Layer name: SELECT
>OGRFeature(SELECT):0
>  id (String) = 1
>  foo (String) = foo
>  bar (String) = bar
>  long (String) = 2
>  lat (String) = 49
>  POINT (2 49)
>
>OGRFeature(SELECT):1
>  id (String) = 1
>  foo (String) = foo
>  bar (String) = bar
>  long (String) = 3
>  lat (String) = 50
>  POINT (3 50)
>
>OGRFeature(SELECT):2
>  id (String) = 2
>  foo (String) = foo2
>  bar (String) = bar2
>  long (String) = -2
>  lat (String) = 49
>  POINT (-2 49)
>
>OGRFeature(SELECT):3
>  id (String) = 2
>  foo (String) = foo2
>  bar (String) = bar2
>  long (String) = -3
>  lat (String) = 51
>  POINT (-3 51)
>
>
># Merge all the points that have the same id into a line :
>
>$ ogrinfo my.csv -dialect sqlite -sql "SELECT id, foo,bar,
>MakeLine(MakePoint(CAST(long AS FLOAT), CAST(lat AS FLOAT))) FROM my
>GROUP BY 
>id" -q
>
>Layer name: SELECT
>OGRFeature(SELECT):0
>  id (String) = 1
>  foo (String) = foo
>  bar (String) = bar
>  LINESTRING (2 49,3 50)
>
>OGRFeature(SELECT):1
>  id (String) = 2
>  foo (String) = foo2
>  bar (String) = bar2
>  LINESTRING (-2 49,-3 51)
>
># Compute the geodesic length of each line :
>
>$ ogrinfo my.csv -dialect sqlite -sql "SELECT id,
>GeodesicLength(SetSRID(MakeLine(MakePoint(CAST(long AS FLOAT), CAST(lat
>AS 
>FLOAT))),4326)) AS total_length FROM my GROUP BY id" -q
>
>Layer name: SELECT
>OGRFeature(SELECT):0
>  id (String) = 1
>  total_length (Real) = 132725.477910869
>
>OGRFeature(SELECT):1
>  id (String) = 2
>  total_length (Real) = 233720.037020965
>
># Appends a new entry in the CSV :
>
>$ ogrinfo my.csv -dialect sqlite -sql "insert into my
>(id,foo,bar,long,lat)
>values (3,'foo3','bar3',2.5,49.5)"
>
>$ cat my.csv
>id,foo,bar,long,lat
>1,"foo","bar",2,49
>1,"foo","bar",3,50
>2,"foo2","bar2",-2,49
>2,"foo2","bar2",-3,51
>3,foo3,bar3,2.5,49.5
>
># Reprojection from EPSG:32631 to EPSG:4326 :
>
>$ ogrinfo poly.shp -dialect sqlite -sql "SELECT
>ST_Transform(SetSRID(GEOMETRY,32631),4326) AS GEOMETRY, * FROM poly WHERE
>EAS_ID = 170"
>INFO: Open of `poly.shp'
>      using driver `ESRI Shapefile' successful.
>
>Layer name: SELECT
>Geometry: Unknown (any)
>Feature Count: 1
>Extent: (2.750069, 43.034444) - (2.751428, 43.035184)
>Layer SRS WKT:
>GEOGCS["WGS 84",
>    DATUM["WGS_1984",
>        SPHEROID["WGS 84",6378137,298.257223563,
>            AUTHORITY["EPSG","7030"]],
>        AUTHORITY["EPSG","6326"]],
>    PRIMEM["Greenwich",0,
>        AUTHORITY["EPSG","8901"]],
>    UNIT["degree",0.0174532925199433,
>        AUTHORITY["EPSG","9122"]],
>    AUTHORITY["EPSG","4326"]]
>Geometry Column = GEOMETRY
>AREA: Real (0.0)
>EAS_ID: Real (0.0)
>PRFEDEA: String (0.0)
>OGRFeature(SELECT):0
>  AREA (Real) = 5268.813
>  EAS_ID (Real) = 170
>  PRFEDEA (String) = 35043413
>  POLYGON ((2.751427625469495 43.034734578878634,2.750298298604006
>43.034443959553869,2.75006933958772 43.03490271631064,2.75124435992688
>43.035184432169061,2.751427625469495 43.034734578878634))
>
>Note: a similar capability was already available in OGR 1.9 for
>Shapefiles, 
>through the use of the VirtualShape module that is embedded in
>Spatialite. See 
>the http://gdal.org/ogr/drv_sqlite.html page.
>
>Best regards,
>
>Even
>
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev


From jmckenna at gatewaygeomatics.com  Sun Aug 19 05:11:42 2012
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Sun, 19 Aug 2012 09:11:42 -0300
Subject: [gdal-dev] [Proposed new feature] A '"SQLite" SQL dialect for
 OGR
In-Reply-To: <CC5548C9.339E4%michael.smith@erdc.dren.mil>
References: <CC5548C9.339E4%michael.smith@erdc.dren.mil>
Message-ID: <5030D7FE.5010108@gatewaygeomatics.com>

I agree, fascinating.

-jeff



On 12-08-18 2:28 PM, Smith, Michael ERDC-RDE-CRREL-NH wrote:
> This is "wicked cool".
> 
> Mike
> 
> -- Michael Smith US Army Corps Remote Sensing GIS/Center On 8/18/12 1:03
> PM, "Even Rouault" <even.rouault at mines-paris.org> wrote:
>> >Hi folks,
>> >
>> >I've attached in 
>> >http://trac.osgeo.org/gdal/attachment/ticket/4782/sqlite_dialect.patch a
>> >patch 
>> >that adds a SQLite alternate SQL dialect that can be used with any OGR
>> >datasource (only available if GDAL/OGR is configured with SQLite support
>> >of 
>> >course)
>> >
>> >To remind you the concept of SQL dialects, for non-RDBMS OGR drivers, OGR
>> >uses 
>> >its own SQL engine, which is the called the OGRSQL dialect. Whereas for
>> >RDBMS 
>> >OGR drivers, their own SQL engine will be used, unless otherwise
>> >specified.
>> >
>> >This patchs adds the capability to use a SQLite dialect (through the
>> >-dialect 
>> >option of ogrinfo or ogr2ogr for example). When doing so, the SQLite SQL
>> >engine is used, and when Spatialite is available, all the Spatialite
>> >functions 
>> >( see http://www.gaia-gis.it/gaia-sins/spatialite-sql-3.0.0.html ) can
>> >also be 
>> >used.
>> >
>> >Technically, this works thanks to a temporary in-memory SQLite DB and a
>> >module 
>> >(ogr/ogrsf_frmts/sqlite/ogrsqlitevirtualogr.cpp) that exposes OGR layers
>> >to 
>> >SQLite through its Virtual Table mechanism (
>> >http://www.sqlite.org/vtab.html
>> >). When the datasource you operate on is opened in update mode and that
>> >the 
>> >corresponding OGR driver supports
>> >CreateFeature()/SetFeature()/DeleteFeature()
>> >operations, SQL INSERT/UPDATE/DELETE operations will work too.
>> >
>> >What do you think about it ?
>> >
>> >A few non-exhaustive examples of things you can do :
>> >
>> ># Initial CSV file :
>> >
>> >$ cat my.csv
>> >id,foo,bar,long,lat
>> >1,"foo","bar",2,49
>> >1,"foo","bar",3,50
>> >2,"foo2","bar2",-2,49
>> >2,"foo2","bar2",-3,51
>> >
>> ># Creates a Geometry field from each (long,lat) tuple :
>> >
>> >$ ogrinfo my.csv -dialect sqlite -sql "SELECT *, MakePoint(CAST(long AS
>> >FLOAT), CAST(lat AS FLOAT)) as geometry FROM my" -q
>> >
>> >Layer name: SELECT
>> >OGRFeature(SELECT):0
>> >  id (String) = 1
>> >  foo (String) = foo
>> >  bar (String) = bar
>> >  long (String) = 2
>> >  lat (String) = 49
>> >  POINT (2 49)
>> >
>> >OGRFeature(SELECT):1
>> >  id (String) = 1
>> >  foo (String) = foo
>> >  bar (String) = bar
>> >  long (String) = 3
>> >  lat (String) = 50
>> >  POINT (3 50)
>> >
>> >OGRFeature(SELECT):2
>> >  id (String) = 2
>> >  foo (String) = foo2
>> >  bar (String) = bar2
>> >  long (String) = -2
>> >  lat (String) = 49
>> >  POINT (-2 49)
>> >
>> >OGRFeature(SELECT):3
>> >  id (String) = 2
>> >  foo (String) = foo2
>> >  bar (String) = bar2
>> >  long (String) = -3
>> >  lat (String) = 51
>> >  POINT (-3 51)
>> >
>> >
>> ># Merge all the points that have the same id into a line :
>> >
>> >$ ogrinfo my.csv -dialect sqlite -sql "SELECT id, foo,bar,
>> >MakeLine(MakePoint(CAST(long AS FLOAT), CAST(lat AS FLOAT))) FROM my
>> >GROUP BY 
>> >id" -q
>> >
>> >Layer name: SELECT
>> >OGRFeature(SELECT):0
>> >  id (String) = 1
>> >  foo (String) = foo
>> >  bar (String) = bar
>> >  LINESTRING (2 49,3 50)
>> >
>> >OGRFeature(SELECT):1
>> >  id (String) = 2
>> >  foo (String) = foo2
>> >  bar (String) = bar2
>> >  LINESTRING (-2 49,-3 51)
>> >
>> ># Compute the geodesic length of each line :
>> >
>> >$ ogrinfo my.csv -dialect sqlite -sql "SELECT id,
>> >GeodesicLength(SetSRID(MakeLine(MakePoint(CAST(long AS FLOAT), CAST(lat
>> >AS 
>> >FLOAT))),4326)) AS total_length FROM my GROUP BY id" -q
>> >
>> >Layer name: SELECT
>> >OGRFeature(SELECT):0
>> >  id (String) = 1
>> >  total_length (Real) = 132725.477910869
>> >
>> >OGRFeature(SELECT):1
>> >  id (String) = 2
>> >  total_length (Real) = 233720.037020965
>> >
>> ># Appends a new entry in the CSV :
>> >
>> >$ ogrinfo my.csv -dialect sqlite -sql "insert into my
>> >(id,foo,bar,long,lat)
>> >values (3,'foo3','bar3',2.5,49.5)"
>> >
>> >$ cat my.csv
>> >id,foo,bar,long,lat
>> >1,"foo","bar",2,49
>> >1,"foo","bar",3,50
>> >2,"foo2","bar2",-2,49
>> >2,"foo2","bar2",-3,51
>> >3,foo3,bar3,2.5,49.5
>> >
>> ># Reprojection from EPSG:32631 to EPSG:4326 :
>> >
>> >$ ogrinfo poly.shp -dialect sqlite -sql "SELECT
>> >ST_Transform(SetSRID(GEOMETRY,32631),4326) AS GEOMETRY, * FROM poly WHERE
>> >EAS_ID = 170"
>> >INFO: Open of `poly.shp'
>> >      using driver `ESRI Shapefile' successful.
>> >
>> >Layer name: SELECT
>> >Geometry: Unknown (any)
>> >Feature Count: 1
>> >Extent: (2.750069, 43.034444) - (2.751428, 43.035184)
>> >Layer SRS WKT:
>> >GEOGCS["WGS 84",
>> >    DATUM["WGS_1984",
>> >        SPHEROID["WGS 84",6378137,298.257223563,
>> >            AUTHORITY["EPSG","7030"]],
>> >        AUTHORITY["EPSG","6326"]],
>> >    PRIMEM["Greenwich",0,
>> >        AUTHORITY["EPSG","8901"]],
>> >    UNIT["degree",0.0174532925199433,
>> >        AUTHORITY["EPSG","9122"]],
>> >    AUTHORITY["EPSG","4326"]]
>> >Geometry Column = GEOMETRY
>> >AREA: Real (0.0)
>> >EAS_ID: Real (0.0)
>> >PRFEDEA: String (0.0)
>> >OGRFeature(SELECT):0
>> >  AREA (Real) = 5268.813
>> >  EAS_ID (Real) = 170
>> >  PRFEDEA (String) = 35043413
>> >  POLYGON ((2.751427625469495 43.034734578878634,2.750298298604006
>> >43.034443959553869,2.75006933958772 43.03490271631064,2.75124435992688
>> >43.035184432169061,2.751427625469495 43.034734578878634))
>> >
>> >Note: a similar capability was already available in OGR 1.9 for
>> >Shapefiles, 
>> >through the use of the VirtualShape module that is embedded in
>> >Spatialite. See 
>> >the http://gdal.org/ogr/drv_sqlite.html page.
>> >


-- 
Jeff McKenna
MapServer Consulting and Training Services
http://www.gatewaygeomatics.com/



From Jukka.Rahkonen at mmmtike.fi  Sun Aug 19 13:51:19 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Sun, 19 Aug 2012 20:51:19 +0000
Subject: [gdal-dev] Gdalinfo slow with big Rasterlite tables
In-Reply-To: <201208181643.34423.even.rouault@mines-paris.org>
References: <loom.20120818T142851-271@post.gmane.org>,
	<201208181643.34423.even.rouault@mines-paris.org>
Message-ID: <84446DEF76453C439E9E97E438E13A63466B35@suutari.haapa.mmm.fi>

Even Rouault wrote:

> Jukka,

>>
>> Is gdalinfo perhaps walking through every single tile in the
>> rasterlite table for gathering the image layer info? Could
>> there be any other way to do it in more effective way on the
>> GDAL side?

> The Rasterlite driver needs to fetch the extent of the "XXXX_metadata" layers
> to establish the extent of the raster XXXX, which might take a long time when
> there are a lot of tiles.

>>
>> When it comes to GDAL, could it make any sense to cache
>> gdalinfo from Rasterlite layers? Three minutes is rather a
>> long time and my 153600 x 249600 pixel sized layer with
>> 780270 rows/tiles in 5 meter resolution in the table is
>> not exceptionally big. If time is increasing with tile
>> count it would mean 12 minutes for getting gdalinfo from
>> 2.5 meter resolution and 48 minutes from 1.25 minutes
>> layer...
>

> Funny because independantly of the issue you raise here, I was working on
> improving the performance of GetFeatureCount() and GetExtent() on Spatialite
> DBs. In Spatialite 3.0, there is a SQL function triggered by "SELECT
> UpdateLayerStatistics()" that creates a "layer_statistics" table that cache
> those both row count and extent.

> I've just pushed an improvement (r24800) in which the SQLite driver can use
> those cached values, if they are up-to-date. The up-to-dateness is determined
> by checking that the timestamp of the last 'UpdateLayerStatistics' event
> recorded in the 'spatialite_history' table matches the timestamp of the file.
> When creating a new Spatialite DB or updating it with the OGR API, the SQLite
> driver makes sure that the statistics are kept up-to-date automatically.
> However, if a third-party tool edits the DB, it is then necessary to run :
> ogrinfo the.db -sql "SELECT UpdateLayerStatistics()". (The driver plays on the
> safe side, and will not use old statistics to avoid getting false results.)

> I've just made marginal changes (r24801) in the Rasterlite driver so that the
> above caching mechanism works automatically in simple gdal_translate and
> gdaladdo scenario. I would expect that it might solve your performance
> problem, although I have not checked that.

Yes, that makes gdalinfo fast. With my biggest layer the time went down from 3 minutes to 3 seconds. However, my gdal_translate test fails. It used to take three minutes before the zero appeared into the progress bar but after that translation itself took only few seconds.  After updating to GDAL r24803 program shows the zero percent progress within couple of seconds but unfortunately nothing happens in any reasonable time after that. 

>gdal_translate -of Gtiff -outsize 1% 1% RASTERLITE:test.sqlite,table=t0080 test.tif
Input file size is 153600, 249600
0

Overviews are ok so taking the one percent downsampes should be fast.
  Overviews: 76800x124800, 38400x62400, 19200x31200, 9600x15600, 4800x7800, 
2400x3900, 1200x1950, 600x975, 300x488

-Jukka-

From even.rouault at mines-paris.org  Sun Aug 19 14:36:44 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sun, 19 Aug 2012 23:36:44 +0200
Subject: [gdal-dev] Gdalinfo slow with big Rasterlite tables
In-Reply-To: <84446DEF76453C439E9E97E438E13A63466B35@suutari.haapa.mmm.fi>
References: <loom.20120818T142851-271@post.gmane.org>
	<201208181643.34423.even.rouault@mines-paris.org>
	<84446DEF76453C439E9E97E438E13A63466B35@suutari.haapa.mmm.fi>
Message-ID: <201208192336.44541.even.rouault@mines-paris.org>


> Yes, that makes gdalinfo fast. With my biggest layer the time went down
> from 3 minutes to 3 seconds. However, my gdal_translate test fails. It
> used to take three minutes before the zero appeared into the progress bar
> but after that translation itself took only few seconds.  After updating
> to GDAL r24803 program shows the zero percent progress within couple of
> seconds but unfortunately nothing happens in any reasonable time after
> that.

Is the reasonable time more than 3 minutes ?

> 
> >gdal_translate -of Gtiff -outsize 1% 1% RASTERLITE:test.sqlite,table=t0080
> >test.tif
> 
> Input file size is 153600, 249600
> 0
> 
> Overviews are ok so taking the one percent downsampes should be fast.
>   Overviews: 76800x124800, 38400x62400, 19200x31200, 9600x15600, 4800x7800,
> 2400x3900, 1200x1950, 600x975, 300x488

I've tested the gdal_translate -outsize 1% 1% with a 104740 x 49510 raster and 
it works fast for me. Could you add --debug on to the above gdal_translate and 
report what it outputs ?

And also, to confirm that it is due to the changes in sqlite driver and not the 
ones in the rasterlite driver, you could retry but after having deleted the 
statistics :

ogrinfo test.sqlite -sql "DELETE FROM layer_statistics"

and then again gdal_translate --debug on [...]

> 
> -Jukka-
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From eborovenskiy at scanex.ru  Mon Aug 20 02:40:31 2012
From: eborovenskiy at scanex.ru (Evgeniy Borovenskiy)
Date: Mon, 20 Aug 2012 13:40:31 +0400
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
Message-ID: <955BDE81516F04498F36F60B0570974979BDADB2E3@vrum-exch2>

Thank you very much for your help. I'll try to write a function create ().

Evgeniy

From even.rouault at mines-paris.org  Mon Aug 20 02:49:21 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 20 Aug 2012 11:49:21 +0200
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
In-Reply-To: <955BDE81516F04498F36F60B0570974979BDADB2E3@vrum-exch2>
References: <955BDE81516F04498F36F60B0570974979BDADB2E3@vrum-exch2>
Message-ID: <1345456161.5032082150672@imp.free.fr>

Selon Evgeniy Borovenskiy <eborovenskiy at scanex.ru>:

> Thank you very much for your help. I'll try to write a function create ().

In the JP2KAK driver you mean ? The challenge is not really in Create(), but
more in implementing a working JP2KAKRasterBand::IWriteBlock() and/or
JP2KAKDataset::IRasterIO() / JP2KAKRasterBand::IRasterIO() that work with
eRWFlag = GF_Write then ;-)

>
> Evgeniy
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>





From eborovenskiy at scanex.ru  Mon Aug 20 03:41:58 2012
From: eborovenskiy at scanex.ru (Evgeniy Borovenskiy)
Date: Mon, 20 Aug 2012 14:41:58 +0400
Subject: [gdal-dev] write JPEG2000 with codek KAKADU without .tif
In-Reply-To: <1345456161.5032082150672@imp.free.fr>
References: <955BDE81516F04498F36F60B0570974979BDADB2E3@vrum-exch2>
	<1345456161.5032082150672@imp.free.fr>
Message-ID: <955BDE81516F04498F36F60B0570974979BDADB2E9@vrum-exch2>

Yes, of course, these functions must also be corrected.

Evgeniy

-----Original Message-----
From: Even Rouault [mailto:even.rouault at mines-paris.org] 
Sent: Monday, August 20, 2012 1:49 PM
To: Evgeniy Borovenskiy
Cc: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] write JPEG2000 with codek KAKADU without .tif

Selon Evgeniy Borovenskiy <eborovenskiy at scanex.ru>:

> Thank you very much for your help. I'll try to write a function create ().

In the JP2KAK driver you mean ? The challenge is not really in Create(), but more in implementing a working JP2KAKRasterBand::IWriteBlock() and/or
JP2KAKDataset::IRasterIO() / JP2KAKRasterBand::IRasterIO() that work with eRWFlag = GF_Write then ;-)

>
> Evgeniy
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>





From jzl5325 at psu.edu  Mon Aug 20 12:16:12 2012
From: jzl5325 at psu.edu (Jay L.)
Date: Mon, 20 Aug 2012 12:16:12 -0700
Subject: [gdal-dev] 32 and 64-bit python bindings concurrently?
Message-ID: <CA+bfmPvK25wpm=ZuQWrFdfo2Uuu4X1dFggzADgY7-cA2bk4Z4A@mail.gmail.com>

List,

I have a number of python scripts leveraging gdal, numpy, and scipy.  It
is necessary, if possible, to support machines which utilize both 32 and 64
bit python installations.  The newest ArcGIS10.1 background geoprocessing
is a perfect example of this, where processes run within arc utilize 32-bit
pyhton 2.7 and processes run in the background open a new instance of
64-bit python2.7.

As a tool writer, it would be great to be able to support both 32-bit
foreground processing and 64-bit background processing which leverages
gdal.  The issue I am currently having is in supporting the python bindings
for both.

A few questions:
Can a 64-bit installation of gdal support the 32-bit python bindings, ie is
a universal binary buildable?
Is it possible to support both 32 and 63 bit installations of the python
bindings?  Does this require both a 32-bit and a 64-bit installation of the
gdal core package?
If it is possible to support both, what order do I need to append my path
in?  Currently I have the gdal install directory first to avoid dll loading
issues (from an earlier mail).

Thanks,
Jay
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120820/52918cf4/attachment.html>

From even.rouault at mines-paris.org  Mon Aug 20 12:24:07 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 20 Aug 2012 21:24:07 +0200
Subject: [gdal-dev] 32 and 64-bit python bindings concurrently?
In-Reply-To: <CA+bfmPvK25wpm=ZuQWrFdfo2Uuu4X1dFggzADgY7-cA2bk4Z4A@mail.gmail.com>
References: <CA+bfmPvK25wpm=ZuQWrFdfo2Uuu4X1dFggzADgY7-cA2bk4Z4A@mail.gmail.com>
Message-ID: <201208202124.07462.even.rouault@mines-paris.org>

> A few questions:
> Can a 64-bit installation of gdal support the 32-bit python bindings, ie is
> a universal binary buildable?

Not sure what you mean by "universal binary" (this is a OSX concept, but I'm 
not aware it exists for Windows), but the most general answer is : No

The python bindings contain DLL, that must have the same bit size as the GDAL 
core DLL.

A 64bit DLL cannot link with a 32bit DLL, and vice versa.

> Is it possible to support both 32 and 63 bit installations of the python
> bindings?

If you install them in separate locations, yes

> Does this require both a 32-bit and a 64-bit installation of the
> gdal core package?

Yes, according to above

> If it is possible to support both, what order do I need to append my path
> in?  Currently I have the gdal install directory first to avoid dll loading
> issues (from an earlier mail).

I would believe that you can put the paths to the 32bit and 64bit binaries and 
that the windows loader will select the right version, but I'm not sure at 
all. That might require confirmation by experimenting

> 
> Thanks,
> Jay

From jzl5325 at psu.edu  Mon Aug 20 12:28:03 2012
From: jzl5325 at psu.edu (Jay L.)
Date: Mon, 20 Aug 2012 12:28:03 -0700
Subject: [gdal-dev] 32 and 64-bit python bindings concurrently?
In-Reply-To: <201208202124.07462.even.rouault@mines-paris.org>
References: <CA+bfmPvK25wpm=ZuQWrFdfo2Uuu4X1dFggzADgY7-cA2bk4Z4A@mail.gmail.com>
	<201208202124.07462.even.rouault@mines-paris.org>
Message-ID: <CA+bfmPt=zkVEU+gK1gQLuxJ7NkX8NbC_gfs_cdwBYVEn2rU_dA@mail.gmail.com>

Evan,

Thanks for the info.  I used universal, purely as a descriptor of the
functionality I was hoping for.  I will have to experiment with installing
GDAL in separate locations to see if I can get both installations to get
along.

Thanks!
Jay

On Mon, Aug 20, 2012 at 12:24 PM, Even Rouault <even.rouault at mines-paris.org
> wrote:

> > A few questions:
> > Can a 64-bit installation of gdal support the 32-bit python bindings, ie
> is
> > a universal binary buildable?
>
> Not sure what you mean by "universal binary" (this is a OSX concept, but
> I'm
> not aware it exists for Windows), but the most general answer is : No
>
> The python bindings contain DLL, that must have the same bit size as the
> GDAL
> core DLL.
>
> A 64bit DLL cannot link with a 32bit DLL, and vice versa.
>
> > Is it possible to support both 32 and 63 bit installations of the python
> > bindings?
>
> If you install them in separate locations, yes
>
> > Does this require both a 32-bit and a 64-bit installation of the
> > gdal core package?
>
> Yes, according to above
>
> > If it is possible to support both, what order do I need to append my path
> > in?  Currently I have the gdal install directory first to avoid dll
> loading
> > issues (from an earlier mail).
>
> I would believe that you can put the paths to the 32bit and 64bit binaries
> and
> that the windows loader will select the right version, but I'm not sure at
> all. That might require confirmation by experimenting
>
> >
> > Thanks,
> > Jay
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120820/da20417b/attachment.html>

From even.rouault at mines-paris.org  Mon Aug 20 14:16:32 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 20 Aug 2012 23:16:32 +0200
Subject: [gdal-dev] [Proposed new feature] A '"SQLite" SQL dialect for
	OGR
In-Reply-To: <201208181903.56368.even.rouault@mines-paris.org>
References: <201208181903.56368.even.rouault@mines-paris.org>
Message-ID: <201208202316.32997.even.rouault@mines-paris.org>

Le samedi 18 ao?t 2012 19:03:56, Even Rouault a ?crit :
> Hi folks,
> 
> I've attached in
> http://trac.osgeo.org/gdal/attachment/ticket/4782/sqlite_dialect.patch a
> patch that adds a SQLite alternate SQL dialect that can be used with any
> OGR datasource (only available if GDAL/OGR is configured with SQLite
> support of course)
> 

This is now commited in trunk. Will need some polishing likely, and above all 
some documentation, but it should be ready enough for general testing.

Best regards,

Even

From al.niessner at gmail.com  Mon Aug 20 22:07:13 2012
From: al.niessner at gmail.com (Al Niessner)
Date: Mon, 20 Aug 2012 22:07:13 -0700
Subject: [gdal-dev] coordinate transforms
Message-ID: <CAO5pCYSUi_GPjkpOMpcjbsdo2J+zGn5BDnJxPsoMfkDh_WytOQ@mail.gmail.com>

OS:    Ubuntu 12.04
lang:   Python
mods: gdal/osr

I am very new to this topic. I have been searching the web for my answers
and have not been able to find them yet. The short version of my question
is, how do I use gdal/osr to transform vectors of points between UTM
(NAD83) and WSG84?

If this is not the correct mailing list, then please let me know and give
me a hint as to where the right one is so that I can get in the correct
room. If I am in the correct room and have your attention, here is the
longer version of the question.

The latest gdal installed with Ubuntu allows me to load the USGS maps in
geo-referenced PDF format into numpy arrays via the dataset (or ds as I
will call it from now on). Those tutorials are straight forward and I
understand them. I can load the geo transform and understand the pixel to
UTM (NAD83) mapping. Not overly difficult really.

Now, I have tracks from my GPS in WSG84 DMS format. Now I want to convert
that vector of points to UTM (NAD83) so that I can lay it back on my numpy
array (USGS Map).

I read the osr Coordinate Transform page and have some vague idea that I
need to create two SpatialReference objects and set some attributes about
them. I can then use these to create a CoordinateTransform, which in turn
contains the method that I want to transform my vector of points. Not fun,
but fun enough.

Creating the WGS84 SpatialReference is pretty straight forward. I just do:
          in_sr.SetWellKnownGeogCS ('WGS84')
and all seems well enough.

Now I need to create my SpatialReference for the UTM (NAD83) coordinates.
So, I go back to my USGS geo-referenced PDF dataset and look at its
projection:
 'PROJCS["unnamed",GEOGCS["NAD83",DATUM["North_American_Datum_1983",SPHEROID["GRS
1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6269"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9108"]],AUTHORITY["EPSG","4269"]],PROJECTION["Albers_Conic_Equal_Area"],PARAMETER["standard_parallel_1",34],PARAMETER["standard_parallel_2",40.5],PARAMETER["latitude_of_center",0],PARAMETER["longitude_of_center",-120],PARAMETER["false_easting",0],PARAMETER["false_northing",-4000000]]'

The projection onto the Albers_Conic is different than the base NAD83 that
is in osr. So, I tried several random swings at doing and ImportFrom but
none of them work. Some even crash hard. Since I do not understand the
acronyms it really is just random guessing. I understand URL and this is
not a URL and same with XML. The rest are a bit of a mystery to me.

So, this is where I am. How do I define my SpatialReference's  so that I
can translate a vector of points. I want to be able to extract as much
information from the PDF as I can because I want to automate this process a
bit more. I basically want to look up the maps given a GPS track and lay it
on the map. First, however, I just need to know how initialize the
SpatialReference and do the CoordinateTransforms.

Thanks for any all help. It is very much appreciated.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120820/b9179a58/attachment.html>

From diregola at gmail.com  Tue Aug 21 02:35:45 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Tue, 21 Aug 2012 11:35:45 +0200
Subject: [gdal-dev] gdalbuildvrt problem with heterogenous band
	characteristics
In-Reply-To: <CABa=8QoD7SMfm27EGs9nDPAPRUnXxN9M3QnYCDxE1FSwq6pLOw@mail.gmail.com>
References: <BCF6B63AE0B25941A7F56567B58A2805AD4117@allkexa1.NIRAS.INT>
	<CABa=8QqDDsfxTcWwMm0jWR=soZ2Ubvdr0EgDuDihLghibEFafA@mail.gmail.com>
	<1345127560.502d04883ce9f@imp.free.fr>
	<CABa=8Qr7HzEtg7LSco66b81hHMbwfrr6DADOxHZygd5wmTenVQ@mail.gmail.com>
	<CACqBkM8yNT7cHCqE6D6EQvc-Dtcy1xx+=Z7kUAqzRMQbXhsfPw@mail.gmail.com>
	<CABa=8QoD7SMfm27EGs9nDPAPRUnXxN9M3QnYCDxE1FSwq6pLOw@mail.gmail.com>
Message-ID: <CABa=8Qo5e_OEFnKM62Hf-NfOVFPO7mg-VkjuqOaFhAo+FRnQPA@mail.gmail.com>

Dear all,

in regard of this different behavior performed by gdalwarp and gdalbuildvrt
respect to different data type entries, I have some considerations. The
error raised by gdalbuildvrt made me wonder about my data and then with
your help I discovered what was wrong with them. On the other hand,
gdalwarp didn't raise any complaint, and i happily created my mosaic,
causing a loss of data (from float to int) which i was not aware of. In my
opinion it would be good to have a warning message in both gdalbuildvrt and
gdalwarp if input data are not homogeneous in type.

Thanks,


On Fri, Aug 17, 2012 at 8:56 AM, Margherita Di Leo <diregola at gmail.com>wrote:

> Hi,
>
> On Thu, Aug 16, 2012 at 11:02 PM, Eli Adam <eadam at co.lincoln.or.us> wrote:
>
>> > Band 1 Block=5000x1 Type=Int16, ColorInterp=Gray
>> ...
>> > Band 1 Block=10000x1 Type=Float32, ColorInterp=Gray
>> >
>> > I can't see anything obvious why these two files can't be mosaiced..
>> >
>>
>> It looks like one is 16 bit and the other 32.  gdalbuildvrt probably
>> can't determine the type of output to create.
>>
>> What is the output type of gdalwarp on the same files? Did gdalwarp do
>> anything to make the input files match in the output?
>>
>
> This is the output of the mosaic made by gdalwarp:
>
> gdalinfo STM_CP-DEMS_EU_mosaic.tif
> Driver: GTiff/GeoTIFF
> Files: /home/leomarg/DATA/SRTM_DEMs/_ALL/STM_CP-DEMS_EU_mosaic.tif
> Size is 64600, 50650
>
> Coordinate System is:
> PROJCS["ETRS89 / LAEA Europe",
>     GEOGCS["ETRS89",
>         DATUM["European_Terrestrial_Reference_System_1989",
>             SPHEROID["GRS 1980",6378137,298.2572221010002,
>
>                 AUTHORITY["EPSG","7019"]],
>             AUTHORITY["EPSG","6258"]],
>         PRIMEM["Greenwich",0],
>         UNIT["degree",0.0174532925199433],
>         AUTHORITY["EPSG","4258"]],
>     PROJECTION["Lambert_Azimuthal_Equal_Area"],
>     PARAMETER["latitude_of_center",52],
>     PARAMETER["longitude_of_center",10],
>     PARAMETER["false_easting",4321000],
>     PARAMETER["false_northing",3210000],
>     UNIT["metre",1,
>         AUTHORITY["EPSG","9001"]],
>     AUTHORITY["EPSG","3035"]]
> Origin = (1540000.000000000000000,6000000.000000000000000)
>
> Pixel Size = (100.000000000000000,-100.000000000000000)
> Metadata:
>   AREA_OR_POINT=Area
> Image Structure Metadata:
>   INTERLEAVE=BAND
> Corner Coordinates:
> Upper Left  ( 1540000.000, 6000000.000) ( 57d31'59.79"W, 63d25'17.15"N)
>
> Lower Left  ( 1540000.000,  935000.000) ( 17d57'14.30"W, 26d50'46.78"N)
> Upper Right ( 8000000.000, 6000000.000) ( 86d 0'31.83"E, 56d26'45.47"N)
> Lower Right ( 8000000.000,  935000.000) ( 46d17'14.56"E, 23d32'41.83"N)
> Center      ( 4770000.000, 3467500.000) ( 16d52'39.75"E, 54d 7'19.36"N)
> Band 1 Block=64600x1 Type=Int16, ColorInterp=Gray
>
> Thanks,
>
>
> --
> Dr. Margherita Di Leo
>



-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120821/19039979/attachment-0001.html>

From radim.blazek at gmail.com  Tue Aug 21 04:01:37 2012
From: radim.blazek at gmail.com (Radim Blazek)
Date: Tue, 21 Aug 2012 13:01:37 +0200
Subject: [gdal-dev] GDALSetRasterNoDataValue and NaN
Message-ID: <CAEMrtYpN1tfYURXeZEzYOXk_pUuEor5z4HwcLtfQDYS8+=iEMA@mail.gmail.com>

Hi,
is it safe to use GDALSetRasterNoDataValue() with
std::numeric_limits<double>::quiet_NaN()?

Radim

From mateusz at loskot.net  Tue Aug 21 04:14:39 2012
From: mateusz at loskot.net (Mateusz Loskot)
Date: Tue, 21 Aug 2012 12:14:39 +0100
Subject: [gdal-dev] GDALSetRasterNoDataValue and NaN
In-Reply-To: <CAEMrtYpN1tfYURXeZEzYOXk_pUuEor5z4HwcLtfQDYS8+=iEMA@mail.gmail.com>
References: <CAEMrtYpN1tfYURXeZEzYOXk_pUuEor5z4HwcLtfQDYS8+=iEMA@mail.gmail.com>
Message-ID: <CABUeae-3CwU5PATJQAyUEPb4pokHsv1dzt9QpK6PYsXcBMeZEg@mail.gmail.com>

On 21 August 2012 12:01, Radim Blazek <radim.blazek at gmail.com> wrote:
> Hi,
> is it safe to use GDALSetRasterNoDataValue() with
> std::numeric_limits<double>::quiet_NaN()?

What kind of safety do you mean?

AFAICT, it does not sound sensible anyway.
Use of NaN would give unreliable results, by definition of NaN:

    double n1 = std::numeric_limits<double>::quiet_NaN();
    double n2 = std::numeric_limits<double>::quiet_NaN();
    assert(n1 != n2);

Best regards,
-- 
Mateusz Loskot, http://mateusz.loskot.net

From sigfrido at tiscali.it  Tue Aug 21 04:21:25 2012
From: sigfrido at tiscali.it (Luca Sigfrido Percich)
Date: Tue, 21 Aug 2012 13:21:25 +0200
Subject: [gdal-dev] coordinate transforms
In-Reply-To: <CAO5pCYSUi_GPjkpOMpcjbsdo2J+zGn5BDnJxPsoMfkDh_WytOQ@mail.gmail.com>
References: <CAO5pCYSUi_GPjkpOMpcjbsdo2J+zGn5BDnJxPsoMfkDh_WytOQ@mail.gmail.com>
Message-ID: <1345548085.2321.20.camel@GOLEM>


Hi Al,

have you tried with ImportFromWkt? The string is a Well Known Text
definition of a SpatialReference.

Sig


srs = osr.SpatialReference()

srs.ImportFromWkt("""
    PROJCS["unnamed",
        GEOGCS["NAD83",
            DATUM["North_American_Datum_1983",
                SPHEROID["GRS
1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],
                TOWGS84[0,0,0,0,0,0,0],
                AUTHORITY["EPSG","6269"]],
                PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],

UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9108"]],
                AUTHORITY["EPSG","4269"]],
        PROJECTION["Albers_Conic_Equal_Area"],
        PARAMETER["standard_parallel_1",34],
        PARAMETER["standard_parallel_2",40.5],
        PARAMETER["latitude_of_center",0],
        PARAMETER["longitude_of_center",-120],
        PARAMETER["false_easting",0],
        PARAMETER["false_northing",-4000000]]
        """)


Il giorno lun, 20/08/2012 alle 22.07 -0700, Al Niessner ha scritto:

> Now I need to create my SpatialReference for the UTM (NAD83)
> coordinates. So, I go back to my USGS geo-referenced PDF dataset and
> look at its projection:
>  'PROJCS["unnamed",GEOGCS["NAD83",DATUM["North_American_Datum_1983",SPHEROID["GRS 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],TOWGS84[0,0,0,0,0,0,0],AUTHORITY["EPSG","6269"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9108"]],AUTHORITY["EPSG","4269"]],PROJECTION["Albers_Conic_Equal_Area"],PARAMETER["standard_parallel_1",34],PARAMETER["standard_parallel_2",40.5],PARAMETER["latitude_of_center",0],PARAMETER["longitude_of_center",-120],PARAMETER["false_easting",0],PARAMETER["false_northing",-4000000]]'
> 
> 
> The projection onto the Albers_Conic is different than the base NAD83
> that is in osr. So, I tried several random swings at doing and
> ImportFrom but none of them work. Some even crash hard. Since I do not
> understand the acronyms it really is just random guessing. I
> understand URL and this is not a URL and same with XML. The rest are a
> bit of a mystery to me.



From even.rouault at mines-paris.org  Tue Aug 21 04:40:27 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 21 Aug 2012 13:40:27 +0200
Subject: [gdal-dev] GDALSetRasterNoDataValue and NaN
In-Reply-To: <CAEMrtYpN1tfYURXeZEzYOXk_pUuEor5z4HwcLtfQDYS8+=iEMA@mail.gmail.com>
References: <CAEMrtYpN1tfYURXeZEzYOXk_pUuEor5z4HwcLtfQDYS8+=iEMA@mail.gmail.com>
Message-ID: <1345549227.503373ab850d0@imp.free.fr>

Selon Radim Blazek <radim.blazek at gmail.com>:

> Hi,
> is it safe to use GDALSetRasterNoDataValue() with
> std::numeric_limits<double>::quiet_NaN()?

There have been some work done in GDAL core (mainly in statistics functions), in
some algorithms (warping for example), in some utilities and in some drivers
(GTiff, VRT) to be able to deal properly with NaN as a nodata value, but the
support might be missing in other parts, because it generally requires a
particular case to deal with it.The support has been added incrementally when
someone raised a misbehaviour in a particular area. Basically, you can grep
CPLIsNan in the source tree and it will give you a good picture of the places
where some work has been done to support it.

>
> Radim
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



From even.rouault at mines-paris.org  Tue Aug 21 12:31:54 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 21 Aug 2012 21:31:54 +0200
Subject: [gdal-dev] OGR as a dynamically loadable sqlite3 extension [was Re:
	new "SQLite dialect" and spatialite]
In-Reply-To: <c6e802122c34b82a0342a2c7c472a464@lqt.it>
References: <c6e802122c34b82a0342a2c7c472a464@lqt.it>
Message-ID: <201208212131.54085.even.rouault@mines-paris.org>

Le mardi 21 ao?t 2012 19:38:51, a.furieri at lqt.it a ?crit :
> Hi Even,
> 
> if I understand well the new "SQLite style dialect" you've
> developed for OGR is mainly based on a VirtualTable.
> 
> Do you have considered that this new feature could be
> really nice to be supported in SpatiaLite as well ?
> 
> I easily imagine that it could be really interesting
> for many users routinely using spatialite-gui or
> spatialite-cli as their preferred SQL front-end tools
> "magically" accessing any generic OGR datasource.
> 
> just few quick technical highlights:
> a) imagining that your VirtualTable OGR-driver could
>     be made available as a "dynamic extension" to SQLite
> b) then simply invoking: SELECT load_extension('even-ogr.dll');
>     will automatically enable both the CLI and the GUI tools
>     to access any OGR supported datasource ... it would be
>     simply fantastic, no ?
> c) in other words: once your extension will be loaded, then
>     an user simply has to create the appropriate OGR VirtualTable,
>     using some syntax looking more or less like:
>     CREATE VIRTUAL TABLE xxx USING VirtualOgr(connection-string);
> 
> the nicest thing I can foresee is in that this approach has
> exactly a ZERO impact on building and installing :-D
> 
> if the "ogr-virtual-extension" library (and all the GDAL/OGR depending
> libraries) could be actually loaded at run time, all is done.
> otherwise you'll simply get some error; no other consequence at all.
> 
> it fully depends on run-time configuration (and installation); there
> is absolutely no need to establish some permanent link between
> spatialite and ogr.
> 
> it looks a very exciting future perspective for me; what do
> you think about all this ?

Sandro,

This is a brillant suggestion and I've just implemented and committed it. It 
required few changes. The OGR virtual extension library is just the OGR 
library for the sake of simplicity.

So here's some things that you can do :

$ sqlite3
SELECT load_extension("libspatialite.so");
SELECT load_extension("libgdal.so");
SELECT ogr_version();
CREATE VIRTUAL TABLE poly USING VirtualOGR("poly.shp");
CREATE VIRTUAL TABLE poly2 USING VirtualOGR("poly.shp", 0);
CREATE VIRTUAL TABLE poly3 USING VirtualOGR("poly.shp", 0, "poly");
SELECT *, aswkt(geometry) FROM poly;

The syntax for VirtualOGR is the following one :

CREATE VIRTUAL TABLE xxx USING VirtualOGR \
     (datasource_name[, update_mode, [layer_name[, expose_ogr_style]]])

* If only datasource_name is specified, then it is opened in read-only mode, 
and it will check that there's only one layer in it, which it will pick up.
* update_mode can be 0 (read-only) or 1 (update mode) to select how the 
datasource is opened.
* expose_ogr_style can be 0 (disabled) or 1 (enabled) to map the special OGR 
attribute StyleString to a OGR_STYLE attribute. Defaults to 0.

This will need to be documented somewhere.

Best regards,

Even

From even.rouault at mines-paris.org  Tue Aug 21 14:12:31 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 21 Aug 2012 23:12:31 +0200
Subject: [gdal-dev] Gdalinfo slow with big Rasterlite tables
In-Reply-To: <84446DEF76453C439E9E97E438E13A63467067@suutari.haapa.mmm.fi>
References: <84446DEF76453C439E9E97E438E13A63467067@suutari.haapa.mmm.fi>
Message-ID: <201208212312.31609.even.rouault@mines-paris.org>

Le mardi 21 ao?t 2012 09:53:50, Rahkonen Jukka a ?crit :
> Even Rouault wrote:
> > Selon Rahkonen Jukka <Jukka.Rahkonen at mmmtike.fi>:
> > > Even Rouault wrote:
> > > >> Better after doing these. 4 minutes and 10 seconds for the biggest
> > > >> layer, record before this was 6 minutes. Big enough difference for
> > > >> being meaningful, I think.
> > > > 
> > > > Meaningful, but I would have expected it to be much better and get
> > > > that
> > > 
> > > back
> > > 
> > > > to a few seconds...
> > > > 
> > > > Could you try : ogrinfo your_rasterlite.db -sql "VACUUM"
> > > 
> > > There were only 1% of unused pages but vacuuming had still an effect.
> > > The first run after vacuum: 50 seconds, next warm runs: 20 seconds.
> > 
> > That's what I call a significant improvement ! I think (but without any
> > strong evidence) that the main effect of vacuuming in that context is to
> > avoid the fragmentation of the data belonging to various tables. For
> > each XXX raster in a rasterlite dataset, you have a XXX_rasters table
> > that contain the binary blobs of the raster tiles, a XXX_metadata table
> > with the extent of each tile, and various utility tables used by the
> > spatial index on XXX_metadata. When generating the rasterlite dataset,
> > all of them are updated each time a tile is inserted in. The
> > fragmentation due to spatial indexes can be solved with building them
> > right at the end, but avoiding the interleaving of XXX_metadata and
> > XXX_rasters would be much harder.
> 
> That does make sense. I have noticed even before that Spatialite gains much
> from vacuuming but never before as much as now.  In this case
> SQLite/Spatialite tools cannot give a hint when vacuuming is needed
> because they only check if there is empty lines in the db and we do not
> have such after ogr2ogr conversion.
> 
> > In fact, you should be able to reduce the time again by running "SELECT
> > UpdateLayerStatistics()" after VACUUM, since currently VACUUM is wrongly
> > invalidating them (I'll fix that). So I think that you are still paying
> > the cost of fetching the extent of the raster (if when running gdalinfo
> > --debug on your_raster.db, you don't see debug traces mentionning the
> > use of layer statistics, that is the case).
> 
> That perhaps cut another couple of seconds. However, going through 700000
> rows in the raster_metadata is quite fast. Of course it is good to take
> care that direct access to statistics work and it would be more important
> with bigger tables.
> 
> > So I think that you can forgot the previous workaround I gave that
> > disables/drop/recreates spatial index, and try the following minimal
> > steps once you have used gdal_translate / gdaladdo to generate the
> > dataset :
> > 
> > ogrinfo your_rasterlite.db -sql "VACUUM"
> > ogrinfo your_rasterlite.db -sql "SELECT UpdateLayerStatistics()" (that
> > one should be unnecesserary once I've fixed the sqlite driver)
> 
> I guess I created a pretty good (= very messy) database (3.5 gigabytes) for
> testing with my workflow: I created first seven Rasterlite layers with
> decreasing pixel size/increasing table size and after that I created the
> overviews. I believe it guarantees that spatial indexes and metadata
> tables for each layer is written to non-continuos parts into the db file.
> And raster data tables, too. Vacuum is the only way to cure the database.
> Rasterlite tools seem to run vacuum always as the last step of the
> process. I think that ogr2ogr should not do it or there should be a switch
> to turn it off. Vacuuming is an awfully slow process and if one wants to
> insert many layers it is waste of time to run vacuum after each layer. But
> driver page http://www.gdal.org/frmt_rasterlite.html might have a
> sub-title about the importance of vacuuming and that it is a good
> investment for the time even it can be slow.

Jukka,

as you've suggested, I've added a "Performance hints" section to 
frmt_rasterlite.html to mention the VACUUM trick.

> 
> -Jukka-

From ian.walberg at airborne.aero  Tue Aug 21 14:09:19 2012
From: ian.walberg at airborne.aero (Ian Walberg)
Date: Tue, 21 Aug 2012 17:09:19 -0400
Subject: [gdal-dev] gdaltindex
Message-ID: <D12323219CEDB24AA8FAE53FF3F59FB4036BBEFA@BE28.exg3.exghost.com>

Hello folks,

Can gdaltindex create a sqlite db instead of a shapefile.

This would be for use with mapserver and we are finding some references
to non shapefiles but cannot get it to work.

Thanks

Ian

From even.rouault at mines-paris.org  Tue Aug 21 14:24:56 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 21 Aug 2012 23:24:56 +0200
Subject: [gdal-dev] gdaltindex
In-Reply-To: <D12323219CEDB24AA8FAE53FF3F59FB4036BBEFA@BE28.exg3.exghost.com>
References: <D12323219CEDB24AA8FAE53FF3F59FB4036BBEFA@BE28.exg3.exghost.com>
Message-ID: <201208212324.56861.even.rouault@mines-paris.org>

Le mardi 21 ao?t 2012 23:09:19, Ian Walberg a ?crit :
> Hello folks,
> 
> Can gdaltindex create a sqlite db instead of a shapefile.

Not directly, but you can use ogr2ogr to convert it to a sqlite db

> 
> This would be for use with mapserver and we are finding some references
> to non shapefiles but cannot get it to work.

I'm not sure that MapServer supports something else than shapefiles as valid 
format for tile index. You should confirm with the MapServer team.

> 
> Thanks
> 
> Ian
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From Michael.Smith at erdc.dren.mil  Tue Aug 21 14:29:40 2012
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Tue, 21 Aug 2012 21:29:40 +0000
Subject: [gdal-dev] gdaltindex
In-Reply-To: <201208212324.56861.even.rouault@mines-paris.org>
Message-ID: <CC5975B0.33F4C%michael.smith@erdc.dren.mil>

Mapserver does. I've used Oracle as a source for a tile index so sqlite
should work as well.

See 
https://github.com/mapserver/mapserver/wiki/MapServer-TILEINDEXes-with-Data
base-RASTERS for using Oracle

And you could add SQLite to the Wiki as well (if it works).

Mike

On 8/21/12 5:24 PM, "Even Rouault" <even.rouault at mines-paris.org> wrote:

>Le mardi 21 ao?t 2012 23:09:19, Ian Walberg a ?crit :
>> Hello folks,
>> 
>> Can gdaltindex create a sqlite db instead of a shapefile.
>
>Not directly, but you can use ogr2ogr to convert it to a sqlite db
>
>> 
>> This would be for use with mapserver and we are finding some references
>> to non shapefiles but cannot get it to work.
>
>I'm not sure that MapServer supports something else than shapefiles as
>valid 
>format for tile index. You should confirm with the MapServer team.
>
>> 
>> Thanks
>> 
>> Ian
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev


From ian.walberg at airborne.aero  Tue Aug 21 14:32:40 2012
From: ian.walberg at airborne.aero (Ian Walberg)
Date: Tue, 21 Aug 2012 17:32:40 -0400
Subject: [gdal-dev] gdaltindex
In-Reply-To: <CC5975B0.33F4C%michael.smith@erdc.dren.mil>
References: <201208212324.56861.even.rouault@mines-paris.org>
	<CC5975B0.33F4C%michael.smith@erdc.dren.mil>
Message-ID: <D12323219CEDB24AA8FAE53FF3F59FB4036BBEFE@BE28.exg3.exghost.com>

Thanks for the details.

We have tried taking a working shp tileindex file and converting it using ogr2ogr and we were getting errors.

Let us look again.

Regards

Ian

-----Original Message-----
From: gdal-dev-bounces at lists.osgeo.org [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of Smith, Michael ERDC-RDE-CRREL-NH
Sent: Tuesday, August 21, 2012 2:30 PM
To: Even Rouault; gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] gdaltindex

Mapserver does. I've used Oracle as a source for a tile index so sqlite should work as well.

See
https://github.com/mapserver/mapserver/wiki/MapServer-TILEINDEXes-with-Data
base-RASTERS for using Oracle

And you could add SQLite to the Wiki as well (if it works).

Mike

On 8/21/12 5:24 PM, "Even Rouault" <even.rouault at mines-paris.org> wrote:

>Le mardi 21 ao?t 2012 23:09:19, Ian Walberg a ?crit :
>> Hello folks,
>> 
>> Can gdaltindex create a sqlite db instead of a shapefile.
>
>Not directly, but you can use ogr2ogr to convert it to a sqlite db
>
>> 
>> This would be for use with mapserver and we are finding some 
>> references to non shapefiles but cannot get it to work.
>
>I'm not sure that MapServer supports something else than shapefiles as 
>valid format for tile index. You should confirm with the MapServer 
>team.
>
>> 
>> Thanks
>> 
>> Ian
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev

_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
http://lists.osgeo.org/mailman/listinfo/gdal-dev

From dlopezaspe at gmail.com  Tue Aug 21 21:32:46 2012
From: dlopezaspe at gmail.com (sigologo)
Date: Tue, 21 Aug 2012 21:32:46 -0700 (PDT)
Subject: [gdal-dev] batch for mean by gdal_calc
Message-ID: <1345609966289-4996911.post@n6.nabble.com>

Hello Gdalers!!!

I'm calculated mean for many image MODIS is posible simply this
calculation!!!! is tooo large...

gdal_calc.py -A MOD13A3_2001001_.tif -B MOD13A3_2002001_.tif -C
MOD13A3_2003001_.tif -D MOD13A3_2004001_.tif -E MOD13A3_2005001_.tif -F
MOD13A3_2006001_.tif -G MOD13A3_2007001_.tif -H MOD13A3_2008001_.tif -I
MOD13A3_2009001_.tif -J MOD13A3_2010001_.tif -K MOD13A3_2011001_.tif -L
MOD13A3_2012001_.tif --outfile=MEAN_001.tif
--calc="(A+B+C+D+E+F+G+H+I+J+K+L)/12"

Regards



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/batch-for-mean-by-gdal-calc-tp4996911.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From jukka.rahkonen at mmmtike.fi  Wed Aug 22 03:11:22 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Wed, 22 Aug 2012 10:11:22 +0000 (UTC)
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
Message-ID: <loom.20120822T102606-517@post.gmane.org>

Hi,

I learned to use ogrinfo with --debug on lately and it revealed what
all happens after sending plain ogrinfo through OCI driver. A few
lines interest me. What is the meaning to doing the select from
ALL_SDO_GEOM_METADATA then insert into USER_SDO_GEOM_METADATA as
follows?

OCI: Prepare(select min(case when r=1 then sdo_lb else null end) minx,
min(case when r=2 then sdo_lb else null end) miny, min(case when r=1
then sdo_ub else null end) maxx, min(case when r=2 then sdo_ub else
null end) maxy from (SELECT d.sdo_dimname, d.sdo_lb, sdo_ub,
sdo_tolerance, rownum r FROM ALL_SDO_GEOM_METADATA m, table(m.diminfo)
d where m.table_name = UPPER('TABLE') and m.COLUMN_NAME =
UPPER('GEOM') ) )

OCI: Prepare(UPDATE USER_SDO_GEOM_METADATA SET DIMINFO =
MDSYS.SDO_DIM_ARRAY(MDSYS.SDO_DIM_ELEMENT('X',2899987.997,4000000.003,
0.001),MDSYS.SDO_DIM_ELEMENT('Y',5999987.997,8000000.003,0.001)) WHERE
TABLE_NAME = 'TABLE')

I guess that meaning is to check all the metadata rows from the
ALL_SDO_GEOM_METADATA view which are referring to the queried table.
There can be several rows created be different Oracle users. Next the
maximum BBOX is constructed and that is updated into
USER_SDO_GEOM_METADATA view.

I have couple of questions:

- Why this update? Perhaps for making sure that bbox reported by
ogrinfo covers the whole area? - Is it correct to take the max values
from mins? Looking at min(case when r=1 then sdo_ub else null end)
maxx - What happens if Oracle user running ogrinfo or ogr2ogr has
limited rights? Case 1: OGR user does not have select rights for
all_sdo_geom_metadata but updating user_sdo_geom_metadata is OK. Will
minx, miny, maxx, maxy in diminfo be updated to nulls? Case 2: Select
is OK but OGR user does not have right to update
user_sdo_geom_metadata.

This is realistic in enterprise environment if OGR user is only making
reports of something like that.

-Jukka Rahkonen-


From radim.blazek at gmail.com  Wed Aug 22 03:19:32 2012
From: radim.blazek at gmail.com (Radim Blazek)
Date: Wed, 22 Aug 2012 12:19:32 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <1345628438183-4996953.post@n6.nabble.com>
References: <1345628438183-4996953.post@n6.nabble.com>
Message-ID: <CAEMrtYoN9Baj2CAqC3fZ6bLQk=gk8MjeQBuiM3Os8Ea+0mW-NA@mail.gmail.com>

On Wed, Aug 22, 2012 at 11:40 AM, haubourg
<regis.haubourg at eau-adour-garonne.fr> wrote:
> Hi all,
> I'm ready to support developpement now, so let's undig a topic discussed
> previously here:
> http://hub.qgis.org/issues/4594 http://hub.qgis.org/issues/4594
>
> Identify for very large ecw (from 1 to 100 Go - 1 080 000 * 1 090 000
> pixels) is extremely long (more than 1min) and results to memory leak.  Very
> often, this only gives a useless RGB info because ecw are orthophotos or
> topographic scans.
>
> This is a problem if identify mode queries all layers under mouse clic.
>
> 1 - Memory leak can be solved by disabling Gdal cache for ecw says Nathan.*
> Do you confirm ? Can you give more details so that I write a contract for
> it? *

QGIS is using GDALRasterIO() which reads a single pixel on original
resolution. AFAIK, ECW is using tiles internally so it should be all
very fast. I can imagine 2 problems:

- the tiles in ECW file are too big - can you verify somehow how big
are the tiles?

- GDAL is reading bigger portion of data than necessary (cc to GDAL list)

Is it drawing of the raster also so slow (on raster resolution zoom)?

Radim

> 2 - *I would also like to add a behaviour to handle very long response time,
> I would really like to have your feedback on it:*
>      - Option 1 : Disable identify for very large raster layers in project
> properties when raster is loaded. Keep QGS properties if raster is loaded
> when opening a project file. Should we add options to configure that in
> general options (" Disable very large raster identify " + "raster size
> threshold")
>      - Option 2 : Offer a checkbox in identify mode options  that could be
> named "disable raster identify"
>      - Option 3 : Considering it's a very particular problem for huge ecw
> users and let's make a plugin that deactivates identify for big raster.   I
> must say I don't vote for here because most french public user I know are
> using big ecw, and I think it might be harder and more expensive to do this
> from python.. (and adds a python plugin to load, adds a thing more to handle
> on enterprise config.. )
>
> *I vote for Option 1*
>
> Thoughts guys?
>
> (And welcome to Victor by the way, congratulations!)
>
>
>
>
> --
> View this message in context: http://osgeo-org.1560.n6.nabble.com/Large-raster-ecw-identify-very-long-tp4996953.html
> Sent from the Quantum GIS - Developer mailing list archive at Nabble.com.
> _______________________________________________
> Qgis-developer mailing list
> Qgis-developer at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/qgis-developer

From stefano.iacovella at gmail.com  Wed Aug 22 04:07:50 2012
From: stefano.iacovella at gmail.com (Stefano Iacovella)
Date: Wed, 22 Aug 2012 13:07:50 +0200
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
In-Reply-To: <loom.20120822T102606-517@post.gmane.org>
References: <loom.20120822T102606-517@post.gmane.org>
Message-ID: <CAG9OqYrW-s=fq7gDj6ebztCqL3uvCFOLakAfutcM93=GVhGovA@mail.gmail.com>

2012/8/22 Jukka Rahkonen <jukka.rahkonen at mmmtike.fi>

> Hi,
>
> I learned to use ogrinfo with --debug on lately and it revealed what
> all happens after sending plain ogrinfo through OCI driver. A few
> lines interest me. What is the meaning to doing the select from
> ALL_SDO_GEOM_METADATA then insert into USER_SDO_GEOM_METADATA as
> follows?
>
> OCI: Prepare(select min(case when r=1 then sdo_lb else null end) minx,
> min(case when r=2 then sdo_lb else null end) miny, min(case when r=1
> then sdo_ub else null end) maxx, min(case when r=2 then sdo_ub else
> null end) maxy from (SELECT d.sdo_dimname, d.sdo_lb, sdo_ub,
> sdo_tolerance, rownum r FROM ALL_SDO_GEOM_METADATA m, table(m.diminfo)
> d where m.table_name = UPPER('TABLE') and m.COLUMN_NAME =
> UPPER('GEOM') ) )
>
> OCI: Prepare(UPDATE USER_SDO_GEOM_METADATA SET DIMINFO =
> MDSYS.SDO_DIM_ARRAY(MDSYS.SDO_DIM_ELEMENT('X',2899987.997,4000000.003,
> 0.001),MDSYS.SDO_DIM_ELEMENT('Y',5999987.997,8000000.003,0.001)) WHERE
> TABLE_NAME = 'TABLE')
>
> I guess that meaning is to check all the metadata rows from the
> ALL_SDO_GEOM_METADATA view which are referring to the queried table.
> There can be several rows created be different Oracle users. Next the
> maximum BBOX is constructed and that is updated into
> USER_SDO_GEOM_METADATA view.
>
>
> It seems to me that first statement  should include an OWNER filter in the
WHERE clause, or it will fetch all records for table with same name and
same geometric filedname.

Regards

stefano
---------------------------------------------------
41.95581N 12.52854E


http://www.linkedin.com/in/stefanoiacovella

http://twitter.com/#!/Iacovellas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120822/3f3e0afe/attachment.html>

From Jukka.Rahkonen at mmmtike.fi  Wed Aug 22 04:36:43 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 22 Aug 2012 11:36:43 +0000
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
Message-ID: <84446DEF76453C439E9E97E438E13A634674EB@suutari.haapa.mmm.fi>

Stefano Iacovella wrote:


>> I guess that meaning is to check all the metadata rows from the
>> ALL_SDO_GEOM_METADATA view which are referring to the queried table.
>> There can be several rows created be different Oracle users. Next the
>> maximum BBOX is constructed and that is updated into
>> USER_SDO_GEOM_METADATA view.

> It seems to me that first statement? should include an OWNER filter in the WHERE clause, or it will fetch all records for table with same name and same geometric filedname.

Not really, it is normal in managed envinronment that db admins or data managers are creating and updating the tables but reporting is done with minimal rights.  So reading ALL_SDO_GEOM_METADATA does make sense.  And actually  USER_SDO_GEOM_METADATA is a view into the same data than ALL_SDO_GEOM_METADATA filtered by the current username.  Oracle holds the data in a real table named mdsys.sdo_geom_metadata_table but users cannot handle that table directly, everything goes through views and triggers.

I do not know if it makes much sense really to have several metadata rows with different owners in the metadata table but it happens and it must be done sometimes. Some programs do not even try to read ALL_SDO_GEOM_METADATA.  That means that developers have not worked too much in a real production environment and they are creating their test tables with some Oracle admin account  and then they are reading the data with their clients with the same admin account. Bad habbit but totally understandable, it is much faster and easier so.  It is OK but before finalizing with coding it would be good to make a test: What if I try to do this with limited rights? It would be good also to write it into documentation what rights and into which tables are needed.  Policy in our house is that a non-admin Oracle user has by default no rights to do anything. Everything must be explicitly granted.  Now we have usually learned by trial and error by adding grants one by one and following what is blocking us next.

-Jukka Rahkonen-


Regards

stefano
---------------------------------------------------
41.95581N 12.52854E


http://www.linkedin.com/in/stefanoiacovella

http://twitter.com/#!/Iacovellas 

From radim.blazek at gmail.com  Wed Aug 22 04:45:57 2012
From: radim.blazek at gmail.com (Radim Blazek)
Date: Wed, 22 Aug 2012 13:45:57 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <1345631387094-4996972.post@n6.nabble.com>
References: <1345628438183-4996953.post@n6.nabble.com>
	<CAEMrtYoN9Baj2CAqC3fZ6bLQk=gk8MjeQBuiM3Os8Ea+0mW-NA@mail.gmail.com>
	<1345631387094-4996972.post@n6.nabble.com>
Message-ID: <CAEMrtYrzAi8nDTVN6ePNk1+0kkNFwQ10aoCM4h2O7Zay=Ziffg@mail.gmail.com>

On Wed, Aug 22, 2012 at 12:29 PM, haubourg
<regis.haubourg at eau-adour-garonne.fr> wrote:
>
> Radim Blazek-2 wrote
>>
>>
>> QGIS is using GDALRasterIO() which reads a single pixel on original
>> resolution. AFAIK, ECW is using tiles internally so it should be all
>> very fast. I can imagine 2 problems:
>>
>> - the tiles in ECW file are too big - can you verify somehow how big
>> are the tiles?
>>
> Hi Radim, I'm not ecw specialist, but I understand it is a wavelet
> compression algorithm, not  a tiled one.
> There is one big image with pyramids inside.

I am not sure, but I thought that it is using wavelet, pyramids and
tiles. Without tiles it could not be fast enough on higher resolution.

> Radim Blazek-2 wrote
>>
>> - GDAL is reading bigger portion of data than necessary (cc to GDAL list)
>>
>> Is it drawing of the raster also so slow (on raster resolution zoom)?
>>
>> Radim
>>
>>
> No everything is fine when drawing data, whatever resolution I use, this is
> the big thing with ecw.
> I must say I find that it was a bit faster with 1.7.4 than 1.8 and later.
> But this could be related to other factors like internal network
> capacities.. I haven't benched on it yet.

I found in GDAL ecwdataset.cpp that it is treating  single row
requests in IRasterIO in a special way:
    if( nYSize == 1 )
    {
        return GDALRasterBand::IRasterIO(eRWFlag, nXOff, nYOff, nXSize, nYSize,
                                         pData, nBufXSize, nBufYSize,
                                         eBufType, nPixelSpace, nLineSpace );
    }
That could be the difference between draw and identify. Are you able
to test with current master if I send you a patch for QGIS GDAL
provider?

Radim

>
>
>
>
>
> --
> View this message in context: http://osgeo-org.1560.n6.nabble.com/Large-raster-ecw-identify-very-long-tp4996953p4996972.html
> Sent from the Quantum GIS - Developer mailing list archive at Nabble.com.
> _______________________________________________
> Qgis-developer mailing list
> Qgis-developer at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/qgis-developer

From Michael.Smith at erdc.dren.mil  Wed Aug 22 05:01:05 2012
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Wed, 22 Aug 2012 12:01:05 +0000
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
In-Reply-To: <84446DEF76453C439E9E97E438E13A634674EB@suutari.haapa.mmm.fi>
Message-ID: <CC5A4141.34025%michael.smith@erdc.dren.mil>

Jukka,

I'm responsible for the code the calculates the min/max extents for
inserting/updating the USER_SDO_GEOM_METADATA view. This is supposed to
only be run via ogr2ogr when loading/updating tables (I didn;t write that
part, just the query to get those extents). There shouldn't be any
updating going on in an ogrinfo call.

Personally, I do think that any calls against the ALL_SDO_GEOM_METADATA
should really only go against USER_SDO_GEOM_METADATA. There were a couple
of tickets about 2 years ago that implemented thee changes. I'll look them
up and post the tickets.

Mike

-- 
Michael Smith

US Army Corps
Remote Sensing GIS/Center



On 8/22/12 7:36 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi> wrote:

>Stefano Iacovella wrote:
>
>
>>> I guess that meaning is to check all the metadata rows from the
>>> ALL_SDO_GEOM_METADATA view which are referring to the queried table.
>>> There can be several rows created be different Oracle users. Next the
>>> maximum BBOX is constructed and that is updated into
>>> USER_SDO_GEOM_METADATA view.
>
>> It seems to me that first statement  should include an OWNER filter in
>>the WHERE clause, or it will fetch all records for table with same name
>>and same geometric filedname.
>
>Not really, it is normal in managed envinronment that db admins or data
>managers are creating and updating the tables but reporting is done with
>minimal rights.  So reading ALL_SDO_GEOM_METADATA does make sense.  And
>actually  USER_SDO_GEOM_METADATA is a view into the same data than
>ALL_SDO_GEOM_METADATA filtered by the current username.  Oracle holds the
>data in a real table named mdsys.sdo_geom_metadata_table but users cannot
>handle that table directly, everything goes through views and triggers.
>
>I do not know if it makes much sense really to have several metadata rows
>with different owners in the metadata table but it happens and it must be
>done sometimes. Some programs do not even try to read
>ALL_SDO_GEOM_METADATA.  That means that developers have not worked too
>much in a real production environment and they are creating their test
>tables with some Oracle admin account  and then they are reading the data
>with their clients with the same admin account. Bad habbit but totally
>understandable, it is much faster and easier so.  It is OK but before
>finalizing with coding it would be good to make a test: What if I try to
>do this with limited rights? It would be good also to write it into
>documentation what rights and into which tables are needed.  Policy in
>our house is that a non-admin Oracle user has by default no rights to do
>anything. Everything must be explicitly granted.  Now we have usually
>learned by trial and error by adding grants one by one and following what
>is blocking us next.
>
>-Jukka Rahkonen-
>
>
>Regards
>
>stefano
>---------------------------------------------------
>41.95581N 12.52854E
>
>
>http://www.linkedin.com/in/stefanoiacovella
>
>http://twitter.com/#!/Iacovellas
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev


From Michael.Smith at erdc.dren.mil  Wed Aug 22 05:11:55 2012
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Wed, 22 Aug 2012 12:11:55 +0000
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
In-Reply-To: <CC5A4141.34025%michael.smith@erdc.dren.mil>
Message-ID: <CC5A4451.34038%michael.smith@erdc.dren.mil>

Actually, thinking about it, ALL_SDO_GEOM_METADATA has to be used to get
the metadata info otherwise cross schema access would not be possible. Eg
I'm connected as user_a but want to read data from user_b.

Normal Oracle grants would control whether reading (or other operation) is
possible.

Mike

-- 
Michael Smith

US Army Corps
Remote Sensing GIS/Center



On 8/22/12 8:01 AM, "Smith, Michael ERDC-RDE-CRREL-NH"
<Michael.Smith at erdc.dren.mil> wrote:

>Jukka,
>
>I'm responsible for the code the calculates the min/max extents for
>inserting/updating the USER_SDO_GEOM_METADATA view. This is supposed to
>only be run via ogr2ogr when loading/updating tables (I didn;t write that
>part, just the query to get those extents). There shouldn't be any
>updating going on in an ogrinfo call.
>
>Personally, I do think that any calls against the ALL_SDO_GEOM_METADATA
>should really only go against USER_SDO_GEOM_METADATA. There were a couple
>of tickets about 2 years ago that implemented thee changes. I'll look them
>up and post the tickets.
>
>Mike
>
>-- 
>Michael Smith
>
>US Army Corps
>Remote Sensing GIS/Center
>
>
>
>On 8/22/12 7:36 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi> wrote:
>
>>Stefano Iacovella wrote:
>>
>>
>>>> I guess that meaning is to check all the metadata rows from the
>>>> ALL_SDO_GEOM_METADATA view which are referring to the queried table.
>>>> There can be several rows created be different Oracle users. Next the
>>>> maximum BBOX is constructed and that is updated into
>>>> USER_SDO_GEOM_METADATA view.
>>
>>> It seems to me that first statement  should include an OWNER filter in
>>>the WHERE clause, or it will fetch all records for table with same name
>>>and same geometric filedname.
>>
>>Not really, it is normal in managed envinronment that db admins or data
>>managers are creating and updating the tables but reporting is done with
>>minimal rights.  So reading ALL_SDO_GEOM_METADATA does make sense.  And
>>actually  USER_SDO_GEOM_METADATA is a view into the same data than
>>ALL_SDO_GEOM_METADATA filtered by the current username.  Oracle holds the
>>data in a real table named mdsys.sdo_geom_metadata_table but users cannot
>>handle that table directly, everything goes through views and triggers.
>>
>>I do not know if it makes much sense really to have several metadata rows
>>with different owners in the metadata table but it happens and it must be
>>done sometimes. Some programs do not even try to read
>>ALL_SDO_GEOM_METADATA.  That means that developers have not worked too
>>much in a real production environment and they are creating their test
>>tables with some Oracle admin account  and then they are reading the data
>>with their clients with the same admin account. Bad habbit but totally
>>understandable, it is much faster and easier so.  It is OK but before
>>finalizing with coding it would be good to make a test: What if I try to
>>do this with limited rights? It would be good also to write it into
>>documentation what rights and into which tables are needed.  Policy in
>>our house is that a non-admin Oracle user has by default no rights to do
>>anything. Everything must be explicitly granted.  Now we have usually
>>learned by trial and error by adding grants one by one and following what
>>is blocking us next.
>>
>>-Jukka Rahkonen-
>>
>>
>>Regards
>>
>>stefano
>>---------------------------------------------------
>>41.95581N 12.52854E
>>
>>
>>http://www.linkedin.com/in/stefanoiacovella
>>
>>http://twitter.com/#!/Iacovellas
>>_______________________________________________
>>gdal-dev mailing list
>>gdal-dev at lists.osgeo.org
>>http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev


From stefano.iacovella at gmail.com  Wed Aug 22 05:13:18 2012
From: stefano.iacovella at gmail.com (Stefano Iacovella)
Date: Wed, 22 Aug 2012 14:13:18 +0200
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
In-Reply-To: <84446DEF76453C439E9E97E438E13A634674EB@suutari.haapa.mmm.fi>
References: <84446DEF76453C439E9E97E438E13A634674EB@suutari.haapa.mmm.fi>
Message-ID: <CAG9OqYp1_-2iNkhF53JWOa9HntfPt8XUzTuZY2_s7=XMqqGe8A@mail.gmail.com>

2012/8/22 Rahkonen Jukka <Jukka.Rahkonen at mmmtike.fi>

> Stefano Iacovella wrote:
>
>
> >> I guess that meaning is to check all the metadata rows from the
> >> ALL_SDO_GEOM_METADATA view which are referring to the queried table.
> >> There can be several rows created be different Oracle users. Next the
> >> maximum BBOX is constructed and that is updated into
> >> USER_SDO_GEOM_METADATA view.
>
> > It seems to me that first statement  should include an OWNER filter in
> the WHERE clause, or it will fetch all records for table with same name and
> same geometric filedname.
>
> Not really, it is normal in managed envinronment that db admins or data
> managers are creating and updating the tables but reporting is done with
> minimal rights.  So reading ALL_SDO_GEOM_METADATA does make sense.

Yes but you may find duplicate rows for tableName if user 1 owns tableGeom
and user 2 owns tableGeom and the geometry column name is the same.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120822/c4850a81/attachment-0001.html>

From Jukka.Rahkonen at mmmtike.fi  Wed Aug 22 05:32:14 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 22 Aug 2012 12:32:14 +0000
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
Message-ID: <84446DEF76453C439E9E97E438E13A63467534@suutari.haapa.mmm.fi>

Hi,

If I do ogrinfo with "--debug on" against Oracle l can see updates for USER_SDO_GEOM_METADATA.  Same happens if I do ogr2ogr with output to for example GML. For me is seems not to happen only with loading and updating. I have not an easy access to Oracle logs and I have studied only the OGR debug messages on my screen.

-Jukka Rahkonen-

Smith, Michael wrote:

> 
> Jukka,
> 
> I'm responsible for the code the calculates the min/max extents for
> inserting/updating the USER_SDO_GEOM_METADATA view. This is supposed
> to only be run via ogr2ogr when loading/updating tables (I didn;t write that
> part, just the query to get those extents). There shouldn't be any updating
> going on in an ogrinfo call.
> 
> Personally, I do think that any calls against the ALL_SDO_GEOM_METADATA
> should really only go against USER_SDO_GEOM_METADATA. There were a
> couple of tickets about 2 years ago that implemented thee changes. I'll look
> them up and post the tickets.
> 
> Mike
> 
> --
> Michael Smith
> 
> US Army Corps
> Remote Sensing GIS/Center
> 
> 
> 
> On 8/22/12 7:36 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi>
> wrote:
> 
> >Stefano Iacovella wrote:
> >
> >
> >>> I guess that meaning is to check all the metadata rows from the
> >>> ALL_SDO_GEOM_METADATA view which are referring to the queried
> table.
> >>> There can be several rows created be different Oracle users. Next
> >>> the maximum BBOX is constructed and that is updated into
> >>> USER_SDO_GEOM_METADATA view.
> >
> >> It seems to me that first statement  should include an OWNER filter
> >>in the WHERE clause, or it will fetch all records for table with same
> >>name and same geometric filedname.
> >
> >Not really, it is normal in managed envinronment that db admins or data
> >managers are creating and updating the tables but reporting is done
> >with minimal rights.  So reading ALL_SDO_GEOM_METADATA does make
> sense.
> >And actually  USER_SDO_GEOM_METADATA is a view into the same data
> than
> >ALL_SDO_GEOM_METADATA filtered by the current username.  Oracle
> holds
> >the data in a real table named mdsys.sdo_geom_metadata_table but users
> >cannot handle that table directly, everything goes through views and
> triggers.
> >
> >I do not know if it makes much sense really to have several metadata
> >rows with different owners in the metadata table but it happens and it
> >must be done sometimes. Some programs do not even try to read
> >ALL_SDO_GEOM_METADATA.  That means that developers have not
> worked too
> >much in a real production environment and they are creating their test
> >tables with some Oracle admin account  and then they are reading the
> >data with their clients with the same admin account. Bad habbit but
> >totally understandable, it is much faster and easier so.  It is OK but
> >before finalizing with coding it would be good to make a test: What if
> >I try to do this with limited rights? It would be good also to write it
> >into documentation what rights and into which tables are needed.
> >Policy in our house is that a non-admin Oracle user has by default no
> >rights to do anything. Everything must be explicitly granted.  Now we
> >have usually learned by trial and error by adding grants one by one and
> >following what is blocking us next.
> >
> >-Jukka Rahkonen-
> >
> >
> >Regards
> >
> >stefano
> >---------------------------------------------------
> >41.95581N 12.52854E
> >
> >
> >http://www.linkedin.com/in/stefanoiacovella
> >
> >http://twitter.com/#!/Iacovellas
> >_______________________________________________
> >gdal-dev mailing list
> >gdal-dev at lists.osgeo.org
> >http://lists.osgeo.org/mailman/listinfo/gdal-dev


From even.rouault at mines-paris.org  Wed Aug 22 05:37:35 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 22 Aug 2012 14:37:35 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <CAEMrtYrzAi8nDTVN6ePNk1+0kkNFwQ10aoCM4h2O7Zay=Ziffg@mail.gmail.com>
References: <1345628438183-4996953.post@n6.nabble.com>
	<CAEMrtYoN9Baj2CAqC3fZ6bLQk=gk8MjeQBuiM3Os8Ea+0mW-NA@mail.gmail.com>
	<1345631387094-4996972.post@n6.nabble.com>
	<CAEMrtYrzAi8nDTVN6ePNk1+0kkNFwQ10aoCM4h2O7Zay=Ziffg@mail.gmail.com>
Message-ID: <1345639055.5034d28f1c960@imp.free.fr>

Selon Radim Blazek <radim.blazek at gmail.com>:

> On Wed, Aug 22, 2012 at 12:29 PM, haubourg
> <regis.haubourg at eau-adour-garonne.fr> wrote:
> >
> > Radim Blazek-2 wrote
> >>
> >>
> >> QGIS is using GDALRasterIO() which reads a single pixel on original
> >> resolution. AFAIK, ECW is using tiles internally so it should be all
> >> very fast. I can imagine 2 problems:
> >>
> >> - the tiles in ECW file are too big - can you verify somehow how big
> >> are the tiles?
> >>
> > Hi Radim, I'm not ecw specialist, but I understand it is a wavelet
> > compression algorithm, not  a tiled one.
> > There is one big image with pyramids inside.
>
> I am not sure, but I thought that it is using wavelet, pyramids and
> tiles. Without tiles it could not be fast enough on higher resolution.
>
> > Radim Blazek-2 wrote
> >>
> >> - GDAL is reading bigger portion of data than necessary (cc to GDAL list)
> >>
> >> Is it drawing of the raster also so slow (on raster resolution zoom)?
> >>
> >> Radim
> >>
> >>
> > No everything is fine when drawing data, whatever resolution I use, this is
> > the big thing with ecw.
> > I must say I find that it was a bit faster with 1.7.4 than 1.8 and later.
> > But this could be related to other factors like internal network
> > capacities.. I haven't benched on it yet.
>
> I found in GDAL ecwdataset.cpp that it is treating  single row
> requests in IRasterIO in a special way:
>     if( nYSize == 1 )
>     {
>         return GDALRasterBand::IRasterIO(eRWFlag, nXOff, nYOff, nXSize,
> nYSize,
>                                          pData, nBufXSize, nBufYSize,
>                                          eBufType, nPixelSpace, nLineSpace );
>     }


Regis,

what are the dimensions (in pixels) of your big ECW ?

Radim,

I tried the following Python script that must be representative of how QGIS must
do picking (I guess it does a RasterIO(, .... x, y, 1, 1, ... 1, 1) )

from osgeo import gdal
import random
import sys

ds = gdal.Open(sys.argv[1])
xsize = ds.RasterXSize
ysize = ds.RasterYSize

while True:
    x = random.randint(0, xsize)
    y = random.randint(0, ysize)
    data = ds.ReadRaster(x,y,1,1)

After some time, the python process occupies the 1/4 of the total RAM. This is
the default behaviour of the ECW SDK documented in
http://gdal.org/frmt_ecw.html. I then set ECW_CACHE_MAXMEM=1000000 (1 million
bytes) and the memory usage was very small as expected. So I believe there is no
memory leak in the driver. Note: in the old ECW SDK 3.3 (I don't know for the
newer ones), there was a bug in some cases : if the RAM was > 8 GB, RAM / 4 > 2
GB which overflowed a 32 bit, resulting in the SDK allocating memory without
limit.

The ECW driver is quite complex in its reading strategy to establish "views",
but from what I've captured and you noticed, when you ask a window with a 1
pixel height, it goes to IReadBlock() which will fetch one entire line and put
it in the GDAL cache. This is to avoid issuing a SetView() each time a line is
read. The intent here is to be clever for the common line-by-line pattern
access. The drawback of this is that if the raster has a big width and you only
want to read one single pixel, the cost for reading the whole line might be much
greater than the cost of establishing SetView() for your single pixel.

I suppose your workaround in QGIS will be to read 1x2 pixel or something like
that.

Ultimately, we would probably need the following GDAL patch. I can't really say
if it will improve performance a lot because my biggest ECW is "just"
10000x10000.

Index: ecwdataset.cpp
===================================================================
--- ecwdataset.cpp	(revision 24824)
+++ ecwdataset.cpp	(working copy)
@@ -246,8 +246,10 @@
 /*      We will drop down to the block oriented API if only a single    */
 /*      scanline was requested. This is based on the assumption that    */
 /*      doing lots of single scanline windows is expensive.             */
+/*      But for single pixel reading (picking use case), this is not a  */
+/*      good strategy for big rasters.                                  */
 /* -------------------------------------------------------------------- */
-    if( nYSize == 1 )
+    if( nYSize == 1 && nXSize != 1 )
     {
 #ifdef NOISY_DEBUG
         CPLDebug( "ECWRasterBand",
@@ -1038,7 +1040,7 @@
 /*      If we are requesting a single line at 1:1, we do a multi-band   */
 /*      AdviseRead() and then TryWinRasterIO() again.                   */
 /* -------------------------------------------------------------------- */
-    if( nYSize == 1 && nBufYSize == 1 && nBandCount > 1 )
+    if( nYSize == 1 && nXSize != 1 && nBufYSize == 1 && nBandCount > 1 )
     {
         CPLErr eErr;

@@ -1064,8 +1066,8 @@
 /*      band case where we post a big window for the view, and allow    */
 /*      sequential reads.                                               */
 /* -------------------------------------------------------------------- */
-    if( nXSize < nBufXSize || nYSize < nBufYSize || nYSize == 1
-        || nBandCount > 100 || nBandCount == 1 || nBufYSize == 1
+    if( nXSize < nBufXSize || nYSize < nBufYSize || (nYSize == 1 && nXSize !=
1)
+        || nBandCount > 100 || nBandCount == 1 || (nBufYSize == 1 && nBufXSize
!= 1)
         || nBandCount > GetRasterCount() )
     {
         return



Best regards,

Even

From Jukka.Rahkonen at mmmtike.fi  Wed Aug 22 05:41:43 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Wed, 22 Aug 2012 12:41:43 +0000
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
Message-ID: <84446DEF76453C439E9E97E438E13A63467551@suutari.haapa.mmm.fi>

Hi,

This part of query takes UB min values as maxx and maxy. Wouldn't it be better to select the max values instead?
min(case when r=1 then sdo_ub else null end) maxx, min(case when r=2 then sdo_ub else null end) maxy 

-Jukka-

Smith, Michael

> 
> Jukka,
> 
> I'm responsible for the code the calculates the min/max extents for
> inserting/updating the USER_SDO_GEOM_METADATA view. This is supposed
> to only be run via ogr2ogr when loading/updating tables (I didn;t write that
> part, just the query to get those extents). There shouldn't be any updating
> going on in an ogrinfo call.
> 
> Personally, I do think that any calls against the ALL_SDO_GEOM_METADATA
> should really only go against USER_SDO_GEOM_METADATA. There were a
> couple of tickets about 2 years ago that implemented thee changes. I'll look
> them up and post the tickets.
> 
> Mike
> 
> --
> Michael Smith
> 
> US Army Corps
> Remote Sensing GIS/Center
> 
> 
> 
> On 8/22/12 7:36 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi>
> wrote:
> 
> >Stefano Iacovella wrote:
> >
> >
> >>> I guess that meaning is to check all the metadata rows from the
> >>> ALL_SDO_GEOM_METADATA view which are referring to the queried
> table.
> >>> There can be several rows created be different Oracle users. Next
> >>> the maximum BBOX is constructed and that is updated into
> >>> USER_SDO_GEOM_METADATA view.
> >
> >> It seems to me that first statement  should include an OWNER filter
> >>in the WHERE clause, or it will fetch all records for table with same
> >>name and same geometric filedname.
> >
> >Not really, it is normal in managed envinronment that db admins or data
> >managers are creating and updating the tables but reporting is done
> >with minimal rights.  So reading ALL_SDO_GEOM_METADATA does make
> sense.
> >And actually  USER_SDO_GEOM_METADATA is a view into the same data
> than
> >ALL_SDO_GEOM_METADATA filtered by the current username.  Oracle
> holds
> >the data in a real table named mdsys.sdo_geom_metadata_table but users
> >cannot handle that table directly, everything goes through views and
> triggers.
> >
> >I do not know if it makes much sense really to have several metadata
> >rows with different owners in the metadata table but it happens and it
> >must be done sometimes. Some programs do not even try to read
> >ALL_SDO_GEOM_METADATA.  That means that developers have not
> worked too
> >much in a real production environment and they are creating their test
> >tables with some Oracle admin account  and then they are reading the
> >data with their clients with the same admin account. Bad habbit but
> >totally understandable, it is much faster and easier so.  It is OK but
> >before finalizing with coding it would be good to make a test: What if
> >I try to do this with limited rights? It would be good also to write it
> >into documentation what rights and into which tables are needed.
> >Policy in our house is that a non-admin Oracle user has by default no
> >rights to do anything. Everything must be explicitly granted.  Now we
> >have usually learned by trial and error by adding grants one by one and
> >following what is blocking us next.
> >
> >-Jukka Rahkonen-
> >
> >
> >Regards
> >
> >stefano
> >---------------------------------------------------
> >41.95581N 12.52854E
> >
> >
> >http://www.linkedin.com/in/stefanoiacovella
> >
> >http://twitter.com/#!/Iacovellas
> >_______________________________________________
> >gdal-dev mailing list
> >gdal-dev at lists.osgeo.org
> >http://lists.osgeo.org/mailman/listinfo/gdal-dev


From Michael.Smith at erdc.dren.mil  Wed Aug 22 06:03:06 2012
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Wed, 22 Aug 2012 13:03:06 +0000
Subject: [gdal-dev] When and why ogrinfo sends update for Oracle?
In-Reply-To: <84446DEF76453C439E9E97E438E13A63467551@suutari.haapa.mmm.fi>
Message-ID: <CC5A5059.28D94%michael.smith@erdc.dren.mil>

Jukka,

Actually, it doesn't matter since only one value is used in the query, min
or max return the same result. Its just using the min function with the
group by to aggregate the values into one row. All the other values are
null.

Mike

-- 
Michael Smith

Remote Sensing/GIS Center
US Army Corps of Engineers

 

On 8/22/12  8:41 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi> wrote:

>Hi,
>
>This part of query takes UB min values as maxx and maxy. Wouldn't it be
>better to select the max values instead?
>min(case when r=1 then sdo_ub else null end) maxx, min(case when r=2 then
>sdo_ub else null end) maxy
>
>-Jukka-
>
>Smith, Michael
>
>> 
>> Jukka,
>> 
>> I'm responsible for the code the calculates the min/max extents for
>> inserting/updating the USER_SDO_GEOM_METADATA view. This is supposed
>> to only be run via ogr2ogr when loading/updating tables (I didn;t write
>>that
>> part, just the query to get those extents). There shouldn't be any
>>updating
>> going on in an ogrinfo call.
>> 
>> Personally, I do think that any calls against the ALL_SDO_GEOM_METADATA
>> should really only go against USER_SDO_GEOM_METADATA. There were a
>> couple of tickets about 2 years ago that implemented thee changes. I'll
>>look
>> them up and post the tickets.
>> 
>> Mike
>> 
>> --
>> Michael Smith
>> 
>> US Army Corps
>> Remote Sensing GIS/Center
>> 
>> 
>> 
>> On 8/22/12 7:36 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi>
>> wrote:
>> 
>> >Stefano Iacovella wrote:
>> >
>> >
>> >>> I guess that meaning is to check all the metadata rows from the
>> >>> ALL_SDO_GEOM_METADATA view which are referring to the queried
>> table.
>> >>> There can be several rows created be different Oracle users. Next
>> >>> the maximum BBOX is constructed and that is updated into
>> >>> USER_SDO_GEOM_METADATA view.
>> >
>> >> It seems to me that first statement  should include an OWNER filter
>> >>in the WHERE clause, or it will fetch all records for table with same
>> >>name and same geometric filedname.
>> >
>> >Not really, it is normal in managed envinronment that db admins or data
>> >managers are creating and updating the tables but reporting is done
>> >with minimal rights.  So reading ALL_SDO_GEOM_METADATA does make
>> sense.
>> >And actually  USER_SDO_GEOM_METADATA is a view into the same data
>> than
>> >ALL_SDO_GEOM_METADATA filtered by the current username.  Oracle
>> holds
>> >the data in a real table named mdsys.sdo_geom_metadata_table but users
>> >cannot handle that table directly, everything goes through views and
>> triggers.
>> >
>> >I do not know if it makes much sense really to have several metadata
>> >rows with different owners in the metadata table but it happens and it
>> >must be done sometimes. Some programs do not even try to read
>> >ALL_SDO_GEOM_METADATA.  That means that developers have not
>> worked too
>> >much in a real production environment and they are creating their test
>> >tables with some Oracle admin account  and then they are reading the
>> >data with their clients with the same admin account. Bad habbit but
>> >totally understandable, it is much faster and easier so.  It is OK but
>> >before finalizing with coding it would be good to make a test: What if
>> >I try to do this with limited rights? It would be good also to write it
>> >into documentation what rights and into which tables are needed.
>> >Policy in our house is that a non-admin Oracle user has by default no
>> >rights to do anything. Everything must be explicitly granted.  Now we
>> >have usually learned by trial and error by adding grants one by one and
>> >following what is blocking us next.
>> >
>> >-Jukka Rahkonen-
>> >
>> >
>> >Regards
>> >
>> >stefano
>> >---------------------------------------------------
>> >41.95581N 12.52854E
>> >
>> >
>> >http://www.linkedin.com/in/stefanoiacovella
>> >
>> >http://twitter.com/#!/Iacovellas
>> >_______________________________________________
>> >gdal-dev mailing list
>> >gdal-dev at lists.osgeo.org
>> >http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev


From oliver.christen at camptocamp.com  Wed Aug 22 09:13:05 2012
From: oliver.christen at camptocamp.com (Oliver Christen)
Date: Wed, 22 Aug 2012 18:13:05 +0200
Subject: [gdal-dev] problem with CloseRings
Message-ID: <CABn2Q9Rva6F_eV-3L_Rt4Grs0ga3ONBtByUhga65e-5tE2-SBg@mail.gmail.com>

dear community

first of all please accept my apologies if this is not the correct
place to ask about such question.

I am trying to manipulate some geometric data using the gdal/ogr
python lib and Im facing a problem when trying to transform invalid
ring into valid ring.

I have polygons with unclosed holes and I expected the CloseRings
function to solve this for me, but unfortunately, that functions
doesnt seem to do anything (in my case).

see below for a simply python testcase,

if you could tell me if I am possibly not using that function
correctly or if there is a more correct way to do that, you would be
very welcome

using python version 2.6.6
osgeo ogr lib version 1.3.40

thank you very much for your attention
best regards
Oliver

from osgeo import ogr

wkt = "POLYGON ((559577.81 142165.04,559577.67 142161.79,559577.66
142161.16,559577.18 142139.0,559564.07 142140.84,559562.99
142132.4,559556.42 142134.85,559556.47 142134.96,559541.39
142140.58,559549.54 142162.4,559547.0200406529475
142163.310114102292573,559550.570425555342808
142173.455536680703517,559577.81 142165.04),(559559.95600777247455
142169.280249390256358,559550.996165407239459
142172.552877245907439,559550.996165407355875
142172.552877245907439,559547.909677243907936
142163.733065433305455,559550.443360350676812
142162.817994827404618,559542.290859716595151
142140.991299878398422,559557.417905980604701
142135.353766721702414,559557.367843619547784
142135.243629527511075,559562.407678314950317
142133.364239115995588,559563.465598454349674
142141.631689094298054,559576.497222575126216
142139.80268921770039,559576.960120304953307
142161.173134415294044,559576.970239149406552
142161.810621617711149,559577.084823867655359
142164.470624003995908,559577.084823867655359
142164.470624004025012,559570.876975534367375
142165.896950183814624,559564.754505693446845
142167.653979024267755,559564.75450569356326
142167.653979024296859,559559.956007772590965
142169.280249390256358,559559.95600777247455
142169.280249390256358),(559560.19 142169.94,559550.64
142173.43,559560.19 142169.94),(559564.97 142168.32,559560.19
142169.94,559564.97 142168.32),(559577.810000000172295
142165.04,559571.34395208011847 142166.499739240010967,559564.97
142168.32,559577.810000000172295 142165.04))"

poly = ogr.CreateGeometryFromWkt(wkt)

poly.IsValid()
ERROR 1: IllegalArgumentException: Invalid number of points in
LinearRing found 3 - must be 0 or >= 4
False

poly.CloseRings()

poly.IsValid()
ERROR 1: IllegalArgumentException: Invalid number of points in
LinearRing found 3 - must be 0 or >= 4
False

From zoltans at geograph.co.za  Wed Aug 22 09:38:52 2012
From: zoltans at geograph.co.za (Zoltan Szecsei)
Date: Wed, 22 Aug 2012 18:38:52 +0200
Subject: [gdal-dev] cutting up large TIFF files with gdal_translate
Message-ID: <50350B1C.7020201@geograph.co.za>

Hi,
I have a large image bounded by:

Upper Left  (  447007.599, 7132849.501) ( 32d28'15.03"E, 25d55'19.12"S)
Lower Left  (  447007.599, 7127851.511) ( 32d28'14.30"E, 25d58' 1.59"S)
Upper Right (  451005.901, 7132849.501) ( 32d30'38.75"E, 25d55'19.63"S)
Lower Right (  451005.901, 7127851.511) ( 32d30'38.08"E, 25d58' 2.10"S)

and I would like to cut it up into 1Km squares starting on the 447000 
7133000 boundary.
The problem is that using:
gdal_translate -of JPEG -projwin $tlx $tly $brx $bry  m_36s.tif 
m_36s_${r}${c}.jpg

gives me:
Computed -srcwin -152 97030 20008 20008 from projected window.
Computed -srcwin falls outside raster size of 79999x100001.

Whilst the error is understandible, I was hoping that extra pixels would 
be automatically inserted as no_data values to make up my 1km tiles.

I'm not sure if -outsize will help me or not.
(ie: I first increase the area of my original tiff image so that it is 
larger than my required tiles, and then cut it up as above)

Is this the function of -outsize ?

Any suggestions how I should go about this issue?

Thanks & regards,
Zoltan



-- 

===========================================
Zoltan Szecsei PrGISc [PGP0031]
Geograph (Pty) Ltd.
P.O. Box 7, Muizenberg 7950, South Africa.

65 Main Road, Muizenberg 7945
Western Cape, South Africa.

34? 6'16.35"S 18?28'5.62"E

Tel: +27-21-7884897  Mobile: +27-83-6004028
Fax: +27-86-6115323     www.geograph.co.za
===========================================


From warmerdam at pobox.com  Wed Aug 22 09:43:12 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Wed, 22 Aug 2012 09:43:12 -0700
Subject: [gdal-dev] cutting up large TIFF files with gdal_translate
In-Reply-To: <50350B1C.7020201@geograph.co.za>
References: <50350B1C.7020201@geograph.co.za>
Message-ID: <CA+YzLBdM7mREGphPp7GcmkZRQqv_Lq6v9ZTfs0pHduyKpC+JaQ@mail.gmail.com>

On Wed, Aug 22, 2012 at 9:38 AM, Zoltan Szecsei <zoltans at geograph.co.za> wrote:
> Hi,
> I have a large image bounded by:
>
> Upper Left  (  447007.599, 7132849.501) ( 32d28'15.03"E, 25d55'19.12"S)
> Lower Left  (  447007.599, 7127851.511) ( 32d28'14.30"E, 25d58' 1.59"S)
> Upper Right (  451005.901, 7132849.501) ( 32d30'38.75"E, 25d55'19.63"S)
> Lower Right (  451005.901, 7127851.511) ( 32d30'38.08"E, 25d58' 2.10"S)
>
> and I would like to cut it up into 1Km squares starting on the 447000
> 7133000 boundary.
> The problem is that using:
> gdal_translate -of JPEG -projwin $tlx $tly $brx $bry  m_36s.tif
> m_36s_${r}${c}.jpg
>
> gives me:
> Computed -srcwin -152 97030 20008 20008 from projected window.
> Computed -srcwin falls outside raster size of 79999x100001.
>
> Whilst the error is understandible, I was hoping that extra pixels would be
> automatically inserted as no_data values to make up my 1km tiles.

Zoltan,

Unfortunately gdal_translate does not support this.  Instead I'd
suggest using gdalwarp:

  gdalwarp -te xmin ymin xmax ymax srcfile dstfile

The "target extent" window may be off the source image without
problem.

> I'm not sure if -outsize will help me or not.
> (ie: I first increase the area of my original tiff image so that it is
> larger than my required tiles, and then cut it up as above)

The -outsize makes the output larger (or smaller) by replication
or decimation not by growing the extents.

Best regards,
Frank

> Is this the function of -outsize ?
>
> Any suggestions how I should go about this issue?
>
> Thanks & regards,
> Zoltan
>
>
>
> --
>
> ===========================================
> Zoltan Szecsei PrGISc [PGP0031]
> Geograph (Pty) Ltd.
> P.O. Box 7, Muizenberg 7950, South Africa.
>
> 65 Main Road, Muizenberg 7945
> Western Cape, South Africa.
>
> 34? 6'16.35"S 18?28'5.62"E
>
> Tel: +27-21-7884897  Mobile: +27-83-6004028
> Fax: +27-86-6115323     www.geograph.co.za
> ===========================================
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer

From zoltans at geograph.co.za  Wed Aug 22 09:45:43 2012
From: zoltans at geograph.co.za (Zoltan Szecsei)
Date: Wed, 22 Aug 2012 18:45:43 +0200
Subject: [gdal-dev] cutting up large TIFF files with gdal_translate -
 Solution
In-Reply-To: <CA+YzLBdM7mREGphPp7GcmkZRQqv_Lq6v9ZTfs0pHduyKpC+JaQ@mail.gmail.com>
References: <50350B1C.7020201@geograph.co.za>
	<CA+YzLBdM7mREGphPp7GcmkZRQqv_Lq6v9ZTfs0pHduyKpC+JaQ@mail.gmail.com>
Message-ID: <50350CB7.1040702@geograph.co.za>

Hi Frank,
Thanks for the prompt reply and explanation.

Kind regards,
Zoltan


On 2012/08/22 18:43, Frank Warmerdam wrote:
> On Wed, Aug 22, 2012 at 9:38 AM, Zoltan Szecsei <zoltans at geograph.co.za> wrote:
>> Hi,
>> I have a large image bounded by:
>>
>> Upper Left  (  447007.599, 7132849.501) ( 32d28'15.03"E, 25d55'19.12"S)
>> Lower Left  (  447007.599, 7127851.511) ( 32d28'14.30"E, 25d58' 1.59"S)
>> Upper Right (  451005.901, 7132849.501) ( 32d30'38.75"E, 25d55'19.63"S)
>> Lower Right (  451005.901, 7127851.511) ( 32d30'38.08"E, 25d58' 2.10"S)
>>
>> and I would like to cut it up into 1Km squares starting on the 447000
>> 7133000 boundary.
>> The problem is that using:
>> gdal_translate -of JPEG -projwin $tlx $tly $brx $bry  m_36s.tif
>> m_36s_${r}${c}.jpg
>>
>> gives me:
>> Computed -srcwin -152 97030 20008 20008 from projected window.
>> Computed -srcwin falls outside raster size of 79999x100001.
>>
>> Whilst the error is understandible, I was hoping that extra pixels would be
>> automatically inserted as no_data values to make up my 1km tiles.
> Zoltan,
>
> Unfortunately gdal_translate does not support this.  Instead I'd
> suggest using gdalwarp:
>
>    gdalwarp -te xmin ymin xmax ymax srcfile dstfile
>
> The "target extent" window may be off the source image without
> problem.
>
>> I'm not sure if -outsize will help me or not.
>> (ie: I first increase the area of my original tiff image so that it is
>> larger than my required tiles, and then cut it up as above)
> The -outsize makes the output larger (or smaller) by replication
> or decimation not by growing the extents.
>
> Best regards,
> Frank
>
>> Is this the function of -outsize ?
>>
>> Any suggestions how I should go about this issue?
>>
>> Thanks & regards,
>> Zoltan
>>
>>
>>
>> --
>>
>> ===========================================
>> Zoltan Szecsei PrGISc [PGP0031]
>> Geograph (Pty) Ltd.
>> P.O. Box 7, Muizenberg 7950, South Africa.
>>
>> 65 Main Road, Muizenberg 7945
>> Western Cape, South Africa.
>>
>> 34? 6'16.35"S 18?28'5.62"E
>>
>> Tel: +27-21-7884897  Mobile: +27-83-6004028
>> Fax: +27-86-6115323     www.geograph.co.za
>> ===========================================
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>


-- 

===========================================
Zoltan Szecsei PrGISc [PGP0031]
Geograph (Pty) Ltd.
P.O. Box 7, Muizenberg 7950, South Africa.

65 Main Road, Muizenberg 7945
Western Cape, South Africa.

34? 6'16.35"S 18?28'5.62"E

Tel: +27-21-7884897  Mobile: +27-83-6004028
Fax: +27-86-6115323     www.geograph.co.za
===========================================


From warmerdam at pobox.com  Wed Aug 22 09:48:49 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Wed, 22 Aug 2012 09:48:49 -0700
Subject: [gdal-dev] problem with CloseRings
In-Reply-To: <CABn2Q9Rva6F_eV-3L_Rt4Grs0ga3ONBtByUhga65e-5tE2-SBg@mail.gmail.com>
References: <CABn2Q9Rva6F_eV-3L_Rt4Grs0ga3ONBtByUhga65e-5tE2-SBg@mail.gmail.com>
Message-ID: <CA+YzLBf=bcdBp0d37phpk4dCvabBJG76UNKz9OO4qec_QrBL0A@mail.gmail.com>

Oliver,

The problem with your rings isn't that they are not closed, it is that
they are degenerate.

For instance:
(559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)

This goes from PointA to PointB back to PointA.  It is closed, it just
is degenerate.  It has no area.  I'm not aware of a super easy way of
cleaning out such junk rings - you might need to explicitly test them
and remove them if they are degenerate.

Best regards,

On Wed, Aug 22, 2012 at 9:13 AM, Oliver Christen
<oliver.christen at camptocamp.com> wrote:
> dear community
>
> first of all please accept my apologies if this is not the correct
> place to ask about such question.
>
> I am trying to manipulate some geometric data using the gdal/ogr
> python lib and Im facing a problem when trying to transform invalid
> ring into valid ring.
>
> I have polygons with unclosed holes and I expected the CloseRings
> function to solve this for me, but unfortunately, that functions
> doesnt seem to do anything (in my case).
>
> see below for a simply python testcase,
>
> if you could tell me if I am possibly not using that function
> correctly or if there is a more correct way to do that, you would be
> very welcome
>
> using python version 2.6.6
> osgeo ogr lib version 1.3.40
>
> thank you very much for your attention
> best regards
> Oliver
>
> from osgeo import ogr
>
> wkt = "POLYGON ((559577.81 142165.04,559577.67 142161.79,559577.66
> 142161.16,559577.18 142139.0,559564.07 142140.84,559562.99
> 142132.4,559556.42 142134.85,559556.47 142134.96,559541.39
> 142140.58,559549.54 142162.4,559547.0200406529475
> 142163.310114102292573,559550.570425555342808
> 142173.455536680703517,559577.81 142165.04),(559559.95600777247455
> 142169.280249390256358,559550.996165407239459
> 142172.552877245907439,559550.996165407355875
> 142172.552877245907439,559547.909677243907936
> 142163.733065433305455,559550.443360350676812
> 142162.817994827404618,559542.290859716595151
> 142140.991299878398422,559557.417905980604701
> 142135.353766721702414,559557.367843619547784
> 142135.243629527511075,559562.407678314950317
> 142133.364239115995588,559563.465598454349674
> 142141.631689094298054,559576.497222575126216
> 142139.80268921770039,559576.960120304953307
> 142161.173134415294044,559576.970239149406552
> 142161.810621617711149,559577.084823867655359
> 142164.470624003995908,559577.084823867655359
> 142164.470624004025012,559570.876975534367375
> 142165.896950183814624,559564.754505693446845
> 142167.653979024267755,559564.75450569356326
> 142167.653979024296859,559559.956007772590965
> 142169.280249390256358,559559.95600777247455
> 142169.280249390256358),(559560.19 142169.94,559550.64
> 142173.43,559560.19 142169.94),(559564.97 142168.32,559560.19
> 142169.94,559564.97 142168.32),(559577.810000000172295
> 142165.04,559571.34395208011847 142166.499739240010967,559564.97
> 142168.32,559577.810000000172295 142165.04))"
>
> poly = ogr.CreateGeometryFromWkt(wkt)
>
> poly.IsValid()
> ERROR 1: IllegalArgumentException: Invalid number of points in
> LinearRing found 3 - must be 0 or >= 4
> False
>
> poly.CloseRings()
>
> poly.IsValid()
> ERROR 1: IllegalArgumentException: Invalid number of points in
> LinearRing found 3 - must be 0 or >= 4
> False
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer

From Doug_Newcomb at fws.gov  Wed Aug 22 10:11:25 2012
From: Doug_Newcomb at fws.gov (Doug_Newcomb at fws.gov)
Date: Wed, 22 Aug 2012 13:11:25 -0400
Subject: [gdal-dev] problem with CloseRings
In-Reply-To: <CA+YzLBf=bcdBp0d37phpk4dCvabBJG76UNKz9OO4qec_QrBL0A@mail.gmail.com>
Message-ID: <OF82E92885.76996795-ON85257A62.005C92A9-85257A62.005E6E2C@fws.gov>

Oliver,

Would it just be a matter of counting the vertices of each polygon, 
selecting the polygons with 3 vertices, and comparing the value of the 
first and last vertex  as you are building wkt value string below? 


Doug



>The problem with your rings isn't that they are not closed, it is that
>they are degenerate.

>For instance:
>(559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)

>This goes from PointA to PointB back to PointA.  It is closed, it just
>is degenerate.  It has no area.  I'm not aware of a super easy way of
>cleaning out such junk rings - you might need to explicitly test them
>and remove them if they are degenerate.

>Best regards,




Doug Newcomb 
USFWS
Raleigh, NC
919-856-4520 ext. 14 doug_newcomb at fws.gov
---------------------------------------------------------------------------------------------------------
The opinions I express are my own and are not representative of the 
official policy of the U.S.Fish and Wildlife Service or Dept. of the 
Interior.   Life is too short for undocumented, proprietary data formats.



Frank Warmerdam <warmerdam at pobox.com> 
Sent by: gdal-dev-bounces at lists.osgeo.org
08/22/2012 12:49 PM

To
Oliver Christen <oliver.christen at camptocamp.com>
cc
gdal-dev at lists.osgeo.org
Subject
Re: [gdal-dev] problem with CloseRings






Oliver,

The problem with your rings isn't that they are not closed, it is that
they are degenerate.

For instance:
(559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)

This goes from PointA to PointB back to PointA.  It is closed, it just
is degenerate.  It has no area.  I'm not aware of a super easy way of
cleaning out such junk rings - you might need to explicitly test them
and remove them if they are degenerate.

Best regards,

On Wed, Aug 22, 2012 at 9:13 AM, Oliver Christen
<oliver.christen at camptocamp.com> wrote:
> dear community
>
> first of all please accept my apologies if this is not the correct
> place to ask about such question.
>
> I am trying to manipulate some geometric data using the gdal/ogr
> python lib and Im facing a problem when trying to transform invalid
> ring into valid ring.
>
> I have polygons with unclosed holes and I expected the CloseRings
> function to solve this for me, but unfortunately, that functions
> doesnt seem to do anything (in my case).
>
> see below for a simply python testcase,
>
> if you could tell me if I am possibly not using that function
> correctly or if there is a more correct way to do that, you would be
> very welcome
>
> using python version 2.6.6
> osgeo ogr lib version 1.3.40
>
> thank you very much for your attention
> best regards
> Oliver
>
> from osgeo import ogr
>
> wkt = "POLYGON ((559577.81 142165.04,559577.67 142161.79,559577.66
> 142161.16,559577.18 142139.0,559564.07 142140.84,559562.99
> 142132.4,559556.42 142134.85,559556.47 142134.96,559541.39
> 142140.58,559549.54 142162.4,559547.0200406529475
> 142163.310114102292573,559550.570425555342808
> 142173.455536680703517,559577.81 142165.04),(559559.95600777247455
> 142169.280249390256358,559550.996165407239459
> 142172.552877245907439,559550.996165407355875
> 142172.552877245907439,559547.909677243907936
> 142163.733065433305455,559550.443360350676812
> 142162.817994827404618,559542.290859716595151
> 142140.991299878398422,559557.417905980604701
> 142135.353766721702414,559557.367843619547784
> 142135.243629527511075,559562.407678314950317
> 142133.364239115995588,559563.465598454349674
> 142141.631689094298054,559576.497222575126216
> 142139.80268921770039,559576.960120304953307
> 142161.173134415294044,559576.970239149406552
> 142161.810621617711149,559577.084823867655359
> 142164.470624003995908,559577.084823867655359
> 142164.470624004025012,559570.876975534367375
> 142165.896950183814624,559564.754505693446845
> 142167.653979024267755,559564.75450569356326
> 142167.653979024296859,559559.956007772590965
> 142169.280249390256358,559559.95600777247455
> 142169.280249390256358),(559560.19 142169.94,559550.64
> 142173.43,559560.19 142169.94),(559564.97 142168.32,559560.19
> 142169.94,559564.97 142168.32),(559577.810000000172295
> 142165.04,559571.34395208011847 142166.499739240010967,559564.97
> 142168.32,559577.810000000172295 142165.04))"
>
> poly = ogr.CreateGeometryFromWkt(wkt)
>
> poly.IsValid()
> ERROR 1: IllegalArgumentException: Invalid number of points in
> LinearRing found 3 - must be 0 or >= 4
> False
>
> poly.CloseRings()
>
> poly.IsValid()
> ERROR 1: IllegalArgumentException: Invalid number of points in
> LinearRing found 3 - must be 0 or >= 4
> False
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, 
warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer
_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
http://lists.osgeo.org/mailman/listinfo/gdal-dev

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120822/9e373f13/attachment-0001.html>

From even.rouault at mines-paris.org  Wed Aug 22 10:47:28 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 22 Aug 2012 19:47:28 +0200
Subject: [gdal-dev] cutting up large TIFF files with gdal_translate
In-Reply-To: <CA+YzLBdM7mREGphPp7GcmkZRQqv_Lq6v9ZTfs0pHduyKpC+JaQ@mail.gmail.com>
References: <50350B1C.7020201@geograph.co.za>
	<CA+YzLBdM7mREGphPp7GcmkZRQqv_Lq6v9ZTfs0pHduyKpC+JaQ@mail.gmail.com>
Message-ID: <201208221947.29007.even.rouault@mines-paris.org>

Le mercredi 22 ao?t 2012 18:43:12, Frank Warmerdam a ?crit :
> On Wed, Aug 22, 2012 at 9:38 AM, Zoltan Szecsei <zoltans at geograph.co.za> 
wrote:
> > Hi,
> > I have a large image bounded by:
> > 
> > Upper Left  (  447007.599, 7132849.501) ( 32d28'15.03"E, 25d55'19.12"S)
> > Lower Left  (  447007.599, 7127851.511) ( 32d28'14.30"E, 25d58' 1.59"S)
> > Upper Right (  451005.901, 7132849.501) ( 32d30'38.75"E, 25d55'19.63"S)
> > Lower Right (  451005.901, 7127851.511) ( 32d30'38.08"E, 25d58' 2.10"S)
> > 
> > and I would like to cut it up into 1Km squares starting on the 447000
> > 7133000 boundary.
> > The problem is that using:
> > gdal_translate -of JPEG -projwin $tlx $tly $brx $bry  m_36s.tif
> > m_36s_${r}${c}.jpg
> > 
> > gives me:
> > Computed -srcwin -152 97030 20008 20008 from projected window.
> > Computed -srcwin falls outside raster size of 79999x100001.
> > 
> > Whilst the error is understandible, I was hoping that extra pixels would
> > be automatically inserted as no_data values to make up my 1km tiles.
> 
> Zoltan,
> 
> Unfortunately gdal_translate does not support this.  Instead I'd
> suggest using gdalwarp:
> 
>   gdalwarp -te xmin ymin xmax ymax srcfile dstfile
> 
> The "target extent" window may be off the source image without
> problem.

FYI, gdal_translate in trunk has been upgraded recently to support that.


From chaitanya.ch at gmail.com  Wed Aug 22 10:27:46 2012
From: chaitanya.ch at gmail.com (Chaitanya kumar CH)
Date: Wed, 22 Aug 2012 22:57:46 +0530
Subject: [gdal-dev] problem with CloseRings
In-Reply-To: <OF82E92885.76996795-ON85257A62.005C92A9-85257A62.005E6E2C@fws.gov>
References: <CA+YzLBf=bcdBp0d37phpk4dCvabBJG76UNKz9OO4qec_QrBL0A@mail.gmail.com>
	<OF82E92885.76996795-ON85257A62.005C92A9-85257A62.005E6E2C@fws.gov>
Message-ID: <CAMKgpOYMJYmv3NeN6UA91EkShKJ-HU1tGT8rdYmQ_iRbmDQq6g@mail.gmail.com>

Doug,

You could rebuild individual polygons by attempting to close the
constituent rings one-by-one while discarding those that give an error with
the CloseRings() method.

On Wed, Aug 22, 2012 at 10:41 PM, <Doug_Newcomb at fws.gov> wrote:

>
> Oliver,
>
> Would it just be a matter of counting the vertices of each polygon,
> selecting the polygons with 3 vertices, and comparing the value of the
> first and last vertex  as you are building wkt value string below?
>
>
> Doug
>
>
>
> >The problem with your rings isn't that they are not closed, it is that
> >they are degenerate.
>
> >For instance:
> >(559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)
>
> >This goes from PointA to PointB back to PointA.  It is closed, it just
> >is degenerate.  It has no area.  I'm not aware of a super easy way of
> >cleaning out such junk rings - you might need to explicitly test them
> >and remove them if they are degenerate.
>
> >Best regards,
>
>
>
>
> Doug Newcomb
> USFWS
> Raleigh, NC
> 919-856-4520 ext. 14 doug_newcomb at fws.gov
>
> ---------------------------------------------------------------------------------------------------------
> The opinions I express are my own and are not representative of the
> official policy of the U.S.Fish and Wildlife Service or Dept. of the
> Interior.   Life is too short for undocumented, proprietary data formats.
>
>
>  *Frank Warmerdam <warmerdam at pobox.com>*
> Sent by: gdal-dev-bounces at lists.osgeo.org
>
> 08/22/2012 12:49 PM
>   To
> Oliver Christen <oliver.christen at camptocamp.com>
> cc
> gdal-dev at lists.osgeo.org
> Subject
> Re: [gdal-dev] problem with CloseRings
>
>
>
>
> Oliver,
>
> The problem with your rings isn't that they are not closed, it is that
> they are degenerate.
>
> For instance:
> (559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)
>
> This goes from PointA to PointB back to PointA.  It is closed, it just
> is degenerate.  It has no area.  I'm not aware of a super easy way of
> cleaning out such junk rings - you might need to explicitly test them
> and remove them if they are degenerate.
>
> Best regards,
>
> On Wed, Aug 22, 2012 at 9:13 AM, Oliver Christen
> <oliver.christen at camptocamp.com> wrote:
> > dear community
> >
> > first of all please accept my apologies if this is not the correct
> > place to ask about such question.
> >
> > I am trying to manipulate some geometric data using the gdal/ogr
> > python lib and Im facing a problem when trying to transform invalid
> > ring into valid ring.
> >
> > I have polygons with unclosed holes and I expected the CloseRings
> > function to solve this for me, but unfortunately, that functions
> > doesnt seem to do anything (in my case).
> >
> > see below for a simply python testcase,
> >
> > if you could tell me if I am possibly not using that function
> > correctly or if there is a more correct way to do that, you would be
> > very welcome
> >
> > using python version 2.6.6
> > osgeo ogr lib version 1.3.40
> >
> > thank you very much for your attention
> > best regards
> > Oliver
> >
> > from osgeo import ogr
> >
> > wkt = "POLYGON ((559577.81 142165.04,559577.67 142161.79,559577.66
> > 142161.16,559577.18 142139.0,559564.07 142140.84,559562.99
> > 142132.4,559556.42 142134.85,559556.47 142134.96,559541.39
> > 142140.58,559549.54 142162.4,559547.0200406529475
> > 142163.310114102292573,559550.570425555342808
> > 142173.455536680703517,559577.81 142165.04),(559559.95600777247455
> > 142169.280249390256358,559550.996165407239459
> > 142172.552877245907439,559550.996165407355875
> > 142172.552877245907439,559547.909677243907936
> > 142163.733065433305455,559550.443360350676812
> > 142162.817994827404618,559542.290859716595151
> > 142140.991299878398422,559557.417905980604701
> > 142135.353766721702414,559557.367843619547784
> > 142135.243629527511075,559562.407678314950317
> > 142133.364239115995588,559563.465598454349674
> > 142141.631689094298054,559576.497222575126216
> > 142139.80268921770039,559576.960120304953307
> > 142161.173134415294044,559576.970239149406552
> > 142161.810621617711149,559577.084823867655359
> > 142164.470624003995908,559577.084823867655359
> > 142164.470624004025012,559570.876975534367375
> > 142165.896950183814624,559564.754505693446845
> > 142167.653979024267755,559564.75450569356326
> > 142167.653979024296859,559559.956007772590965
> > 142169.280249390256358,559559.95600777247455
> > 142169.280249390256358),(559560.19 142169.94,559550.64
> > 142173.43,559560.19 142169.94),(559564.97 142168.32,559560.19
> > 142169.94,559564.97 142168.32),(559577.810000000172295
> > 142165.04,559571.34395208011847 142166.499739240010967,559564.97
> > 142168.32,559577.810000000172295 142165.04))"
> >
> > poly = ogr.CreateGeometryFromWkt(wkt)
> >
> > poly.IsValid()
> > ERROR 1: IllegalArgumentException: Invalid number of points in
> > LinearRing found 3 - must be 0 or >= 4
> > False
> >
> > poly.CloseRings()
> >
> > poly.IsValid()
> > ERROR 1: IllegalArgumentException: Invalid number of points in
> > LinearRing found 3 - must be 0 or >= 4
> > False
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
>
> --
>
> ---------------------------------------+--------------------------------------
> I set the clouds in motion - turn up   | Frank Warmerdam,
> warmerdam at pobox.com
> light and sound - activate the windows |
> <http://lists.osgeo.org/mailman/listinfo/gdal-dev>
> http://pobox.com/~warmerdam
> and watch the world go round - Rush    | Geospatial Software Developer
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
>  <http://pobox.com/%7Ewarmerdam>
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



-- 
Best regards,
Chaitanya kumar CH.

+91-9494447584
17.2416N 80.1426E
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120822/acd00cdd/attachment.html>

From radim.blazek at gmail.com  Wed Aug 22 11:13:39 2012
From: radim.blazek at gmail.com (Radim Blazek)
Date: Wed, 22 Aug 2012 20:13:39 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <1345639055.5034d28f1c960@imp.free.fr>
References: <1345628438183-4996953.post@n6.nabble.com>
	<CAEMrtYoN9Baj2CAqC3fZ6bLQk=gk8MjeQBuiM3Os8Ea+0mW-NA@mail.gmail.com>
	<1345631387094-4996972.post@n6.nabble.com>
	<CAEMrtYrzAi8nDTVN6ePNk1+0kkNFwQ10aoCM4h2O7Zay=Ziffg@mail.gmail.com>
	<1345639055.5034d28f1c960@imp.free.fr>
Message-ID: <CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>

Even,
thanks for exhaustive explanation and testing.

On Wed, Aug 22, 2012 at 2:37 PM, Even Rouault
<even.rouault at mines-paris.org> wrote:
>> I found in GDAL ecwdataset.cpp that it is treating  single row
>> requests in IRasterIO in a special way:
>
> I tried the following Python script that must be representative of how QGIS must
> do picking (I guess it does a RasterIO(, .... x, y, 1, 1, ... 1, 1) )

Yes.

> I suppose your workaround in QGIS will be to read 1x2 pixel or something like that.

Yes, I have used 2x2.

Radim

From even.rouault at mines-paris.org  Wed Aug 22 11:34:09 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Wed, 22 Aug 2012 20:34:09 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
References: <1345628438183-4996953.post@n6.nabble.com>
	<1345639055.5034d28f1c960@imp.free.fr>
	<CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
Message-ID: <201208222034.09342.even.rouault@mines-paris.org>

Le mercredi 22 ao?t 2012 20:13:39, Radim Blazek a ?crit :
> Even,
> thanks for exhaustive explanation and testing.
> 
> On Wed, Aug 22, 2012 at 2:37 PM, Even Rouault
> 
> <even.rouault at mines-paris.org> wrote:
> >> I found in GDAL ecwdataset.cpp that it is treating  single row
> > 
> >> requests in IRasterIO in a special way:
> > I tried the following Python script that must be representative of how
> > QGIS must do picking (I guess it does a RasterIO(, .... x, y, 1, 1, ...
> > 1, 1) )
> 
> Yes.
> 
> > I suppose your workaround in QGIS will be to read 1x2 pixel or something
> > like that.
> 
> Yes, I have used 2x2.

Hum, I humbly suggest that the fix should be done in the ECW driver rather than 
in QGIS. The issue with the 2x2 workaround is that if other GDAL drivers have 
optimizations for the 1x1 pixel use case (which would be reasonable), they 
will be unused now.

> 
> Radim

From diregola at gmail.com  Wed Aug 22 23:53:31 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Thu, 23 Aug 2012 08:53:31 +0200
Subject: [gdal-dev] can't handle grib file
Message-ID: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>

Hi all,

I have a problem handling some grib files, I get a warning message and I
can't understand how to deal with it..

running gdalinfo, it says:

Un-handled possible ensemble section center 78 subcenter 255
[... several times, cut]
Un-handled possible ensemble section center 78 subcenter 255
Driver: GRIB/GRIdded Binary (.grb)
Files:
/home/leomarg/Desktop/Fire_event_test_case_Valencia/grib/dwd_grib1_ispra_gmi202_2012063000

Size is 201, 161
Coordinate System is:
GEOGCS["Coordinate System imported from GRIB file",
    DATUM["unknown",
        SPHEROID["Sphere",6367470,0]],
    PRIMEM["Greenwich",0],
    UNIT["degree",0.0174532925199433]]
Origin = (-10.000000000000000,74.960000000000008)
Pixel Size = (0.000000000000000,-0.000000000000000)
Corner Coordinates:
Upper Left  ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
Lower Left  ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
Upper Right ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
Lower Right ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
Center      ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
Band 1 Block=201x1 Type=Float64, ColorInterp=Undefined
  Description = 10[m] HTGL (Specified height level above ground)
  Metadata:
    GRIB_COMMENT=u-component (zonal) of wind [m/s]
    GRIB_ELEMENT=U
    GRIB_FORECAST_SECONDS=0 sec
    GRIB_REF_TIME=  1341014400 sec UTC
    GRIB_SHORT_NAME=10-HTGL
    GRIB_UNIT=[m/s]
    GRIB_VALID_TIME=  1341014400 sec UTC
Band 2 Block=201x1 Type=Float64, ColorInterp=Undefined
  Description = 10[m] HTGL (Specified height level above ground)
  Metadata:
    GRIB_COMMENT=v-component (merdional) of wind [m/s]
    GRIB_ELEMENT=V
    GRIB_FORECAST_SECONDS=0 sec
    GRIB_REF_TIME=  1341014400 sec UTC
    GRIB_SHORT_NAME=10-HTGL
    GRIB_UNIT=[m/s]
    GRIB_VALID_TIME=  1341014400 sec UTC

[...]

Furthermore, when I try with gdal_translate to convert one of the bands in
tif format, the size of the pixels created is 0x0.

Thanks in advance for any hint.

-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120823/d687c21b/attachment.html>

From radim.blazek at gmail.com  Thu Aug 23 04:49:32 2012
From: radim.blazek at gmail.com (Radim Blazek)
Date: Thu, 23 Aug 2012 13:49:32 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <201208222034.09342.even.rouault@mines-paris.org>
References: <1345628438183-4996953.post@n6.nabble.com>
	<1345639055.5034d28f1c960@imp.free.fr>
	<CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
	<201208222034.09342.even.rouault@mines-paris.org>
Message-ID: <CAEMrtYpaJoooCquq9NMe9Yg7U84R1UMXBsYqVhvF2aan-Zbi4A@mail.gmail.com>

On Wed, Aug 22, 2012 at 8:34 PM, Even Rouault
<even.rouault at mines-paris.org> wrote:
>> > I suppose your workaround in QGIS will be to read 1x2 pixel or something
>> > like that.
>>
>> Yes, I have used 2x2.
>
> Hum, I humbly suggest that the fix should be done in the ECW driver rather than
> in QGIS. The issue with the 2x2 workaround is that if other GDAL drivers have
> optimizations for the 1x1 pixel use case (which would be reasonable), they
> will be unused now.

Until it get fixed in GDAL we can use

  if ( GDALGetDriverShortName() == "ECW")

and once you fix that

  #if defined(GDAL_VERSION_NUM) && GDAL_VERSION_NUM < x.x
      if ( GDALGetDriverShortName() == "ECW")

Radim

From even.rouault at mines-paris.org  Thu Aug 23 05:42:26 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 23 Aug 2012 14:42:26 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <CAEMrtYpaJoooCquq9NMe9Yg7U84R1UMXBsYqVhvF2aan-Zbi4A@mail.gmail.com>
References: <1345628438183-4996953.post@n6.nabble.com>
	<1345639055.5034d28f1c960@imp.free.fr>
	<CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
	<201208222034.09342.even.rouault@mines-paris.org>
	<CAEMrtYpaJoooCquq9NMe9Yg7U84R1UMXBsYqVhvF2aan-Zbi4A@mail.gmail.com>
Message-ID: <1345725746.50362532bb17e@imp.free.fr>


> Until it get fixed in GDAL we can use
>
>   if ( GDALGetDriverShortName() == "ECW")
>
> and once you fix that
>
>   #if defined(GDAL_VERSION_NUM) && GDAL_VERSION_NUM < x.x
>       if ( GDALGetDriverShortName() == "ECW")

Seems reasonnable. Except I suggest using a string comparison function and not
== ;-)

Would you mind creating a ticket in GDAL trac about that ?

>
> Radim
>



From diregola at gmail.com  Thu Aug 23 06:52:58 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Thu, 23 Aug 2012 15:52:58 +0200
Subject: [gdal-dev] can't handle grib file
In-Reply-To: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>
References: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>
Message-ID: <CABa=8QowT0nMqWaHjLXVqBYGovL-gG=HP4_-fptMnzOwpHue_g@mail.gmail.com>

In order to check what is inside the grib file, I just installed the grib
API [1] and ran

grib_dump dwd_grib1_ispra_gmi202_2012063000 > tst.txt

The information I get looking into the txt file is:

***** FILE: dwd_grib1_ispra_gmi202_2012063000
#==============   MESSAGE 1 ( length=68884 )               ==============
GRIB {
  editionNumber = 1;
  table2Version = 2;
  # Offenbach  (RSMC)  (grib1/0.table)
  centre = 78;
  generatingProcessIdentifier = 207;
  # U U-component of wind m s**-1 (grib1/2.0.2.table)
  indicatorOfParameter = 33;
  # Fixed height above ground height in meters  (2 octets)  (grib1/3.table)

  indicatorOfTypeOfLevel = 105;
  level = 10;
  # Initialized analysis product for reference time  (P1=0)
 (grib1/5.table)
  timeRangeIndicator = 1;
  # Unknown code table entry ()
  subCentre = 255;
  paramId = 165;
  #-READ ONLY- units = m s**-1;
  #-READ ONLY- nameECMF = 10 metre U wind component;
  #-READ ONLY- name = 10 metre U wind component;
  decimalScaleFactor = 0;
  dataDate = 20120630;
  dataTime = 0;
  # Hour (stepUnits.table)
  stepUnits = 1;
  stepRange = 0;
  startStep = 0;
  endStep = 0;
  #-READ ONLY- marsParam = 33.2;
  shortName = 10u;
  GDSPresent = 1;
  bitmapPresent = 1;
  numberOfVerticalCoordinateValues = 0;
  Ni = 201;
  Nj = 161;
  latitudeOfFirstGridPointInDegrees = 35;
  longitudeOfFirstGridPointInDegrees = -10;
  earthIsOblate = 0;
  uvRelativeToGrid = 0;
  latitudeOfLastGridPointInDegrees = 74.96;
  longitudeOfLastGridPointInDegrees = 40.04;
  iScansNegatively = 0;
  jScansPositively = 1;
  jPointsAreConsecutive = 0;
  #-READ ONLY- alternativeRowScanning = 0;
  jDirectionIncrementInDegrees = 0.24975;
  iDirectionIncrementInDegrees = 0.2502;
  #-READ ONLY- numberOfDataPoints = 32361;
  #-READ ONLY- numberOfValues = 32361;
  missingValue = 9999;
  tableReference = 0;
  #-READ ONLY- binaryScaleFactor = -11;
  #-READ ONLY- referenceValue = -11.346;
  sphericalHarmonics = 0;
  complexPacking = 0;
  integerPointValues = 0;
  additionalFlagPresent = 0;
  packingType = grid_simple;
  bitsPerValue = 16;
  values(32361) =  {
  1.5509548187e+00, 1.4977321625e+00, 1.5494899750e+00, 1.6993923187e+00,
1.9513454437e+00,
  2.2316188812e+00, 2.5079860687e+00, 2.7740993500e+00, 3.0099391937e+00,
3.2716579437e+00,
  3.5905056000e+00, 3.9567165375e+00, 4.3610134125e+00, 4.6178493500e+00,
4.2081813812e+00,
  1.7648220062e+00, 1.5626735687e+00, 1.2032985687e+00, 6.4226341248e-01,
4.3620872498e-01,
  6.7986106873e-01, -9.1135025024e-02, 8.1716537476e-02, 2.3650169373e-01,
5.7488059998e-01,
  8.7077903748e-01, 3.6931419373e-01, -2.2541236877e-01, -7.8439712524e-02,
-6.3312721252e-01,
  -7.3127174377e-01, -3.0500221252e-01, 4.7087669373e-01, 8.9812278748e-01,
7.7019309998e-01,
  6.2175559998e-01, 7.5798606873e-01, 6.8425559998e-01, 9.6941184998e-01,
1.1735134125e+00,
  7.9851341248e-01, 2.5163841248e-01, -6.4386940002e-01, -1.0427951813e+00,
-9.9543190002e-01,
  -2.3191623688e+00, -1.5120334625e+00, 5.5388450623e-01, 1.7501735687e+00,
1.6022243500e+00,
  -1.3963108063e+00, -2.5066623688e+00, -2.1536350250e+00,
-2.0496311188e+00, -1.8875217438e+00,
  -1.5056858063e+00, -7.7424049377e-01, -8.3283424377e-01,
-9.7248268127e-01, -6.6681861877e-01,
  -1.1380100250e+00, -2.5716037750e+00, -3.6634006500e+00,
-3.5447483063e+00, -2.6272678375e+00,
  -1.4226779938e+00, -9.0168190002e-01, -8.6750221252e-01,
-1.0720920563e+00, -1.6135959625e+00,
  -1.5720920563e+00, -1.0823459625e+00, -9.9201393127e-01,
-5.9504127502e-01, -7.6105690002e-01,
  -1.1116428375e+00, -7.0002174377e-01, -2.5861549377e-01,
-2.4201393127e-01, 2.2673606873e-01,
  5.2907943726e-02, -4.4318580627e-01, -6.2287330627e-01,
-6.9855690002e-01, -7.3615455627e-01,
  -1.9607639313e+00, -2.2805881500e+00, -2.2483615875e+00,
-2.0520725250e+00, -1.8782444000e+00,
  -1.7024631500e+00, -1.4602756500e+00, -1.1492404938e+00,
-8.0695533752e-01, -4.1486549377e-01,
  4.3142318726e-02, 5.3532981873e-01, 9.9675559998e-01, 1.4259548187e+00,
1.8199977875e+00
  ... 32261 more values
  }
  #-READ ONLY- numberOfCodedValues = 32361;
  #-READ ONLY- maximum = 13.5881;
  #-READ ONLY- minimum = -11.346;
  #-READ ONLY- average = 0.101585;
  #-READ ONLY- numberOfMissing = 0;
  #-READ ONLY- standardDeviation = 3.29306;
  #-READ ONLY- skewness = -29313.5;
  #-READ ONLY- kurtosis = 1.62527e+07;
  #-READ ONLY- isConstant = 0;
  gridType = regular_ll;
  #-READ ONLY- getNumberOfValues = 32361;

[...]

So it looks like the information is actually there, but the gdal driver
can't handle it. Any hint?

Thanks,

Margherita

[1] http://www.ecmwf.int/products/data/software/grib_api.html

On Thu, Aug 23, 2012 at 8:53 AM, Margherita Di Leo <diregola at gmail.com>wrote:

> Hi all,
>
> I have a problem handling some grib files, I get a warning message and I
> can't understand how to deal with it..
>
> running gdalinfo, it says:
>
> Un-handled possible ensemble section center 78 subcenter 255
> [... several times, cut]
> Un-handled possible ensemble section center 78 subcenter 255
> Driver: GRIB/GRIdded Binary (.grb)
> Files:
> /home/leomarg/Desktop/Fire_event_test_case_Valencia/grib/dwd_grib1_ispra_gmi202_
> 2012063000
> Size is 201, 161
> Coordinate System is:
> GEOGCS["Coordinate System imported from GRIB file",
>     DATUM["unknown",
>         SPHEROID["Sphere",6367470,0]],
>     PRIMEM["Greenwich",0],
>     UNIT["degree",0.0174532925199433]]
> Origin = (-10.000000000000000,74.960000000000008)
> Pixel Size = (0.000000000000000,-0.000000000000000)
> Corner Coordinates:
> Upper Left  ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> Lower Left  ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> Upper Right ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> Lower Right ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> Center      ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> Band 1 Block=201x1 Type=Float64, ColorInterp=Undefined
>   Description = 10[m] HTGL (Specified height level above ground)
>   Metadata:
>     GRIB_COMMENT=u-component (zonal) of wind [m/s]
>     GRIB_ELEMENT=U
>     GRIB_FORECAST_SECONDS=0 sec
>     GRIB_REF_TIME=  1341014400 sec UTC
>     GRIB_SHORT_NAME=10-HTGL
>     GRIB_UNIT=[m/s]
>     GRIB_VALID_TIME=  1341014400 sec UTC
> Band 2 Block=201x1 Type=Float64, ColorInterp=Undefined
>   Description = 10[m] HTGL (Specified height level above ground)
>   Metadata:
>     GRIB_COMMENT=v-component (merdional) of wind [m/s]
>     GRIB_ELEMENT=V
>     GRIB_FORECAST_SECONDS=0 sec
>     GRIB_REF_TIME=  1341014400 sec UTC
>     GRIB_SHORT_NAME=10-HTGL
>     GRIB_UNIT=[m/s]
>     GRIB_VALID_TIME=  1341014400 sec UTC
>
> [...]
>
> Furthermore, when I try with gdal_translate to convert one of the bands in
> tif format, the size of the pixels created is 0x0.
>
> Thanks in advance for any hint.
>
> --
> Dr. Margherita Di Leo
>



-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120823/11da436a/attachment-0001.html>

From even.rouault at mines-paris.org  Thu Aug 23 11:36:26 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 23 Aug 2012 20:36:26 +0200
Subject: [gdal-dev] can't handle grib file
In-Reply-To: <CABa=8QowT0nMqWaHjLXVqBYGovL-gG=HP4_-fptMnzOwpHue_g@mail.gmail.com>
References: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>
	<CABa=8QowT0nMqWaHjLXVqBYGovL-gG=HP4_-fptMnzOwpHue_g@mail.gmail.com>
Message-ID: <201208232036.27009.even.rouault@mines-paris.org>


> So it looks like the information is actually there, but the gdal driver
> can't handle it. Any hint?

Margherita,

There's a possibility that your data file is of a type that isn't understood by 
the underlying library that GDAL uses to decode GRIB files. Or perhaps GDAL 
isn't using it correctly with that particular file. Difficult to know.

GDAL uses the g2clib library (v1.0.4), that has evolved ( 
http://www.nco.ncep.noaa.gov/pmb/docs/grib2/download/g2clib.changes ) since it 
was integrated in GDAL. So perhaps a newer version of it better supports your 
data file. (but merging a newer version to GDAL might be non trivial, since a 
lot of fixes were done in GDAL copy (to address cross-platform portability, 
etc..)).

> 
> Thanks,
> 
> Margherita
> 
> [1] http://www.ecmwf.int/products/data/software/grib_api.html
> 
> On Thu, Aug 23, 2012 at 8:53 AM, Margherita Di Leo 
<diregola at gmail.com>wrote:
> > Hi all,
> > 
> > I have a problem handling some grib files, I get a warning message and I
> > can't understand how to deal with it..
> > 
> > running gdalinfo, it says:
> > 
> > Un-handled possible ensemble section center 78 subcenter 255
> > [... several times, cut]
> > Un-handled possible ensemble section center 78 subcenter 255
> > Driver: GRIB/GRIdded Binary (.grb)
> > Files:
> > /home/leomarg/Desktop/Fire_event_test_case_Valencia/grib/dwd_grib1_ispra_
> > gmi202_ 2012063000
> > Size is 201, 161
> > Coordinate System is:
> > GEOGCS["Coordinate System imported from GRIB file",
> > 
> >     DATUM["unknown",
> >     
> >         SPHEROID["Sphere",6367470,0]],
> >     
> >     PRIMEM["Greenwich",0],
> >     UNIT["degree",0.0174532925199433]]
> > 
> > Origin = (-10.000000000000000,74.960000000000008)
> > Pixel Size = (0.000000000000000,-0.000000000000000)
> > Corner Coordinates:
> > Upper Left  ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> > Lower Left  ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> > Upper Right ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> > Lower Right ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> > Center      ( -10.0000000,  74.9600000) ( 10d 0' 0.00"W, 74d57'36.00"N)
> > Band 1 Block=201x1 Type=Float64, ColorInterp=Undefined
> > 
> >   Description = 10[m] HTGL (Specified height level above ground)
> >   
> >   Metadata:
> >     GRIB_COMMENT=u-component (zonal) of wind [m/s]
> >     GRIB_ELEMENT=U
> >     GRIB_FORECAST_SECONDS=0 sec
> >     GRIB_REF_TIME=  1341014400 sec UTC
> >     GRIB_SHORT_NAME=10-HTGL
> >     GRIB_UNIT=[m/s]
> >     GRIB_VALID_TIME=  1341014400 sec UTC
> > 
> > Band 2 Block=201x1 Type=Float64, ColorInterp=Undefined
> > 
> >   Description = 10[m] HTGL (Specified height level above ground)
> >   
> >   Metadata:
> >     GRIB_COMMENT=v-component (merdional) of wind [m/s]
> >     GRIB_ELEMENT=V
> >     GRIB_FORECAST_SECONDS=0 sec
> >     GRIB_REF_TIME=  1341014400 sec UTC
> >     GRIB_SHORT_NAME=10-HTGL
> >     GRIB_UNIT=[m/s]
> >     GRIB_VALID_TIME=  1341014400 sec UTC
> > 
> > [...]
> > 
> > Furthermore, when I try with gdal_translate to convert one of the bands
> > in tif format, the size of the pixels created is 0x0.
> > 
> > Thanks in advance for any hint.
> > 
> > --
> > Dr. Margherita Di Leo

From peter.mallen at airborne.aero  Thu Aug 23 11:27:12 2012
From: peter.mallen at airborne.aero (Peter Mallen)
Date: Thu, 23 Aug 2012 14:27:12 -0400
Subject: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile
Message-ID: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>

Hi Everyone,

 

I am attempting to convert data from a .dat file (X-Plane data) into
shapefiles.  Below is the ogr2ogr command I found online, but this
always gives errors:

 

ogr2ogr apt_shapes apt.dat

 

If anyone has any experience or tips on how to correctly do this I would
really appreciate it.

 

 

Thank You,

 

 

Peter Mallen

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120823/11ee74ee/attachment.html>

From kyle at pobox.com  Thu Aug 23 11:40:11 2012
From: kyle at pobox.com (Kyle Shannon)
Date: Thu, 23 Aug 2012 12:40:11 -0600
Subject: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile
In-Reply-To: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
References: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
Message-ID: <CAJ0mEz3mzABKaXSKPiAoPAQTpEOs59kLjLdcFZm8GVLZtXxssg@mail.gmail.com>

What are the errors?

On Thu, Aug 23, 2012 at 12:27 PM, Peter Mallen
<peter.mallen at airborne.aero>wrote:

> Hi Everyone,****
>
> ** **
>
> I am attempting to convert data from a .dat file (X-Plane data) into
> shapefiles.  Below is the ogr2ogr command I found online, but this always
> gives errors:****
>
> ** **
>
> ogr2ogr apt_shapes apt.dat****
>
> ** **
>
> If anyone has any experience or tips on how to correctly do this I would
> really appreciate it.****
>
> ** **
>
> ** **
>
> Thank You,****
>
> ** **
>
> ** **
>
> Peter Mallen****
>
> ** **
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120823/d6e06c9c/attachment.html>

From even.rouault at mines-paris.org  Thu Aug 23 11:47:16 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 23 Aug 2012 20:47:16 +0200
Subject: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile
In-Reply-To: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
References: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
Message-ID: <201208232047.16804.even.rouault@mines-paris.org>

Le jeudi 23 ao?t 2012 20:27:12, Peter Mallen a ?crit :
> Hi Everyone,
> 
> I am attempting to convert data from a .dat file (X-Plane data) into
> shapefiles.  Below is the ogr2ogr command I found online, but this
> always gives errors:
> 
> ogr2ogr apt_shapes apt.dat
> 
> If anyone has any experience or tips on how to correctly do this I would
> really appreciate it.

Peter,

I've just tried with 
http://dev.x-plane.com/update/data/AptNav201208XP900.zip

(with GDAL 1.9.0)

$ ogr2ogr apt_shapes apt.dat

Warning 1: organizePolygons() received a polygon with more than 100 parts. The 
processing may be really slow.
You can skip the processing by setting METHOD=SKIP, or only make it analyze 
counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the 
outline of holes is counter-clock wise defined
Warning 6: Normalized/laundered field name: 'elevation_m' to 'elevation_'
Warning 6: Normalized/laundered field name: 'hgt_tower_m' to 'hgt_tower_'
Warning 6: Normalized/laundered field name: 'centerline_lights' to 'centerline'
Warning 6: Normalized/laundered field name: 'edge_lighting' to 'edge_light'
Warning 6: Normalized/laundered field name: 'distance_remaining_signs' to 
'distance_r'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 1: Value '2800' of field width_m has been truncated to 3 characters.
This warning will not be emitted any more for that layer.
Warning 6: Normalized/laundered field name: 'centerline_lights' to 'centerline'
Warning 6: Normalized/laundered field name: 'edge_lighting' to 'edge_light'
Warning 6: Normalized/laundered field name: 'distance_remaining_signs' to 
'distance_r'
Warning 6: Normalized/laundered field name: 'displaced_threshold_m' to 
'displaced_'
Warning 6: Normalized/laundered field name: 'is_displaced' to 'is_displac'
Warning 6: Normalized/laundered field name: 'stopway_length_m' to 'stopway_le'
Warning 6: Normalized/laundered field name: 'approach_lighting' to 'approach_l'
Warning 6: Normalized/laundered field name: 'touchdown_lights' to 'touchdown_'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 1: Value '1037' of field displaced_ has been truncated to 3 characters.
This warning will not be emitted any more for that layer.
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 1: Value '-1' of field has_buoys has been truncated to 1 characters.
This warning will not be emitted any more for that layer.
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 1: Value '-1' of field has_buoys has been truncated to 1 characters.
This warning will not be emitted any more for that layer.
Warning 6: Normalized/laundered field name: 'helipad_name' to 'helipad_na'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 6: Normalized/laundered field name: 'edge_lighting' to 'edge_light'
Warning 6: Normalized/laundered field name: 'helipad_name' to 'helipad_na'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 6: Normalized/laundered field name: 'edge_lighting' to 'edge_light'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 6: Normalized/laundered field name: 'edge_lighting' to 'edge_light'
Warning 1: Value '1090' of field width_m has been truncated to 3 characters.
This warning will not be emitted any more for that layer.
Warning 6: Normalized/laundered field name: 'texture_heading' to 'texture_he'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 6: Normalized/laundered field name: 'is_illuminated' to 'is_illumin'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 6: Normalized/laundered field name: 'true_heading_deg' to 'true_headi'
Warning 6: Normalized/laundered field name: 'visual_glide_deg' to 'visual_gli'
Warning 1: Value 'VASI' of field rwy_num has been truncated to 3 characters.
This warning will not be emitted any more for that layer.

A bit verbose, but nothing to really worry about. They are just warnings, not 
errors.

And the result in a viewer looks right.

From peter.mallen at airborne.aero  Thu Aug 23 11:57:19 2012
From: peter.mallen at airborne.aero (Peter Mallen)
Date: Thu, 23 Aug 2012 14:57:19 -0400
Subject: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile
In-Reply-To: <CAJ0mEz3mzABKaXSKPiAoPAQTpEOs59kLjLdcFZm8GVLZtXxssg@mail.gmail.com>
References: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
	<CAJ0mEz3mzABKaXSKPiAoPAQTpEOs59kLjLdcFZm8GVLZtXxssg@mail.gmail.com>
Message-ID: <0342A56AD728D64185DB36D9514E2E7ED8CBDF@BE64.exg3.exghost.com>

Hi Klye,

 

The errors received are below:

 

FAILURE:

Unable to open datasource '\APTNav201107XP900\apt.dat' with the
following drivers.

 

-> ESRI Shapefile 

  -> MapInfo File 

  -> UK .NTF 

  -> SDTS 

  -> TIGER 

  -> S57 

  -> DGN 

  -> VRT 

  -> REC 

  -> Memory 

  -> BNA 

  -> CSV 

  -> GML 

  -> GPX 

  -> KML 

  -> GeoJSON 

  -> GMT 

  -> SQLite 

  -> PCIDSK 

  -> XPlane 

  -> AVCBin 

  -> AVCE00 

  -> DXF 

  -> Geoconcept 

  -> GeoRSS 

  -> GPSTrackMaker 

  -> VFK

 

From: Kyle Shannon [mailto:kyle at pobox.com] 
Sent: Thursday, August 23, 2012 11:40 AM
To: Peter Mallen
Cc: gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile

 

What are the errors?

On Thu, Aug 23, 2012 at 12:27 PM, Peter Mallen
<peter.mallen at airborne.aero> wrote:

Hi Everyone,

 

I am attempting to convert data from a .dat file (X-Plane data) into
shapefiles.  Below is the ogr2ogr command I found online, but this
always gives errors:

 

ogr2ogr apt_shapes apt.dat

 

If anyone has any experience or tips on how to correctly do this I would
really appreciate it.

 

 

Thank You,

 

 

Peter Mallen

 


_______________________________________________
gdal-dev mailing list
gdal-dev at lists.osgeo.org
http://lists.osgeo.org/mailman/listinfo/gdal-dev

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120823/643e293d/attachment-0001.html>

From even.rouault at mines-paris.org  Thu Aug 23 12:00:27 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 23 Aug 2012 21:00:27 +0200
Subject: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile
In-Reply-To: <0342A56AD728D64185DB36D9514E2E7ED8CBDF@BE64.exg3.exghost.com>
References: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
	<CAJ0mEz3mzABKaXSKPiAoPAQTpEOs59kLjLdcFZm8GVLZtXxssg@mail.gmail.com>
	<0342A56AD728D64185DB36D9514E2E7ED8CBDF@BE64.exg3.exghost.com>
Message-ID: <201208232100.27526.even.rouault@mines-paris.org>

Le jeudi 23 ao?t 2012 20:57:19, Peter Mallen a ?crit :
> Hi Klye,
> 
> 
> 
> The errors received are below:
> 
> 
> 
> FAILURE:
> 
> Unable to open datasource '\APTNav201107XP900\apt.dat' with the
> following drivers.

Ah, this is just that the input filename is likely incorrect. Perhaps try 
removing the leading anti-slash, or if the APTNav201107XP900 directory is just 
at the root of the C drive,
use "c:\APTNav201107XP900\apt.dat" instead.

From peter.mallen at airborne.aero  Thu Aug 23 12:15:50 2012
From: peter.mallen at airborne.aero (Peter Mallen)
Date: Thu, 23 Aug 2012 15:15:50 -0400
Subject: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile
In-Reply-To: <201208232100.27526.even.rouault@mines-paris.org>
References: <0342A56AD728D64185DB36D9514E2E7ED8CBB4@BE64.exg3.exghost.com>
	<CAJ0mEz3mzABKaXSKPiAoPAQTpEOs59kLjLdcFZm8GVLZtXxssg@mail.gmail.com>
	<0342A56AD728D64185DB36D9514E2E7ED8CBDF@BE64.exg3.exghost.com>
	<201208232100.27526.even.rouault@mines-paris.org>
Message-ID: <0342A56AD728D64185DB36D9514E2E7ED8CBF4@BE64.exg3.exghost.com>

I tried removing the leading anti-slash as well as adding "c:" to the path and the same error message was received for both instances.

I was able to convert the other.dat files from the downloaded data to shapefiles but for some reason the apt.dat file is not working.



-----Original Message-----
From: Even Rouault [mailto:even.rouault at mines-paris.org] 
Sent: Thursday, August 23, 2012 12:00 PM
To: gdal-dev at lists.osgeo.org
Cc: Peter Mallen; Kyle Shannon
Subject: Re: [gdal-dev] Converting a .dat(X-Plane) file to a shapefile

Le jeudi 23 ao?t 2012 20:57:19, Peter Mallen a ?crit :
> Hi Klye,
> 
> 
> 
> The errors received are below:
> 
> 
> 
> FAILURE:
> 
> Unable to open datasource '\APTNav201107XP900\apt.dat' with the 
> following drivers.

Ah, this is just that the input filename is likely incorrect. Perhaps try removing the leading anti-slash, or if the APTNav201107XP900 directory is just at the root of the C drive, use "c:\APTNav201107XP900\apt.dat" instead.

From sfkeller at gmail.com  Thu Aug 23 22:24:29 2012
From: sfkeller at gmail.com (Stefan Keller)
Date: Fri, 24 Aug 2012 07:24:29 +0200
Subject: [gdal-dev] FWTools outdated on GDAL/OGR download page
Message-ID: <CAFcOn2_XkQ8ZZXg0jPEKECDvX_p9HoJF3-CN5nvyUE=_VnrowQ@mail.gmail.com>

Hi,

The FWTools mentioned on the bottom of the download page of GDAL/OGR
Binaries [1] leads to releases where the latest build dates back to
2007.

I think there should be a note that FWTools are outdated and not
maintained any more - unless I'm wrong.

Yours, S.

[1] http://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries
[2] http://fwtools.maptools.org/

From oliver.christen at camptocamp.com  Thu Aug 23 23:09:26 2012
From: oliver.christen at camptocamp.com (Oliver Christen)
Date: Fri, 24 Aug 2012 08:09:26 +0200
Subject: [gdal-dev] problem with CloseRings
In-Reply-To: <CAFcOn2_XkQ8ZZXg0jPEKECDvX_p9HoJF3-CN5nvyUE=_VnrowQ@mail.gmail.com>
References: <CAFcOn2_XkQ8ZZXg0jPEKECDvX_p9HoJF3-CN5nvyUE=_VnrowQ@mail.gmail.com>
Message-ID: <50371A96.8030708@camptocamp.com>

Thank you Frank, Doug, Chaitanya

I effectively didnt notice the "degenerate" state of the ring :(
Now I understand why CloseRings didnt help in some cases.
It seems I will have to toy a bit with the geometries.

thanks again
best regards
Oliver


 > Doug,
 >
 > You could rebuild individual polygons by attempting to close the
 > constituent rings one-by-one while discarding those that give an 
error with
 > the CloseRings() method.
 >
 > On Wed, Aug 22, 2012 at 10:41 PM, <Doug_Newcomb at fws.gov> wrote:
 >
 > >
 > > Oliver,
 > >
 > > Would it just be a matter of counting the vertices of each polygon,
 > > selecting the polygons with 3 vertices, and comparing the value of the
 > > first and last vertex  as you are building wkt value string below?
 > >
 > >
 > > Doug
 > >
 > >
 > >
 > > >The problem with your rings isn't that they are not closed, it is that
 > > >they are degenerate.
 > >
 > > >For instance:
 > > >(559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)
 > >
 > > >This goes from PointA to PointB back to PointA.  It is closed, it just
 > > >is degenerate.  It has no area.  I'm not aware of a super easy way of
 > > >cleaning out such junk rings - you might need to explicitly test them
 > > >and remove them if they are degenerate.
 > >
 > > >Best regards,
 > >
 > >
 > >
 > >
 > > Doug Newcomb
 > > USFWS
 > > Raleigh, NC
 > > 919-856-4520 ext. 14 doug_newcomb at fws.gov
 > >
 > > 
---------------------------------------------------------------------------------------------------------
 > > The opinions I express are my own and are not representative of the
 > > official policy of the U.S.Fish and Wildlife Service or Dept. of the
 > > Interior.   Life is too short for undocumented, proprietary data 
formats.
 > >
 > >
 > >  *Frank Warmerdam <warmerdam at pobox.com>*
 > > Sent by: gdal-dev-bounces at lists.osgeo.org
 > >
 > > 08/22/2012 12:49 PM
 > >   To
 > > Oliver Christen <oliver.christen at camptocamp.com>
 > > cc
 > > gdal-dev at lists.osgeo.org
 > > Subject
 > > Re: [gdal-dev] problem with CloseRings
 > >
 > >
 > >
 > >
 > > Oliver,
 > >
 > > The problem with your rings isn't that they are not closed, it is that
 > > they are degenerate.
 > >
 > > For instance:
 > > (559560.19 142169.94,559550.64 142173.43,559560.19 142169.94)
 > >
 > > This goes from PointA to PointB back to PointA.  It is closed, it just
 > > is degenerate.  It has no area.  I'm not aware of a super easy way of
 > > cleaning out such junk rings - you might need to explicitly test them
 > > and remove them if they are degenerate.
 > >
 > > Best regards,
 > >
 > > On Wed, Aug 22, 2012 at 9:13 AM, Oliver Christen
 > > <oliver.christen at camptocamp.com> wrote:
 > > > dear community
 > > >
 > > > first of all please accept my apologies if this is not the correct
 > > > place to ask about such question.
 > > >
 > > > I am trying to manipulate some geometric data using the gdal/ogr
 > > > python lib and Im facing a problem when trying to transform invalid
 > > > ring into valid ring.
 > > >
 > > > I have polygons with unclosed holes and I expected the CloseRings
 > > > function to solve this for me, but unfortunately, that functions
 > > > doesnt seem to do anything (in my case).
 > > >
 > > > see below for a simply python testcase,
 > > >
 > > > if you could tell me if I am possibly not using that function
 > > > correctly or if there is a more correct way to do that, you would be
 > > > very welcome
 > > >
 > > > using python version 2.6.6
 > > > osgeo ogr lib version 1.3.40
 > > >
 > > > thank you very much for your attention
 > > > best regards
 > > > Oliver
 > > >
 > > > from osgeo import ogr
 > > >
 > > > wkt = "POLYGON ((559577.81 142165.04,559577.67 142161.79,559577.66
 > > > 142161.16,559577.18 142139.0,559564.07 142140.84,559562.99
 > > > 142132.4,559556.42 142134.85,559556.47 142134.96,559541.39
 > > > 142140.58,559549.54 142162.4,559547.0200406529475
 > > > 142163.310114102292573,559550.570425555342808
 > > > 142173.455536680703517,559577.81 142165.04),(559559.95600777247455
 > > > 142169.280249390256358,559550.996165407239459
 > > > 142172.552877245907439,559550.996165407355875
 > > > 142172.552877245907439,559547.909677243907936
 > > > 142163.733065433305455,559550.443360350676812
 > > > 142162.817994827404618,559542.290859716595151
 > > > 142140.991299878398422,559557.417905980604701
 > > > 142135.353766721702414,559557.367843619547784
 > > > 142135.243629527511075,559562.407678314950317
 > > > 142133.364239115995588,559563.465598454349674
 > > > 142141.631689094298054,559576.497222575126216
 > > > 142139.80268921770039,559576.960120304953307
 > > > 142161.173134415294044,559576.970239149406552
 > > > 142161.810621617711149,559577.084823867655359
 > > > 142164.470624003995908,559577.084823867655359
 > > > 142164.470624004025012,559570.876975534367375
 > > > 142165.896950183814624,559564.754505693446845
 > > > 142167.653979024267755,559564.75450569356326
 > > > 142167.653979024296859,559559.956007772590965
 > > > 142169.280249390256358,559559.95600777247455
 > > > 142169.280249390256358),(559560.19 142169.94,559550.64
 > > > 142173.43,559560.19 142169.94),(559564.97 142168.32,559560.19
 > > > 142169.94,559564.97 142168.32),(559577.810000000172295
 > > > 142165.04,559571.34395208011847 142166.499739240010967,559564.97
 > > > 142168.32,559577.810000000172295 142165.04))"
 > > >
 > > > poly = ogr.CreateGeometryFromWkt(wkt)
 > > >
 > > > poly.IsValid()
 > > > ERROR 1: IllegalArgumentException: Invalid number of points in
 > > > LinearRing found 3 - must be 0 or >= 4
 > > > False
 > > >
 > > > poly.CloseRings()
 > > >
 > > > poly.IsValid()
 > > > ERROR 1: IllegalArgumentException: Invalid number of points in
 > > > LinearRing found 3 - must be 0 or >= 4
 > > > False
 > > > _______________________________________________
 > > > gdal-dev mailing list
 > > > gdal-dev at lists.osgeo.org
 > > > http://lists.osgeo.org/mailman/listinfo/gdal-dev
 > >
 > >
 > >
 > > --
 > >
 > > 
---------------------------------------+--------------------------------------
 > > I set the clouds in motion - turn up   | Frank Warmerdam,
 > > warmerdam at pobox.com
 > > light and sound - activate the windows |
 > > <http://lists.osgeo.org/mailman/listinfo/gdal-dev>
 > > http://pobox.com/~warmerdam
 > > and watch the world go round - Rush    | Geospatial Software Developer
 > > _______________________________________________
 > > gdal-dev mailing list
 > > gdal-dev at lists.osgeo.org
 > >  <http://pobox.com/%7Ewarmerdam>
 > > http://lists.osgeo.org/mailman/listinfo/gdal-dev
 > >
 > >
 > > _______________________________________________
 > > gdal-dev mailing list
 > > gdal-dev at lists.osgeo.org
 > > http://lists.osgeo.org/mailman/listinfo/gdal-dev
 > >
 >
 >
 >
 > --
 > Best regards,
 > Chaitanya kumar CH.
 >
 > +91-9494447584
 > 17.2416N 80.1426E

From diregola at gmail.com  Fri Aug 24 00:05:05 2012
From: diregola at gmail.com (Margherita Di Leo)
Date: Fri, 24 Aug 2012 09:05:05 +0200
Subject: [gdal-dev] can't handle grib file
In-Reply-To: <201208232036.27009.even.rouault@mines-paris.org>
References: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>
	<CABa=8QowT0nMqWaHjLXVqBYGovL-gG=HP4_-fptMnzOwpHue_g@mail.gmail.com>
	<201208232036.27009.even.rouault@mines-paris.org>
Message-ID: <CABa=8Qqz=nOUZM8KtyvCRuh-Fw4HhbESQ-C8H=AowzxUVyoKPA@mail.gmail.com>

Even,

On Thu, Aug 23, 2012 at 8:36 PM, Even Rouault
<even.rouault at mines-paris.org>wrote:

>
> > So it looks like the information is actually there, but the gdal driver
> > can't handle it. Any hint?
>
> Margherita,
>
> There's a possibility that your data file is of a type that isn't
> understood by
> the underlying library that GDAL uses to decode GRIB files. Or perhaps GDAL
> isn't using it correctly with that particular file. Difficult to know.
>
> GDAL uses the g2clib library (v1.0.4), that has evolved (
> http://www.nco.ncep.noaa.gov/pmb/docs/grib2/download/g2clib.changes )
> since it
> was integrated in GDAL. So perhaps a newer version of it better supports
> your
> data file. (but merging a newer version to GDAL might be non trivial,
> since a
> lot of fixes were done in GDAL copy (to address cross-platform portability,
> etc..)).
>
> Thank you for your hints. I understand that grib is a pretty much flexible
type of file and in some cases flexibility is difficult to handle. If you
devs think it's worthy, I'd file a ticket about it and I can send you the
grib file if you wish to make tests on it. Please let me know.

Thanks,

-- 
Dr. Margherita Di Leo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120824/7e538aaf/attachment.html>

From jrepetto at free.fr  Fri Aug 24 00:32:28 2012
From: jrepetto at free.fr (Jean-Claude Repetto)
Date: Fri, 24 Aug 2012 09:32:28 +0200
Subject: [gdal-dev] FWTools outdated on GDAL/OGR download page
In-Reply-To: <CAFcOn2_XkQ8ZZXg0jPEKECDvX_p9HoJF3-CN5nvyUE=_VnrowQ@mail.gmail.com>
References: <CAFcOn2_XkQ8ZZXg0jPEKECDvX_p9HoJF3-CN5nvyUE=_VnrowQ@mail.gmail.com>
Message-ID: <50372E0C.40805@free.fr>

Le 24/08/2012 07:24, Stefan Keller a ?crit :
> Hi,
>
> The FWTools mentioned on the bottom of the download page of GDAL/OGR
> Binaries [1] leads to releases where the latest build dates back to
> 2007.
>
> I think there should be a note that FWTools are outdated and not
> maintained any more - unless I'm wrong.

Hi,

There is already a note :

The latest FWtools version for Windows, 2.4.7, dates back to a pre-1.6 
GDAL version. In order to benefit from the latest and greatest, you can 
refer to the other binary builds mentionned above.

Jean-Claude

From Jukka.Rahkonen at mmmtike.fi  Fri Aug 24 04:12:37 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Fri, 24 Aug 2012 11:12:37 +0000
Subject: [gdal-dev] About sqlite tileindex and Mapserver
Message-ID: <84446DEF76453C439E9E97E438E13A63467A01@suutari.haapa.mmm.fi>

Hi,

There is a trick with using Spatialite tileindex with Mapserver. I have no idea anymore how I came to this solution but most probably I was reading something about it from the internet.

Try odd trick is that you cannot user Spatialite directly as tileindex but you must first create a LAYER from Spatialite and use that as tileindex. Let's take an example.  In the following  "z:\tindex\aerial_images.sqlite" is the Spatialite db and tile locations are in the table "aerial_images"

LAYER
        NAME "sqlite_tileindex"
        STATUS OFF
        TYPE POLYGON
        CONNECTIONTYPE OGR
        CONNECTION "z:\tindex\aerial_images.sqlite"
        DATA "aerial_images"
    END

Now for the real aerial image layer the tileindex is read from the LAYER that was just created

LAYER
        NAME "aerial_imagery"
        STATUS ON
        TILEINDEX "sqlite_tileindex"


-Jukka Rahkonen-

From Michael.Smith at erdc.dren.mil  Fri Aug 24 04:22:20 2012
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Fri, 24 Aug 2012 11:22:20 +0000
Subject: [gdal-dev] About sqlite tileindex and Mapserver
In-Reply-To: <84446DEF76453C439E9E97E438E13A63467A01@suutari.haapa.mmm.fi>
Message-ID: <CC5CDBE9.3440A%michael.smith@erdc.dren.mil>

Jukka,

Perhaps you can document this on the Wiki as a Spatialite example in
addition to the example for Oracle
(https://github.com/mapserver/mapserver/wiki/MapServer-TILEINDEXes-with-Dat
abase-RASTERS)

Mike

-- 
Michael Smith

US Army Corps
Remote Sensing GIS/Center



On 8/24/12 7:12 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi> wrote:

>Hi,
>
>There is a trick with using Spatialite tileindex with Mapserver. I have
>no idea anymore how I came to this solution but most probably I was
>reading something about it from the internet.
>
>Try odd trick is that you cannot user Spatialite directly as tileindex
>but you must first create a LAYER from Spatialite and use that as
>tileindex. Let's take an example.  In the following
>"z:\tindex\aerial_images.sqlite" is the Spatialite db and tile locations
>are in the table "aerial_images"
>
>LAYER
>        NAME "sqlite_tileindex"
>        STATUS OFF
>        TYPE POLYGON
>        CONNECTIONTYPE OGR
>        CONNECTION "z:\tindex\aerial_images.sqlite"
>        DATA "aerial_images"
>    END
>
>Now for the real aerial image layer the tileindex is read from the LAYER
>that was just created
>
>LAYER
>        NAME "aerial_imagery"
>        STATUS ON
>        TILEINDEX "sqlite_tileindex"
>
>
>-Jukka Rahkonen-
>_______________________________________________
>gdal-dev mailing list
>gdal-dev at lists.osgeo.org
>http://lists.osgeo.org/mailman/listinfo/gdal-dev


From Jukka.Rahkonen at mmmtike.fi  Fri Aug 24 04:34:14 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Fri, 24 Aug 2012 11:34:14 +0000
Subject: [gdal-dev] About sqlite tileindex and Mapserver
Message-ID: <84446DEF76453C439E9E97E438E13A63467A2F@suutari.haapa.mmm.fi>

Hi,

It is documented in http://mapserver.org/mapfile/layer.html .  
TILEINDEX [filename|layername]

    Name of the tileindex file or layer. A tileindex is similar to an ArcInfo library index. The tileindex contains polygon features for each tile. The item that contains the location of the tiled data is given using the TILEITEM parameter. When a file is used as the tileindex for shapefile or raster layers, the tileindex should be a shapefile. For CONNECTIONTYPE OGR layers, any OGR supported datasource can be a tileindex. Normally the location should contain the path to the tile file relative to the shapepath, not relative to the tileindex itself. If the DATA parameter contains a value then it is added to the end of the location. When a tileindex layer is used, it works similarly to directly referring to a file, but any supported feature source can be used (ie. postgres, oracle).

Perhaps this tileindex section could have direct links to some tileindex layer examples rather than having them only in wiki?

-Jukka Rahkonen-

Smith, Michael wrote:
 
> Jukka,
> 
> Perhaps you can document this on the Wiki as a Spatialite example in
> addition to the example for Oracle
> (https://github.com/mapserver/mapserver/wiki/MapServer-TILEINDEXes-
> with-Dat
> abase-RASTERS)
> 
> Mike
> 
> --
> Michael Smith
> 
> US Army Corps
> Remote Sensing GIS/Center
> 
> 
> 
> On 8/24/12 7:12 AM, "Rahkonen Jukka" <Jukka.Rahkonen at mmmtike.fi>
> wrote:
> 
> >Hi,
> >
> >There is a trick with using Spatialite tileindex with Mapserver. I have
> >no idea anymore how I came to this solution but most probably I was
> >reading something about it from the internet.
> >
> >Try odd trick is that you cannot user Spatialite directly as tileindex
> >but you must first create a LAYER from Spatialite and use that as
> >tileindex. Let's take an example.  In the following
> >"z:\tindex\aerial_images.sqlite" is the Spatialite db and tile
> >locations are in the table "aerial_images"
> >
> >LAYER
> >        NAME "sqlite_tileindex"
> >        STATUS OFF
> >        TYPE POLYGON
> >        CONNECTIONTYPE OGR
> >        CONNECTION "z:\tindex\aerial_images.sqlite"
> >        DATA "aerial_images"
> >    END
> >
> >Now for the real aerial image layer the tileindex is read from the
> >LAYER that was just created
> >
> >LAYER
> >        NAME "aerial_imagery"
> >        STATUS ON
> >        TILEINDEX "sqlite_tileindex"
> >
> >
> >-Jukka Rahkonen-
> >_______________________________________________
> >gdal-dev mailing list
> >gdal-dev at lists.osgeo.org
> >http://lists.osgeo.org/mailman/listinfo/gdal-dev


From Jukka.Rahkonen at mmmtike.fi  Fri Aug 24 05:23:33 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Fri, 24 Aug 2012 12:23:33 +0000
Subject: [gdal-dev] Large raster (ecw) identify very long
Message-ID: <84446DEF76453C439E9E97E438E13A63467AA0@suutari.haapa.mmm.fi>

Hi,

Even was missing a proper sample image in ECW format. This one comes originally from the geotorrent.org site which obviously disappeared at the same time than ER Mapper.  Anyway, I have been trying to keep the image available. Image is a mosaic made from Landsat landcover scenes (bands 7-4-2) and it is in public domain.
http://laillisettorrentit.net/index.php?page=torrent-details&id=d2c502c1aec3cce0180d92b31721597cbb523751

-Jukka Rahkonen-

From jmckenna at gatewaygeomatics.com  Fri Aug 24 07:03:01 2012
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Fri, 24 Aug 2012 11:03:01 -0300
Subject: [gdal-dev] About sqlite tileindex and Mapserver
In-Reply-To: <CC5CDBE9.3440A%michael.smith@erdc.dren.mil>
References: <CC5CDBE9.3440A%michael.smith@erdc.dren.mil>
Message-ID: <50378995.1030002@gatewaygeomatics.com>

On 12-08-24 8:22 AM, Smith, Michael ERDC-RDE-CRREL-NH wrote:
> Jukka,
> 
> Perhaps you can document this on the Wiki as a Spatialite example in
> addition to the example for Oracle
> (https://github.com/mapserver/mapserver/wiki/MapServer-TILEINDEXes-with-Dat
> abase-RASTERS)
> 
> Mike
> 

I would side with keeping the various examples in the wiki (you can even
add screengrabs of tables and index bounding rectangles there directly
in your wiki page).

-jeff






-- 
Jeff McKenna
MapServer Consulting and Training Services
http://www.gatewaygeomatics.com/



From even.rouault at mines-paris.org  Fri Aug 24 13:45:57 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Fri, 24 Aug 2012 22:45:57 +0200
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
References: <1345628438183-4996953.post@n6.nabble.com>
	<1345639055.5034d28f1c960@imp.free.fr>
	<CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
Message-ID: <201208242245.57431.even.rouault@mines-paris.org>

Le mercredi 22 ao?t 2012 20:13:39, Radim Blazek a ?crit :
> Even,
> thanks for exhaustive explanation and testing.
> 
> On Wed, Aug 22, 2012 at 2:37 PM, Even Rouault
> 
> <even.rouault at mines-paris.org> wrote:
> >> I found in GDAL ecwdataset.cpp that it is treating  single row
> > 
> >> requests in IRasterIO in a special way:
> > I tried the following Python script that must be representative of how
> > QGIS must do picking (I guess it does a RasterIO(, .... x, y, 1, 1, ...
> > 1, 1) )
> 
> Yes.
> 
> > I suppose your workaround in QGIS will be to read 1x2 pixel or something
> > like that.
> 
> Yes, I have used 2x2.

Radim,

I've tested the big ECW (1.8 GB, 141970 x 141970) provided by Jukka and could 
indeed reproduce a noticable performance issue when simulating picking with my 
tiny GDAL python script. In QGIS, the performance was still OK however, a few 
hundreds of milliseconds for each picking. It is just when you do a lot of 
iterations that you begin to notice the slowness, or if the dataset is really 
huge.

I've fixed that in http://trac.osgeo.org/gdal/ticket/4790 in trunk and 1.9 
branch. So it will be in GDAL 1.9.2. Actually, as I think that the ECW driver 
is generally available through a plugin (and not built-in in GDAL DLL), this 
could be available sooner if the ECW plugin is rebuilt with the fixed sources.

Best regards,

Even

From warmerdam at pobox.com  Fri Aug 24 13:57:02 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Fri, 24 Aug 2012 13:57:02 -0700
Subject: [gdal-dev] [Qgis-developer] Large raster (ecw) identify very
	long
In-Reply-To: <201208242245.57431.even.rouault@mines-paris.org>
References: <1345628438183-4996953.post@n6.nabble.com>
	<1345639055.5034d28f1c960@imp.free.fr>
	<CAEMrtYpKVmpyh5QGET_O9NP1Hjo97GzhKHeO27sJCe2rqKeZ1g@mail.gmail.com>
	<201208242245.57431.even.rouault@mines-paris.org>
Message-ID: <CA+YzLBdiuck3h-hunMZCAXeFZeeow8WuoY2bQEtKp8DeV-iD6A@mail.gmail.com>

On Fri, Aug 24, 2012 at 1:45 PM, Even Rouault
<even.rouault at mines-paris.org> wrote:
> I've fixed that in http://trac.osgeo.org/gdal/ticket/4790 in trunk and 1.9
> branch. So it will be in GDAL 1.9.2. Actually, as I think that the ECW driver
> is generally available through a plugin (and not built-in in GDAL DLL), this
> could be available sooner if the ECW plugin is rebuilt with the fixed sources.

Folks,

I have created a calendar item for me on the weekend to rebuild
the 1.9 ECW plugin for OSGeo4W.  Hopefully I'll get it done soon.

Best regards,
-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer

From JDuchesne at korem.com  Fri Aug 24 15:03:40 2012
From: JDuchesne at korem.com (Duchesne, Jimmy)
Date: Fri, 24 Aug 2012 18:03:40 -0400
Subject: [gdal-dev] SQL Server Driver
Message-ID: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>

Hello,

I've been using SQL Server Driver for a few days now, and I noticed it was very slow, whatever the parameters, such as GT, I was using.

I need to insert millions of rows in a table.

To give you an idea, it takes around 1 minute to import 10k records with the driver

On the other hand, if I write my own routine which reads a MapInfo file and does batch insert into the database, I can insert over 125k records per minute.

I tried reading the same TAB file with ogr2ogr but writing to PostGis and noticed the speed was about the same than my routine, which is enough for my needs.

Would it be possible that the SQL Server Driver does not do bulk insert?

Thanks for the help.

Jimmy Duchesne

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120824/7885ade4/attachment.html>

From giuseppe.amatulli at gmail.com  Fri Aug 24 15:27:41 2012
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Fri, 24 Aug 2012 17:27:41 -0500
Subject: [gdal-dev] can't handle grib file
In-Reply-To: <CABa=8Qqz=nOUZM8KtyvCRuh-Fw4HhbESQ-C8H=AowzxUVyoKPA@mail.gmail.com>
References: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>
	<CABa=8QowT0nMqWaHjLXVqBYGovL-gG=HP4_-fptMnzOwpHue_g@mail.gmail.com>
	<201208232036.27009.even.rouault@mines-paris.org>
	<CABa=8Qqz=nOUZM8KtyvCRuh-Fw4HhbESQ-C8H=AowzxUVyoKPA@mail.gmail.com>
Message-ID: <CAKoiDHLWOSSC5p3u_w+1vO=mEgMvYQub2sU8qpieN3WBridNiw@mail.gmail.com>

Ciao
Years ago to handling easily grib file i was using
CDO " http://www.nersc.gov/users/software/vis-analytics/climate-data-operators-cdo/
" .
it can also convert grib to  geoTiff.
ciao

On 24 August 2012 02:05, Margherita Di Leo <diregola at gmail.com> wrote:
> Even,
>
> On Thu, Aug 23, 2012 at 8:36 PM, Even Rouault <even.rouault at mines-paris.org>
> wrote:
>>
>>
>> > So it looks like the information is actually there, but the gdal driver
>> > can't handle it. Any hint?
>>
>> Margherita,
>>
>> There's a possibility that your data file is of a type that isn't
>> understood by
>> the underlying library that GDAL uses to decode GRIB files. Or perhaps
>> GDAL
>> isn't using it correctly with that particular file. Difficult to know.
>>
>> GDAL uses the g2clib library (v1.0.4), that has evolved (
>> http://www.nco.ncep.noaa.gov/pmb/docs/grib2/download/g2clib.changes )
>> since it
>> was integrated in GDAL. So perhaps a newer version of it better supports
>> your
>> data file. (but merging a newer version to GDAL might be non trivial,
>> since a
>> lot of fixes were done in GDAL copy (to address cross-platform
>> portability,
>> etc..)).
>>
> Thank you for your hints. I understand that grib is a pretty much flexible
> type of file and in some cases flexibility is difficult to handle. If you
> devs think it's worthy, I'd file a ticket about it and I can send you the
> grib file if you wish to make tests on it. Please let me know.
>
> Thanks,
>
> --
> Dr. Margherita Di Leo
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Giuseppe Amatulli
Web: www.spatial-ecology.net

From szekerest at gmail.com  Fri Aug 24 15:37:11 2012
From: szekerest at gmail.com (Tamas Szekeres)
Date: Sat, 25 Aug 2012 00:37:11 +0200
Subject: [gdal-dev] SQL Server Driver
In-Reply-To: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>
References: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>
Message-ID: <CACALY+QR7oWWb07UnZd3ofDyf5fnb6t5cTFFxdDk0w83F8U3WQ@mail.gmail.com>

Hi,

Assuming you refer to the MSSQL driver the driver should provide fast data
retrieval, but hasn't yet been optimized to provide fast data upload.
Currently the MSSQL driver use WKT for the geometries when submitting data
to the server, while when retrieving data we use the native
SqlGeometry/SqlGeography serialization format.

Not sure what you mean by "do not do bulk insert". How your own routine is
looking like? Is this a .NET based program (using SqlGeometry by default)?

Best regards,

Tamas



2012/8/25 Duchesne, Jimmy <JDuchesne at korem.com>

> Hello,****
>
> ** **
>
> I?ve been using SQL Server Driver for a few days now, and I noticed it was
> very slow, whatever the parameters, such as GT, I was using.****
>
> ** **
>
> I need to insert millions of rows in a table.****
>
> ** **
>
> To give you an idea, it takes around 1 minute to import 10k records with
> the driver****
>
> ** **
>
> On the other hand, if I write my own routine which reads a MapInfo file
> and does batch insert into the database, I can insert over 125k records per
> minute.****
>
> ** **
>
> I tried reading the same TAB file with ogr2ogr but writing to PostGis and
> noticed the speed was about the same than my routine, which is enough for
> my needs.****
>
> ** **
>
> Would it be possible that the SQL Server Driver does not do bulk insert?**
> **
>
> ** **
>
> Thanks for the help.****
>
> ** **
>
> *Jimmy Duchesne ***
>
> ** **
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120825/e41a9721/attachment.html>

From warmerdam at pobox.com  Fri Aug 24 15:39:04 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Fri, 24 Aug 2012 15:39:04 -0700
Subject: [gdal-dev] SQL Server Driver
In-Reply-To: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>
References: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>
Message-ID: <CA+YzLBe-zVKamgEo_5B2n6VrnPjk+89aR79-zzkCpWodAXe=AA@mail.gmail.com>

Jimmy,

>From an examination of MSSQLSpatialTableLayer::CreateFeature() it
appears a regular INSERT statement is done for each feature written to
the db rather than any sort of bulk mechanism.  I could be missing
something of course.  Hopefully Tamas will provide a more experienced
answer.

Best regards,
Frank


On Fri, Aug 24, 2012 at 3:03 PM, Duchesne, Jimmy <JDuchesne at korem.com> wrote:
> Hello,
>
>
>
> I?ve been using SQL Server Driver for a few days now, and I noticed it was
> very slow, whatever the parameters, such as GT, I was using.
>
>
>
> I need to insert millions of rows in a table.
>
>
>
> To give you an idea, it takes around 1 minute to import 10k records with the
> driver
>
>
>
> On the other hand, if I write my own routine which reads a MapInfo file and
> does batch insert into the database, I can insert over 125k records per
> minute.
>
>
>
> I tried reading the same TAB file with ogr2ogr but writing to PostGis and
> noticed the speed was about the same than my routine, which is enough for my
> needs.
>
>
>
> Would it be possible that the SQL Server Driver does not do bulk insert?
>
>
>
> Thanks for the help.
>
>
>
> Jimmy Duchesne
>
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer

From etourigny.dev at gmail.com  Fri Aug 24 16:07:41 2012
From: etourigny.dev at gmail.com (Etienne Tourigny)
Date: Fri, 24 Aug 2012 20:07:41 -0300
Subject: [gdal-dev] can't handle grib file
In-Reply-To: <CAKoiDHLWOSSC5p3u_w+1vO=mEgMvYQub2sU8qpieN3WBridNiw@mail.gmail.com>
References: <CABa=8QqRqP-gLh4F6Lr2Xp+XrzAHa0=_1RP61Wgk7X6+rCmSJQ@mail.gmail.com>
	<CABa=8QowT0nMqWaHjLXVqBYGovL-gG=HP4_-fptMnzOwpHue_g@mail.gmail.com>
	<201208232036.27009.even.rouault@mines-paris.org>
	<CABa=8Qqz=nOUZM8KtyvCRuh-Fw4HhbESQ-C8H=AowzxUVyoKPA@mail.gmail.com>
	<CAKoiDHLWOSSC5p3u_w+1vO=mEgMvYQub2sU8qpieN3WBridNiw@mail.gmail.com>
Message-ID: <CA+TxYvP99RsUDXiFyFeTyxLrd=6yOBSASONJQC0LP9r85s=1Tw@mail.gmail.com>

On Fri, Aug 24, 2012 at 7:27 PM, Giuseppe Amatulli
<giuseppe.amatulli at gmail.com> wrote:
> Ciao
> Years ago to handling easily grib file i was using
> CDO " http://www.nersc.gov/users/software/vis-analytics/climate-data-operators-cdo/
> " .
> it can also convert grib to  geoTiff.

I doubt cdo can convert to geotiff (in fact I am sure of ir, as I was
having a discussion with the devs about it some months ago).

Perhaps you are confusing with other software (or a really old
versions used to do that).

However, it can convert to netcdf which is well supported in gdal/qgis.

The proper (current) page for cdo is  https://code.zmaw.de/projects/cdo/

cheers
Etienne

> ciao
>
> On 24 August 2012 02:05, Margherita Di Leo <diregola at gmail.com> wrote:
>> Even,
>>
>> On Thu, Aug 23, 2012 at 8:36 PM, Even Rouault <even.rouault at mines-paris.org>
>> wrote:
>>>
>>>
>>> > So it looks like the information is actually there, but the gdal driver
>>> > can't handle it. Any hint?
>>>
>>> Margherita,
>>>
>>> There's a possibility that your data file is of a type that isn't
>>> understood by
>>> the underlying library that GDAL uses to decode GRIB files. Or perhaps
>>> GDAL
>>> isn't using it correctly with that particular file. Difficult to know.
>>>
>>> GDAL uses the g2clib library (v1.0.4), that has evolved (
>>> http://www.nco.ncep.noaa.gov/pmb/docs/grib2/download/g2clib.changes )
>>> since it
>>> was integrated in GDAL. So perhaps a newer version of it better supports
>>> your
>>> data file. (but merging a newer version to GDAL might be non trivial,
>>> since a
>>> lot of fixes were done in GDAL copy (to address cross-platform
>>> portability,
>>> etc..)).
>>>
>> Thank you for your hints. I understand that grib is a pretty much flexible
>> type of file and in some cases flexibility is difficult to handle. If you
>> devs think it's worthy, I'd file a ticket about it and I can send you the
>> grib file if you wish to make tests on it. Please let me know.
>>
>> Thanks,
>>
>> --
>> Dr. Margherita Di Leo
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
>
> --
> Giuseppe Amatulli
> Web: www.spatial-ecology.net
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From chapmanm at pixia.com  Sat Aug 25 20:45:11 2012
From: chapmanm at pixia.com (Martin Chapman)
Date: Sat, 25 Aug 2012 23:45:11 -0400 (EDT)
Subject: [gdal-dev] RPFTOC driver question
Message-ID: <108f9d8a.00001b30.00000002@CHAPMANM7S>

Even,

 

I have an RPF dataset (CIB 5Meter in Zone 1) that will not display using
the RPFTOC driver because on line 605 of file
gdal19\gdal\frmts\nitf\rpftocdataset.cpp in function
RPFTOCProxyRasterDataSet::SanityCheckOK(GDALDataset* sourceDS) the line of
code:

 

WARN_CHECK_DS(fabs(adfGeoTransform[GEOTRSFRM_TOPLEFT_X] - nwLong) <
1e-10); Fails.  

 

Where:

 

adfGeoTransform[GEOTRSFRM_TOPLEFT_X] = 32.036011080332401

and

nwLong = 32.036035630999997

 

which equals -0.000024550667596

 

and is then greater than 1e-10.

 

I was wondering why this sanity check is there?  Do you think I have some
bad frame files or a bad toc file?  If so, why would you reject the entire
boundary from rendering?

 

By the way, thanks a ton for creating this driver.

 

Best regards,

Martin

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120825/a9af93fe/attachment.html>

From yehil at rafael.co.il  Sat Aug 25 22:09:49 2012
From: yehil at rafael.co.il (Livneh Yehiyam)
Date: Sun, 26 Aug 2012 08:09:49 +0300
Subject: [gdal-dev] RPFTOC driver question
Message-ID: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B8C@MAILBOXSERVER.rf.local>

Martin
We have removed the check completly, and so far have not had any problems. We have come to the conclusion that it is too restrictive.
Yehiyam

Sent from my mobile


-----------------------------
From: "Martin Chapman"
Subject: [gdal-dev] RPFTOC driver question
Date: 26 ?????? 2012 06:46

Even,

I have an RPF dataset (CIB 5Meter in Zone 1) that will not display using the RPFTOC driver because on line 605 of file gdal19\gdal\frmts\nitf\rpftocdataset.cpp in function RPFTOCProxyRasterDataSet::SanityCheckOK(GDALDataset* sourceDS) the line of code:

WARN_CHECK_DS(fabs(adfGeoTransform[GEOTRSFRM_TOPLEFT_X] - nwLong) < 1e-10); Fails.

Where:

adfGeoTransform[GEOTRSFRM_TOPLEFT_X] = 32.036011080332401
and
nwLong = 32.036035630999997

which equals -0.000024550667596

and is then greater than 1e-10.

I was wondering why this sanity check is there?  Do you think I have some bad frame files or a bad toc file?  If so, why would you reject the entire boundary from rendering?

By the way, thanks a ton for creating this driver.

Best regards,
Martin


**********************************************************************************************
This message (including any attachments) issued by RAFAEL- ADVANCED DEFENSE SYSTEMS LTD. 
(hereinafter "RAFAEL") contains confidential information intended for a specific individual and purpose, may 
constitute information that is privileged or confidential or otherwise protected from disclosure. If you are not 
the intended recipient, you should contact us immediately and thereafter delete this message from your 
system. You are hereby notified that any disclosure, copying, dissemination, distribution or forwarding of this 
message, or the taking of any action based on it, is strictly prohibited. If you have received this e-mail in error, 
please notify us immediately by e-mail mailto:lawraf at rafael.co.il and completely delete or destroy any and all 
electronic or other copies of the original message and any attachments thereof.
**********************************************************************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120826/91441bf4/attachment.html>

From chapmanm at pixia.com  Sat Aug 25 23:04:45 2012
From: chapmanm at pixia.com (Martin Chapman)
Date: Sun, 26 Aug 2012 02:04:45 -0400 (EDT)
Subject: [gdal-dev] RPFTOC driver question
In-Reply-To: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B8C@MAILBOXSERVER.rf.local>
References: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B8C@MAILBOXSERVER.rf.local>
Message-ID: <ed248ffb.00001514.00000002@CHAPMANM7S>

Yehiyam,



Thanks for that feedback.  I?ll take it out too unless Even has a good 
reason to keep it in there.  I am interested to know what his thought 
process was when he stuck it in and whether he got it out of the 
specification of did it on his own.  Do you guys use a lot of CIB or CADRG 
or both?



Best regards,

Martin



From: Livneh Yehiyam [mailto:yehil at rafael.co.il]
Sent: Saturday, August 25, 2012 11:10 PM
To: Martin Chapman; gdal-dev at lists.osgeo.org
Subject: Re: [gdal-dev] RPFTOC driver question



Martin
We have removed the check completly, and so far have not had any problems. 
We have come to the conclusion that it is too restrictive.
Yehiyam

Sent from my mobile


-----------------------------
From: "Martin Chapman"
Subject: [gdal-dev] RPFTOC driver question
Date: 26 ?????? 2012 06:46




Even,



I have an RPF dataset (CIB 5Meter in Zone 1) that will not display using the 
RPFTOC driver because on line 605 of file 
gdal19\gdal\frmts\nitf\rpftocdataset.cpp in function 
RPFTOCProxyRasterDataSet::SanityCheckOK(GDALDataset* sourceDS) the line of 
code:



WARN_CHECK_DS(fabs(adfGeoTransform[GEOTRSFRM_TOPLEFT_X] - nwLong) < 1e-10); 
Fails.



Where:



adfGeoTransform[GEOTRSFRM_TOPLEFT_X] = 32.036011080332401

and

nwLong = 32.036035630999997



which equals -0.000024550667596



and is then greater than 1e-10.



I was wondering why this sanity check is there?  Do you think I have some 
bad frame files or a bad toc file?  If so, why would you reject the entire 
boundary from rendering?



By the way, thanks a ton for creating this driver.



Best regards,

Martin





  _____

This message (including any attachments) issued by RAFAEL- ADVANCED DEFENSE 
SYSTEMS LTD. (hereinafter "RAFAEL") contains confidential information 
intended for a specific individual and purpose, may constitute information 
that is privileged or confidential or otherwise protected from disclosure. 
If you are not the intended recipient, you should contact us immediately and 
thereafter delete this message from your system. You are hereby notified 
that any disclosure, copying, dissemination, distribution or forwarding of 
this message, or the taking of any action based on it, is strictly 
prohibited. If you have received this e-mail in error, please notify us 
immediately by e-mail mailto:lawraf at rafael.co.il and completely delete or 
destroy any and all electronic or other copies of the original message and 
any attachments thereof.

  _____

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120826/e3ef547c/attachment-0001.html>

From even.rouault at mines-paris.org  Sun Aug 26 00:04:05 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sun, 26 Aug 2012 09:04:05 +0200
Subject: [gdal-dev] RPFTOC driver question
In-Reply-To: <ed248ffb.00001514.00000002@CHAPMANM7S>
References: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B8C@MAILBOXSERVER.rf.local>
	<ed248ffb.00001514.00000002@CHAPMANM7S>
Message-ID: <201208260904.05385.even.rouault@mines-paris.org>

Le dimanche 26 ao?t 2012 08:04:45, Martin Chapman a ?crit :
> Yehiyam,
> 
> 
> 
> Thanks for that feedback.  I?ll take it out too unless Even has a good
> reason to keep it in there.  I am interested to know what his thought
> process was when he stuck it in and whether he got it out of the
> specification of did it on his own.  Do you guys use a lot of CIB or CADRG
> or both?

When I developed the driver, I've tested it extensively with quite a lot of 
CADRG datasets, but I have no access to CIB.

SanityCheckOK() was very usefull when developping the driver, so some of the 
checks are not strictly necessary indeed.

Anyway, see http://trac.osgeo.org/gdal/ticket/4791 for my analysis and a fix 
that should avoid that kind of annoyance in the future.

From chapmanm at pixia.com  Sun Aug 26 00:57:59 2012
From: chapmanm at pixia.com (Martin Chapman)
Date: Sun, 26 Aug 2012 03:57:59 -0400 (EDT)
Subject: [gdal-dev] RPFTOC driver question
In-Reply-To: <201208260904.05385.even.rouault@mines-paris.org>
References: <C5D1974ECA44D2429ECBC64B967C34C0C81C5F3B8C@MAILBOXSERVER.rf.local>
	<ed248ffb.00001514.00000002@CHAPMANM7S>
	<201208260904.05385.even.rouault@mines-paris.org>
Message-ID: <628296de.00001514.00000014@CHAPMANM7S>

Even,

You are the man.  Thanks bud!

Best regards,
Martin

-----Original Message-----
From: Even Rouault [mailto:even.rouault at mines-paris.org]
Sent: Sunday, August 26, 2012 1:04 AM
To: gdal-dev at lists.osgeo.org
Cc: Martin Chapman; 'Livneh Yehiyam'
Subject: Re: [gdal-dev] RPFTOC driver question

Le dimanche 26 ao?t 2012 08:04:45, Martin Chapman a ?crit :
> Yehiyam,
>
>
>
> Thanks for that feedback.  I?ll take it out too unless Even has a good
> reason to keep it in there.  I am interested to know what his thought
> process was when he stuck it in and whether he got it out of the
> specification of did it on his own.  Do you guys use a lot of CIB or
> CADRG or both?

When I developed the driver, I've tested it extensively with quite a lot of 
CADRG datasets, but I have no access to CIB.

SanityCheckOK() was very usefull when developping the driver, so some of the 
checks are not strictly necessary indeed.

Anyway, see http://trac.osgeo.org/gdal/ticket/4791 for my analysis and a fix 
that should avoid that kind of annoyance in the future.

From aperi2007 at gmail.com  Sun Aug 26 02:51:26 2012
From: aperi2007 at gmail.com (Andrea Peri)
Date: Sun, 26 Aug 2012 11:51:26 +0200
Subject: [gdal-dev] How use the esri-filegdb
Message-ID: <CABqTJk-X2B38PLxpFYbGMi38HHQVY7XJhUOdr8sEE2G=PNcdYw@mail.gmail.com>

Hi,
I like to test the esri-filegdb with ogr2ogr.

So I'm reading information from gdal and from esri.

Reading the gdal information on file-gdb format,
http://www.gdal.org/ogr/drv_filegdb.html

I read:

>Bulk feature loading (OGR >= 2.0)
>Special SQL requests (OGR >= 2.0)

this mean I should use the trunk version of gdal to test this options ?
Or, instead, this is an ption actually not available ?

Also I see theat in the instruction is write:

>Dataset Creation Options
>none

This mean that the driver is not capable to create a new empty database ?


Thx,


-- 
-----------------
Andrea Peri
. . . . . . . . .
qwerty ?????
-----------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120826/842e0184/attachment.html>

From even.rouault at mines-paris.org  Sun Aug 26 03:24:39 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sun, 26 Aug 2012 12:24:39 +0200
Subject: [gdal-dev] How use the esri-filegdb
In-Reply-To: <CABqTJk-X2B38PLxpFYbGMi38HHQVY7XJhUOdr8sEE2G=PNcdYw@mail.gmail.com>
References: <CABqTJk-X2B38PLxpFYbGMi38HHQVY7XJhUOdr8sEE2G=PNcdYw@mail.gmail.com>
Message-ID: <201208261224.39905.even.rouault@mines-paris.org>

Le dimanche 26 ao?t 2012 11:51:26, Andrea Peri a ?crit :
> Hi,
> I like to test the esri-filegdb with ogr2ogr.
> 
> So I'm reading information from gdal and from esri.
> 
> Reading the gdal information on file-gdb format,
> http://www.gdal.org/ogr/drv_filegdb.html
> 
> I read:
> >Bulk feature loading (OGR >= 2.0)
> >Special SQL requests (OGR >= 2.0)
> 
> this mean I should use the trunk version of gdal to test this options ?

Yes, when this is documented as GDAL/OGR >= 2.0, it means it is available with 
trunk (we don't advertize features that are not implemented at all)

> 
> Also I see theat in the instruction is write:
> >Dataset Creation Options
> >none
> 
> This mean that the driver is not capable to create a new empty database ?

No, this means that there's no special option to specify. Dataset creation 
options are the ones that may be passed with the -dsco flag of ogr2ogr.

> 
> 
> Thx,

From p.vanbreugel at gmail.com  Sun Aug 26 08:36:59 2012
From: p.vanbreugel at gmail.com (Paulo van Breugel)
Date: Sun, 26 Aug 2012 17:36:59 +0200
Subject: [gdal-dev] compiling gdal 1.9.1 with grass support
Message-ID: <503A429B.9090308@gmail.com>

Hi, I am trying to compile gdal (version 1.9.1). Compiling without GRASS 
support, configure (and make / make install) works fine.

Compiling with GRASS 6.4.3 
(--with-grass=/usr/local/grass6.4/grass-6.4.3svn) also works fine.

Running configure with support for GRASS 7 ( 
--with-grass=/usr/local/grass7/grass-7.0.svn) fails, with the error 
message: configure: error: HDF4 support requested with arg "yes", but 
neither hdf4 nor mfhdf lib found

Any idea how to solve this?

Paulo

p.s. I know of the gdal-grass plugin, but that doesn't support GRASS 7 
(yet), so I am now trying to get gdal with GRASS support.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120826/b9983c58/attachment.html>

From even.rouault at mines-paris.org  Sun Aug 26 08:40:59 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Sun, 26 Aug 2012 17:40:59 +0200
Subject: [gdal-dev] compiling gdal 1.9.1 with grass support
In-Reply-To: <503A429B.9090308@gmail.com>
References: <503A429B.9090308@gmail.com>
Message-ID: <201208261740.59256.even.rouault@mines-paris.org>

Le dimanche 26 ao?t 2012 17:36:59, Paulo van Breugel a ?crit :
> Hi, I am trying to compile gdal (version 1.9.1). Compiling without GRASS
> support, configure (and make / make install) works fine.
> 
> Compiling with GRASS 6.4.3
> (--with-grass=/usr/local/grass6.4/grass-6.4.3svn) also works fine.
> 
> Running configure with support for GRASS 7 (
> --with-grass=/usr/local/grass7/grass-7.0.svn) fails, with the error
> message: configure: error: HDF4 support requested with arg "yes", but
> neither hdf4 nor mfhdf lib found
> 
> Any idea how to solve this?

The GRASS driver/configuration isn't ready for GRASS 7. There is one ticket in 
GDAL trac about that. But I think that the GRASS team intends in creating a 
LGPL lib to access GRASS raster, instead of linking to the GRASS libs 
themselves.

> 
> Paulo
> 
> p.s. I know of the gdal-grass plugin, but that doesn't support GRASS 7
> (yet), so I am now trying to get gdal with GRASS support.

From warmerdam at pobox.com  Sun Aug 26 20:58:06 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Sun, 26 Aug 2012 20:58:06 -0700
Subject: [gdal-dev] GSoC Image Correlator
Message-ID: <503AF04E.1090401@pobox.com>

Folks,

?????? ?????? (Andrew) has completed his Google Summer of Code image
correlator project and I have moderately adapted the code and checked
into GDAL trunk svn.  Some information is available at:

   http://trac.osgeo.org/gdal/wiki/Correlator
   http://correlatorgsoc2012.blogspot.com/
   https://github.com/migal-drew/GDAL-correlator
   http://trac.osgeo.org/gdal/changeset/24868

While I have exposed a function with the following signature, I have
not yet checked in any changes that would use this from an existing
commandline program.  My plan is to expose it via SWIG and write some
demonstration Python scripts using it:

GDAL_GCP CPL_DLL *
GDALComputeMatchingPoints( GDALDatasetH hFirstImage,
                            GDALDatasetH hSecondImage,
                            char **papszOptions,
                            int *pnGCPCount );


I have successfully use it to perform an image match between a UTM image
and the same image warped into WGS84.  I then wrote out the GCPS and use
them to warp the the one to the other and got a good result.

I will also document the GDALComputeMatchingPoints() function based on the
extensive documentation already prepared by Andrew for lower level functions.

Andrew has done a great job this summer, and I hope we will continue to
evolve and exploit the new functionality developed.

Best regards,
-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://home.gdal.org/warmerda
and watch the world go round - Rush    | Geospatial Software Developer


From even.rouault at mines-paris.org  Mon Aug 27 02:58:43 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 27 Aug 2012 11:58:43 +0200
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <503AF04E.1090401@pobox.com>
References: <503AF04E.1090401@pobox.com>
Message-ID: <1346061523.503b44d3bb7a7@imp.free.fr>

Selon Frank Warmerdam <warmerdam at pobox.com>:

> Folks,
>
> ???????????? ???????????? (Andrew) has completed his Google Summer of Code
> image
> correlator project and I have moderately adapted the code and checked
> into GDAL trunk svn.  Some information is available at:
>
>    http://trac.osgeo.org/gdal/wiki/Correlator
>    http://correlatorgsoc2012.blogspot.com/
>    https://github.com/migal-drew/GDAL-correlator
>    http://trac.osgeo.org/gdal/changeset/24868
>
> While I have exposed a function with the following signature, I have
> not yet checked in any changes that would use this from an existing
> commandline program.  My plan is to expose it via SWIG and write some
> demonstration Python scripts using it:
>
> GDAL_GCP CPL_DLL *
> GDALComputeMatchingPoints( GDALDatasetH hFirstImage,
>                             GDALDatasetH hSecondImage,
>                             char **papszOptions,
>                             int *pnGCPCount );
>
>
> I have successfully use it to perform an image match between a UTM image
> and the same image warped into WGS84.  I then wrote out the GCPS and use
> them to warp the the one to the other and got a good result.
>
> I will also document the GDALComputeMatchingPoints() function based on the
> extensive documentation already prepared by Andrew for lower level functions.
>
> Andrew has done a great job this summer, and I hope we will continue to
> evolve and exploit the new functionality developed.

I've done a quick review of the code and indeed it is impressively
documented ! I guess I should find some paper that explains the maths behind for
a better understanding. Perhaps Andrew has someuseful links ?

Looking at gdalmatching.cpp, I'm wondering if GDALComputeMatchingPoints()
shouldn't operate on bands directly rather than on datasets. Because I see that
the first processing step is to compute a luminosity buffer from the R,G,B
bands. This could perhaps be done in a different API, like :

GDALRasterBandH GDALCreateLuminosityBandFromRGB(GDALDatasetH hDS);

void GDALFreeLuminosityBand(GDALRasterBandH );

(could be implemented internally by a VRT dataset that uses a custom pixel
function)

That you would call before GDALComputeMatchingPoints(), and that you will not
need to call if you operate directly on single band datasets.

I've noted that GDALSimpleSURF::ConvertRGBToLuminosity() does a normalization of
the values to [0,1] by dividing by 255, so that assumes that the input range is
[0,255]. Is that a strong requirement that the values are in the [0,1] range
after ConvertRGBToLuminosity() ? I guess there are use cases where satellite
imagery could be in other datatypes, and that dividing by 255 isn't the
appropriate normalization value. But perhaps the normalization must still be
done in order to be able to compare properly the 2 images.

so the API could be :

GDAL_GCP CPL_DLL *
GDALComputeMatchingPoints( GDALRasterBandH hFirstBand,
                           double dfMinFirstBand, double dfMaxFirstBand,
                           GDALDatasetH hSecondImage,
                           double dfMinSecondBand, double dfMaxSecondBand,
                           char **papszOptions,
                           int *pnGCPCount )

dfMinFirstBand and dfMaxFirstBand would be used to do the normalization to
[0,1]. (We could deduce them from statistics, but sometimes you perhaps want to
clamp input values because the extremes are not significant : error measures,
etc...).

(We could argue that the normalization could be done before calling
GDALComputeMatchingPoints(), but that's perhaps not necesserary).

The other important point is that the algorithms assume that each image can
entirely fits in RAM. I've the feeling by looking at gdal_octave.cpp that the
maths done effectively imply to have the full image (or that modifying it to be
able to operate on regions might require a significant rewrite). So we should
probably at least catch std::bad_alloc exceptions in GDALComputeMatchingPoints()

Best regards,

Even

From even.rouault at mines-paris.org  Mon Aug 27 03:00:48 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 27 Aug 2012 12:00:48 +0200
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <1346061523.503b44d3bb7a7@imp.free.fr>
References: <503AF04E.1090401@pobox.com> <1346061523.503b44d3bb7a7@imp.free.fr>
Message-ID: <1346061648.503b45508afef@imp.free.fr>


> GDAL_GCP CPL_DLL *
> GDALComputeMatchingPoints( GDALRasterBandH hFirstBand,
>                            double dfMinFirstBand, double dfMaxFirstBand,
>                            GDALDatasetH hSecondImage,
>                            double dfMinSecondBand, double dfMaxSecondBand,
>                            char **papszOptions,
>                            int *pnGCPCount )

I of course meant GDALRasterBandH hSecondBand in the above signature.

From JDuchesne at korem.com  Mon Aug 27 05:52:21 2012
From: JDuchesne at korem.com (Duchesne, Jimmy)
Date: Mon, 27 Aug 2012 08:52:21 -0400
Subject: [gdal-dev] SQL Server Driver
In-Reply-To: <CA+YzLBe-zVKamgEo_5B2n6VrnPjk+89aR79-zzkCpWodAXe=AA@mail.gmail.com>
References: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>
	<CA+YzLBe-zVKamgEo_5B2n6VrnPjk+89aR79-zzkCpWodAXe=AA@mail.gmail.com>
Message-ID: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15F24@sqexc01>

Thanks for the answers guys.

What you're saying concurs with what I was experiencing, and I believe, what I was seeing with the SQL Server Management profiler.

Also, I don't know if inserting with something else than WKT would actually improve the performance because my test, bulk inserts done with Java, were also inserting using WKT.

Finally, just to be sure, is there any issue with using this driver on a Linux OS?

Jimmy.

-----Original Message-----
From: fwarmerdam at gmail.com [mailto:fwarmerdam at gmail.com] On Behalf Of Frank Warmerdam
Sent: August-24-12 6:39 PM
To: Duchesne, Jimmy
Cc: gdal-dev at lists.osgeo.org; Szekeres Tam?s
Subject: Re: [gdal-dev] SQL Server Driver

Jimmy,

>From an examination of MSSQLSpatialTableLayer::CreateFeature() it
appears a regular INSERT statement is done for each feature written to
the db rather than any sort of bulk mechanism.  I could be missing
something of course.  Hopefully Tamas will provide a more experienced
answer.

Best regards,
Frank


On Fri, Aug 24, 2012 at 3:03 PM, Duchesne, Jimmy <JDuchesne at korem.com> wrote:
> Hello,
>
>
>
> I've been using SQL Server Driver for a few days now, and I noticed it was
> very slow, whatever the parameters, such as GT, I was using.
>
>
>
> I need to insert millions of rows in a table.
>
>
>
> To give you an idea, it takes around 1 minute to import 10k records with the
> driver
>
>
>
> On the other hand, if I write my own routine which reads a MapInfo file and
> does batch insert into the database, I can insert over 125k records per
> minute.
>
>
>
> I tried reading the same TAB file with ogr2ogr but writing to PostGis and
> noticed the speed was about the same than my routine, which is enough for my
> needs.
>
>
>
> Would it be possible that the SQL Server Driver does not do bulk insert?
>
>
>
> Thanks for the help.
>
>
>
> Jimmy Duchesne
>
>
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer

From szekerest at gmail.com  Mon Aug 27 08:22:39 2012
From: szekerest at gmail.com (Tamas Szekeres)
Date: Mon, 27 Aug 2012 17:22:39 +0200
Subject: [gdal-dev] SQL Server Driver
In-Reply-To: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15F24@sqexc01>
References: <B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15EDA@sqexc01>
	<CA+YzLBe-zVKamgEo_5B2n6VrnPjk+89aR79-zzkCpWodAXe=AA@mail.gmail.com>
	<B9E886E5DA17AE44BEB8E7B6E1BC6341292BA15F24@sqexc01>
Message-ID: <CACALY+T+riiqBu8UNgD=WnPkK8=-RWSqhXPYU4qvHXMV_oc3Ww@mail.gmail.com>

Jimmy,

Seems we can get the significant improvement by using bulk inserts then.
You may submit a ticket to keep this enhancements in scope.
Some of the guys used the driver successfully by using FreeTDS on Linux.

Best regards,

Tamas



2012/8/27 Duchesne, Jimmy <JDuchesne at korem.com>

> Thanks for the answers guys.
>
> What you're saying concurs with what I was experiencing, and I believe,
> what I was seeing with the SQL Server Management profiler.
>
> Also, I don't know if inserting with something else than WKT would
> actually improve the performance because my test, bulk inserts done with
> Java, were also inserting using WKT.
>
> Finally, just to be sure, is there any issue with using this driver on a
> Linux OS?
>
> Jimmy.
>
> -----Original Message-----
> From: fwarmerdam at gmail.com [mailto:fwarmerdam at gmail.com] On Behalf Of
> Frank Warmerdam
> Sent: August-24-12 6:39 PM
> To: Duchesne, Jimmy
> Cc: gdal-dev at lists.osgeo.org; Szekeres Tam?s
> Subject: Re: [gdal-dev] SQL Server Driver
>
> Jimmy,
>
> From an examination of MSSQLSpatialTableLayer::CreateFeature() it
> appears a regular INSERT statement is done for each feature written to
> the db rather than any sort of bulk mechanism.  I could be missing
> something of course.  Hopefully Tamas will provide a more experienced
> answer.
>
> Best regards,
> Frank
>
>
> On Fri, Aug 24, 2012 at 3:03 PM, Duchesne, Jimmy <JDuchesne at korem.com>
> wrote:
> > Hello,
> >
> >
> >
> > I've been using SQL Server Driver for a few days now, and I noticed it
> was
> > very slow, whatever the parameters, such as GT, I was using.
> >
> >
> >
> > I need to insert millions of rows in a table.
> >
> >
> >
> > To give you an idea, it takes around 1 minute to import 10k records with
> the
> > driver
> >
> >
> >
> > On the other hand, if I write my own routine which reads a MapInfo file
> and
> > does batch insert into the database, I can insert over 125k records per
> > minute.
> >
> >
> >
> > I tried reading the same TAB file with ogr2ogr but writing to PostGis and
> > noticed the speed was about the same than my routine, which is enough
> for my
> > needs.
> >
> >
> >
> > Would it be possible that the SQL Server Driver does not do bulk insert?
> >
> >
> >
> > Thanks for the help.
> >
> >
> >
> > Jimmy Duchesne
> >
> >
> >
> >
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
>
>
> --
>
> ---------------------------------------+--------------------------------------
> I set the clouds in motion - turn up   | Frank Warmerdam,
> warmerdam at pobox.com
> light and sound - activate the windows | http://pobox.com/~warmerdam
> and watch the world go round - Rush    | Geospatial Software Developer
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120827/3d4e2063/attachment.html>

From even.rouault at mines-paris.org  Mon Aug 27 08:50:14 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 27 Aug 2012 17:50:14 +0200
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <CAHepgKVkBeN=Aagmokphg-f8X0vVV4SUOvs1=vCpAg43t2HQeQ@mail.gmail.com>
References: <503AF04E.1090401@pobox.com> <1346061523.503b44d3bb7a7@imp.free.fr>
	<1346061648.503b45508afef@imp.free.fr>
	<CAHepgKVkBeN=Aagmokphg-f8X0vVV4SUOvs1=vCpAg43t2HQeQ@mail.gmail.com>
Message-ID: <1346082614.503b9736d0985@imp.free.fr>

(Answering and forwarding to the list since you're apparently not subscribed.)

> Even,

> My implementation is based on SURF algorithm.
> http://en.wikipedia.org/wiki/SURF (brief summary and bunch of external
> links)
> http://www.vision.ee.ethz.ch/~surf/papers.html (here you can download
> original pdf paper which entirely describes algorithm)

Thanks for the links

> Normalization is a convenient technique.
> Luminosity image (buffer) should have values in [0, 1], because this image
> is used
> to create an integral representation which is sum of values. So, if don't
> perform
> normalization, in further it's possible to overflow data type. Furthermore,
> threshold for feature point detection will be drastically different for
> each image
> (that's why it will be impossible to use only one threshold for most of
> photos).
> Therefore, it's a very important requirement. (and I don't have enough
> information
> what results (stable or not) will be without it).
> I noticed that I've used a "255" value. It was my instant decision when I
> was
> working with my image samples. I agree that it should be replaced with more
> appropriate value. Something like "RasterBand->GetMaxValue()".
> As I mentioned above, normalization is significant step and it have to be
> done
> before feature point detection.

Ok, that's what I had imagined. To sum it up, the constraint is that
GDALIntegralImage::Initialize receives a buffer of values in the [0,1] range.

>
> The other important point is that the algorithms assume that each image can
> > entirely fits in RAM
> >
> It's a weak part of current realization. Now algorithm deals with entire
> image, because
> initially I planned to work with small copies (otherwise, i think it's
> possible to cut
> photo into pieces and run algorithm using pieces one by one. It will not
> detect points near
> corners of photo's parts, but it is a still possible solution).
> I think that in further development algorithm for detection feature points
> can be implemented
> using several threads in case of huge rasters. Every thread will be use
> only a fragment of image.
> By the way, I didn't write some tricky methods which make algorithm faster.
> In future I'm going to implement these refinements. There are still a lot
> of work.

Making algorithm work with imagery that is piece-wise loaded can be very
complicated indeed. And if you try to correlate images that are taken by sensors
that have very different angles, then you could need to correlate parts that are
not at all at the same position in the 2 images.
IMO, it is OK for now that the algorithm has this limitation. It just needs to
be mentionned in the doc, and catching allocation exceptions should be
sufficient to handle those situations (we don't want C++ exceptions to upwind to
C callers).

>
> Because I see that the first processing step is to compute a luminosity
> > buffer from the R,G,B
> > bands. This could perhaps be done in a different API, like :
> >
> > GDALRasterBandH GDALCreateLuminosityBandFromRG
> > B(GDALDatasetH hDS);
> >
> > void GDALFreeLuminosityBand(GDALRasterBandH );
> >
> It's a possible modification.
>
> Overall, I'm not confident about changes in API, it's a tricky task for me
> now.

I didn't imply that you needed to made them ;-) I was curious about Frank's and
your's opinions. That's something that other GDAL committers could do. This only
touches the "front-end" of the algorithm, so it does not require an in-depth
knowledge of it. Actually the RGB to luminosity converter can be done in an
independant step (that could be usefull for other purposes).

>
> Best regards,
> Andrew Migal
>



From warmerdam at pobox.com  Mon Aug 27 09:12:13 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Mon, 27 Aug 2012 12:12:13 -0400
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <1346082614.503b9736d0985@imp.free.fr>
References: <503AF04E.1090401@pobox.com> <1346061523.503b44d3bb7a7@imp.free.fr>
	<1346061648.503b45508afef@imp.free.fr>
	<CAHepgKVkBeN=Aagmokphg-f8X0vVV4SUOvs1=vCpAg43t2HQeQ@mail.gmail.com>
	<1346082614.503b9736d0985@imp.free.fr>
Message-ID: <CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>

On Mon, Aug 27, 2012 at 11:50 AM, Even Rouault
<even.rouault at mines-paris.org> wrote:
> Making algorithm work with imagery that is piece-wise loaded can be very
> complicated indeed. And if you try to correlate images that are taken by sensors
> that have very different angles, then you could need to correlate parts that are
> not at all at the same position in the 2 images.

Even,

I think it will actually not be too hard to remove this problem
with loading the whole image.  It seems that the reference
point objects (the somewhat poorly named GDALFeaturePoint)
stores a "descriptor" representation of the point with it and so
after these are collected from one of the images it is not
necessary to keep the original image in memory.

I'm still not sure how to handle the image scaling and
conversion to a luminosity image more smoothly.

Best regards,
-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://pobox.com/~warmerdam
and watch the world go round - Rush    | Geospatial Software Developer

From giuseppe.amatulli at gmail.com  Mon Aug 27 09:26:15 2012
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Mon, 27 Aug 2012 11:26:15 -0500
Subject: [gdal-dev] batch for mean by gdal_calc
In-Reply-To: <1345609966289-4996911.post@n6.nabble.com>
References: <1345609966289-4996911.post@n6.nabble.com>
Message-ID: <CAKoiDHLZKGMOYhvG9w6BzFPu2t+zmhhyBFSNUz0VLBGyb2uGMQ@mail.gmail.com>

check also
oft-cal in open foris
http://km.fao.org/OFwiki/index.php/Oft-calc

something  like

oft-calc stk_sseb_2001 stk_sseb_2001_ave.tif<<EOF
1
#1 #2 #3 #4 + + +  4 /
EOF

all the best
Giuseppe
Web: www.spatial-ecology.net


On 21 August 2012 23:32, sigologo <dlopezaspe at gmail.com> wrote:
> Hello Gdalers!!!
>
> I'm calculated mean for many image MODIS is posible simply this
> calculation!!!! is tooo large...
>
> gdal_calc.py -A MOD13A3_2001001_.tif -B MOD13A3_2002001_.tif -C
> MOD13A3_2003001_.tif -D MOD13A3_2004001_.tif -E MOD13A3_2005001_.tif -F
> MOD13A3_2006001_.tif -G MOD13A3_2007001_.tif -H MOD13A3_2008001_.tif -I
> MOD13A3_2009001_.tif -J MOD13A3_2010001_.tif -K MOD13A3_2011001_.tif -L
> MOD13A3_2012001_.tif --outfile=MEAN_001.tif
> --calc="(A+B+C+D+E+F+G+H+I+J+K+L)/12"
>
> Regards
>
>
>
> --
> View this message in context: http://osgeo-org.1560.n6.nabble.com/batch-for-mean-by-gdal-calc-tp4996911.html
> Sent from the GDAL - Dev mailing list archive at Nabble.com.
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev



-- 
Giuseppe Amatulli
Web: www.spatial-ecology.net

From nhatzop at gmail.com  Mon Aug 27 10:39:03 2012
From: nhatzop at gmail.com (Nikolaos Hatzopoulos)
Date: Mon, 27 Aug 2012 10:39:03 -0700
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>
References: <503AF04E.1090401@pobox.com> <1346061523.503b44d3bb7a7@imp.free.fr>
	<1346061648.503b45508afef@imp.free.fr>
	<CAHepgKVkBeN=Aagmokphg-f8X0vVV4SUOvs1=vCpAg43t2HQeQ@mail.gmail.com>
	<1346082614.503b9736d0985@imp.free.fr>
	<CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>
Message-ID: <CALDJGKCGONAE3E4f+E6vXVbbriwNM2c2CV8Z7JcZrs11uF3HDA@mail.gmail.com>

I see the code:

CPLErr GDALSimpleSURF::ConvertRGBToLuminosity


const double forRed = 0.21;
    const double forGreen = 0.72;
    const double forBlue = 0.07;

question:
if you have a sensor with more than this three channels
probably it will not work you need to have an RGB image.

how about have an option how many channels to choose.

Probably this process is working for one channel as well.


--Nikos



On Mon, Aug 27, 2012 at 9:12 AM, Frank Warmerdam <warmerdam at pobox.com>wrote:

> On Mon, Aug 27, 2012 at 11:50 AM, Even Rouault
> <even.rouault at mines-paris.org> wrote:
> > Making algorithm work with imagery that is piece-wise loaded can be very
> > complicated indeed. And if you try to correlate images that are taken by
> sensors
> > that have very different angles, then you could need to correlate parts
> that are
> > not at all at the same position in the 2 images.
>
> Even,
>
> I think it will actually not be too hard to remove this problem
> with loading the whole image.  It seems that the reference
> point objects (the somewhat poorly named GDALFeaturePoint)
> stores a "descriptor" representation of the point with it and so
> after these are collected from one of the images it is not
> necessary to keep the original image in memory.
>
> I'm still not sure how to handle the image scaling and
> conversion to a luminosity image more smoothly.
>
> Best regards,
> --
>
> ---------------------------------------+--------------------------------------
> I set the clouds in motion - turn up   | Frank Warmerdam,
> warmerdam at pobox.com
> light and sound - activate the windows | http://pobox.com/~warmerdam
> and watch the world go round - Rush    | Geospatial Software Developer
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120827/2a7455bd/attachment.html>

From polimax at mail.ru  Mon Aug 27 10:47:47 2012
From: polimax at mail.ru (Dmitry Baryshnikov)
Date: Mon, 27 Aug 2012 21:47:47 +0400
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>
References: <503AF04E.1090401@pobox.com> <1346061523.503b44d3bb7a7@imp.free.fr>
	<1346061648.503b45508afef@imp.free.fr>
	<CAHepgKVkBeN=Aagmokphg-f8X0vVV4SUOvs1=vCpAg43t2HQeQ@mail.gmail.com>
	<1346082614.503b9736d0985@imp.free.fr>
	<CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>
Message-ID: <503BB2C3.1060305@mail.ru>

27.08.2012 20:12, Frank Warmerdam ?????:
> On Mon, Aug 27, 2012 at 11:50 AM, Even Rouault
> <even.rouault at mines-paris.org> wrote:
>> Making algorithm work with imagery that is piece-wise loaded can be very
>> complicated indeed. And if you try to correlate images that are taken by sensors
>> that have very different angles, then you could need to correlate parts that are
>> not at all at the same position in the 2 images.
> Even,
>
> I think it will actually not be too hard to remove this problem
> with loading the whole image.  It seems that the reference
> point objects (the somewhat poorly named GDALFeaturePoint)
> stores a "descriptor" representation of the point with it and so
> after these are collected from one of the images it is not
> necessary to keep the original image in memory.
>
> I'm still not sure how to handle the image scaling and
> conversion to a luminosity image more smoothly.
>
> Best regards,
There are several ways to use not the whole images (prevent load full 
image to the memory).
1) Use aerial images metadata (e.g. 
ftp://www.aerialrobotics.eu/winter-high-overlap/trace.txt.TRIG1-001.pix4d.dat) 
to get overlapped areas or part of this areas
2) Use overviews to gather points, and make their placement more 
accurate on full size image parts
3) May be OpenCL or some parallel threads
4) Gather small amount of points, and use them to make inaccurate 
orientation, and after make more accurate feature points gathering on 
overlapped areas, etc.

But I think, that by now the block images (>2) points adjustment is next 
step to create single seamless image.

Best regards,
Dmitry

From even.rouault at mines-paris.org  Mon Aug 27 11:04:42 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Mon, 27 Aug 2012 20:04:42 +0200
Subject: [gdal-dev] GSoC Image Correlator
In-Reply-To: <CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>
References: <503AF04E.1090401@pobox.com> <1346082614.503b9736d0985@imp.free.fr>
	<CA+YzLBc8MDcw5BGDEOpRB+esZ2OyuiyUY-6Jna23w1h9QaD7qQ@mail.gmail.com>
Message-ID: <201208272004.42785.even.rouault@mines-paris.org>

Le lundi 27 ao?t 2012 18:12:13, Frank Warmerdam a ?crit :
> On Mon, Aug 27, 2012 at 11:50 AM, Even Rouault
> 
> <even.rouault at mines-paris.org> wrote:
> > Making algorithm work with imagery that is piece-wise loaded can be very
> > complicated indeed. And if you try to correlate images that are taken by
> > sensors that have very different angles, then you could need to
> > correlate parts that are not at all at the same position in the 2
> > images.
> 
> Even,
> 
> I think it will actually not be too hard to remove this problem
> with loading the whole image.  It seems that the reference
> point objects (the somewhat poorly named GDALFeaturePoint)
> stores a "descriptor" representation of the point with it and so
> after these are collected from one of the images it is not
> necessary to keep the original image in memory.

Good point. Then the simplest solution I imagine would be to call 
GDALIntegralImage::Initialize() and GDALSimpleSURF::ExtractFeaturePoints() on 
image extracts (for example horizontal swaths), and shift the y of the 
returned points according to the y of the top of the swath.

But I feel there's a risk not to identify features that are located at the top 
or bottom of each swath (or perhaps having false positives, but that would be 
annoying for the general non-windowed case). What makes me believe that, is 
that I see a lot of loops that are iterating over each pixel, with 
computations based on a neighborhood of pixels. It is then likely that no 
usefull computation can be made on border pixels.
So, the alg would probably need to make sure thath there is some overlapping 
between successive swaths (typically of the order of 2 times the window 
radius), and discard the feature points that are too close of the border of a 
swath.

Example with ASCII art of what I mean :

-------------------------------------------------------


      1


                   2

      3
                                      4
++++++++++++++++++++++
               5
~~~~~~~~~~~~~~~~~~~~~~
                           6
-------------------------------------------------------
       7

                    8





++++++++++++++++++++++

Let's say that the first processing swath is limited by the 2 ------ lines , 
and the second swath is limited by the 2 +++ lines. The distance between ~~~~~ 
and ------- (or between ~~~~~~ and ++++++) would be the window radius.
When processing the first swath, you would keep 1,2,3,4 and 5, but would reject 
6 (if it is revealed by the algorithm) because potentially affected by edge 
effects. When processing the second swath, you would ignore 5 for the same 
reason, and keep 6, 7, 8, etc...


> 
> I'm still not sure how to handle the image scaling and
> conversion to a luminosity image more smoothly.
> 
> Best regards,

From bijalwanneha7 at gmail.com  Tue Aug 28 01:36:04 2012
From: bijalwanneha7 at gmail.com (Neha Bijalwan)
Date: Tue, 28 Aug 2012 14:06:04 +0530
Subject: [gdal-dev] gdal info in python script
Message-ID: <CAOmuWhYXynuwWByg1qmMoHWHQvkBp64bN_PgKL8DdCQsyTnkfQ@mail.gmail.com>

how to use gdalinfo with python script? i intend to store the result
of gdalinfo for a raster into a variable and display it, the end
result being the output of gdalinfo being displayed? how is it
possible?

From chaitanya.ch at gmail.com  Tue Aug 28 02:12:52 2012
From: chaitanya.ch at gmail.com (Chaitanya kumar CH)
Date: Tue, 28 Aug 2012 14:42:52 +0530
Subject: [gdal-dev] gdal info in python script
In-Reply-To: <CAOmuWhYXynuwWByg1qmMoHWHQvkBp64bN_PgKL8DdCQsyTnkfQ@mail.gmail.com>
References: <CAOmuWhYXynuwWByg1qmMoHWHQvkBp64bN_PgKL8DdCQsyTnkfQ@mail.gmail.com>
Message-ID: <CAMKgpOaSmBncSx8JGjpPops2EjPZeaOKoz2P0U1vZN4582M-=A@mail.gmail.com>

Neha,

You can use the subprocess module of Python.

On Tue, Aug 28, 2012 at 2:06 PM, Neha Bijalwan <bijalwanneha7 at gmail.com>wrote:

> how to use gdalinfo with python script? i intend to store the result
> of gdalinfo for a raster into a variable and display it, the end
> result being the output of gdalinfo being displayed? how is it
> possible?
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



-- 
Best regards,
Chaitanya kumar CH.

+91-9494447584
17.2416N 80.1426E
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120828/b58dbc30/attachment.html>

From even.rouault at mines-paris.org  Tue Aug 28 02:23:49 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 28 Aug 2012 11:23:49 +0200
Subject: [gdal-dev] gdal info in python script
In-Reply-To: <CAMKgpOaSmBncSx8JGjpPops2EjPZeaOKoz2P0U1vZN4582M-=A@mail.gmail.com>
References: <CAOmuWhYXynuwWByg1qmMoHWHQvkBp64bN_PgKL8DdCQsyTnkfQ@mail.gmail.com>
	<CAMKgpOaSmBncSx8JGjpPops2EjPZeaOKoz2P0U1vZN4582M-=A@mail.gmail.com>
Message-ID: <1346145829.503c8e25daeab@imp.free.fr>

Selon Chaitanya kumar CH <chaitanya.ch at gmail.com>:

> Neha,
>
> You can use the subprocess module of Python.

I can also mention a Python port of gdalinfo that you can adapt to extract the
information that interest you and/or reformat the output according to your needs
: http://svn.osgeo.org/gdal/trunk/gdal/swig/python/samples/gdalinfo.py

>
> On Tue, Aug 28, 2012 at 2:06 PM, Neha Bijalwan
> <bijalwanneha7 at gmail.com>wrote:
>
> > how to use gdalinfo with python script? i intend to store the result
> > of gdalinfo for a raster into a variable and display it, the end
> > result being the output of gdalinfo being displayed? how is it
> > possible?
> > _______________________________________________
> > gdal-dev mailing list
> > gdal-dev at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/gdal-dev
> >
>
>
>
> --
> Best regards,
> Chaitanya kumar CH.
>
> +91-9494447584
> 17.2416N 80.1426E
>



From zoltans at geograph.co.za  Tue Aug 28 03:07:50 2012
From: zoltans at geograph.co.za (Zoltan Szecsei)
Date: Tue, 28 Aug 2012 12:07:50 +0200
Subject: [gdal-dev] Gauss conformal Lo33 on Clarke 1880 Cape Datum to WGS84
	UTM36S
In-Reply-To: <0F348F23-3D73-4611-8C34-B731E69BCEF2@gmail.com>
References: <50115E83.2060506@geograph.co.za>
	<18E2A919-2218-4922-9C69-9FAB5A7F829D@carmenta.com>
	<502A777D.3070806@geograph.co.za>
	<0DA58EB5D84A2744B1229C32174A8D522B75DF72@BY2PRD0610MB352.namprd06.prod.outlook.com>
	<0F348F23-3D73-4611-8C34-B731E69BCEF2@gmail.com>
Message-ID: <503C9876.2040004@geograph.co.za>

Hi Gdal-ers,
This is cross-posted on the proj list, but my query also concerns 
whether gdalwarp notices the NTv2 grid or not, as my results vary from 
the control data (point BM1) I was given.
I'm using gdal/ogr v1.9.1 on ubuntu 12.04.
Please read on, and comment:

Hi All,
This issue goes on, slower than a snail.
I have finally managed to get some source and target points from the 
original surveyor.

BM1

	

2872274.540m

	

49717.410m

	

7128571.659m

	

450273.237m

	

4275103.524m


I load my source image that is on Lo33 Clarke 1880 into QGIS and hover 
the mouse over BM1, a nicely painted white target.
I get:  -49717.33  -2872272.46  which is good on the eastings, but my 
source image is 2m north of this value from the surveyor. For the 
moment, so what.

I then run:
ogr2ogr -f "DGN" -dsco "3D=YES" -s_srs "+proj=tmerc +lon_0=33 
+a=6378249.145 +b=6356514.966398753 +nadgrids=./SA.gsb" -t_srs 
"+init=epsg:32736" Cl_Revised_v7_36s.dgn    Cl_Revised_v7.dgn
gdalwarp                        -s_srs "+proj=tmerc +lon_0=33 
+a=6378249.145 +b=6356514.966398753 +nadgrids=./SA.gsb" -t_srs 
"+init=epsg:32736" images.vrt               images_36s.tif

My UTM 36S WGS84 coordinate for BM1 is now:
450288.88  and  7128578.76  and this puts my transformed image 15m to 
the east and 7m to the north of the Surveyors value.

My question is:
Did I specify the s_srs and t_srs parameters correctly?
Can I be certain that the SA.gsb grid was used?

I have no idea how the original surveyor got his source and target 
values for BM1, as I have no access to this person.
Regards,
Zoltan



>>
>> I have no idea how big, or what extents are in these NTv2 grid files, as
>> I have never used them before.
>>
>> To this end, my area of interest is in Maputo (Mozambique), and
>> Mozambique apparently uses Clarke 1866 (not 1880) - but the surveyor
>> "swears blind" that the coords are on "1880" and not "1866".
>>
>> This begs the question:
>> Do the extents of this Clarke 1880 NTv2 grid stop at the South African
>> border (some 50Km west of my area of interest), or do they cover Maputo
>> sufficiently?
>>
Yes, they go up to 33E which just covers Maputo, and when I load the 
grid plus my data into QGIS, my data is inside the grid extents.
>>
>>
>>
>> On 2012/07/26 21:42, Mikael Rittri wrote:
>> > Hello Zoltan.
>> > Yes, as you say, the traditional transverse mercator projections 
>> for Southern Africa have
>> > axes positive west and south. This can be handled in Proj 4.8.0 
>> (see http://trac.osgeo.org/proj/wiki/TMSO ).
>> > However, since both your example coordinates are negative, I think 
>> you have data in a less traditional
>> > but more GIS-friendly variant, where the axes go east and north and 
>> the traditional coordinate values
>> > have been negated.
>> >
>> > Another problem is caused by the Cape datum having distortions that 
>> are not handled well
>> > by a simple Helmert datum shift ( +towgs84 in Proj.4). Such a datum 
>> shift will have errors up to 15 meters,
>> > perhaps more. You can get much better accuracy from a grid shift 
>> file. So I think your source CRS
>> > is best constructed as
>> >
>> > +proj=tmerc +lon_0=33 +a=6378249.145 +b=6356514.966398753 
>> +nadgrids=SA.gsb
>> >
>> > where SA.gsb is an NTv2 grid shift file from Cape to 
>> Hartebeesthoek94 (or to WGS84),
>> > covering South Africa. To find out where you can download it, see
>> >
>> > 
>> http://eepublishers.co.za/article/datum-transformations-using-the-ntv2-grid.html
>> >
>> > About your target CRS, I don't think there is an EPSG code for the 
>> combination of Hartebeesthoek94 and
>> > a UTM projection. But since H94 is the same as WGS84 except for 
>> tectonic motion, I think you
>> > can use WGS84 / UTM zone 36S, which can be defined as
>> >
>> >? ? ? ?  +init=epsg:32736
>> >
>> > Hope this helps,
>> >
>> > Mikael Rittri
>> > Carmenta
>> > Sweden
>> > http://www.carmenta.com
>> >
>> > 26 jul 2012 kl. 17:14 skrev "Zoltan Szecsei" 
>> <zoltans at geograph.co.za <mailto:zoltans at geograph.co.za>>:
>> >
>> >> Hi Everyone,
>> >> I have some orthos and some 3D vector data that I need to 
>> reproject from
>> >> Clarke 1880 Cape Datum, Lo33 to WGS84 Hartebeeshoek94 datum UTM 36S.
>> >>
>> >>
>>
>

-- 

===========================================
Zoltan Szecsei PrGISc [PGP0031]
Geograph (Pty) Ltd.
P.O. Box 7, Muizenberg 7950, South Africa.

65 Main Road, Muizenberg 7945
Western Cape, South Africa.

34?? 6'16.35"S 18??28'5.62"E

Tel: +27-21-7884897  Mobile: +27-83-6004028
Fax: +27-86-6115323www.geograph.co.za
===========================================

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120828/dfaa9b41/attachment.html>
-------------- next part --------------
_______________________________________________
Proj mailing list
Proj at lists.maptools.org
http://lists.maptools.org/mailman/listinfo/proj

From dleimbach at zebris.com  Tue Aug 28 03:24:00 2012
From: dleimbach at zebris.com (David1980)
Date: Tue, 28 Aug 2012 03:24:00 -0700 (PDT)
Subject: [gdal-dev] Compile GDAL with HDF4 and Shapefile-Support (64bit)
Message-ID: <1346149440153-4998275.post@n6.nabble.com>

I need GDAL with both Shapefile and HDF4-Support, if possible in 64 bit. 
Since the normal GDAL-versions from http://www.gisinternals.com/sdk/ have
Shapefile, but no HDF4 and the version from FWTools
has HDF4, but no Shapefiles, Im afraid I have to compile a GDAL-version by
myself.
The problem is that Im 'just' a geographer with programming skills, but no
real IT-expert, and Ive never compiled open source by myself,
so maybe my question is quite simple for you. :)

First Ive downloaded the source code from
http://trac.osgeo.org/gdal/wiki/DownloadSource. 
Then I opened makegdal90.vcproj with Visual Studio 2010. It needed to do
some updates, then it opened.
If I compile it without changes, I get a GDAL-folder with a new GDAL19.dll. 
If I try to use this whole folder in my C#-project that works with normal
GDAL-versions, I get a error.
But if I only copy the new GDAL19.dll over the old one in the existing
GDAL(32 bit)-folder it works.
Is this how it should be or is something going wrong here already ?

The second step is to switch to 64bit, in nmake.opt I changed the following
entry:
# Uncomment the following if you are building for 64-bit windows
# (x64). You'll need to have PATH, INCLUDE and LIB set up for 64-bit
# compiles.
WIN64=YES
Then I changed the setting of the VS-project to X64 and compiled again.
It still works as before: I get a new GDAL19.dll that works fine in my old
GDAL(64 bit)-folder.

But then I cant do the third step, including HDF4. I found and changed the
following section in nmake.opt:
# Uncomment the following and update to enable NCSA HDF Release 4 support.
HDF4_PLUGIN = NO
HDF4_DIR =	C:\HDF
HDF4_LIB =	/LIBPATH:$(HDF4_DIR)\lib Ws2_32.lib
I tried it maybe 100 times, but it never worked. Sometimes I get a corrupt
GDAL19.dll, sometimes I get >100 errors when compiling
and sometimes I get a working GDAL19.dll without HDF4-support. I've read
almost every Google-hit in English and German I found,
but it never worked. One problem is that the files mentioned there do not
exist in the HDF-versions Ive downloaded. I guess, this
tips were for much older versions of GDAL and HDF4.

So can anybody give a step by step tutorial "How to compile GDAL with HDF4
for dummies" ? ;)
I need to know which HDF4-files I need, where to get them, and what exactly
I have to write in nmake.opt.
Or is there a ready to use GDAL-download with HDF4 and Shapefiles somewhere
?
(32 bit would be OK to, that isnt that important)



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/Compile-GDAL-with-HDF4-and-Shapefile-Support-64bit-tp4998275.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From eborovenskiy at scanex.ru  Tue Aug 28 04:31:23 2012
From: eborovenskiy at scanex.ru (eborovenskiy at scanex.ru)
Date: Tue, 28 Aug 2012 15:31:23 +0400
Subject: [gdal-dev] The file HDF5 is filled in with data
Message-ID: <2933331346153483@web18d.yandex.ru>

Good afternoon,

I am experiencing the following problem - in my program when opening and closing a file with the format HDF5, it remains filled in with data and it's impossible to delete it, rename, etc., until I close the entire program.
Version GDAL 1.8.1. (I also tried to use files for the driver HDF5 from the version 1.9.1).
I also tried to open these files in the program Quantum GIS. It says that this program also uses GDAL, but it was also impossible to rename the file, delete it, etc., until I close the entire program. 
Has anybody experienced the same problem before? Or do you know what could be causing it to happen?

Thank you very much for your help in advance.


Evgeniy

From oliver.bgr at googlemail.com  Tue Aug 28 05:05:57 2012
From: oliver.bgr at googlemail.com (Oliver Burger)
Date: Tue, 28 Aug 2012 14:05:57 +0200
Subject: [gdal-dev] autoreconf fails
Message-ID: <503CB425.8040908@googlemail.com>

Currently I can't build gdal any more.
A normal build told me:
libtool: Version mismatch error.  This is libtool 2.4.2, but the
libtool: definition of this LT_INIT comes from libtool 2.4.
libtool: You should recreate aclocal.m4 with macros from libtool 2.4.2
libtool: and run autoconf again.

But doing so, I get the following error message:
+ aclocal
configure.in:424: warning: macro 'AM_ICONV' not found in library
+ autoreconf
configure.in:424: warning: macro 'AM_ICONV' not found in library
configure.in:78: error: possibly undefined macro: AC_LD_SHARED
      If this token and others are legitimate, please use m4_pattern_allow.
      See the Autoconf documentation.
configure.in:106: error: possibly undefined macro: AC_HAVE_LONG_LONG
configure.in:107: error: possibly undefined macro: AC_UNIX_STDIO_64
configure.in:155: error: possibly undefined macro: AC_CHECK_FUNC_CUSTOM
configure.in:424: error: possibly undefined macro: AM_ICONV
autoreconf: /usr/bin/autoconf failed with exit status: 1

Any ideas how to fix this?

Oliver

-- 
Oliver Burger aka obgr_seneca

Mageia contributor

From jmckenna at gatewaygeomatics.com  Tue Aug 28 05:21:30 2012
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Tue, 28 Aug 2012 09:21:30 -0300
Subject: [gdal-dev] Compile GDAL with HDF4 and Shapefile-Support (64bit)
In-Reply-To: <1346149440153-4998275.post@n6.nabble.com>
References: <1346149440153-4998275.post@n6.nabble.com>
Message-ID: <503CB7CA.5050003@gatewaygeomatics.com>

I wish I had an easy answer for you.  I know for MS4W the next release
will contain HDF4 support (only HDF5 support is included at the moment).
 Also, we maintain built steps for HDF at:
http://trac.osgeo.org/gdal/wiki/HDF

That doesn't answer any of your questions, but at least now you know
where the hints live (bookmark this page
http://trac.osgeo.org/gdal/wiki/BuildHints) and you can now add to those
pages as you travel down this (hard) path.

-jeff



-- 
Jeff McKenna
MapServer Consulting and Training Services
http://www.gatewaygeomatics.com/




On 12-08-28 7:24 AM, David1980 wrote:
> I need GDAL with both Shapefile and HDF4-Support, if possible in 64 bit. 
> Since the normal GDAL-versions from http://www.gisinternals.com/sdk/ have
> Shapefile, but no HDF4 and the version from FWTools
> has HDF4, but no Shapefiles, Im afraid I have to compile a GDAL-version by
> myself.
> The problem is that Im 'just' a geographer with programming skills, but no
> real IT-expert, and Ive never compiled open source by myself,
> so maybe my question is quite simple for you. :)
> 
> First Ive downloaded the source code from
> http://trac.osgeo.org/gdal/wiki/DownloadSource. 
> Then I opened makegdal90.vcproj with Visual Studio 2010. It needed to do
> some updates, then it opened.
> If I compile it without changes, I get a GDAL-folder with a new GDAL19.dll. 
> If I try to use this whole folder in my C#-project that works with normal
> GDAL-versions, I get a error.
> But if I only copy the new GDAL19.dll over the old one in the existing
> GDAL(32 bit)-folder it works.
> Is this how it should be or is something going wrong here already ?
> 
> The second step is to switch to 64bit, in nmake.opt I changed the following
> entry:
> # Uncomment the following if you are building for 64-bit windows
> # (x64). You'll need to have PATH, INCLUDE and LIB set up for 64-bit
> # compiles.
> WIN64=YES
> Then I changed the setting of the VS-project to X64 and compiled again.
> It still works as before: I get a new GDAL19.dll that works fine in my old
> GDAL(64 bit)-folder.
> 
> But then I cant do the third step, including HDF4. I found and changed the
> following section in nmake.opt:
> # Uncomment the following and update to enable NCSA HDF Release 4 support.
> HDF4_PLUGIN = NO
> HDF4_DIR =	C:\HDF
> HDF4_LIB =	/LIBPATH:$(HDF4_DIR)\lib Ws2_32.lib
> I tried it maybe 100 times, but it never worked. Sometimes I get a corrupt
> GDAL19.dll, sometimes I get >100 errors when compiling
> and sometimes I get a working GDAL19.dll without HDF4-support. I've read
> almost every Google-hit in English and German I found,
> but it never worked. One problem is that the files mentioned there do not
> exist in the HDF-versions Ive downloaded. I guess, this
> tips were for much older versions of GDAL and HDF4.
> 
> So can anybody give a step by step tutorial "How to compile GDAL with HDF4
> for dummies" ? ;)
> I need to know which HDF4-files I need, where to get them, and what exactly
> I have to write in nmake.opt.
> Or is there a ready to use GDAL-download with HDF4 and Shapefiles somewhere
> ?
> (32 bit would be OK to, that isnt that important)
> 
> 


From even.rouault at mines-paris.org  Tue Aug 28 05:33:09 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 28 Aug 2012 14:33:09 +0200
Subject: [gdal-dev] Compile GDAL with HDF4 and Shapefile-Support (64bit)
In-Reply-To: <1346149440153-4998275.post@n6.nabble.com>
References: <1346149440153-4998275.post@n6.nabble.com>
Message-ID: <1346157189.503cba85827aa@imp.free.fr>

Selon David1980 <dleimbach at zebris.com>:

> the version from FWTools
> has HDF4, but no Shapefiles

FWTools has definitely shapefile support. The shapefile driver doesn't require
external libraries, so every GDAL/OGR build has shapefile support.

C:Program FilesFWTools2.4.7>ogrinfo --formats
Supported Formats:
  -> "ESRI Shapefile" (read/write)  <--- look here
  -> "MapInfo File" (read/write)
  -> "UK .NTF" (readonly)
  -> "SDTS" (readonly)
  -> "TIGER" (read/write)
  -> "S57" (read/write)
  -> "DGN" (read/write)
etc etc...




























From even.rouault at mines-paris.org  Tue Aug 28 05:45:55 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Tue, 28 Aug 2012 14:45:55 +0200
Subject: [gdal-dev] autoreconf fails
In-Reply-To: <503CB425.8040908@googlemail.com>
References: <503CB425.8040908@googlemail.com>
Message-ID: <1346157955.503cbd830a814@imp.free.fr>

Selon Oliver Burger <oliver.bgr at googlemail.com>:

Did you try autogen.sh ?

$ less gdal/autogen.sh
#!/bin/sh
set -x
#libtoolize --force --copy
aclocal -I ./m4
# We deliberately do not use autoheader, since it introduces PACKAGE junk
# that conflicts with other packages in cpl_config.h.in (FrankW)
#autoheader
autoconf

But I'm indeed not sure how this behaves with new versions of autoconf /
libtool. The autoconf version used to regenerate configure from configure.in is
2.68, and I personnaly avoid using libtool.

I believe that you likely need to replace the libtool.m4 in the m4 directory
with a more recent version that is consistant with your system libtool 2.4.2.
The latest svn entry for that file is indeed :

"""
$ svn log gdal/m4/libtool.m4
------------------------------------------------------------------------
r22256 | warmerdam | 2011-04-29 21:05:48 +0200 (Fri, 29 Apr 2011) | 1 line

update to libtool 2.4
"""

If you confirm that it works, we'll probably need to upgrade in SVN.




From dleimbach at zebris.com  Tue Aug 28 06:29:05 2012
From: dleimbach at zebris.com (David1980)
Date: Tue, 28 Aug 2012 06:29:05 -0700 (PDT)
Subject: [gdal-dev] Compile GDAL with HDF4 and Shapefile-Support (64bit)
In-Reply-To: <1346157189.503cba85827aa@imp.free.fr>
References: <1346149440153-4998275.post@n6.nabble.com>
	<1346157189.503cba85827aa@imp.free.fr>
Message-ID: <1346160545474-4998322.post@n6.nabble.com>

@Jeff McKenna:
I know this 2 pages, but it didnt help me. Im afraid the tips there are to
short for me because the authors thought every reader would know things I
simply dont know. ;)
(e.g.: "If your OS distribution already contains prebuilt HDF library you
can use one from the distribution. " -> Which files do I have to search to
find out if I have a distribution ? )

@Even Rouault:
If I try to show OGR-drivers in my C#-project, I get the following error:
The type-initialiser for "OSGeo.OGR.Ogs" has caused an exception.
System.EntryPointNotFoundException: The entry point
"CSharp_OLCDeleteField_get" was not found in the DLL "ogr_wrap".
at OSGeo.OGR.OgrPINVOKE.OLCDeleteField_get()
at OSGeo.OGR.Ogr..cctor()
(translated from German by myself)

My code for that:
(..)
//Without Ogr.RegisterAll() it works fine:
Ogr.RegisterAll();
(..)
for (int i = 0; i < Ogr.GetDriverCount(); i++)
     Console.WriteLine(Ogr.GetDriver(i).name);
(..)

What could cause this exception, anyboy tried to use the FWTools-GDAL via C#
?
The same code works with other GDAL-versions incl. Shapefiles, so I never
thought about the possibility that something is wrong here. I always thought
that happens because FWTools was only build for raster images, but if it has
Shapefile-support build in, it could be sufficent for now. :)
(Its an old GDAL 1.7 32bit, so sooner or later we might need a newer one,
but for now I would be glad if I had at least one version that works with
both filetypes)




--
View this message in context: http://osgeo-org.1560.n6.nabble.com/Compile-GDAL-with-HDF4-and-Shapefile-Support-64bit-tp4998275p4998322.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From ramirogonzalez at suremptec.com.ar  Tue Aug 28 10:42:20 2012
From: ramirogonzalez at suremptec.com.ar (Ramiro Gonzalez)
Date: Tue, 28 Aug 2012 14:42:20 -0300
Subject: [gdal-dev] Problem when resizing main frame in Windows 7.
Message-ID: <CAAb2t_krbRdu=vXCBE=DNoW=UqEGuTaN69VobZ9cHV976FDgJA@mail.gmail.com>

Hi,

I use wx 2.8.12 in a multiplatform application, I have been having a
problem with the layout when I resize the main Frame, but '''only happens
in Windows 7'''.

I couldn't find the source of the problem, so I was hoping someone could
help me with it.

My application have several wxPanels composed in a tree structure with
sizers, after resizing the top level window, the layout algorithm executes,
but stops before reaching the last few panels(near leafs, and only in one
branch of the tree). This branch of the tree is 8/9 panels in lenght.

I looked closely to the state of the sizers in that branch, and find out
that one of the sizer's dimension was not being updated, so its dimension
was different to the size of the containing window.
{{{
Window size: h 891 s 1076
Sizer size: h 389 s 656
}}}

While debugging, I added a panel several levels up in the tree(containing
the inconsistent panel). After this, the bug moved one level up, that is,
the inconsistency between the windows an the sizer now happened in the
parent of the previously broken window.

As a temporal fix, I am listening for wxEVT_SIZE in one of the
parents(before broken sizer) and manually fixing the Size mismatch:
{{{
void FixSizers(wxWindow* pWindow) {
   if(!pWindow->IsShown())
      return;

   wxSize windowsize =  pWindow->GetSize();
   if (pWindow->GetSizer())
      pWindow->GetSizer()->SetDimension(0, 0, windowsize.GetWidth(),
windowsize.GetHeight());

   wxWindowList& children = pWindow->GetChildren();
   for (size_t i = 0; i < children.size(); i++)
      FixSizers(children[i]);
}
}}}

This solved the problem, but I would like to know if this has happened to
someone else, and what could be a probable cause of this behaviour?

Thanks
Ramiro
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120828/2a7a9618/attachment.html>

From chaitanya.ch at gmail.com  Tue Aug 28 10:57:50 2012
From: chaitanya.ch at gmail.com (Chaitanya kumar CH)
Date: Tue, 28 Aug 2012 23:27:50 +0530
Subject: [gdal-dev] Problem when resizing main frame in Windows 7.
In-Reply-To: <CAAb2t_krbRdu=vXCBE=DNoW=UqEGuTaN69VobZ9cHV976FDgJA@mail.gmail.com>
References: <CAAb2t_krbRdu=vXCBE=DNoW=UqEGuTaN69VobZ9cHV976FDgJA@mail.gmail.com>
Message-ID: <CAMKgpOa-+P=VW1gxpJVnXM2ZhH-JQPHpf1dm+K3uJDZGp0uV6A@mail.gmail.com>

Ramiro,

This is not the mailing list for wx.

On Tue, Aug 28, 2012 at 11:12 PM, Ramiro Gonzalez <
ramirogonzalez at suremptec.com.ar> wrote:

> Hi,
>
> I use wx 2.8.12 in a multiplatform application, I have been having a
> problem with the layout when I resize the main Frame, but '''only happens
> in Windows 7'''.
>
> I couldn't find the source of the problem, so I was hoping someone could
> help me with it.
>
> My application have several wxPanels composed in a tree structure with
> sizers, after resizing the top level window, the layout algorithm executes,
> but stops before reaching the last few panels(near leafs, and only in one
> branch of the tree). This branch of the tree is 8/9 panels in lenght.
>
> I looked closely to the state of the sizers in that branch, and find out
> that one of the sizer's dimension was not being updated, so its dimension
> was different to the size of the containing window.
> {{{
> Window size: h 891 s 1076
> Sizer size: h 389 s 656
> }}}
>
> While debugging, I added a panel several levels up in the tree(containing
> the inconsistent panel). After this, the bug moved one level up, that is,
> the inconsistency between the windows an the sizer now happened in the
> parent of the previously broken window.
>
> As a temporal fix, I am listening for wxEVT_SIZE in one of the
> parents(before broken sizer) and manually fixing the Size mismatch:
> {{{
> void FixSizers(wxWindow* pWindow) {
>    if(!pWindow->IsShown())
>       return;
>
>    wxSize windowsize =  pWindow->GetSize();
>    if (pWindow->GetSizer())
>       pWindow->GetSizer()->SetDimension(0, 0, windowsize.GetWidth(),
> windowsize.GetHeight());
>
>    wxWindowList& children = pWindow->GetChildren();
>    for (size_t i = 0; i < children.size(); i++)
>       FixSizers(children[i]);
> }
> }}}
>
> This solved the problem, but I would like to know if this has happened to
> someone else, and what could be a probable cause of this behaviour?
>
> Thanks
> Ramiro
>
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>



-- 
Best regards,
Chaitanya kumar CH.

+91-9494447584
17.2416N 80.1426E
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120828/b2eec0db/attachment-0001.html>

From ramirogonzalez at suremptec.com.ar  Tue Aug 28 11:22:41 2012
From: ramirogonzalez at suremptec.com.ar (Ramiro Gonzalez)
Date: Tue, 28 Aug 2012 15:22:41 -0300
Subject: [gdal-dev] Problem when resizing main frame in Windows 7.
In-Reply-To: <CAMKgpOa-+P=VW1gxpJVnXM2ZhH-JQPHpf1dm+K3uJDZGp0uV6A@mail.gmail.com>
References: <CAAb2t_krbRdu=vXCBE=DNoW=UqEGuTaN69VobZ9cHV976FDgJA@mail.gmail.com>
	<CAMKgpOa-+P=VW1gxpJVnXM2ZhH-JQPHpf1dm+K3uJDZGp0uV6A@mail.gmail.com>
Message-ID: <CAAb2t_=mCuimFNVF7gevE59RuguCQz=0V5OrTixm7w5khiAgKw@mail.gmail.com>

Sorry.

2012/8/28 Chaitanya kumar CH <chaitanya.ch at gmail.com>

> Ramiro,
>
> This is not the mailing list for wx.
>
> On Tue, Aug 28, 2012 at 11:12 PM, Ramiro Gonzalez <
> ramirogonzalez at suremptec.com.ar> wrote:
>
>> Hi,
>>
>> I use wx 2.8.12 in a multiplatform application, I have been having a
>> problem with the layout when I resize the main Frame, but '''only happens
>> in Windows 7'''.
>>
>> I couldn't find the source of the problem, so I was hoping someone could
>> help me with it.
>>
>> My application have several wxPanels composed in a tree structure with
>> sizers, after resizing the top level window, the layout algorithm executes,
>> but stops before reaching the last few panels(near leafs, and only in one
>> branch of the tree). This branch of the tree is 8/9 panels in lenght.
>>
>> I looked closely to the state of the sizers in that branch, and find out
>> that one of the sizer's dimension was not being updated, so its dimension
>> was different to the size of the containing window.
>> {{{
>> Window size: h 891 s 1076
>> Sizer size: h 389 s 656
>> }}}
>>
>> While debugging, I added a panel several levels up in the tree(containing
>> the inconsistent panel). After this, the bug moved one level up, that is,
>> the inconsistency between the windows an the sizer now happened in the
>> parent of the previously broken window.
>>
>> As a temporal fix, I am listening for wxEVT_SIZE in one of the
>> parents(before broken sizer) and manually fixing the Size mismatch:
>> {{{
>> void FixSizers(wxWindow* pWindow) {
>>    if(!pWindow->IsShown())
>>       return;
>>
>>    wxSize windowsize =  pWindow->GetSize();
>>    if (pWindow->GetSizer())
>>       pWindow->GetSizer()->SetDimension(0, 0, windowsize.GetWidth(),
>> windowsize.GetHeight());
>>
>>    wxWindowList& children = pWindow->GetChildren();
>>    for (size_t i = 0; i < children.size(); i++)
>>       FixSizers(children[i]);
>> }
>> }}}
>>
>> This solved the problem, but I would like to know if this has happened to
>> someone else, and what could be a probable cause of this behaviour?
>>
>> Thanks
>> Ramiro
>>
>>
>> _______________________________________________
>> gdal-dev mailing list
>> gdal-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>>
>
>
>
> --
> Best regards,
> Chaitanya kumar CH.
>
> +91-9494447584
> 17.2416N 80.1426E
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120828/737a233c/attachment.html>

From dleimbach at zebris.com  Tue Aug 28 06:20:05 2012
From: dleimbach at zebris.com (David1980)
Date: Tue, 28 Aug 2012 06:20:05 -0700 (PDT)
Subject: [gdal-dev] Compile GDAL with HDF4 and Shapefile-Support (64bit)
In-Reply-To: <1346157189.503cba85827aa@imp.free.fr>
References: <1346149440153-4998275.post@n6.nabble.com>
	<1346157189.503cba85827aa@imp.free.fr>
Message-ID: <1346160005350-4998320.post@n6.nabble.com>

If I try to show OGR-drivers in my C#-project, I get the following error:

The type-initialiser for "OSGeo.OGR.Ogs" has caused an exception. 
System.EntryPointNotFoundException: The entry point
"CSharp_OLCDeleteField_get" was not found in the DLL "ogr_wrap".
at OSGeo.OGR.OgrPINVOKE.OLCDeleteField_get()
at OSGeo.OGR.Ogr..cctor()
(translated from German by myself)

My code for that:
(..)
//Without Ogr.RegisterAll() it works fine:
Ogr.RegisterAll();
(..)
for (int i = 0; i < Ogr.GetDriverCount(); i++)
     Console.WriteLine(Ogr.GetDriver(i).name);
(..)

What could cause this exception, anyboy tried to use the FWTools-GDAL via C#
?

I always thought that happens because FWTools was only build for raster
images, but if it has Shapefile-support build in, it could be sufficent for
now. :)
(Its an old GDAL 1.7, so sooner or later we might need a newer one, but for
now I would be glad if I had at least one version that works with both
filetypes)





--
View this message in context: http://osgeo-org.1560.n6.nabble.com/Compile-GDAL-with-HDF4-and-Shapefile-Support-64bit-tp4998275p4998320.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From JPalmer at linz.govt.nz  Wed Aug 29 21:26:14 2012
From: JPalmer at linz.govt.nz (Jeremy Palmer)
Date: Thu, 30 Aug 2012 16:26:14 +1200
Subject: [gdal-dev] OGR WFS WFSLayerMetadata broken
Message-ID: <666FB8D75E95AE42965A0E76A5E5337E0E2B7A0A8E@prdlsmmsg01.ad.linz.govt.nz>

I'm trying to setup a simple python script to query the WFS layers from a service. When using the special WFSLayerMetadata layer it seems to get screwed up. After the first comma within an abstract is found the field alignment becomes broken..

If I look here http://trac.osgeo.org/gdal/browser/trunk/gdal/ogr/ogrsf_frmts/wfs/ogrwfsdatasource.cpp#L1221 it seems the fields are being double quoted before being included into temp CSV data

This is the place where the temp mem CSV layer is actually created:
http://trac.osgeo.org/gdal/browser/trunk/gdal/ogr/ogrsf_frmts/wfs/ogrwfsdatasource.cpp#L242

any ideas?

See script below. 

---script---

import ogr
import gdal

wfs_drv = ogr.GetDriverByName('WFS')

gdal.SetConfigOption('OGR_WFS_LOAD_MULTIPLE_LAYER_DEFN', 'NO')

# Note: if you want to use the URL below you need to sign up at
# data.linz.govt.nz and create yourself an API key...
ds = ogr.Open('WFS:http://wfs.data.linz.govt.nz/<my-private-key>/wfs')

layermetadata = ds.GetLayerByName("WFSLayerMetadata")

feat = layermetadata.GetNextFeature()
while feat is not None:
    name = feat.GetFieldAsString('layer_name')
    title = feat.GetFieldAsString('title')
    print( "%s, %s" % (name, title) )
    feat = layermetadata.GetNextFeature()
feat = None

exit(0)

---script---

This message contains information, which is confidential and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From jukka.rahkonen at mmmtike.fi  Wed Aug 29 23:25:56 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Thu, 30 Aug 2012 06:25:56 +0000 (UTC)
Subject: [gdal-dev] How to write many raster layers into PDF?
Message-ID: <loom.20120830T081806-419@post.gmane.org>

Hi,

Is there a way to write several raster images into geospatial PDF so that they
would appear as own selectable layers in the resulting PDF? With extra vector
layers it is possible be making a .vrt file combines the original layers into
one OGR_DATASOURCE. Does this work somehow also with raster sources and if it
does, could it be possible to see a simple example?

-Jukka Rahkonen-


From even.rouault at mines-paris.org  Thu Aug 30 00:13:23 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 30 Aug 2012 09:13:23 +0200
Subject: [gdal-dev] OGR WFS WFSLayerMetadata broken
In-Reply-To: <666FB8D75E95AE42965A0E76A5E5337E0E2B7A0A8E@prdlsmmsg01.ad.linz.govt.nz>
References: <666FB8D75E95AE42965A0E76A5E5337E0E2B7A0A8E@prdlsmmsg01.ad.linz.govt.nz>
Message-ID: <1346310803.503f12937779d@imp.free.fr>

Selon Jeremy Palmer <JPalmer at linz.govt.nz>:

> I'm trying to setup a simple python script to query the WFS layers from a
> service. When using the special WFSLayerMetadata layer it seems to get
> screwed up. After the first comma within an abstract is found the field
> alignment becomes broken..
>
> If I look here
>
http://trac.osgeo.org/gdal/browser/trunk/gdal/ogr/ogrsf_frmts/wfs/ogrwfsdatasource.cpp#L1221
> it seems the fields are being double quoted before being included into temp
> CSV data

Yes, so I suspect the issue is not the presence of a comma in the abstract, but
a present of a double-quote in the abstract, that should be CSV-escaped. Could
you check that ? (or send the GetCapabilities document)

From even.rouault at mines-paris.org  Thu Aug 30 00:42:59 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 30 Aug 2012 09:42:59 +0200
Subject: [gdal-dev] How to write many raster layers into PDF?
In-Reply-To: <loom.20120830T081806-419@post.gmane.org>
References: <loom.20120830T081806-419@post.gmane.org>
Message-ID: <1346312579.503f19832713f@imp.free.fr>

Selon Jukka Rahkonen <jukka.rahkonen at mmmtike.fi>:

> Hi,
>
> Is there a way to write several raster images into geospatial PDF so that
> they
> would appear as own selectable layers in the resulting PDF? With extra vector
> layers it is possible be making a .vrt file combines the original layers into
> one OGR_DATASOURCE. Does this work somehow also with raster sources and if it
> does, could it be possible to see a simple example?

No, this isn't currently possible. You can merge several raster images into one
single one before transforming to PDF, but that's not what you are looking
for. There is also the possibility of inserting non-georeferenced images with
the EXTRA_IMAGES option. That could be possibly used to add another
georeferenced image if you manage to find the right offset values.

There would be some difficulties in implementing a EXTRA_DATASETS option. Mainly
to deal with possible different projections and/or different georeferenced
extents. For example, when inputs are in different projections and/or have
different extent, should they be reprojected/mosaiced to overlap on each other,
with a common georeferencing, or should they be handled as map insets (a bit
like Hawa? is represented in a USA map), each one with its own georeferencing
info. Nothing that can't be solved, but would need some work.

>
> -Jukka Rahkonen-
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev
>









From lcelati at latitude-geosystems.com  Thu Aug 30 01:10:23 2012
From: lcelati at latitude-geosystems.com (laurent celati)
Date: Thu, 30 Aug 2012 01:10:23 -0700 (PDT)
Subject: [gdal-dev] How to compile "GDAL from gdal trunk" and qgis from
	source?
Message-ID: <1346314223758-4998802.post@n6.nabble.com>

Hello,

I have posted a message there a few weeks. I asked you a way to compile the
"last Gdal version from trunk" and Qgis from source targeting your gdal
source as library in order to use the last Gdal postis raster driver. You
answered that the last binairies qgis 1.8 version is available with the last
version of gdal (1.9.1) and that it's useless to compile.

I understand your reply. BUT I have talked last days with developpers of
"Gdal Postgis raster driver". They just add several important updates to the
driver. And they confirm to me that the only way to use the last driver is
to compile GDAL from gdal trunk and qgis from source using that compilation
as GDAL version.
Please to read below few sentences written by those developpers :
----------------------------------------------------------
That's the only way to get the development version working. You have to
compile GDAL from svn and qgis from source using that compilation as GDAL
version.
I'm not following osgeo4w binaries, but I don't think they would
provide a QGIS build with both gdal and qgis from svn. It's not entirely
impossible because I know they release a few nightly snapshots.
So, you have to use the last GDAL version from trunk in order to have the
last "Gdal Postgis raster driver updates".You just need to compile QGIS from
source targeting your GDAL source as library.I think that if you make any
header changes you may need to recompile it all since QGIS depends on
GDAL.So you have to work with last gdal version from trunk.
----------------------------------------------------------

I need this last version of Gdal Postgis raster driver on my windows 7-64
bits station but those developpers working on Linux.
Could you explain to me the way to compile GDAL from gdal trunk and qgis
from source using that compilation as GDAL version (sources links to
download, compilation proc?dure,etc.). I am a thematician geograph and i am
a novice in software compilation;-(

In advance, thank you for your reply.

Kind regards.

Laurent Celati 



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/How-to-compile-GDAL-from-gdal-trunk-and-qgis-from-source-tp4998802.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From chaitanya.ch at gmail.com  Thu Aug 30 01:36:10 2012
From: chaitanya.ch at gmail.com (Chaitanya kumar CH)
Date: Thu, 30 Aug 2012 14:06:10 +0530
Subject: [gdal-dev] How to compile "GDAL from gdal trunk" and qgis from
	source?
In-Reply-To: <1346314223758-4998802.post@n6.nabble.com>
References: <1346314223758-4998802.post@n6.nabble.com>
Message-ID: <CAMKgpOYpju11a4zv2qzEP0EbVjhGWosND=uF3y3vaNtgjcqFVw@mail.gmail.com>

Laurent,

Compilation is easy as long as you don't run into any obstacles :-)

Follow these links to read how to get the latest source and how to compile
it for Microsoft Windows.
GDAL:
http://trac.osgeo.org/gdal/wiki/DownloadSource#Subversion
http://trac.osgeo.org/gdal/wiki/BuildingOnWindows
QGIS:
http://hub.qgis.org/projects/quantum-gis/wiki/Download#61-Source-Code
http://www.qgis.org/api/INSTALL.html#toc13

On Thu, Aug 30, 2012 at 1:40 PM, laurent celati <
lcelati at latitude-geosystems.com> wrote:

> Hello,
>
> I have posted a message there a few weeks. I asked you a way to compile the
> "last Gdal version from trunk" and Qgis from source targeting your gdal
> source as library in order to use the last Gdal postis raster driver. You
> answered that the last binairies qgis 1.8 version is available with the
> last
> version of gdal (1.9.1) and that it's useless to compile.
>
> I understand your reply. BUT I have talked last days with developpers of
> "Gdal Postgis raster driver". They just add several important updates to
> the
> driver. And they confirm to me that the only way to use the last driver is
> to compile GDAL from gdal trunk and qgis from source using that compilation
> as GDAL version.
> Please to read below few sentences written by those developpers :
> ----------------------------------------------------------
> That's the only way to get the development version working. You have to
> compile GDAL from svn and qgis from source using that compilation as GDAL
> version.
> I'm not following osgeo4w binaries, but I don't think they would
> provide a QGIS build with both gdal and qgis from svn. It's not entirely
> impossible because I know they release a few nightly snapshots.
> So, you have to use the last GDAL version from trunk in order to have the
> last "Gdal Postgis raster driver updates".You just need to compile QGIS
> from
> source targeting your GDAL source as library.I think that if you make any
> header changes you may need to recompile it all since QGIS depends on
> GDAL.So you have to work with last gdal version from trunk.
> ----------------------------------------------------------
>
> I need this last version of Gdal Postgis raster driver on my windows 7-64
> bits station but those developpers working on Linux.
> Could you explain to me the way to compile GDAL from gdal trunk and qgis
> from source using that compilation as GDAL version (sources links to
> download, compilation proc?dure,etc.). I am a thematician geograph and i am
> a novice in software compilation;-(
>
> In advance, thank you for your reply.
>
> Kind regards.
>
> Laurent Celati
>
>
>
> --
> View this message in context:
> http://osgeo-org.1560.n6.nabble.com/How-to-compile-GDAL-from-gdal-trunk-and-qgis-from-source-tp4998802.html
> Sent from the GDAL - Dev mailing list archive at Nabble.com.
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev




-- 
Best regards,
Chaitanya kumar CH.

+91-9494447584
17.2416N 80.1426E
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/gdal-dev/attachments/20120830/f2b27bcc/attachment.html>

From Jukka.Rahkonen at mmmtike.fi  Thu Aug 30 02:15:15 2012
From: Jukka.Rahkonen at mmmtike.fi (Rahkonen Jukka)
Date: Thu, 30 Aug 2012 09:15:15 +0000
Subject: [gdal-dev] How to write many raster layers into PDF?
Message-ID: <84446DEF76453C439E9E97E438E13A634689CF@suutari.haapa.mmm.fi>

Even Rouault wrote: 


> There would be some difficulties in implementing a EXTRA_DATASETS option.
> Mainly to deal with possible different projections and/or different
> georeferenced extents. For example, when inputs are in different
> projections and/or have different extent, should they be
> reprojected/mosaiced to overlap on each other, with a common
> georeferencing, or should they be handled as map insets (a bit like Hawa? is
> represented in a USA map), each one with its own georeferencing info.
> Nothing that can't be solved, but would need some work.

I was thinking about something simple like taking the extents from the master raster layer and clipping extra layers with it. Equivalent to running gdal_translate -projwin ulx uly lrx lry and appending what gets clipped as a new PDF layer. OGR layers are already trimmed this way.

-Jukka Rahkonen-


From elliott at cpi.com  Thu Aug 30 08:10:56 2012
From: elliott at cpi.com (elliott)
Date: Thu, 30 Aug 2012 11:10:56 -0400
Subject: [gdal-dev] Compiling GDAL with HDF5 Support
Message-ID: <503F8280.60206@cpi.com>

Hello,

I have configured gdal 1.9.1 as follows:

./configure --with-python --with-hdf4=/home/hdf-4.2.6/hdf4 
--with-hdf5=/home/hdf5-1.8.9/hdf5

It looks like everything builds successfully.  However, when I try to 
use gdalinfo on a MODIS Land Cover HDF-EOS version 5 file, I get the 
following error:

 > gdalinfo MCD12Q1.A2009001.h28v05.005.2011059194456.hdf
  ERROR 4: 'MCD12Q1.A2009001.h28v05.005.2011059194456.hdf' not 
recognized as a supported file format.

gdalinfo failed - unable to open 
'MCD12Q1.A2009001.h28v05.005.2011059194456.hdf'.

Any ideas on what I am doing wrong?

Thanks


From etourigny.dev at gmail.com  Thu Aug 30 10:29:28 2012
From: etourigny.dev at gmail.com (Etienne Tourigny)
Date: Thu, 30 Aug 2012 14:29:28 -0300
Subject: [gdal-dev] Compiling GDAL with HDF5 Support
In-Reply-To: <503F8280.60206@cpi.com>
References: <503F8280.60206@cpi.com>
Message-ID: <CA+TxYvPvMNywCNMrATDdS-6-eC-ELP26uWApQB2yxzaz38v9iQ@mail.gmail.com>

are you using the gdalinfo that you installed? You can find this out with
which gdalinfo

to make sure that hdf5 support was builtin, try gdalinfo --formats

also when you did configure, did it give you any errors about hdf5?

and try gdalinfo --debug on <file.hdf>

Etienne

On Thu, Aug 30, 2012 at 12:10 PM, elliott <elliott at cpi.com> wrote:
> Hello,
>
> I have configured gdal 1.9.1 as follows:
>
> ./configure --with-python --with-hdf4=/home/hdf-4.2.6/hdf4
> --with-hdf5=/home/hdf5-1.8.9/hdf5
>
> It looks like everything builds successfully.  However, when I try to use
> gdalinfo on a MODIS Land Cover HDF-EOS version 5 file, I get the following
> error:
>
>> gdalinfo MCD12Q1.A2009001.h28v05.005.2011059194456.hdf
>  ERROR 4: 'MCD12Q1.A2009001.h28v05.005.2011059194456.hdf' not recognized as
> a supported file format.
>
> gdalinfo failed - unable to open
> 'MCD12Q1.A2009001.h28v05.005.2011059194456.hdf'.
>
> Any ideas on what I am doing wrong?
>
> Thanks
>
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From lauri.kajan at gmail.com  Thu Aug 30 13:04:33 2012
From: lauri.kajan at gmail.com (Lauri Kajan)
Date: Thu, 30 Aug 2012 23:04:33 +0300
Subject: [gdal-dev] building error on libgdal.so
Message-ID: <CAKWoFM+CfUpFwPzrLLbe3PWEscSaNf6Akcsvih-0e4XjgPWtXQ@mail.gmail.com>

Hi all,

I'm trying to build GDAL 1.9.1 from source on Ubuntu 12.04 but I get an error.
I configured gdal with ./configure --with-threads --with-python
--with-odbc --with-pg

Here is the error message?

libtool: link: g++ .libs/gdal_translate.o .libs/commonutils.o -o
.libs/gdal_translate  /home/l/asennukset/gdal-1.9.1/.libs/libgdal.so
-L/usr/local/lib -L/usr/lib /usr/local/lib/libgeos_c.so
/usr/local/lib/libgeos.so /usr/lib/x86_64-linux-gnu/libexpat.so -lpq
-lz -lpthread -lrt -ldl
/home/l/asennukset/gdal-1.9.1/.libs/libgdal.so: undefined reference to
`OGRCreateExpatXMLParser()'
collect2: ld returned 1 exit status
make[1]: *** [gdal_translate] Error 1
make[1]: *** Waiting for unfinished jobs....
/home/l/asennukset/gdal-1.9.1/.libs/libgdal.so: undefined reference to
`OGRCreateExpatXMLParser()'
collect2: ld returned 1 exit status
make[1]: *** [gdalinfo] Error 1
make[1]: Leaving directory `/home/l/asennukset/gdal-1.9.1/apps'
make: *** [apps-target] Error 2

Am I missing some dependency?
I have already installed Postgis and with that libxml2-dev. If this
has anything to do with that.

Could anybody help me with this?



Thanks

Lauri

From even.rouault at mines-paris.org  Thu Aug 30 13:25:26 2012
From: even.rouault at mines-paris.org (Even Rouault)
Date: Thu, 30 Aug 2012 22:25:26 +0200
Subject: [gdal-dev] building error on libgdal.so
In-Reply-To: <CAKWoFM+CfUpFwPzrLLbe3PWEscSaNf6Akcsvih-0e4XjgPWtXQ@mail.gmail.com>
References: <CAKWoFM+CfUpFwPzrLLbe3PWEscSaNf6Akcsvih-0e4XjgPWtXQ@mail.gmail.com>
Message-ID: <201208302225.26695.even.rouault@mines-paris.org>

Le jeudi 30 ao?t 2012 22:04:33, Lauri Kajan a ?crit :
> Hi all,
> 
> I'm trying to build GDAL 1.9.1 from source on Ubuntu 12.04 but I get an
> error. I configured gdal with ./configure --with-threads --with-python
> --with-odbc --with-pg
> 
> Here is the error message?
> 
> libtool: link: g++ .libs/gdal_translate.o .libs/commonutils.o -o
> .libs/gdal_translate  /home/l/asennukset/gdal-1.9.1/.libs/libgdal.so
> -L/usr/local/lib -L/usr/lib /usr/local/lib/libgeos_c.so
> /usr/local/lib/libgeos.so /usr/lib/x86_64-linux-gnu/libexpat.so -lpq
> -lz -lpthread -lrt -ldl
> /home/l/asennukset/gdal-1.9.1/.libs/libgdal.so: undefined reference to
> `OGRCreateExpatXMLParser()'
> collect2: ld returned 1 exit status
> make[1]: *** [gdal_translate] Error 1
> make[1]: *** Waiting for unfinished jobs....
> /home/l/asennukset/gdal-1.9.1/.libs/libgdal.so: undefined reference to
> `OGRCreateExpatXMLParser()'
> collect2: ld returned 1 exit status
> make[1]: *** [gdalinfo] Error 1
> make[1]: Leaving directory `/home/l/asennukset/gdal-1.9.1/apps'
> make: *** [apps-target] Error 2
> 
> Am I missing some dependency?
> I have already installed Postgis and with that libxml2-dev. If this
> has anything to do with that.
> 
> Could anybody help me with this?

Looks like there is an issue with expat. Shouldn't happen, but perhaps you 
have made several build attempts without proper cleaning. Make sure that you 
have installed the developement package for libexpat, and configure, make 
clean, make

> 
> 
> 
> Thanks
> 
> Lauri
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From zhenchen17 at gmail.com  Thu Aug 30 22:01:53 2012
From: zhenchen17 at gmail.com (chen zhen)
Date: Fri, 31 Aug 2012 13:01:53 +0800
Subject: [gdal-dev] Building gdal 1.9.1 on AIX with
Message-ID: <CAHC6U2WDOFisUSVWT+EZqyTh1X7jNC7b3FP8PAfHS0gaRhp8VA@mail.gmail.com>

Hi All,

I met a compile problem when trying to build gdal 1.9.1 on AIX
platform with xlc toolset. Here is the compile log:

-----------------------------------------------------------------------------------------------------------------------------------------------------
make[2]: Entering directory `/home/sdb/BeyonDB_20/ads_3rlib/gdal/frmts/ers'
/bin/sh /home/sdb/BeyonDB_20/ads_3rlib/gdal/libtool --mode=compile
--tag=CXX xlc_r -q32 -q32  -Wall
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/gcore
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/alg
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr/ogrsf_frmts -I../raw
-DOGR_ENABLED -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
-I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp
-I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp/include
-I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp
-I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp/include  -c -o
../o/ersdataset.lo ersdataset.cpp
libtool: compile:  xlc_r -q32 -q32 -Wall
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/gcore
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/alg
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr
-I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr/ogrsf_frmts -I../raw
-DOGR_ENABLED -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
-I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp
-I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp/include
-I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp
-I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp/include -c ersdataset.cpp
-o ../o/ersdataset.o
xlc_r: 1501-289 (W) Option -Wall was incorrectly specified. The option
will be ignored.
"ersdataset.cpp", line 690.41: 1540-0207 (S) No common type found for
operands with type "CPLString" and "const char [4]".
"ersdataset.cpp", line 691.42: 1540-0207 (S) No common type found for
operands with type "CPLString" and "const char [6]".
"ersdataset.cpp", line 692.42: 1540-0207 (S) No common type found for
operands with type "CPLString" and "const char [7]".
"ersdataset.cpp", line 1048.51: 1540-0207 (S) No common type found for
operands with type "CPLString" and "const char [4]".
"ersdataset.cpp", line 1049.52: 1540-0207 (S) No common type found for
operands with type "CPLString" and "const char [6]".
"ersdataset.cpp", line 1050.52: 1540-0207 (S) No common type found for
operands with type "CPLString" and "const char [7]".
make[2]: *** [../o/ersdataset.lo] Error 1
make[2]: Leaving directory `/home/sdb/BeyonDB_20/ads_3rlib/gdal/frmts/ers'
-------------------------------------------------------------------------------------------------------------------------------------------------------

the correspond source code in ersdataset.cpp is :
-------------------------------------------------------------------------------------------------------------------------------------------------------
    oSRS.importFromERM( osProj.size() ? osProj : "RAW",
                        osDatum.size() ? osDatum : "WGS84",
                        osUnits.size() ? osUnits : "METERS" );
-------------------------------------------------------------------------------------------------------------------------------------------------------

It seems the compiler can't convert a CPLString to a const char []
format. However there is a cast operator in CPLString declaration:

------------------------------------------------------------------------------------------------------------------------------------------------------

    operator const char* (void) const { return c_str(); }
------------------------------------------------------------------------------------------------------------------------------------------------------

I am not sure why the xlc compiler can't recognize this cast
operation, maybe it think const char [] and   const char * are
different?

 I modified the source code a bit which does an explicit cast, it at
least passed the compiling.

-------------------------------------------------------------------------------------------------------------------------------------------------------
    oSRS.importFromERM( osProj.size() ? (const char *)osProj : "RAW",
                        osDatum.size() ? (const char *)osDatum : "WGS84",
                        osUnits.size() ? (const char *)osUnits : "METERS" );
-------------------------------------------------------------------------------------------------------------------------------------------------------

I  am looking for if there is any way working around this issue(such
as adding a compile parameter to xlc) or should this be a patch that
mkes gdal playing will on AIX?

Regards,

zhen

From warmerdam at pobox.com  Thu Aug 30 23:17:52 2012
From: warmerdam at pobox.com (Frank Warmerdam)
Date: Thu, 30 Aug 2012 23:17:52 -0700
Subject: [gdal-dev] Building gdal 1.9.1 on AIX with
In-Reply-To: <CAHC6U2WDOFisUSVWT+EZqyTh1X7jNC7b3FP8PAfHS0gaRhp8VA@mail.gmail.com>
References: <CAHC6U2WDOFisUSVWT+EZqyTh1X7jNC7b3FP8PAfHS0gaRhp8VA@mail.gmail.com>
Message-ID: <50405710.6020606@pobox.com>

On 12-08-30 10:01 PM, chen zhen wrote:
> Hi All,
>
> I met a compile problem when trying to build gdal 1.9.1 on AIX
> platform with xlc toolset. Here is the compile log:
>
> -----------------------------------------------------------------------------------------------------------------------------------------------------
> make[2]: Entering directory `/home/sdb/BeyonDB_20/ads_3rlib/gdal/frmts/ers'
> /bin/sh /home/sdb/BeyonDB_20/ads_3rlib/gdal/libtool --mode=compile
> --tag=CXX xlc_r -q32 -q32  -Wall
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/gcore
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/alg
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr/ogrsf_frmts -I../raw
> -DOGR_ENABLED -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp
> -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp/include
> -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp
> -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp/include  -c -o
> ../o/ersdataset.lo ersdataset.cpp
> libtool: compile:  xlc_r -q32 -q32 -Wall
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/gcore
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/alg
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr
> -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr/ogrsf_frmts -I../raw
> -DOGR_ENABLED -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp
> -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp/include
> -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp
> -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp/include -c ersdataset.cpp
> -o ../o/ersdataset.o
> xlc_r: 1501-289 (W) Option -Wall was incorrectly specified. The option
> will be ignored.
> "ersdataset.cpp", line 690.41: 1540-0207 (S) No common type found for
> operands with type "CPLString" and "const char [4]".
> "ersdataset.cpp", line 691.42: 1540-0207 (S) No common type found for
> operands with type "CPLString" and "const char [6]".
> "ersdataset.cpp", line 692.42: 1540-0207 (S) No common type found for
> operands with type "CPLString" and "const char [7]".
> "ersdataset.cpp", line 1048.51: 1540-0207 (S) No common type found for
> operands with type "CPLString" and "const char [4]".
> "ersdataset.cpp", line 1049.52: 1540-0207 (S) No common type found for
> operands with type "CPLString" and "const char [6]".
> "ersdataset.cpp", line 1050.52: 1540-0207 (S) No common type found for
> operands with type "CPLString" and "const char [7]".
> make[2]: *** [../o/ersdataset.lo] Error 1
> make[2]: Leaving directory `/home/sdb/BeyonDB_20/ads_3rlib/gdal/frmts/ers'
> -------------------------------------------------------------------------------------------------------------------------------------------------------
>
> the correspond source code in ersdataset.cpp is :
> -------------------------------------------------------------------------------------------------------------------------------------------------------
>      oSRS.importFromERM( osProj.size() ? osProj : "RAW",
>                          osDatum.size() ? osDatum : "WGS84",
>                          osUnits.size() ? osUnits : "METERS" );
> -------------------------------------------------------------------------------------------------------------------------------------------------------
>
> It seems the compiler can't convert a CPLString to a const char []
> format. However there is a cast operator in CPLString declaration:
>
> ------------------------------------------------------------------------------------------------------------------------------------------------------
>
>      operator const char* (void) const { return c_str(); }
> ------------------------------------------------------------------------------------------------------------------------------------------------------
>
> I am not sure why the xlc compiler can't recognize this cast
> operation, maybe it think const char [] and   const char * are
> different?
>
>   I modified the source code a bit which does an explicit cast, it at
> least passed the compiling.
>
> -------------------------------------------------------------------------------------------------------------------------------------------------------
>      oSRS.importFromERM( osProj.size() ? (const char *)osProj : "RAW",
>                          osDatum.size() ? (const char *)osDatum : "WGS84",
>                          osUnits.size() ? (const char *)osUnits : "METERS" );
> -------------------------------------------------------------------------------------------------------------------------------------------------------
>
> I  am looking for if there is any way working around this issue(such
> as adding a compile parameter to xlc) or should this be a patch that
> mkes gdal playing will on AIX?

Zhen,

I don't know why this confuses xlc but the work around is harmless
enough so please feel free to submit a patch via trac once the build
completes successfully.

Best regards,


-- 
---------------------------------------+--------------------------------------
I set the clouds in motion - turn up   | Frank Warmerdam, warmerdam at pobox.com
light and sound - activate the windows | http://home.gdal.org/warmerda
and watch the world go round - Rush    | Geospatial Software Developer


From zhenchen17 at gmail.com  Thu Aug 30 23:37:06 2012
From: zhenchen17 at gmail.com (chen zhen)
Date: Fri, 31 Aug 2012 14:37:06 +0800
Subject: [gdal-dev] Building gdal 1.9.1 on AIX with
In-Reply-To: <50405710.6020606@pobox.com>
References: <CAHC6U2WDOFisUSVWT+EZqyTh1X7jNC7b3FP8PAfHS0gaRhp8VA@mail.gmail.com>
	<50405710.6020606@pobox.com>
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAACB7n0ju325JjVt71UKe9THCgAAAEAAAABArMO4eSrpBi7yYp44CuUYBAAAAAA==@gmail.com>

Frank,

Thanks.

Another problem.

I got the similar situation with this post :
http://trac.osgeo.org/gdal/ticket/2375. 

It is caused by minor difference definition in inttypes.h between Linux(
CentOS 6.3 at hand) and AIX (6.1). int32 data type is defined intypes.h on
AIX but not on Linux. There is a conflict in shpopen.c by defining int32 by
hand. There is no good way tell the platform strictly unless adding
preprocessor -DAIX or something like:

#ifndef _H_INTTYPES /* inttypes.h macro on AIX compared to _INTTYPES_H on
Linux */
....
#endif

Any comments?

Regards,

zhen

> -----Original Message-----
> From: gdal-dev-bounces at lists.osgeo.org
> [mailto:gdal-dev-bounces at lists.osgeo.org] On Behalf Of Frank Warmerdam
> Sent: Friday, August 31, 2012 2:18 PM
> To: gdal-dev at lists.osgeo.org
> Subject: Re: [gdal-dev] Building gdal 1.9.1 on AIX with
> 
> On 12-08-30 10:01 PM, chen zhen wrote:
> > Hi All,
> >
> > I met a compile problem when trying to build gdal 1.9.1 on AIX
> > platform with xlc toolset. Here is the compile log:
> >
> > ----------------------------------------------------------------------
> > ----------------------------------------------------------------------
> > ---------
> > make[2]: Entering directory
> `/home/sdb/BeyonDB_20/ads_3rlib/gdal/frmts/ers'
> > /bin/sh /home/sdb/BeyonDB_20/ads_3rlib/gdal/libtool --mode=compile
> > --tag=CXX xlc_r -q32 -q32  -Wall
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/gcore
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/alg
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr/ogrsf_frmts -I../raw
> > -DOGR_ENABLED -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> > -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp
> > -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp/include
> > -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp
> > -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp/include  -c -o
> > ../o/ersdataset.lo ersdataset.cpp
> > libtool: compile:  xlc_r -q32 -q32 -Wall
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/gcore
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/alg
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr
> > -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/ogr/ogrsf_frmts -I../raw
> > -DOGR_ENABLED -I/home/sdb/BeyonDB_20/ads_3rlib/gdal/port
> > -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp
> > -I/home/sdb/BeyonDB_20/ads_3rlib/jpeg/temp/include
> > -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp
> > -I/home/sdb/BeyonDB_20/ads_3rlib/zlib/temp/include -c ersdataset.cpp
> > -o ../o/ersdataset.o
> > xlc_r: 1501-289 (W) Option -Wall was incorrectly specified. The option
> > will be ignored.
> > "ersdataset.cpp", line 690.41: 1540-0207 (S) No common type found for
> > operands with type "CPLString" and "const char [4]".
> > "ersdataset.cpp", line 691.42: 1540-0207 (S) No common type found for
> > operands with type "CPLString" and "const char [6]".
> > "ersdataset.cpp", line 692.42: 1540-0207 (S) No common type found for
> > operands with type "CPLString" and "const char [7]".
> > "ersdataset.cpp", line 1048.51: 1540-0207 (S) No common type found for
> > operands with type "CPLString" and "const char [4]".
> > "ersdataset.cpp", line 1049.52: 1540-0207 (S) No common type found for
> > operands with type "CPLString" and "const char [6]".
> > "ersdataset.cpp", line 1050.52: 1540-0207 (S) No common type found for
> > operands with type "CPLString" and "const char [7]".
> > make[2]: *** [../o/ersdataset.lo] Error 1
> > make[2]: Leaving directory
> `/home/sdb/BeyonDB_20/ads_3rlib/gdal/frmts/ers'
> > ----------------------------------------------------------------------
> > ----------------------------------------------------------------------
> > -----------
> >
> > the correspond source code in ersdataset.cpp is :
> >
>
----------------------------------------------------------------------------
-----------------------
> ----------------------------------------------------
> >      oSRS.importFromERM( osProj.size() ? osProj : "RAW",
> >                          osDatum.size() ? osDatum : "WGS84",
> >                          osUnits.size() ? osUnits : "METERS" );
> > ----------------------------------------------------------------------
> > ----------------------------------------------------------------------
> > -----------
> >
> > It seems the compiler can't convert a CPLString to a const char []
> > format. However there is a cast operator in CPLString declaration:
> >
> > ----------------------------------------------------------------------
> > ----------------------------------------------------------------------
> > ----------
> >
> >      operator const char* (void) const { return c_str(); }
> > ----------------------------------------------------------------------
> > ----------------------------------------------------------------------
> > ----------
> >
> > I am not sure why the xlc compiler can't recognize this cast
> > operation, maybe it think const char [] and   const char * are
> > different?
> >
> >   I modified the source code a bit which does an explicit cast, it at
> > least passed the compiling.
> >
> >
>
----------------------------------------------------------------------------
-----------------------
> ----------------------------------------------------
> >      oSRS.importFromERM( osProj.size() ? (const char *)osProj : "RAW",
> >                          osDatum.size() ? (const char *)osDatum :
> "WGS84",
> >                          osUnits.size() ? (const char *)osUnits :
> > "METERS" );
> > ----------------------------------------------------------------------
> > ----------------------------------------------------------------------
> > -----------
> >
> > I  am looking for if there is any way working around this issue(such
> > as adding a compile parameter to xlc) or should this be a patch that
> > mkes gdal playing will on AIX?
> 
> Zhen,
> 
> I don't know why this confuses xlc but the work around is harmless enough
so
> please feel free to submit a patch via trac once the build completes
> successfully.
> 
> Best regards,
> 
> 
> --
> ---------------------------------------+--------------------------------
> ---------------------------------------+------
> I set the clouds in motion - turn up   | Frank Warmerdam,
> warmerdam at pobox.com
> light and sound - activate the windows | http://home.gdal.org/warmerda
> and watch the world go round - Rush    | Geospatial Software Developer
> 
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev


From taibc_coltech at yahoo.com  Fri Aug 31 02:07:26 2012
From: taibc_coltech at yahoo.com (taibc)
Date: Fri, 31 Aug 2012 02:07:26 -0700 (PDT)
Subject: [gdal-dev] How to convert a .dgn file into image (jpg or bmp)
Message-ID: <1346404046936-4998992.post@n6.nabble.com>

Hi friends,

Do you know how to convert (or save) a .dgn file into a image (such as .jpg
or bmp) ? (by using C/C++ or C#)

I am wanting write a method to do that, so I can store the image into my
database (SQL Server).

Thanks for your help !







--
View this message in context: http://osgeo-org.1560.n6.nabble.com/How-to-convert-a-dgn-file-into-image-jpg-or-bmp-tp4998992.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From jukka.rahkonen at mmmtike.fi  Fri Aug 31 03:39:39 2012
From: jukka.rahkonen at mmmtike.fi (Jukka Rahkonen)
Date: Fri, 31 Aug 2012 10:39:39 +0000 (UTC)
Subject: [gdal-dev] How to convert a .dgn file into image (jpg or bmp)
References: <1346404046936-4998992.post@n6.nabble.com>
Message-ID: <loom.20120831T123855-867@post.gmane.org>

taibc <taibc_coltech <at> yahoo.com> writes:

> 
> Hi friends,
> 
> Do you know how to convert (or save) a .dgn file into a image (such as .jpg
> or bmp) ? (by using C/C++ or C#)

Perhaps http://www.gdal.org/gdal_rasterize.html could be something to start with.

-Jukka Rahkonen-


From dleimbach at zebris.com  Fri Aug 31 04:59:35 2012
From: dleimbach at zebris.com (David1980)
Date: Fri, 31 Aug 2012 04:59:35 -0700 (PDT)
Subject: [gdal-dev] Compilation of gdal for reading hdf4 with python
In-Reply-To: <4E3A7971.30706@nersc.no>
References: <1312386852470-6649238.post@n2.nabble.com>
	<4E3A7971.30706@nersc.no>
Message-ID: <1346414375011-4999046.post@n6.nabble.com>

The link doesnt work anymore, if you happen to read this: Do you know where
this texts are now ?
Im also trying to compile GDAL +HDF4, maybe they could be usefull for me. :)



--
View this message in context: http://osgeo-org.1560.n6.nabble.com/Compilation-of-gdal-for-reading-hdf4-with-python-tp3744051p4999046.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

From etourigny.dev at gmail.com  Fri Aug 31 05:15:43 2012
From: etourigny.dev at gmail.com (Etienne Tourigny)
Date: Fri, 31 Aug 2012 09:15:43 -0300
Subject: [gdal-dev] Compilation of gdal for reading hdf4 with python
In-Reply-To: <1346414375011-4999046.post@n6.nabble.com>
References: <1312386852470-6649238.post@n2.nabble.com>
	<4E3A7971.30706@nersc.no>
	<1346414375011-4999046.post@n6.nabble.com>
Message-ID: <CA+TxYvNNecn8Le2GpG3UANmdzOUvkHhgm1z3eDHS16ist--HHw@mail.gmail.com>

Have you tried the gdal docs on this topic?

http://trac.osgeo.org/gdal/wiki/HDF
http://www.gdal.org/frmt_hdf4.html

Etienne

On Fri, Aug 31, 2012 at 8:59 AM, David1980 <dleimbach at zebris.com> wrote:
> The link doesnt work anymore, if you happen to read this: Do you know where
> this texts are now ?
> Im also trying to compile GDAL +HDF4, maybe they could be usefull for me. :)
>
>
>
> --
> View this message in context: http://osgeo-org.1560.n6.nabble.com/Compilation-of-gdal-for-reading-hdf4-with-python-tp3744051p4999046.html
> Sent from the GDAL - Dev mailing list archive at Nabble.com.
> _______________________________________________
> gdal-dev mailing list
> gdal-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/gdal-dev

From dlopezaspe at gmail.com  Fri Aug 31 07:47:01 2012
From: dlopezaspe at gmail.com (sigologo)
Date: Fri, 31 Aug 2012 07:47:01 -0700 (PDT)
Subject: [gdal-dev] batch for mean by gdal_calc
In-Reply-To: <CAKoiDHLZKGMOYhvG9w6BzFPu2t+zmhhyBFSNUz0VLBGyb2uGMQ@mail.gmail.com>
References: <1345609966289-4996911.post@n6.nabble.com>
	<CAKoiDHLZKGMOYhvG9w6BzFPu2t+zmhhyBFSNUz0VLBGyb2uGMQ@mail.gmail.com>
Message-ID: <1346424421295-4999080.post@n6.nabble.com>

Thanks a Lot Giuseppe....
 Great link... but I have the question?????
is possible calculated Standard Deviation with oft-cal..................... 
 
Regards




--
View this message in context: http://osgeo-org.1560.n6.nabble.com/batch-for-mean-by-gdal-calc-tp4996911p4999080.html
Sent from the GDAL - Dev mailing list archive at Nabble.com.

