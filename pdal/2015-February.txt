From o.martinezrubi at tudelft.nl  Wed Feb  4 01:37:24 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 04 Feb 2015 10:37:24 +0100
Subject: [pdal] pgpointcloud selector filter and max_capacity
Message-ID: <54D1E854.5050705@tudelft.nl>

Hi,

After 1.5 years using an old PDAL installation I convinced myself to try 
the latest one.

The first issue I encountered is that since a while ago, PDAL uses c++11 
features, and the gcc that comes with CentOS 6 was not happy with that, 
so I had to install a newer gcc from source (4.8) in order to make it 
compile. Also I had to use boost 1.55 (1.57 was also giving some problems)

I use PDAL to load in postgres,so I use the pgpointcloud plugin. In the 
latest PDAL I miss a couple of things that I can not find anymore:

1 - The selector filter. I only want to load X, Y and Z. How can I do 
that in current PDAL?
2 - There seems to be a hardcoded maximum of 400 points per patch in the 
pgpointcloud writer. I know that is the recommended patch size but for 
massive point clouds I use larger number which use to be possible with 
older PDALs but not anymore.

Thanks!

Regards,

Oscar

From o.martinezrubi at tudelft.nl  Wed Feb  4 05:37:43 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 04 Feb 2015 14:37:43 +0100
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <54D1E854.5050705@tudelft.nl>
References: <54D1E854.5050705@tudelft.nl>
Message-ID: <54D220A7.5010100@tudelft.nl>

Hi,

About the capacity I found out that i need to specify the capacity in 
both writter and chipper.

Still do not know how to select only x,y,z?

I was also trying to use scale_x,y,z but it crashes when inserting the 
patch. Did somebody managed to do this?

My XML looked like this:

<?xml version="1.0" encoding="utf-8"?>
<Pipeline version="1.0">
     <Writer type="writers.pgpointcloud">
         <Option name="connection">
              dbname='pf20' user='oscar'
         </Option>
         <Option name="table">patches</Option>
         <Option name="compression">dimensional</Option>
         <Option name="capacity">3000</Option>
         <Option name="srid">28992</Option>
         <Option name="scale_x">0.01</Option>
         <Option name="scale_y">0.01</Option>
         <Option name="scale_z">0.01</Option>
         <Filter type="filters.chipper">
             <Option name="capacity">3000</Option>
             <Reader type="readers.las">
                 <Option 
name="filename">/home/oscar/ahn_minibench.laz</Option>
                 <Option name="spatialreference">EPSG:28992</Option>
             </Reader>
         </Filter>
     </Writer>
</Pipeline>

Thanks,

O.



On 04-02-15 10:37, Oscar Martinez Rubi wrote:
> Hi,
>
> After 1.5 years using an old PDAL installation I convinced myself to 
> try the latest one.
>
> The first issue I encountered is that since a while ago, PDAL uses 
> c++11 features, and the gcc that comes with CentOS 6 was not happy 
> with that, so I had to install a newer gcc from source (4.8) in order 
> to make it compile. Also I had to use boost 1.55 (1.57 was also giving 
> some problems)
>
> I use PDAL to load in postgres,so I use the pgpointcloud plugin. In 
> the latest PDAL I miss a couple of things that I can not find anymore:
>
> 1 - The selector filter. I only want to load X, Y and Z. How can I do 
> that in current PDAL?
> 2 - There seems to be a hardcoded maximum of 400 points per patch in 
> the pgpointcloud writer. I know that is the recommended patch size but 
> for massive point clouds I use larger number which use to be possible 
> with older PDALs but not anymore.
>
> Thanks!
>
> Regards,
>
> Oscar
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal


From andrew.bell.ia at gmail.com  Wed Feb  4 07:04:57 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 4 Feb 2015 09:04:57 -0600
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <54D220A7.5010100@tudelft.nl>
References: <54D1E854.5050705@tudelft.nl>
	<54D220A7.5010100@tudelft.nl>
Message-ID: <CACJ51z2VwGzEyAVM5AkiOs4O4ps=WLZX5ythmQ9UhG4th0jRaQ@mail.gmail.com>

On Wed, Feb 4, 2015 at 7:37 AM, Oscar Martinez Rubi <
o.martinezrubi at tudelft.nl> wrote:

> Hi,
>
> About the capacity I found out that i need to specify the capacity in both
> writter and chipper.
>
> Still do not know how to select only x,y,z?
>

Hi Oscar,

Thanks for giving the code a try.

Right now there isn't a way to select dimensions for write.  I'll add some
option to the writer to select the dimensions.

I was also trying to use scale_x,y,z but it crashes when inserting the
> patch. Did somebody managed to do this?
>

Please report the bug with some detail if things aren't working for you.
I'm not sure that the postgres driver has gotten much of a workout since
the scaling code was added.  I'll try your pipeline.

<?xml version="1.0" encoding="utf-8"?>
> <Pipeline version="1.0">
>     <Writer type="writers.pgpointcloud">
>         <Option name="connection">
>              dbname='pf20' user='oscar'
>         </Option>
>         <Option name="table">patches</Option>
>         <Option name="compression">dimensional</Option>
>         <Option name="capacity">3000</Option>
>         <Option name="srid">28992</Option>
>         <Option name="scale_x">0.01</Option>
>         <Option name="scale_y">0.01</Option>
>         <Option name="scale_z">0.01</Option>
>         <Filter type="filters.chipper">
>             <Option name="capacity">3000</Option>
>             <Reader type="readers.las">
>                 <Option name="filename">/home/oscar/
> ahn_minibench.laz</Option>
>                 <Option name="spatialreference">EPSG:28992</Option>
>             </Reader>
>         </Filter>
>     </Writer>
> </Pipeline>
>

Also, I don't think anyone has tried boost 1.57 that I'm aware of.  We're
trying to purge boost from our code because of issues like this, but we
haven't gotten there yet.  I'll build it and try.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/f4bddc44/attachment.html>

From howard at hobu.co  Wed Feb  4 07:11:54 2015
From: howard at hobu.co (Howard Butler)
Date: Wed, 4 Feb 2015 09:11:54 -0600
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <54D1E854.5050705@tudelft.nl>
References: <54D1E854.5050705@tudelft.nl>
Message-ID: <C3CC2DC2-8EB1-494F-9EE8-C474F51AA568@hobu.co>


> On Feb 4, 2015, at 3:37 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
> 
> 2 - There seems to be a hardcoded maximum of 400 points per patch in the pgpointcloud writer. I know that is the recommended patch size but for massive point clouds I use larger number which use to be possible with older PDALs but not anymore.

> About the capacity I found out that i need to specify the capacity in both writter and chipper.

Because of the way PDAL used to work, you needed to specify the patch size on both the writer and the filters.chipper. That doesn't have to be the case anymore (but still is). The issue that's left is how to communicate the filter's capacity down to the pgpointcloud writer...

I would note that during my tests, there was a huge performance penalty for patches greater than a database page size due to the way that toast works [1]. With compression turned on, this will allow you to have more points per patch, but I think you still want their total storage to be less than the page size if you can help it.

Howard


[1] http://www.postgresql.org/docs/9.4/static/storage-toast.html

From andrew.bell.ia at gmail.com  Wed Feb  4 07:26:20 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 4 Feb 2015 09:26:20 -0600
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <C3CC2DC2-8EB1-494F-9EE8-C474F51AA568@hobu.co>
References: <54D1E854.5050705@tudelft.nl>
	<C3CC2DC2-8EB1-494F-9EE8-C474F51AA568@hobu.co>
Message-ID: <CACJ51z0S0SeOuXArq5XGAD2P+jfWDiQhJ-6=f87oQ_EKD=Oinw@mail.gmail.com>

On Wed, Feb 4, 2015 at 9:11 AM, Howard Butler <howard at hobu.co> wrote:

>
> > On Feb 4, 2015, at 3:37 AM, Oscar Martinez Rubi <
> O.MartinezRubi at tudelft.nl> wrote:
> >
> > 2 - There seems to be a hardcoded maximum of 400 points per patch in the
> pgpointcloud writer. I know that is the recommended patch size but for
> massive point clouds I use larger number which use to be possible with
> older PDALs but not anymore.
>
> > About the capacity I found out that i need to specify the capacity in
> both writter and chipper.
>
> Because of the way PDAL used to work, you needed to specify the patch size
> on both the writer and the filters.chipper. That doesn't have to be the
> case anymore (but still is). The issue that's left is how to communicate
> the filter's capacity down to the pgpointcloud writer...
>

We can eliminate the capacity option on the pgwriter, since it assumes
things are already chipped/split.  If we wanted to remove that assumption,
we'd have to do something else.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/c8621351/attachment.html>

From o.martinezrubi at tudelft.nl  Wed Feb  4 07:36:17 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 04 Feb 2015 16:36:17 +0100
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <C3CC2DC2-8EB1-494F-9EE8-C474F51AA568@hobu.co>
References: <54D1E854.5050705@tudelft.nl>
	<C3CC2DC2-8EB1-494F-9EE8-C474F51AA568@hobu.co>
Message-ID: <54D23C71.3030903@tudelft.nl>

Thanks for your response!

Well, about the optimal block size. I did a test 1 year ago that 
suggested that using small blocks (fitting to page size) was not as 
beneficial as one would imagine.

I loaded two datasets, one with 20 million points and another with 210 
million points with both compression and without it.

And I tried with different block sizes (from 300 to 5000) to both load 
and query the data.

In the loading (with PDAL) I only saw benefit of using small blocks in 
the loading of the small dataset and if dimensional compression was 
used. In the rest of cases (uncompressed and/or larger dataset) using 
larger blocks was faster in loading. See attached figure.

In the queries, only some complex queries (query 6 in the graph) has 
benefit from smaller block sizes. Other not-so-complex queries (query 2 
and 4 in the graphs) such as rectangles benefit from larger sizes.

Since then, I have been using a block size of around 3000.

O.


On 04-02-15 16:11, Howard Butler wrote:
>> On Feb 4, 2015, at 3:37 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
>>
>> 2 - There seems to be a hardcoded maximum of 400 points per patch in the pgpointcloud writer. I know that is the recommended patch size but for massive point clouds I use larger number which use to be possible with older PDALs but not anymore.
>> About the capacity I found out that i need to specify the capacity in both writter and chipper.
> Because of the way PDAL used to work, you needed to specify the patch size on both the writer and the filters.chipper. That doesn't have to be the case anymore (but still is). The issue that's left is how to communicate the filter's capacity down to the pgpointcloud writer...
>
> I would note that during my tests, there was a huge performance penalty for patches greater than a database page size due to the way that toast works [1]. With compression turned on, this will allow you to have more points per patch, but I think you still want their total storage to be less than the page size if you can help it.
>
> Howard
>
>
> [1] http://www.postgresql.org/docs/9.4/static/storage-toast.html

-------------- next part --------------
A non-text attachment was scrubbed...
Name: sol1_querying_time.png
Type: image/png
Size: 89430 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/cc0e35f2/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: sol1_loading.png
Type: image/png
Size: 58656 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/cc0e35f2/attachment-0003.png>

From o.martinezrubi at tudelft.nl  Wed Feb  4 08:02:49 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 04 Feb 2015 17:02:49 +0100
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <CACJ51z2VwGzEyAVM5AkiOs4O4ps=WLZX5ythmQ9UhG4th0jRaQ@mail.gmail.com>
References: <54D1E854.5050705@tudelft.nl>	<54D220A7.5010100@tudelft.nl>
	<CACJ51z2VwGzEyAVM5AkiOs4O4ps=WLZX5ythmQ9UhG4th0jRaQ@mail.gmail.com>
Message-ID: <54D242A9.8050708@tudelft.nl>

Good idea to try to purge boost!

At some point I though that the selection of dimensions could be done 
when I insert the point cloud format in the DB (I only insert a format 
with X,Y,Z) but I found out that after running PDAL the one I inserted 
is ignored and a new format with all the dimensions is used. So, we 
definitively need a way to tell the writter which columns are desired.

Just to be clear, the scale_x..., is supposed to be specified in the 
PDAL pipeline XML or in the point cloud format inserted in the DB or in 
both?

Well, I attach the sql file I execute to set the DB
and the pipeline xml I am using to run pdal pipeline.

With these ones I get a PDAL: ERROR:  unterminated quoted string at or 
near "....
Looks like mismatch between expected format and the actual block format

O.


On 04-02-15 16:04, Andrew Bell wrote:
> On Wed, Feb 4, 2015 at 7:37 AM, Oscar Martinez Rubi 
> <o.martinezrubi at tudelft.nl <mailto:o.martinezrubi at tudelft.nl>> wrote:
>
>     Hi,
>
>     About the capacity I found out that i need to specify the capacity
>     in both writter and chipper.
>
>     Still do not know how to select only x,y,z?
>
>
> Hi Oscar,
>
> Thanks for giving the code a try.
>
> Right now there isn't a way to select dimensions for write.  I'll add 
> some option to the writer to select the dimensions.
>
>     I was also trying to use scale_x,y,z but it crashes when inserting
>     the patch. Did somebody managed to do this?
>
>
> Please report the bug with some detail if things aren't working for 
> you.  I'm not sure that the postgres driver has gotten much of a 
> workout since the scaling code was added.  I'll try your pipeline.
>
>     <?xml version="1.0" encoding="utf-8"?>
>     <Pipeline version="1.0">
>         <Writer type="writers.pgpointcloud">
>             <Option name="connection">
>                  dbname='pf20' user='oscar'
>             </Option>
>             <Option name="table">patches</Option>
>             <Option name="compression">dimensional</Option>
>             <Option name="capacity">3000</Option>
>             <Option name="srid">28992</Option>
>             <Option name="scale_x">0.01</Option>
>             <Option name="scale_y">0.01</Option>
>             <Option name="scale_z">0.01</Option>
>             <Filter type="filters.chipper">
>                 <Option name="capacity">3000</Option>
>                 <Reader type="readers.las">
>                     <Option
>     name="filename">/home/oscar/ahn_minibench.laz</Option>
>                     <Option name="spatialreference">EPSG:28992</Option>
>                 </Reader>
>             </Filter>
>         </Writer>
>     </Pipeline>
>
>
> Also, I don't think anyone has tried boost 1.57 that I'm aware of.  
> We're trying to purge boost from our code because of issues like this, 
> but we haven't gotten there yet.  I'll build it and try.
>
> -- 
> Andrew Bell
> andrew.bell.ia at gmail.com <mailto:andrew.bell.ia at gmail.com>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/b86cab65/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: init.sql
Type: application/sql
Size: 1720 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/b86cab65/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: pdal_pipeline.xml
Type: text/xml
Size: 740 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/b86cab65/attachment.xml>

From andrew.bell.ia at gmail.com  Wed Feb  4 15:12:49 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 4 Feb 2015 17:12:49 -0600
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <54D242A9.8050708@tudelft.nl>
References: <54D1E854.5050705@tudelft.nl> <54D220A7.5010100@tudelft.nl>
	<CACJ51z2VwGzEyAVM5AkiOs4O4ps=WLZX5ythmQ9UhG4th0jRaQ@mail.gmail.com>
	<54D242A9.8050708@tudelft.nl>
Message-ID: <CACJ51z2Bz4HVBpQKG72hDhNCfWwAn-ZCA14fad2nRAv+TXNQgw@mail.gmail.com>

On Wed, Feb 4, 2015 at 10:02 AM, Oscar Martinez Rubi <
o.martinezrubi at tudelft.nl> wrote:

> At some point I though that the selection of dimensions could be done when
> I insert the point cloud format in the DB (I only insert a format with
> X,Y,Z) but I found out that after running PDAL the one I inserted is
> ignored and a new format with all the dimensions is used. So, we
> definitively need a way to tell the writter which columns are desired.
>
> Just to be clear, the scale_x..., is supposed to be specified in the PDAL
> pipeline XML or in the point cloud format inserted in the DB or in both?
>

You specify this in the pipeline and the values are stored as integers with
a scaling factor instead of as double.  I'll document.

Well, I attach the sql file I execute to set the DB
> and the pipeline xml I am using to run pdal pipeline.
>
> With these ones I get a PDAL: ERROR:  unterminated quoted string at or
> near "....
> Looks like mismatch between expected format and the actual block format
>

I fixed this bug and it has been merged to the master branch in github.

Also, I have selector-type behavior working and I should have that in for
the database drivers tomorrow.

Best,

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150204/2f5abccd/attachment.html>

From O.MartinezRubi at tudelft.nl  Thu Feb  5 00:44:13 2015
From: O.MartinezRubi at tudelft.nl (Oscar Martinez Rubi)
Date: Thu, 5 Feb 2015 08:44:13 +0000
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <CACJ51z2Bz4HVBpQKG72hDhNCfWwAn-ZCA14fad2nRAv+TXNQgw@mail.gmail.com>
References: <54D1E854.5050705@tudelft.nl>	<54D220A7.5010100@tudelft.nl>
	<CACJ51z2VwGzEyAVM5AkiOs4O4ps=WLZX5ythmQ9UhG4th0jRaQ@mail.gmail.com>
	<54D242A9.8050708@tudelft.nl>,
	<CACJ51z2Bz4HVBpQKG72hDhNCfWwAn-ZCA14fad2nRAv+TXNQgw@mail.gmail.com>
Message-ID: <96abw2lclxum5jovxjbqfycy.1423125848493@email.android.com>

That was fast! Thanks
I will pull latest pdal and give it a try.
Let me know how the selector works and i will also try that one.
Regards
O.


Enviado de Samsung Mobile


-------- Mensaje original --------
De: Andrew Bell
Fecha:05/02/2015 00:12 (GMT+01:00)
Para: Oscar Martinez Rubi
Cc: pdal at lists.osgeo.org
Asunto: Re: [pdal] pgpointcloud selector filter and max_capacity

On Wed, Feb 4, 2015 at 10:02 AM, Oscar Martinez Rubi <o.martinezrubi at tudelft.nl<mailto:o.martinezrubi at tudelft.nl>> wrote:
At some point I though that the selection of dimensions could be done when I insert the point cloud format in the DB (I only insert a format with X,Y,Z) but I found out that after running PDAL the one I inserted is ignored and a new format with all the dimensions is used. So, we definitively need a way to tell the writter which columns are desired.

Just to be clear, the scale_x..., is supposed to be specified in the PDAL pipeline XML or in the point cloud format inserted in the DB or in both?

You specify this in the pipeline and the values are stored as integers with a scaling factor instead of as double.  I'll document.

Well, I attach the sql file I execute to set the DB
and the pipeline xml I am using to run pdal pipeline.

With these ones I get a PDAL: ERROR:  unterminated quoted string at or near "....
Looks like mismatch between expected format and the actual block format

I fixed this bug and it has been merged to the master branch in github.

Also, I have selector-type behavior working and I should have that in for the database drivers tomorrow.

Best,

--
Andrew Bell
andrew.bell.ia at gmail.com<mailto:andrew.bell.ia at gmail.com>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150205/15c0c80a/attachment.html>

From mhanson at appliedgeosolutions.com  Fri Feb  6 12:13:06 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Fri, 6 Feb 2015 15:13:06 -0500
Subject: [pdal] Setting SRS on las file
Message-ID: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>

We have las files that have no spatial reference embedded in the file.
For one, I'm not sure it's necessary to actually add the spatial reference
to the las file.  We want to create DEM's, so perhaps it's better to just
leave them as is then set the SRS on the final GeoTiffs.

However, for the moment assuming that this makes sense, when I run pdal
translate
$ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX

I get a file that is bigger than the original because it's seemed to add 4
new dimensions: Time, Red, Green, Blue.   The original file did not have
them, although I notice that lasinfo reports min and max for all those
fields in both files, even though they are missing from the original.

Are these standard dimensions in las files, and is there any way to control
if they are added or not?    If we want to add the SRS to files, I'd rather
not increase the size of them all.  Although maybe this is moot since, as
per above, it just doesn't make sense to add the SRS anyway.

Thanks,

Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150206/bbe45019/attachment.html>

From mhanson at appliedgeosolutions.com  Fri Feb  6 13:00:06 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Fri, 6 Feb 2015 16:00:06 -0500
Subject: [pdal] ground filtering
Message-ID: <CA+BxjXJUxKFhQy_bx+irDeg5p35y_qqrRKgTLgP4_QviSCb-tg@mail.gmail.com>

Hello,

While pdal ground seems to work fine, I'm trying to get it to work with
pdal pcl and PCL Block JSON, so we can test out different parameters.

However, when I run it using the simple example from the online docs:

$ pdal pcl -i input.las -o output.las -p PMFsimple.json -v4

with this JSON*:

{
    "pipeline":
    {
        "name": "ProgressiveMorphologicalFilterExample",
        "filters":
        [
            {
                "name": "ProgressiveMorphologicalFilter",
                "setMaxWindowSize": 200
            }
        ]
    }}


I get an error:
####################################################
NAME:   ProgressiveMorphologicalFilterExample ()
HELP:
AUTHOR:
--------------------------------------------------------------------------------
process tile 0 through the pipeline

   Step 1) ProgressiveMorphologicalFilter

      max window size: 200
      slope: 1.000000
      max distance: 2.500000
      initial distance: 0.150000
      cell size: 1.000000
      base: 2.000000
      exponential: true
      negative: false
      Iteration 0 (height threshold = 0.150000, window size =
3.000000)...ground now has 108129 points
      Iteration 1 (height threshold = 2.150000, window size =
5.000000)...ground now has 79939 points
      Iteration 2 (height threshold = 2.500000, window size =
9.000000)...ground now has 78532 points
      Iteration 3 (height threshold = 2.500000, window size =
17.000000)...ground now has 78243 points
      Iteration 4 (height threshold = 2.500000, window size =
33.000000)...ground now has 77934 points
      Iteration 5 (height threshold = 2.500000, window size =
65.000000)...ground now has 77537 points
      Iteration 6 (height threshold = 2.500000, window size =
129.000000)...ground now has 77127 points
      Iteration 7 (height threshold = 2.500000, window size =
257.000000)...ground now has 76664 points
      1069983 points filtered to 76664 following progressive morphological
filter
tile 0 filtered to 76664 points, adding to output, which now has 76664
points

.simplepfm-test.las: Found invalid value of '0' for point's return number.
simplepfm-test.las: Found invalid value of '0' for point's number of
returns.
.............................................simplepfm-test.las: Found
invalid value of '28' for point's return number.
simplepfm-test.las: Found invalid value of '224' for point's number of
returns.
Caught PDAL exception: Unable to fetch data and convert as requested:
ScanAngleRank:float(-4.72698e+19) -> signed char
###############################################

Which is similar to the error I was getting with pdal ground a few weeks
ago before it was kindly fixed by the devs.   So I'm wondering if perhaps
this JSON is out of date and there is some additional information required?

Thanks in advance!



* there's a syntax error in the JSON provided on the website with the
commas, this one is fixed



Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150206/5d85e0f6/attachment.html>

From mhanson at appliedgeosolutions.com  Fri Feb  6 13:24:55 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Fri, 6 Feb 2015 16:24:55 -0500
Subject: [pdal] SegFault with p2g pipeline
Message-ID: <CA+BxjX+jwc1gsS9Wy5KP2OGm_tZichYiON4V+8AntQSO2Jm5jw@mail.gmail.com>

Hello,

I'm currently trying to generate a tif file from a simple test las file.
For now I'm just trying to spit out a tif of point density:
#####################################
<?xml version="1.0" encoding="utf-8"?>
<Pipeline version="1.0">
  <Writer type="writers.p2g">
    <Option name="grid_dist_x">
      1.0
    </Option>
    <Option name="grid_dist_y">
      1.0
    </Option>
    <Option name="radius">
      3.0
    </Option>
    <Option name="filename">
      p2g-test
    </Options>
    <Option name="output_type">
      den
    </Option>
    <Option name="output_format">
      tif
    </Option>
        <Reader type="readers.las">
          <Option name="filename">
            input.las
          </Option>
        </Reader>
  </Writer>
</Pipeline>
#####################################

Unfortunately I get a segfault in the output:
#####################################
(writers.p2g Debug: 3): X grid size: 522
(writers.p2g Debug: 3): Y grid size: 495
(writers.p2g Debug: 3): X grid distance: 1.000000
(writers.p2g Debug: 3): Y grid distance: 1.000000
numFiles 1
[0,494]
[0,494]
0. file size: 18604080
0: from 0 to 258390
0: from 0 to 495
Merging 0: from 0 to 495
        0: from 0 to 0
Merging 0: from 0 to 495
        0: from 0 to 0
Output Execution time: 0.014058
Segmentation fault (core dumped)

real 0m8.603s
user 0m7.747s
sys 0m0.619s
#####################################

Any clues on what could be going wrong?

Thanks in advance!


Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150206/99668381/attachment.html>

From pete.gadomski at gmail.com  Fri Feb  6 17:08:25 2015
From: pete.gadomski at gmail.com (pete.gadomski at gmail.com)
Date: Fri, 06 Feb 2015 17:08:25 -0800 (PST)
Subject: [pdal] SegFault with p2g pipeline
In-Reply-To: <CA+BxjX+jwc1gsS9Wy5KP2OGm_tZichYiON4V+8AntQSO2Jm5jw@mail.gmail.com>
References: <CA+BxjX+jwc1gsS9Wy5KP2OGm_tZichYiON4V+8AntQSO2Jm5jw@mail.gmail.com>
Message-ID: <1423271305118.f64570cc@Nodemailer>

Hello Matthew,




I can't reproduce your results from the information provided. A PDAL+points2grid run works a-ok on my local system.




Can you provide PDAL and points2grid versions? If you're on a Unix-style and have points2grid installed to /usr/local you can do:




? ? cat /usr/local/include/points2grid/config.h | grep P2G_VERSION_STRING




For PDAL:




? ? pdal --version




That might help track things down.




Cheers,

Pete


-- 
Pete GadomskiPhysical Scientist

Cold Regions Research & Engineering Lab

pete.gadomski at gmail.com

530.440.4630

On Fri, Feb 6, 2015 at 3:25 PM, Matthew Hanson
<mhanson at appliedgeosolutions.com> wrote:

> Hello,
> I'm currently trying to generate a tif file from a simple test las file.
> For now I'm just trying to spit out a tif of point density:
> #####################################
> <?xml version="1.0" encoding="utf-8"?>
> <Pipeline version="1.0">
>   <Writer type="writers.p2g">
>     <Option name="grid_dist_x">
>       1.0
>     </Option>
>     <Option name="grid_dist_y">
>       1.0
>     </Option>
>     <Option name="radius">
>       3.0
>     </Option>
>     <Option name="filename">
>       p2g-test
>     </Options>
>     <Option name="output_type">
>       den
>     </Option>
>     <Option name="output_format">
>       tif
>     </Option>
>         <Reader type="readers.las">
>           <Option name="filename">
>             input.las
>           </Option>
>         </Reader>
>   </Writer>
> </Pipeline>
> #####################################
> Unfortunately I get a segfault in the output:
> #####################################
> (writers.p2g Debug: 3): X grid size: 522
> (writers.p2g Debug: 3): Y grid size: 495
> (writers.p2g Debug: 3): X grid distance: 1.000000
> (writers.p2g Debug: 3): Y grid distance: 1.000000
> numFiles 1
> [0,494]
> [0,494]
> 0. file size: 18604080
> 0: from 0 to 258390
> 0: from 0 to 495
> Merging 0: from 0 to 495
>         0: from 0 to 0
> Merging 0: from 0 to 495
>         0: from 0 to 0
> Output Execution time: 0.014058
> Segmentation fault (core dumped)
> real 0m8.603s
> user 0m7.747s
> sys 0m0.619s
> #####################################
> Any clues on what could be going wrong?
> Thanks in advance!
> Matthew Hanson
> Applied GeoSolutions
> (603) 659-3363 x91
> http://appliedgeosolutions.com
> mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150206/d2ec9183/attachment-0001.html>

From howard at hobu.co  Sun Feb  8 07:55:01 2015
From: howard at hobu.co (Howard Butler)
Date: Sun, 8 Feb 2015 09:55:01 -0600
Subject: [pdal] Setting SRS on las file
In-Reply-To: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>
References: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>
Message-ID: <2DC0D25B-5168-48F5-89EF-4E4AB6C5AAC4@hobu.co>


> On Feb 6, 2015, at 2:13 PM, Matthew Hanson <mhanson at appliedgeosolutions.com> wrote:
> 
> 
> We have las files that have no spatial reference embedded in the file.   For one, I'm not sure it's necessary to actually add the spatial reference to the las file.  We want to create DEM's, so perhaps it's better to just leave them as is then set the SRS on the final GeoTiffs.
> 
> However, for the moment assuming that this makes sense, when I run pdal translate
> $ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX
> 
> I get a file that is bigger than the original because it's seemed to add 4 new dimensions: Time, Red, Green, Blue.   The original file did not have them, although I notice that lasinfo reports min and max for all those fields in both files, even though they are missing from the original.
> 
> Are these standard dimensions in las files, and is there any way to control if they are added or not?  

Control it with the "format" option, and set it to 0 if you don't want Time or RGB. It defaults to 3, which includes those dimensions. 

> $ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX --writers.las.format=0


>  If we want to add the SRS to files, I'd rather not increase the size of them all.  Although maybe this is moot since, as per above, it just doesn't make sense to add the SRS anyway.

It is probably easiest to leave the SRS alone until the final GeoTIFF write (and then set it with a GDAL VRT). The only advantage of setting it on the file before processing is so you don't have to do it in a later step.

Another problem here is setting the SRS is going to cause a rewrite of the entire file due to the VLRs needing to be modified. This is one entire extra i/o step that's not needed.

Hope this helps,

Howard


From o.martinezrubi at tudelft.nl  Mon Feb  9 02:43:31 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Mon, 09 Feb 2015 11:43:31 +0100
Subject: [pdal] pgpointcloud selector filter and max_capacity
In-Reply-To: <96abw2lclxum5jovxjbqfycy.1423125848493@email.android.com>
References: <54D1E854.5050705@tudelft.nl>	<54D220A7.5010100@tudelft.nl>	<CACJ51z2VwGzEyAVM5AkiOs4O4ps=WLZX5ythmQ9UhG4th0jRaQ@mail.gmail.com>	<54D242A9.8050708@tudelft.nl>,
	<CACJ51z2Bz4HVBpQKG72hDhNCfWwAn-ZCA14fad2nRAv+TXNQgw@mail.gmail.com>
	<96abw2lclxum5jovxjbqfycy.1423125848493@email.android.com>
Message-ID: <54D88F53.3080504@tudelft.nl>

Hi Andrew,

I have been testing with the scale, selector and the new stuff and 
everything works perfectly! Thanks!

As an example for other people which may be interested in how to make it 
work:

createdb testdb
psql testdb -f init.sql
pdal pipeline pipeline.xml

This stores only x, y and z as int_32 with dimensional compression and 
block size of 3000 points

Regards,

O.

-----
where init.sql is:

CREATE EXTENSION postgis;
CREATE EXTENSION pointcloud;
CREATE EXTENSION pointcloud_postgis;
INSERT INTO pointcloud_formats (pcid, srid, schema) VALUES (1, 28992,
'<?xml version="1.0" encoding="UTF-8"?>
  <pc:PointCloudSchema xmlns:pc="http://pointcloud.org/schemas/PC/" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
<pc:dimension>
<pc:position>1</pc:position>
<pc:size>4</pc:size>
    <pc:description>X coordinate</pc:description>
<pc:scale>0.01</pc:scale>
<pc:offset>0</pc:offset>
<pc:name>X</pc:name>
<pc:interpretation>int32_t</pc:interpretation>
<pc:active>true</pc:active>
</pc:dimension>
<pc:dimension>
<pc:position>2</pc:position>
<pc:size>4</pc:size>
    <pc:description>Y coordinate</pc:description>
<pc:scale>0.01</pc:scale>
<pc:offset>0</pc:offset>
<pc:name>Y</pc:name>
<pc:interpretation>int32_t</pc:interpretation>
<pc:active>true</pc:active>
</pc:dimension>
<pc:dimension>
<pc:position>3</pc:position>
<pc:size>4</pc:size>
    <pc:description>Z coordinate</pc:description>
<pc:scale>0.01</pc:scale>
<pc:offset>0</pc:offset>
<pc:name>Z</pc:name>
<pc:interpretation>int32_t</pc:interpretation>
<pc:active>true</pc:active>
</pc:dimension>
<pc:metadata>
  <Metadata name="compression" 
type="string">dimensional</Metadata></pc:metadata>
<pc:orientation>point</pc:orientation>
  </pc:PointCloudSchema>');

CREATE TABLE patches (
     id SERIAL PRIMARY KEY,
     pa PCPATCH(1)
);

-----

and pipeline.xml is:

<?xml version="1.0" encoding="utf-8"?>
<Pipeline version="1.0">
     <Writer type="writers.pgpointcloud">
         <Option name="connection">dbname='testdb'</Option>
         <Option name="table">patches</Option>
         <Option name="column">pa</Option>
         <Option name="srid">28992</Option>
         <Option name="overwrite">false</Option>
         <Option name="pcid">1</Option>
         <Option name="capacity">3000</Option>
         <Option name="compression">dimensional</Option>
         <Option name="output_dims">X,Y,Z</Option>
         <Option name="offset_x">0</Option>
         <Option name="offset_y">0</Option>
         <Option name="offset_z">0</Option>
         <Option name="scale_x">0.01</Option>
         <Option name="scale_y">0.01</Option>
         <Option name="scale_z">0.01</Option>
         <Filter type="filters.chipper">
             <Option name="capacity">3000</Option>
             <Reader type="readers.las">
                 <Option 
name="filename">/home/oscar/ahn_minibench.laz</Option>
                 <Option name="spatialreference">EPSG:28992</Option>
             </Reader>
         </Filter>
     </Writer>
</Pipeline>


On 05-02-15 09:44, Oscar Martinez Rubi wrote:
> That was fast! Thanks
> I will pull latest pdal and give it a try.
> Let me know how the selector works and i will also try that one.
> Regards
> O.
>
>
> Enviado de Samsung Mobile
>
>
> -------- Mensaje original --------
> De: Andrew Bell
> Fecha:05/02/2015 00:12 (GMT+01:00)
> Para: Oscar Martinez Rubi
> Cc: pdal at lists.osgeo.org
> Asunto: Re: [pdal] pgpointcloud selector filter and max_capacity
>
> On Wed, Feb 4, 2015 at 10:02 AM, Oscar Martinez Rubi 
> <o.martinezrubi at tudelft.nl <mailto:o.martinezrubi at tudelft.nl>> wrote:
>
>     At some point I though that the selection of dimensions could be
>     done when I insert the point cloud format in the DB (I only insert
>     a format with X,Y,Z) but I found out that after running PDAL the
>     one I inserted is ignored and a new format with all the dimensions
>     is used. So, we definitively need a way to tell the writter which
>     columns are desired.
>
>     Just to be clear, the scale_x..., is supposed to be specified in
>     the PDAL pipeline XML or in the point cloud format inserted in the
>     DB or in both?
>
>
> You specify this in the pipeline and the values are stored as integers 
> with a scaling factor instead of as double.  I'll document.
>
>     Well, I attach the sql file I execute to set the DB
>     and the pipeline xml I am using to run pdal pipeline.
>
>     With these ones I get a PDAL: ERROR:  unterminated quoted string
>     at or near "....
>     Looks like mismatch between expected format and the actual block
>     format
>
>
> I fixed this bug and it has been merged to the master branch in github.
>
> Also, I have selector-type behavior working and I should have that in 
> for the database drivers tomorrow.
>
> Best,
>
> -- 
> Andrew Bell
> andrew.bell.ia at gmail.com <mailto:andrew.bell.ia at gmail.com>
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150209/d83aa926/attachment.html>

From mhanson at appliedgeosolutions.com  Mon Feb  9 08:48:54 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Mon, 9 Feb 2015 11:48:54 -0500
Subject: [pdal] Setting SRS on las file
In-Reply-To: <2DC0D25B-5168-48F5-89EF-4E4AB6C5AAC4@hobu.co>
References: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>
	<2DC0D25B-5168-48F5-89EF-4E4AB6C5AAC4@hobu.co>
Message-ID: <CA+BxjXK6ZsS1Hsk+CmRsrpw8a7oKYuYZfRYYYkK6Uv2u+3q7rg@mail.gmail.com>

Thanks to you both, this is indeed helpful

Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com


On Sun, Feb 8, 2015 at 10:55 AM, Howard Butler <howard at hobu.co> wrote:

>
> > On Feb 6, 2015, at 2:13 PM, Matthew Hanson <
> mhanson at appliedgeosolutions.com> wrote:
> >
> >
> > We have las files that have no spatial reference embedded in the file.
>  For one, I'm not sure it's necessary to actually add the spatial reference
> to the las file.  We want to create DEM's, so perhaps it's better to just
> leave them as is then set the SRS on the final GeoTiffs.
> >
> > However, for the moment assuming that this makes sense, when I run pdal
> translate
> > $ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX
> >
> > I get a file that is bigger than the original because it's seemed to add
> 4 new dimensions: Time, Red, Green, Blue.   The original file did not have
> them, although I notice that lasinfo reports min and max for all those
> fields in both files, even though they are missing from the original.
> >
> > Are these standard dimensions in las files, and is there any way to
> control if they are added or not?
>
> Control it with the "format" option, and set it to 0 if you don't want
> Time or RGB. It defaults to 3, which includes those dimensions.
>
> > $ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX
> --writers.las.format=0
>
>
> >  If we want to add the SRS to files, I'd rather not increase the size of
> them all.  Although maybe this is moot since, as per above, it just doesn't
> make sense to add the SRS anyway.
>
> It is probably easiest to leave the SRS alone until the final GeoTIFF
> write (and then set it with a GDAL VRT). The only advantage of setting it
> on the file before processing is so you don't have to do it in a later step.
>
> Another problem here is setting the SRS is going to cause a rewrite of the
> entire file due to the VLRs needing to be modified. This is one entire
> extra i/o step that's not needed.
>
> Hope this helps,
>
> Howard
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150209/84360830/attachment.html>

From mhanson at appliedgeosolutions.com  Mon Feb  9 08:51:02 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Mon, 9 Feb 2015 11:51:02 -0500
Subject: [pdal] SegFault with p2g pipeline
In-Reply-To: <1423271305118.f64570cc@Nodemailer>
References: <CA+BxjX+jwc1gsS9Wy5KP2OGm_tZichYiON4V+8AntQSO2Jm5jw@mail.gmail.com>
	<1423271305118.f64570cc@Nodemailer>
Message-ID: <CA+BxjX+vhq8VTPEJGzUpnpHZHE_mh_vHV8ajxVJ8Zs8MeZw6GA@mail.gmail.com>

I'm working off the PDAL master branch, and a fresh clone of p2g.

#define P2G_VERSION_STRING 1.3.0

pdal (PDAL 1.0.0.b1 (1634fc) with GeoTIFF 1.4.0 GDAL 1.11.0 LASzip 2.2.0)


Perhaps it's a problem with my input file?




Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com


On Fri, Feb 6, 2015 at 8:08 PM, <pete.gadomski at gmail.com> wrote:

> Hello Matthew,
>
> I can't reproduce your results from the information provided. A
> PDAL+points2grid run works a-ok on my local system.
>
> Can you provide PDAL and points2grid versions? If you're on a Unix-style
> and have points2grid installed to /usr/local you can do:
>
>     cat /usr/local/include/points2grid/config.h | grep P2G_VERSION_STRING
>
> For PDAL:
>
>     pdal --version
>
> That might help track things down.
>
> Cheers,
> Pete
>
> --
> Pete Gadomski
> Physical Scientist
> Cold Regions Research & Engineering Lab
> pete.gadomski at gmail.com
> 530.440.4630
>
>
> On Fri, Feb 6, 2015 at 3:25 PM, Matthew Hanson <
> mhanson at appliedgeosolutions.com> wrote:
>
>> Hello,
>>
>> I'm currently trying to generate a tif file from a simple test las file.
>>   For now I'm just trying to spit out a tif of point density:
>> #####################################
>>  <?xml version="1.0" encoding="utf-8"?>
>> <Pipeline version="1.0">
>>   <Writer type="writers.p2g">
>>     <Option name="grid_dist_x">
>>       1.0
>>     </Option>
>>     <Option name="grid_dist_y">
>>       1.0
>>     </Option>
>>     <Option name="radius">
>>       3.0
>>     </Option>
>>     <Option name="filename">
>>       p2g-test
>>     </Options>
>>     <Option name="output_type">
>>       den
>>     </Option>
>>     <Option name="output_format">
>>       tif
>>     </Option>
>>         <Reader type="readers.las">
>>           <Option name="filename">
>>             input.las
>>           </Option>
>>         </Reader>
>>   </Writer>
>> </Pipeline>
>>  #####################################
>>
>> Unfortunately I get a segfault in the output:
>> #####################################
>>  (writers.p2g Debug: 3): X grid size: 522
>> (writers.p2g Debug: 3): Y grid size: 495
>> (writers.p2g Debug: 3): X grid distance: 1.000000
>> (writers.p2g Debug: 3): Y grid distance: 1.000000
>> numFiles 1
>> [0,494]
>> [0,494]
>> 0. file size: 18604080
>> 0: from 0 to 258390
>> 0: from 0 to 495
>> Merging 0: from 0 to 495
>>         0: from 0 to 0
>> Merging 0: from 0 to 495
>>         0: from 0 to 0
>> Output Execution time: 0.014058
>> Segmentation fault (core dumped)
>>
>> real 0m8.603s
>> user 0m7.747s
>> sys 0m0.619s
>>  #####################################
>>
>> Any clues on what could be going wrong?
>>
>> Thanks in advance!
>>
>>
>>  Matthew Hanson
>> Applied GeoSolutions
>> (603) 659-3363 x91
>> http://appliedgeosolutions.com
>> mhanson at appliedgeosolutions.com
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150209/6da9af30/attachment-0001.html>

From pete.gadomski at gmail.com  Mon Feb  9 08:52:35 2015
From: pete.gadomski at gmail.com (pete.gadomski at gmail.com)
Date: Mon, 09 Feb 2015 08:52:35 -0800 (PST)
Subject: [pdal] SegFault with p2g pipeline
In-Reply-To: <CA+BxjX+vhq8VTPEJGzUpnpHZHE_mh_vHV8ajxVJ8Zs8MeZw6GA@mail.gmail.com>
References: <CA+BxjX+vhq8VTPEJGzUpnpHZHE_mh_vHV8ajxVJ8Zs8MeZw6GA@mail.gmail.com>
Message-ID: <1423500755407.708dd3d@Nodemailer>

Could be. I'd be happy to take a look locally to verify and track down the segfault if you're able to provide the input file.




-Pete


-- 
Pete GadomskiPhysical Scientist

Cold Regions Research & Engineering Lab

pete.gadomski at gmail.com

530.440.4630

On Mon, Feb 9, 2015 at 10:51 AM, Matthew Hanson
<mhanson at appliedgeosolutions.com> wrote:

> I'm working off the PDAL master branch, and a fresh clone of p2g.
> #define P2G_VERSION_STRING 1.3.0
> pdal (PDAL 1.0.0.b1 (1634fc) with GeoTIFF 1.4.0 GDAL 1.11.0 LASzip 2.2.0)
> Perhaps it's a problem with my input file?
> Matthew Hanson
> Applied GeoSolutions
> (603) 659-3363 x91
> http://appliedgeosolutions.com
> mhanson at appliedgeosolutions.com
> On Fri, Feb 6, 2015 at 8:08 PM, <pete.gadomski at gmail.com> wrote:
>> Hello Matthew,
>>
>> I can't reproduce your results from the information provided. A
>> PDAL+points2grid run works a-ok on my local system.
>>
>> Can you provide PDAL and points2grid versions? If you're on a Unix-style
>> and have points2grid installed to /usr/local you can do:
>>
>>     cat /usr/local/include/points2grid/config.h | grep P2G_VERSION_STRING
>>
>> For PDAL:
>>
>>     pdal --version
>>
>> That might help track things down.
>>
>> Cheers,
>> Pete
>>
>> --
>> Pete Gadomski
>> Physical Scientist
>> Cold Regions Research & Engineering Lab
>> pete.gadomski at gmail.com
>> 530.440.4630
>>
>>
>> On Fri, Feb 6, 2015 at 3:25 PM, Matthew Hanson <
>> mhanson at appliedgeosolutions.com> wrote:
>>
>>> Hello,
>>>
>>> I'm currently trying to generate a tif file from a simple test las file.
>>>   For now I'm just trying to spit out a tif of point density:
>>> #####################################
>>>  <?xml version="1.0" encoding="utf-8"?>
>>> <Pipeline version="1.0">
>>>   <Writer type="writers.p2g">
>>>     <Option name="grid_dist_x">
>>>       1.0
>>>     </Option>
>>>     <Option name="grid_dist_y">
>>>       1.0
>>>     </Option>
>>>     <Option name="radius">
>>>       3.0
>>>     </Option>
>>>     <Option name="filename">
>>>       p2g-test
>>>     </Options>
>>>     <Option name="output_type">
>>>       den
>>>     </Option>
>>>     <Option name="output_format">
>>>       tif
>>>     </Option>
>>>         <Reader type="readers.las">
>>>           <Option name="filename">
>>>             input.las
>>>           </Option>
>>>         </Reader>
>>>   </Writer>
>>> </Pipeline>
>>>  #####################################
>>>
>>> Unfortunately I get a segfault in the output:
>>> #####################################
>>>  (writers.p2g Debug: 3): X grid size: 522
>>> (writers.p2g Debug: 3): Y grid size: 495
>>> (writers.p2g Debug: 3): X grid distance: 1.000000
>>> (writers.p2g Debug: 3): Y grid distance: 1.000000
>>> numFiles 1
>>> [0,494]
>>> [0,494]
>>> 0. file size: 18604080
>>> 0: from 0 to 258390
>>> 0: from 0 to 495
>>> Merging 0: from 0 to 495
>>>         0: from 0 to 0
>>> Merging 0: from 0 to 495
>>>         0: from 0 to 0
>>> Output Execution time: 0.014058
>>> Segmentation fault (core dumped)
>>>
>>> real 0m8.603s
>>> user 0m7.747s
>>> sys 0m0.619s
>>>  #####################################
>>>
>>> Any clues on what could be going wrong?
>>>
>>> Thanks in advance!
>>>
>>>
>>>  Matthew Hanson
>>> Applied GeoSolutions
>>> (603) 659-3363 x91
>>> http://appliedgeosolutions.com
>>> mhanson at appliedgeosolutions.com
>>>
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150209/447fae94/attachment.html>

From mhanson at appliedgeosolutions.com  Wed Feb 11 12:37:11 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Wed, 11 Feb 2015 15:37:11 -0500
Subject: [pdal] Setting SRS on las file
In-Reply-To: <CA+BxjXK6ZsS1Hsk+CmRsrpw8a7oKYuYZfRYYYkK6Uv2u+3q7rg@mail.gmail.com>
References: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>
	<2DC0D25B-5168-48F5-89EF-4E4AB6C5AAC4@hobu.co>
	<CA+BxjXK6ZsS1Hsk+CmRsrpw8a7oKYuYZfRYYYkK6Uv2u+3q7rg@mail.gmail.com>
Message-ID: <CA+BxjX+48bkvdGWkL1EnRahS-CRhogAT70x-_DrC+wH7zWy48Q@mail.gmail.com>

I've got a follow-up question with this.

I've got a pipeline XML file to generate the output TIF, and set the input
and output filenames on the command line like so:

pdal pipeline -i density.xml --writers.p2g.filename=aal_232_9752_class
--readers.las.filename=aal_232_9752_class.las

Is there a way to set the output srs at the same time?  I don't want to
reproject it, just assign it.  For example, something like this (although
this didn't work):

pdal pipeline -i density.xml --writers.p2g.filename=aal_232_9752_class
--readers.las.filename=aal_232_9752_class.las -v4
--writers.p2g.out_srs=EPSG:32750


Thanks for all the help so far,

matt






Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com


On Mon, Feb 9, 2015 at 11:48 AM, Matthew Hanson <
mhanson at appliedgeosolutions.com> wrote:

> Thanks to you both, this is indeed helpful
>
> Matthew Hanson
> Applied GeoSolutions
> (603) 659-3363 x91
> http://appliedgeosolutions.com
> mhanson at appliedgeosolutions.com
>
>
> On Sun, Feb 8, 2015 at 10:55 AM, Howard Butler <howard at hobu.co> wrote:
>
>>
>> > On Feb 6, 2015, at 2:13 PM, Matthew Hanson <
>> mhanson at appliedgeosolutions.com> wrote:
>> >
>> >
>> > We have las files that have no spatial reference embedded in the file.
>>  For one, I'm not sure it's necessary to actually add the spatial reference
>> to the las file.  We want to create DEM's, so perhaps it's better to just
>> leave them as is then set the SRS on the final GeoTiffs.
>> >
>> > However, for the moment assuming that this makes sense, when I run pdal
>> translate
>> > $ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX
>> >
>> > I get a file that is bigger than the original because it's seemed to
>> add 4 new dimensions: Time, Red, Green, Blue.   The original file did not
>> have them, although I notice that lasinfo reports min and max for all those
>> fields in both files, even though they are missing from the original.
>> >
>> > Are these standard dimensions in las files, and is there any way to
>> control if they are added or not?
>>
>> Control it with the "format" option, and set it to 0 if you don't want
>> Time or RGB. It defaults to 3, which includes those dimensions.
>>
>> > $ pdal translate -i input.las -o output.las -a_srs EPSG:XXXXX
>> --writers.las.format=0
>>
>>
>> >  If we want to add the SRS to files, I'd rather not increase the size
>> of them all.  Although maybe this is moot since, as per above, it just
>> doesn't make sense to add the SRS anyway.
>>
>> It is probably easiest to leave the SRS alone until the final GeoTIFF
>> write (and then set it with a GDAL VRT). The only advantage of setting it
>> on the file before processing is so you don't have to do it in a later step.
>>
>> Another problem here is setting the SRS is going to cause a rewrite of
>> the entire file due to the VLRs needing to be modified. This is one entire
>> extra i/o step that's not needed.
>>
>> Hope this helps,
>>
>> Howard
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150211/02f8077a/attachment.html>

From howard at hobu.co  Wed Feb 11 13:03:03 2015
From: howard at hobu.co (Howard Butler)
Date: Wed, 11 Feb 2015 16:03:03 -0500
Subject: [pdal] Setting SRS on las file
In-Reply-To: <CA+BxjX+48bkvdGWkL1EnRahS-CRhogAT70x-_DrC+wH7zWy48Q@mail.gmail.com>
References: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>
	<2DC0D25B-5168-48F5-89EF-4E4AB6C5AAC4@hobu.co>
	<CA+BxjXK6ZsS1Hsk+CmRsrpw8a7oKYuYZfRYYYkK6Uv2u+3q7rg@mail.gmail.com>
	<CA+BxjX+48bkvdGWkL1EnRahS-CRhogAT70x-_DrC+wH7zWy48Q@mail.gmail.com>
Message-ID: <F8702D78-B65E-4400-B3D3-DB39AD5C64E7@hobu.co>


> On Feb 11, 2015, at 3:37 PM, Matthew Hanson <mhanson at appliedgeosolutions.com> wrote:
> 
> Is there a way to set the output srs at the same time?  I don't want to reproject it, just assign it.  --writers.p2g.out_srs=EPSG:32750

You might try calling it --writers.p2g.spatialreference=EPSG:32750

If that doesn't work, I'd be happy to tweak the driver to do it.

Howard

From mhanson at appliedgeosolutions.com  Thu Feb 12 09:45:25 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Thu, 12 Feb 2015 12:45:25 -0500
Subject: [pdal] Setting SRS on las file
In-Reply-To: <F8702D78-B65E-4400-B3D3-DB39AD5C64E7@hobu.co>
References: <CA+BxjXKkoXrPMcs3CmJ2KNa+-iiva947dhUTBE5zpGtzQMZhaA@mail.gmail.com>
	<2DC0D25B-5168-48F5-89EF-4E4AB6C5AAC4@hobu.co>
	<CA+BxjXK6ZsS1Hsk+CmRsrpw8a7oKYuYZfRYYYkK6Uv2u+3q7rg@mail.gmail.com>
	<CA+BxjX+48bkvdGWkL1EnRahS-CRhogAT70x-_DrC+wH7zWy48Q@mail.gmail.com>
	<F8702D78-B65E-4400-B3D3-DB39AD5C64E7@hobu.co>
Message-ID: <CA+BxjXK+xm4JnUg4o7_e-i8CRqssESiiFG=U-Co_neMnfRDysw@mail.gmail.com>

That did work, thanks!

Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com


On Wed, Feb 11, 2015 at 4:03 PM, Howard Butler <howard at hobu.co> wrote:

>
> > On Feb 11, 2015, at 3:37 PM, Matthew Hanson <
> mhanson at appliedgeosolutions.com> wrote:
> >
> > Is there a way to set the output srs at the same time?  I don't want to
> reproject it, just assign it.  --writers.p2g.out_srs=EPSG:32750
>
> You might try calling it --writers.p2g.spatialreference=EPSG:32750
>
> If that doesn't work, I'd be happy to tweak the driver to do it.
>
> Howard
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150212/2e290045/attachment.html>

From mhanson at appliedgeosolutions.com  Thu Feb 12 11:52:44 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Thu, 12 Feb 2015 14:52:44 -0500
Subject: [pdal] p2g density
Message-ID: <CA+BxjXKYc6usbUKCC_TTwaXFnjXEwnFh9Ocv7ku-uATBYgpQWQ@mail.gmail.com>

Hello again,

I'm not sure this is the right list for this question which is more about
points2grid, but I thought someone here might have run into this issue.

I'm creating a tiff of point density from a las file.    My las file is
1000x1000 m with about 24 million points.    I create a tiff of density
(den) using a grid size of 1.0x1.0 and a radius of 0.56.   Thus my search
area is about 1.0, the same as my grid area.

I would expect the sum of all my points to be about equal to the total # of
points, and the mean pixel value to be about 24.   However it's not.   I
get a significantly higher total - about 37 million points and a mean of
about 37.     I've adjusted the search radius and it does change, but the
numbers are quite a bit higher in all cases than what would be expected.

Am I misunderstanding what the density output is supposed to be?   Or has
someone else stumbled across this?

Thanks,


Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150212/93ee83b3/attachment.html>

From howard at hobu.co  Thu Feb 12 12:31:59 2015
From: howard at hobu.co (Howard Butler)
Date: Thu, 12 Feb 2015 15:31:59 -0500
Subject: [pdal] Pointdown: Openly specified point cloud streaming
Message-ID: <C43B68E4-E892-4FF5-A0E9-A11F71E55A98@hobu.co>

All,

One of the outcome of the Philly Code Sprint where many of the PDAL developers have attended is the intention to work together with other point cloud developers to attempt to specify a point cloud streaming mechanism [1]. Together we have christened an effort, called Pointdown, to do this using an open methodology like the one used to develop GeoJSON. Any who are interested in participating can do so via the mailing list [2].

If you have interest or ideas to contribute, we look forward to your contribution!

Howard

[1] http://lists.osgeo.org/pipermail/pointdown/2015-February/000000.html
[2] http://lists.osgeo.org/cgi-bin/mailman/listinfo/pointdown

From mhanson at appliedgeosolutions.com  Thu Feb 12 12:39:50 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Thu, 12 Feb 2015 15:39:50 -0500
Subject: [pdal] Filtering by Classification, Return #, etc
Message-ID: <CA+BxjXJChHy-PVZe2su73WsVjHH51-DWFw_JBG9aQw46=pT6Lw@mail.gmail.com>

I think I now mostly understand the complete process necessary to go from
our collected point clouds to DEM products.

However, when trying to construct the filter to filter out the ground
points, I realized that the PassThrough filter only supports certain
dimensions and Classification is not one of them (I was going to set min
and max Classification to 2).   On a similar note I'll want to filter by
other things such as return number.

So it looks like I just need to put together a Python function and use a
predicate filter, which looks easy enough.   However I wanted to make sure
I'm not missing anything.   Is there another, preferred way to do this
filtering?    I'm especially interested in speed as we'll be processing a
fair amount of data.

Thanks again for all the help from the developers, it's been a great help.
  I'll buy you a drink if I see you at FOSS4G in SF next month.


Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150212/a7e8a246/attachment.html>

From howard at hobu.co  Thu Feb 12 12:49:27 2015
From: howard at hobu.co (Howard Butler)
Date: Thu, 12 Feb 2015 15:49:27 -0500
Subject: [pdal] Filtering by Classification, Return #, etc
In-Reply-To: <CA+BxjXJChHy-PVZe2su73WsVjHH51-DWFw_JBG9aQw46=pT6Lw@mail.gmail.com>
References: <CA+BxjXJChHy-PVZe2su73WsVjHH51-DWFw_JBG9aQw46=pT6Lw@mail.gmail.com>
Message-ID: <ED545AFD-A4F6-49EB-9A38-9103BEBD3011@hobu.co>


> On Feb 12, 2015, at 3:39 PM, Matthew Hanson <mhanson at appliedgeosolutions.com> wrote:
> 
> I think I now mostly understand the complete process necessary to go from our collected point clouds to DEM products.
> 
> However, when trying to construct the filter to filter out the ground points, I realized that the PassThrough filter only supports certain dimensions and Classification is not one of them (I was going to set min and max Classification to 2).   On a similar note I'll want to filter by other things such as return number.
> 
> So it looks like I just need to put together a Python function and use a predicate filter, which looks easy enough.   However I wanted to make sure I'm not missing anything.   Is there another, preferred way to do this filtering?    I'm especially interested in speed as we'll be processing a fair amount of data.

There is a new thing called filters.rangefilter that you can use to do this filtering. You are correct that normally you would reach for the Python filter, and that was the prescribed way to do this in the past. The rangefilter is a kind of specialization of this common task, whereas you would use the Python filter for something more complex like "give me last returns".

See the RangeFilter test code for inspiration on how to say what you want.

https://github.com/PDAL/PDAL/blob/master/test/unit/filters/RangeFilterTest.cpp

> Thanks again for all the help from the developers, it's been a great help.   I'll buy you a drink if I see you at FOSS4G in SF next month.

Unfortunately, I have used all of my familial travel credits on the Philly Code Sprint, which has been a great success as far as PDAL is concerned. Michael Gerlek plans to attend, and I'm sure he'd be happy to connect with you over a beverage.

Howard

From brad.chambers at gmail.com  Thu Feb 12 12:53:31 2015
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Thu, 12 Feb 2015 15:53:31 -0500
Subject: [pdal] Filtering by Classification, Return #, etc
In-Reply-To: <ED545AFD-A4F6-49EB-9A38-9103BEBD3011@hobu.co>
References: <CA+BxjXJChHy-PVZe2su73WsVjHH51-DWFw_JBG9aQw46=pT6Lw@mail.gmail.com>
	<ED545AFD-A4F6-49EB-9A38-9103BEBD3011@hobu.co>
Message-ID: <CAJyqqPxst_RHxnuvH6nKEFKS9JgfGPiJGbL9MddEpEoOHdOE_g@mail.gmail.com>

For pipeline use of the range filter, you can also take a look at
https://github.com/PDAL/PDAL/blob/master/test/data/filters/range_z_classification.xml.in
.

Brad

On Thu, Feb 12, 2015 at 3:49 PM, Howard Butler <howard at hobu.co> wrote:

>
> > On Feb 12, 2015, at 3:39 PM, Matthew Hanson <
> mhanson at appliedgeosolutions.com> wrote:
> >
> > I think I now mostly understand the complete process necessary to go
> from our collected point clouds to DEM products.
> >
> > However, when trying to construct the filter to filter out the ground
> points, I realized that the PassThrough filter only supports certain
> dimensions and Classification is not one of them (I was going to set min
> and max Classification to 2).   On a similar note I'll want to filter by
> other things such as return number.
> >
> > So it looks like I just need to put together a Python function and use a
> predicate filter, which looks easy enough.   However I wanted to make sure
> I'm not missing anything.   Is there another, preferred way to do this
> filtering?    I'm especially interested in speed as we'll be processing a
> fair amount of data.
>
> There is a new thing called filters.rangefilter that you can use to do
> this filtering. You are correct that normally you would reach for the
> Python filter, and that was the prescribed way to do this in the past. The
> rangefilter is a kind of specialization of this common task, whereas you
> would use the Python filter for something more complex like "give me last
> returns".
>
> See the RangeFilter test code for inspiration on how to say what you want.
>
>
> https://github.com/PDAL/PDAL/blob/master/test/unit/filters/RangeFilterTest.cpp
>
> > Thanks again for all the help from the developers, it's been a great
> help.   I'll buy you a drink if I see you at FOSS4G in SF next month.
>
> Unfortunately, I have used all of my familial travel credits on the Philly
> Code Sprint, which has been a great success as far as PDAL is concerned.
> Michael Gerlek plans to attend, and I'm sure he'd be happy to connect with
> you over a beverage.
>
> Howard
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150212/e1dca951/attachment.html>

From brad.chambers at gmail.com  Thu Feb 12 13:05:07 2015
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Thu, 12 Feb 2015 16:05:07 -0500
Subject: [pdal] p2g density
In-Reply-To: <CA+BxjXKYc6usbUKCC_TTwaXFnjXEwnFh9Ocv7ku-uATBYgpQWQ@mail.gmail.com>
References: <CA+BxjXKYc6usbUKCC_TTwaXFnjXEwnFh9Ocv7ku-uATBYgpQWQ@mail.gmail.com>
Message-ID: <CAJyqqPwbjSQCSHx9e8g=StvzGJP3QedgAzhQym8cXacpdEob_g@mail.gmail.com>

Matthew,

Have you looked at
http://www.opentopography.org/index.php/Tools/otforge/points2grid and the
resources linked off of it? That may be useful.

I believe most of our modifications to points2grid have been to provide
support for things like CMake, Windows, GeoTIFF, etc., and not to
fundamentally change the underlying algorithms.

Brad

On Thu, Feb 12, 2015 at 2:52 PM, Matthew Hanson <
mhanson at appliedgeosolutions.com> wrote:

> Hello again,
>
> I'm not sure this is the right list for this question which is more about
> points2grid, but I thought someone here might have run into this issue.
>
> I'm creating a tiff of point density from a las file.    My las file is
> 1000x1000 m with about 24 million points.    I create a tiff of density
> (den) using a grid size of 1.0x1.0 and a radius of 0.56.   Thus my search
> area is about 1.0, the same as my grid area.
>
> I would expect the sum of all my points to be about equal to the total #
> of points, and the mean pixel value to be about 24.   However it's not.   I
> get a significantly higher total - about 37 million points and a mean of
> about 37.     I've adjusted the search radius and it does change, but the
> numbers are quite a bit higher in all cases than what would be expected.
>
> Am I misunderstanding what the density output is supposed to be?   Or has
> someone else stumbled across this?
>
> Thanks,
>
>
> Matthew Hanson
> Applied GeoSolutions
> (603) 659-3363 x91
> http://appliedgeosolutions.com
> mhanson at appliedgeosolutions.com
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150212/3fb935a4/attachment.html>

From mhanson at appliedgeosolutions.com  Thu Feb 12 13:06:47 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Thu, 12 Feb 2015 16:06:47 -0500
Subject: [pdal] p2g density
In-Reply-To: <CAJyqqPwbjSQCSHx9e8g=StvzGJP3QedgAzhQym8cXacpdEob_g@mail.gmail.com>
References: <CA+BxjXKYc6usbUKCC_TTwaXFnjXEwnFh9Ocv7ku-uATBYgpQWQ@mail.gmail.com>
	<CAJyqqPwbjSQCSHx9e8g=StvzGJP3QedgAzhQym8cXacpdEob_g@mail.gmail.com>
Message-ID: <CA+BxjXK=9iERdoV+m=ygVzBmTthLL=kKrnscKG-oi4AT-RdN+Q@mail.gmail.com>

I did look at that, but assuming I understand it correctly something seems
off.

I'll send feedback to the provided email, thanks.

matt

Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com


On Thu, Feb 12, 2015 at 4:05 PM, Bradley Chambers <brad.chambers at gmail.com>
wrote:

> Matthew,
>
> Have you looked at
> http://www.opentopography.org/index.php/Tools/otforge/points2grid and the
> resources linked off of it? That may be useful.
>
> I believe most of our modifications to points2grid have been to provide
> support for things like CMake, Windows, GeoTIFF, etc., and not to
> fundamentally change the underlying algorithms.
>
> Brad
>
> On Thu, Feb 12, 2015 at 2:52 PM, Matthew Hanson <
> mhanson at appliedgeosolutions.com> wrote:
>
>> Hello again,
>>
>> I'm not sure this is the right list for this question which is more about
>> points2grid, but I thought someone here might have run into this issue.
>>
>> I'm creating a tiff of point density from a las file.    My las file is
>> 1000x1000 m with about 24 million points.    I create a tiff of density
>> (den) using a grid size of 1.0x1.0 and a radius of 0.56.   Thus my search
>> area is about 1.0, the same as my grid area.
>>
>> I would expect the sum of all my points to be about equal to the total #
>> of points, and the mean pixel value to be about 24.   However it's not.   I
>> get a significantly higher total - about 37 million points and a mean of
>> about 37.     I've adjusted the search radius and it does change, but the
>> numbers are quite a bit higher in all cases than what would be expected.
>>
>> Am I misunderstanding what the density output is supposed to be?   Or has
>> someone else stumbled across this?
>>
>> Thanks,
>>
>>
>> Matthew Hanson
>> Applied GeoSolutions
>> (603) 659-3363 x91
>> http://appliedgeosolutions.com
>> mhanson at appliedgeosolutions.com
>>
>>
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/pdal
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150212/057d966a/attachment-0001.html>

From mhanson at appliedgeosolutions.com  Fri Feb 13 13:20:05 2015
From: mhanson at appliedgeosolutions.com (Matthew Hanson)
Date: Fri, 13 Feb 2015 16:20:05 -0500
Subject: [pdal] Mosaic and crop
Message-ID: <CA+BxjX+tbNA6OYkjf2N_5L-+1w+X+FCyD3P-Rs_V69++=AoTmA@mail.gmail.com>

I'm trying to extract a single region from multiple LAS files (I want all
the points from all LAS files to be included in my output las).    There's
a couple comments on the website about filters.mosaic, but the examples
given don't work, and there doesn't appear to be a filters.mosaic.  I
assume this is outdated.

So how do I provide multiple Reader stages to filters.crop?  This is what I
tried:


<?xml version="1.0" encoding="utf-8"?>
<Pipeline version="1.0">
    <Writer type="writers.las">
        <Option name="filename">testout.las</Option>
        <Filter type="filters.crop">
            <Option name="bounds">
                ([232000.00, 232999.99],[9752000.00, 9752999.99],[0, 100])
            </Option>
            <Multifilter type="filters.mosaic">
                <Reader type="readers.las">
                    <Option name="filename">test1.las</Option>
                </Reader>
                <Reader type="readers.las">
                    <Option name="filename">test2.las</Option>
                </Reader>
                <Reader type="readers.las">
                    <Option name="filename">test3.las</Option>
                </Reader>
            </Multifilter>
        </Filter>
    </Writer>
</Pipeline>



Matthew Hanson
Applied GeoSolutions
(603) 659-3363 x91
http://appliedgeosolutions.com
mhanson at appliedgeosolutions.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150213/9cf99ab3/attachment.html>

From brad.chambers at gmail.com  Fri Feb 13 17:55:32 2015
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Fri, 13 Feb 2015 20:55:32 -0500
Subject: [pdal] Mosaic and crop
In-Reply-To: <CA+BxjX+tbNA6OYkjf2N_5L-+1w+X+FCyD3P-Rs_V69++=AoTmA@mail.gmail.com>
References: <CA+BxjX+tbNA6OYkjf2N_5L-+1w+X+FCyD3P-Rs_V69++=AoTmA@mail.gmail.com>
Message-ID: <CAJyqqPzf7VRMLfp05ZK2+qQQouH_mOdfEaKWy927H0Ly46bnvw@mail.gmail.com>

Matthew,

filters.merge should do what you need. Take a look at
https://github.com/PDAL/PDAL/blob/master/test/data/filters/merge.xml.in.

Let us know if you are still having trouble.

Brad

On Fri, Feb 13, 2015 at 4:20 PM, Matthew Hanson <
mhanson at appliedgeosolutions.com> wrote:

> I'm trying to extract a single region from multiple LAS files (I want all
> the points from all LAS files to be included in my output las).    There's
> a couple comments on the website about filters.mosaic, but the examples
> given don't work, and there doesn't appear to be a filters.mosaic.  I
> assume this is outdated.
>
> So how do I provide multiple Reader stages to filters.crop?  This is what
> I tried:
>
>
> <?xml version="1.0" encoding="utf-8"?>
> <Pipeline version="1.0">
>     <Writer type="writers.las">
>         <Option name="filename">testout.las</Option>
>         <Filter type="filters.crop">
>             <Option name="bounds">
>                 ([232000.00, 232999.99],[9752000.00, 9752999.99],[0, 100])
>             </Option>
>             <Multifilter type="filters.mosaic">
>                 <Reader type="readers.las">
>                     <Option name="filename">test1.las</Option>
>                 </Reader>
>                 <Reader type="readers.las">
>                     <Option name="filename">test2.las</Option>
>                 </Reader>
>                 <Reader type="readers.las">
>                     <Option name="filename">test3.las</Option>
>                 </Reader>
>             </Multifilter>
>         </Filter>
>     </Writer>
> </Pipeline>
>
>
>
> Matthew Hanson
> Applied GeoSolutions
> (603) 659-3363 x91
> http://appliedgeosolutions.com
> mhanson at appliedgeosolutions.com
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150213/83a8e09b/attachment.html>

From o.martinezrubi at tudelft.nl  Tue Feb 17 06:20:09 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Tue, 17 Feb 2015 15:20:09 +0100
Subject: [pdal] Oracle point cloud
Message-ID: <54E34E19.5020508@tudelft.nl>

Hi Guys,

I am trying to import some points into Oracle with PDAL.

I am getting this error message:

PDAL: GDAL Failure number=1: ORA-00054: resource busy and acquire with NOWAIT specified or timeout expired
ORA-06512: at "MDSYS.SDOTNPC", line 321
ORA-06512: at "MDSYS.SDO_PC_PKG", line 573
ORA-06512: at line 3

GDAL: In GDALDestroy - unloading GDAL shared library.

I used the XML below to call PDAL pipeline.

Has someone recently tried this code successfully? (with Oracle 12c)

BTW, in the PDAL docs I saw that also scale and offsets could be specified. Is this really the case or advisable at all? I mean in PostgreSQL the format is defined in the pointcloud_formats but in Oracle I think there is nothing like that. The points are internally stored as Doubles as far as I know and I thought we could not change that (but maybe I am wrong)

Thanks

Regards,

O.

-----------

<?xml version="1.0" encoding="utf-8"?>
<Pipeline version="1.0">
     <Writer type="writers.oci">
         <Option name="debug">
             true
         </Option>
         <Option name="verbose">
             1
         </Option>
         <Option name="connection">
             o20/solution3 at pctest
         </Option>
         <Option name="base_table_name">
             AHN_BASE
         </Option>
         <Option name="block_table_name">
             AHN_BLCK
         </Option>
         <Option name="cloud_column_name">
             PC
         </Option>
         <Option name="is3d">
             false
         </Option>
         <Option name="solid">
             false
         </Option>
         <Option name="overwrite">
             true
         </Option>
         <Option name="srid">
             28992
         </Option>
         <Option name="base_table_aux_columns">
         </Option>
         <Option name="base_table_aux_values">
         </Option>
         <Option name="base_table_boundary_column">
         </Option>
         <Option name="base_table_boundary_wkt">
         </Option>
         <Option name="pre_block_sql">
         </Option>
         <Option name="pre_sql">
         </Option>
         <Option name="post_block_sql">
         </Option>
         <Option name="capacity">
             25000
         </Option>
         <Option name="stream_output_precision">
             8
         </Option>
         <Option name="disable_cloud_trigger">
             true
         </Option>
         <Option name="pack_ignored_fields">
             false
         </Option>
         <Filter type="filters.chipper">
             <Option name="capacity">25000</Option>
             <Reader type="readers.las">
                 <Option name="filename">/pak2/usrdata/ahn2/benchmarks/20M/ahn_minibench.laz</Option>
                 <Option name="spatialreference">EPSG:28992</Option>
             </Reader>
         </Filter>
     </Writer>
</Pipeline>





From andrew.bell.ia at gmail.com  Tue Feb 17 06:26:30 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 17 Feb 2015 09:26:30 -0500
Subject: [pdal] Oracle point cloud
In-Reply-To: <54E34E19.5020508@tudelft.nl>
References: <54E34E19.5020508@tudelft.nl>
Message-ID: <CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>

On Tue, Feb 17, 2015 at 9:20 AM, Oscar Martinez Rubi <
o.martinezrubi at tudelft.nl> wrote:

> Hi Guys,
>
> I am trying to import some points into Oracle with PDAL.
>
> I am getting this error message:
>
> PDAL: GDAL Failure number=1: ORA-00054: resource busy and acquire with
> NOWAIT specified or timeout expired
> ORA-06512: at "MDSYS.SDOTNPC", line 321
> ORA-06512: at "MDSYS.SDO_PC_PKG", line 573
> ORA-06512: at line 3
>
> GDAL: In GDALDestroy - unloading GDAL shared library.
>

I'm sorry, but I can't help you with this.  Perhaps Howard Butler has some
thoughts.


> BTW, in the PDAL docs I saw that also scale and offsets could be
> specified. Is this really the case or advisable at all?


Yes, this is the case.  If you specify scale and/or offset, the X, Y and Z
values are stored as 32-bit integers instead of doubles.  This works the
same as it does in SQLite or pgpointcloud (PostreSQL).

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150217/cb219842/attachment.html>

From howard at hobu.co  Tue Feb 17 06:28:06 2015
From: howard at hobu.co (Howard Butler)
Date: Tue, 17 Feb 2015 08:28:06 -0600
Subject: [pdal] Oracle point cloud
In-Reply-To: <CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
References: <54E34E19.5020508@tudelft.nl>
	<CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
Message-ID: <A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>


> PDAL: GDAL Failure number=1: ORA-00054: resource busy and acquire with NOWAIT specified or timeout expired
> ORA-06512: at "MDSYS.SDOTNPC", line 321
> ORA-06512: at "MDSYS.SDO_PC_PKG", line 573
> ORA-06512: at line 3
> 
> GDAL: In GDALDestroy - unloading GDAL shared library.
> 
> I'm sorry, but I can't help you with this.  Perhaps Howard Butler has some thoughts.

You must have written to the table once, but failed, and Oracle has left the indexes locked. The only way I've found to get around this is to nuke the index via its session in SQLDeveloper or such.

Hope this helps,

Howard

From o.martinezrubi at tudelft.nl  Tue Feb 17 06:54:24 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Tue, 17 Feb 2015 15:54:24 +0100
Subject: [pdal] Oracle point cloud
In-Reply-To: <A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>
References: <54E34E19.5020508@tudelft.nl>	<CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
	<A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>
Message-ID: <54E35620.7080604@tudelft.nl>

Thanks guys! Still not working though

To get rid of that message I recreated the DB (well the user) and create 
the base and blocks tables:

create table blocks tablespace users pctfree 0 nologging
lob(points) store as securefile (tablespace users nocompress
cache reads nologging) as
SELECT * FROM mdsys.SDO_PC_BLK_TABLE where 0 = 1;

create table blocksbase (id number, pc sdo_pc) tablespace users pctfree 
0 nologging;

BTW, I had to add the ID to the base table (which I was not doing before).

But when I run PDAL now I get a Segmentation fault (XML below)

Anything else I may be doing wrong?

Regard,

O.

----------------------


<?xml version="1.0" encoding="utf-8"?>
<Pipeline version="1.0">
     <Writer type="writers.oci">
         <Option name="debug">
             true
         </Option>
         <Option name="verbose">
             1
         </Option>
         <Option name="connection">
             opdal/opdal at pctest
         </Option>
         <Option name="base_table_name">
             blocksbase
         </Option>
         <Option name="block_table_name">
             blocks
         </Option>
         <Option name="cloud_column_name">
             pc
         </Option>
         <Option name="is3d">
             false
         </Option>
         <Option name="solid">
             false
         </Option>
         <Option name="overwrite">
             false
         </Option>
         <Option name="srid">
             28992
         </Option>
         <Option name="base_table_aux_columns">
         </Option>
         <Option name="base_table_aux_values">
         </Option>
         <Option name="base_table_boundary_column">
         </Option>
         <Option name="base_table_boundary_wkt">
         </Option>
         <Option name="pre_block_sql">
         </Option>
         <Option name="pre_sql">
         </Option>
         <Option name="post_block_sql">
         </Option>
         <Option name="capacity">
             25000
         </Option>
         <Option name="stream_output_precision">
             8
         </Option>
         <Option name="disable_cloud_trigger">
             true
         </Option>
         <Option name="pack_ignored_fields">
             false
         </Option>
         <Filter type="filters.chipper">
             <Option name="capacity">25000</Option>
             <Reader type="readers.las">
                 <Option 
name="filename">/pak2/usrdata/ahn2/benchmarks/20M/ahn_minibench.laz</Option>
                 <Option name="spatialreference">EPSG:28992</Option>
             </Reader>
         </Filter>
     </Writer>
</Pipeline>

On 17-02-15 15:28, Howard Butler wrote:
>> PDAL: GDAL Failure number=1: ORA-00054: resource busy and acquire with NOWAIT specified or timeout expired
>> ORA-06512: at "MDSYS.SDOTNPC", line 321
>> ORA-06512: at "MDSYS.SDO_PC_PKG", line 573
>> ORA-06512: at line 3
>>
>> GDAL: In GDALDestroy - unloading GDAL shared library.
>>
>> I'm sorry, but I can't help you with this.  Perhaps Howard Butler has some thoughts.
> You must have written to the table once, but failed, and Oracle has left the indexes locked. The only way I've found to get around this is to nuke the index via its session in SQLDeveloper or such.
>
> Hope this helps,
>
> Howard
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal


From howard at hobu.co  Sun Feb 22 15:23:53 2015
From: howard at hobu.co (Howard Butler)
Date: Sun, 22 Feb 2015 17:23:53 -0600
Subject: [pdal] Oracle point cloud
In-Reply-To: <54E35620.7080604@tudelft.nl>
References: <54E34E19.5020508@tudelft.nl>
	<CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
	<A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>
	<54E35620.7080604@tudelft.nl>
Message-ID: <E1418D8A-0EB9-435D-9189-15A99D6C9FD5@hobu.co>


> On Feb 17, 2015, at 8:54 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
> 
> Thanks guys! Still not working though
> 
> To get rid of that message I recreated the DB (well the user) and create the base and blocks tables:
> 
> create table blocks tablespace users pctfree 0 nologging
> lob(points) store as securefile (tablespace users nocompress
> cache reads nologging) as
> SELECT * FROM mdsys.SDO_PC_BLK_TABLE where 0 = 1;
> 
> create table blocksbase (id number, pc sdo_pc) tablespace users pctfree 0 nologging;
> 
> BTW, I had to add the ID to the base table (which I was not doing before).
> 
> But when I run PDAL now I get a Segmentation fault (XML below)

$ gdb --args pdal pipeline -i myfile.xml --developer-debug

Then press 'r' to run

when crashes, press 'bt' for backtrace. Please report the traceback here.

I just tested https://github.com/PDAL/PDAL/blob/master/test/data/oracle/write.xml with the autzen-dd.las file in test/data/autzen and it successfully loaded for me with no crash. If that one succeeds for you, we might be able to make some progress.

Sorry for the challenges.

Howard


From WOMeara at Radiantblue.com  Wed Feb 25 08:03:13 2015
From: WOMeara at Radiantblue.com (OMeara, Whitney)
Date: Wed, 25 Feb 2015 16:03:13 +0000
Subject: [pdal] Vagrant ubuntu/trusty64 issue
Message-ID: <44A10BB04DB1CF4CB221604BDFC6C0CC45863D30@NBSVR-MAIL01.radiantblue.local>

Hey everyone,

I think I finally have Vagrant configured to setup GeoWave, but I'm having issues getting vagrant up.  While trying to deploy ubuntu/trusty64, I get the following error message:

The requested URL returned error: 404 Not Found

I looked around online and found a bug report describing my issue here: https://github.com/mitchellh/vagrant/issues/4875.  Apparently trusty64 is not hosted directly by Vagrant Cloud, and is instead just a proxy for a user-hosted .box file.

In any case, I'm just wondering if you guys have experienced issues with this and how you fixed it.  In the meantime, I am going to test deployment on a fresh install of trusty64 to make sure that my changes are working.  Once I have that working, I'll do a pull request.

Thanks,
Whitney
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150225/482f9825/attachment.html>

From connor at hobu.co  Wed Feb 25 08:46:32 2015
From: connor at hobu.co (Connor Manning)
Date: Wed, 25 Feb 2015 10:46:32 -0600
Subject: [pdal]  Vagrant ubuntu/trusty64 issue
Message-ID: <CAO=Fyj+U1s1aZWO=k9e8eh25TbvbGc2-Q8gtU4BiZZ_a5WsKJQ@mail.gmail.com>

Ran into this on Greyhound a while back.  I just updated PDAL's Trusty URL
on master.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150225/600fd09e/attachment.html>

From o.martinezrubi at tudelft.nl  Wed Feb 25 08:55:26 2015
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 25 Feb 2015 17:55:26 +0100
Subject: [pdal] Oracle point cloud
In-Reply-To: <E1418D8A-0EB9-435D-9189-15A99D6C9FD5@hobu.co>
References: <54E34E19.5020508@tudelft.nl>
	<CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
	<A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>
	<54E35620.7080604@tudelft.nl>
	<E1418D8A-0EB9-435D-9189-15A99D6C9FD5@hobu.co>
Message-ID: <54EDFE7E.6040908@tudelft.nl>

Hi Howard,

I run the pdal pipeline with gdb, please see below.

I also tested with the write.xml and autzen-dd.las in the test folder 
and I get the same output.

BTW, I am running this in a Oracle 12.1.0.2 in RedHat 6.5

Any insight?

Regards,

O.


---------------------------
-bash-4.1$ gdb --args pdal pipeline -i oracle_pipeline.xml --developer-debug
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-75.el6)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later 
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /home/oscar/sw/PDAL-trunk/build/bin/pdal...(no 
debugging symbols found)...done.
(gdb) r
Starting program: /home/oscar/sw/PDAL-trunk/build/bin/pdal pipeline -i 
oracle_pipeline.xml --developer-debug
[Thread debugging using libthread_db enabled]
warning: File "/usr/local/gcc484/lib64/libstdc++.so.6.0.19-gdb.py" 
auto-loading has been declined by your `auto-load safe-path' set to 
"/usr/share/gdb/auto-load:/usr/lib/debug:/usr/bin/mono-gdb.py".
To enable execution of this file add
     add-auto-load-safe-path 
/usr/local/gcc484/lib64/libstdc++.so.6.0.19-gdb.py
line to your configuration file "/home/oscar/.gdbinit".
To completely disable this security protection add
     set auto-load safe-path /
line to your configuration file "/home/oscar/.gdbinit".
For more information about this security protection see the
"Auto-loading safe path" section in the GDB manual.  E.g., run from the 
shell:
     info "(gdb)Auto-loading safe path"

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff314a7fe in kotgttc () from 
/opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
Missing separate debuginfos, use: debuginfo-install 
bzip2-libs-1.0.5-7.el6_0.x86_64 cyrus-sasl-lib-2.1.23-15.el6_6.1.x86_64 
geos-3.4.2-1.rhel6.x86_64 glibc-2.12-1.149.el6_6.5.x86_64 
keyutils-libs-1.4-5.el6.x86_64 krb5-libs-1.10.3-33.el6.x86_64 
libaio-0.3.107-10.el6.x86_64 libcom_err-1.41.12-21.el6.x86_64 
libcurl-7.19.7-40.el6_6.4.x86_64 libidn-1.18-2.el6.x86_64 
libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64 
libselinux-2.0.94-5.8.el6.x86_64 libssh2-1.4.2-1.el6_6.1.x86_64 
libtiff-3.9.4-10.el6_5.x86_64 libtool-ltdl-2.2.6-15.5.el6.x86_64 
libxml2-2.7.6-17.el6_6.1.x86_64 nspr-4.10.6-1.el6_5.x86_64 
nss-3.16.2.3-3.el6_6.x86_64 nss-softokn-freebl-3.14.3-22.el6_6.x86_64 
nss-util-3.16.2.3-2.el6_6.x86_64 numactl-2.0.9-2.el6.x86_64 
openldap-2.4.39-8.el6.x86_64 openssl-1.0.1e-30.el6_6.5.x86_64 
pcre-7.8-6.el6.x86_64 proj-4.8.0-3.el6.x86_64 sqlite-3.6.20-1.el6.x86_64 
unixODBC-2.2.14-14.el6.x86_64 zlib-1.2.3-29.el6.x86_64
(gdb) bt
#0  0x00007ffff314a7fe in kotgttc () from 
/opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
#1  0x00007ffff302d1cb in OCIObjectNew () from 
/opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
#2  0x00007ffff6daec98 in OWConnection::CreateType(OCIColl**, OCIType*) 
() from /home/oscar/sw/gdal-trunk/build/lib/libgdal.so
#3  0x00007fffe9fe4ca5 in pdal::OciWriter::writeTile(pdal::PointBuffer 
const&) ()
    from /home/oscar/sw/PDAL-trunk/build/lib/libpdal_plugin_writer_oci.so
#4  0x00007ffff7d06640 in 
pdal::Writer::run(std::shared_ptr<pdal::PointBuffer>) () from 
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#5  0x00007ffff7ce2908 in pdal::Stage::execute(pdal::PointContext) () 
from /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#6  0x00007ffff7da2a5e in pdal::PipelineKernel::execute() () from 
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#7  0x00007ffff7ca0d57 in pdal::Kernel::innerRun() () from 
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#8  0x00007ffff7ca0fa5 in pdal::Kernel::do_execution() () from 
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#9  0x00007ffff7ca12b4 in pdal::Kernel::run(int, char const**, 
std::basic_string<char, std::char_traits<char>, std::allocator<char> > 
const&) ()
    from /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#10 0x000000000040f96c in main ()


On 23-02-15 00:23, Howard Butler wrote:
>> On Feb 17, 2015, at 8:54 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
>>
>> Thanks guys! Still not working though
>>
>> To get rid of that message I recreated the DB (well the user) and create the base and blocks tables:
>>
>> create table blocks tablespace users pctfree 0 nologging
>> lob(points) store as securefile (tablespace users nocompress
>> cache reads nologging) as
>> SELECT * FROM mdsys.SDO_PC_BLK_TABLE where 0 = 1;
>>
>> create table blocksbase (id number, pc sdo_pc) tablespace users pctfree 0 nologging;
>>
>> BTW, I had to add the ID to the base table (which I was not doing before).
>>
>> But when I run PDAL now I get a Segmentation fault (XML below)
> $ gdb --args pdal pipeline -i myfile.xml --developer-debug
>
> Then press 'r' to run
>
> when crashes, press 'bt' for backtrace. Please report the traceback here.
>
> I just tested https://github.com/PDAL/PDAL/blob/master/test/data/oracle/write.xml with the autzen-dd.las file in test/data/autzen and it successfully loaded for me with no crash. If that one succeeds for you, we might be able to make some progress.
>
> Sorry for the challenges.
>
> Howard
>


From O.MartinezRubi at tudelft.nl  Wed Feb 25 13:17:59 2015
From: O.MartinezRubi at tudelft.nl (Oscar Martinez Rubi - BK)
Date: Wed, 25 Feb 2015 21:17:59 +0000
Subject: [pdal] Oracle point cloud
In-Reply-To: <54EDFE7E.6040908@tudelft.nl>
References: <54E34E19.5020508@tudelft.nl>
	<CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
	<A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>
	<54E35620.7080604@tudelft.nl>
	<E1418D8A-0EB9-435D-9189-15A99D6C9FD5@hobu.co>,
	<54EDFE7E.6040908@tudelft.nl>
Message-ID: <7nqjtuwqpv2v6ykmbi5nfoyk.1424899073539@email.android.com>

BTW, what commands do you use to create the blocks and base tables?


Enviado de Samsung Mobile


-------- Mensaje original --------
De: Oscar Martinez Rubi
Fecha:25/02/2015 17:55 (GMT+01:00)
Para: Howard Butler
Cc: pdal at lists.osgeo.org, Theo Tijssen - BK
Asunto: Re: [pdal] Oracle point cloud

Hi Howard,

I run the pdal pipeline with gdb, please see below.

I also tested with the write.xml and autzen-dd.las in the test folder
and I get the same output.

BTW, I am running this in a Oracle 12.1.0.2 in RedHat 6.5

Any insight?

Regards,

O.


---------------------------
-bash-4.1$ gdb --args pdal pipeline -i oracle_pipeline.xml --developer-debug
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-75.el6)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /home/oscar/sw/PDAL-trunk/build/bin/pdal...(no
debugging symbols found)...done.
(gdb) r
Starting program: /home/oscar/sw/PDAL-trunk/build/bin/pdal pipeline -i
oracle_pipeline.xml --developer-debug
[Thread debugging using libthread_db enabled]
warning: File "/usr/local/gcc484/lib64/libstdc++.so.6.0.19-gdb.py"
auto-loading has been declined by your `auto-load safe-path' set to
"/usr/share/gdb/auto-load:/usr/lib/debug:/usr/bin/mono-gdb.py".
To enable execution of this file add
     add-auto-load-safe-path
/usr/local/gcc484/lib64/libstdc++.so.6.0.19-gdb.py
line to your configuration file "/home/oscar/.gdbinit".
To completely disable this security protection add
     set auto-load safe-path /
line to your configuration file "/home/oscar/.gdbinit".
For more information about this security protection see the
"Auto-loading safe path" section in the GDB manual.  E.g., run from the
shell:
     info "(gdb)Auto-loading safe path"

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff314a7fe in kotgttc () from
/opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
Missing separate debuginfos, use: debuginfo-install
bzip2-libs-1.0.5-7.el6_0.x86_64 cyrus-sasl-lib-2.1.23-15.el6_6.1.x86_64
geos-3.4.2-1.rhel6.x86_64 glibc-2.12-1.149.el6_6.5.x86_64
keyutils-libs-1.4-5.el6.x86_64 krb5-libs-1.10.3-33.el6.x86_64
libaio-0.3.107-10.el6.x86_64 libcom_err-1.41.12-21.el6.x86_64
libcurl-7.19.7-40.el6_6.4.x86_64 libidn-1.18-2.el6.x86_64
libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64
libselinux-2.0.94-5.8.el6.x86_64 libssh2-1.4.2-1.el6_6.1.x86_64
libtiff-3.9.4-10.el6_5.x86_64 libtool-ltdl-2.2.6-15.5.el6.x86_64
libxml2-2.7.6-17.el6_6.1.x86_64 nspr-4.10.6-1.el6_5.x86_64
nss-3.16.2.3-3.el6_6.x86_64 nss-softokn-freebl-3.14.3-22.el6_6.x86_64
nss-util-3.16.2.3-2.el6_6.x86_64 numactl-2.0.9-2.el6.x86_64
openldap-2.4.39-8.el6.x86_64 openssl-1.0.1e-30.el6_6.5.x86_64
pcre-7.8-6.el6.x86_64 proj-4.8.0-3.el6.x86_64 sqlite-3.6.20-1.el6.x86_64
unixODBC-2.2.14-14.el6.x86_64 zlib-1.2.3-29.el6.x86_64
(gdb) bt
#0  0x00007ffff314a7fe in kotgttc () from
/opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
#1  0x00007ffff302d1cb in OCIObjectNew () from
/opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
#2  0x00007ffff6daec98 in OWConnection::CreateType(OCIColl**, OCIType*)
() from /home/oscar/sw/gdal-trunk/build/lib/libgdal.so
#3  0x00007fffe9fe4ca5 in pdal::OciWriter::writeTile(pdal::PointBuffer
const&) ()
    from /home/oscar/sw/PDAL-trunk/build/lib/libpdal_plugin_writer_oci.so
#4  0x00007ffff7d06640 in
pdal::Writer::run(std::shared_ptr<pdal::PointBuffer>) () from
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#5  0x00007ffff7ce2908 in pdal::Stage::execute(pdal::PointContext) ()
from /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#6  0x00007ffff7da2a5e in pdal::PipelineKernel::execute() () from
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#7  0x00007ffff7ca0d57 in pdal::Kernel::innerRun() () from
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#8  0x00007ffff7ca0fa5 in pdal::Kernel::do_execution() () from
/home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#9  0x00007ffff7ca12b4 in pdal::Kernel::run(int, char const**,
std::basic_string<char, std::char_traits<char>, std::allocator<char> >
const&) ()
    from /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
#10 0x000000000040f96c in main ()


On 23-02-15 00:23, Howard Butler wrote:
>> On Feb 17, 2015, at 8:54 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
>>
>> Thanks guys! Still not working though
>>
>> To get rid of that message I recreated the DB (well the user) and create the base and blocks tables:
>>
>> create table blocks tablespace users pctfree 0 nologging
>> lob(points) store as securefile (tablespace users nocompress
>> cache reads nologging) as
>> SELECT * FROM mdsys.SDO_PC_BLK_TABLE where 0 = 1;
>>
>> create table blocksbase (id number, pc sdo_pc) tablespace users pctfree 0 nologging;
>>
>> BTW, I had to add the ID to the base table (which I was not doing before).
>>
>> But when I run PDAL now I get a Segmentation fault (XML below)
> $ gdb --args pdal pipeline -i myfile.xml --developer-debug
>
> Then press 'r' to run
>
> when crashes, press 'bt' for backtrace. Please report the traceback here.
>
> I just tested https://github.com/PDAL/PDAL/blob/master/test/data/oracle/write.xml with the autzen-dd.las file in test/data/autzen and it successfully loaded for me with no crash. If that one succeeds for you, we might be able to make some progress.
>
> Sorry for the challenges.
>
> Howard
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150225/02bfa1e8/attachment.html>

From albert.godfrind at oracle.com  Wed Feb 25 13:28:17 2015
From: albert.godfrind at oracle.com (Albert Godfrind)
Date: Wed, 25 Feb 2015 22:28:17 +0100
Subject: [pdal] Oracle point cloud
In-Reply-To: <7nqjtuwqpv2v6ykmbi5nfoyk.1424899073539@email.android.com>
References: <54E34E19.5020508@tudelft.nl>
	<CACJ51z2bihe6RrBm6V8evnu5w48gHfC6wjkkoVFBgOBR2SiZ8w@mail.gmail.com>
	<A7285F62-8F9F-4333-BC16-6419107CD977@hobu.co>
	<54E35620.7080604@tudelft.nl>
	<E1418D8A-0EB9-435D-9189-15A99D6C9FD5@hobu.co>
	<54EDFE7E.6040908@tudelft.nl>
	<7nqjtuwqpv2v6ykmbi5nfoyk.1424899073539@email.android.com>
Message-ID: <5A74E5AF-B35D-4304-B92A-D6D122916A73@oracle.com>

I would like to test this too in my environments (I have a 11.2.0.1 and a 11.2.0.2 environment)

@Oscar: can you share your PDAL build (it would save me building it myself)

Albert 
--
Albert Godfrind, Oracle
+33 6 09 97 27 23
Sent from my iPhone

> On 25 f?vr. 2015, at 22:17, Oscar Martinez Rubi - BK <O.MartinezRubi at tudelft.nl> wrote:
> 
> BTW, what commands do you use to create the blocks and base tables?
> 
> 
> Enviado de Samsung Mobile
> 
> 
> -------- Mensaje original --------
> De: Oscar Martinez Rubi
> Fecha:25/02/2015 17:55 (GMT+01:00)
> Para: Howard Butler
> Cc: pdal at lists.osgeo.org, Theo Tijssen - BK
> Asunto: Re: [pdal] Oracle point cloud
> 
> Hi Howard,
> 
> I run the pdal pipeline with gdb, please see below.
> 
> I also tested with the write.xml and autzen-dd.las in the test folder 
> and I get the same output.
> 
> BTW, I am running this in a Oracle 12.1.0.2 in RedHat 6.5
> 
> Any insight?
> 
> Regards,
> 
> O.
> 
> 
> ---------------------------
> -bash-4.1$ gdb --args pdal pipeline -i oracle_pipeline.xml --developer-debug
> GNU gdb (GDB) Red Hat Enterprise Linux (7.2-75.el6)
> Copyright (C) 2010 Free Software Foundation, Inc.
> License GPLv3+: GNU GPL version 3 or later 
> <http://gnu.org/licenses/gpl.html>
> This is free software: you are free to change and redistribute it.
> There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
> and "show warranty" for details.
> This GDB was configured as "x86_64-redhat-linux-gnu".
> For bug reporting instructions, please see:
> <http://www.gnu.org/software/gdb/bugs/>...
> Reading symbols from /home/oscar/sw/PDAL-trunk/build/bin/pdal...(no 
> debugging symbols found)...done.
> (gdb) r
> Starting program: /home/oscar/sw/PDAL-trunk/build/bin/pdal pipeline -i 
> oracle_pipeline.xml --developer-debug
> [Thread debugging using libthread_db enabled]
> warning: File "/usr/local/gcc484/lib64/libstdc++.so.6.0.19-gdb.py" 
> auto-loading has been declined by your `auto-load safe-path' set to 
> "/usr/share/gdb/auto-load:/usr/lib/debug:/usr/bin/mono-gdb.py".
> To enable execution of this file add
>      add-auto-load-safe-path 
> /usr/local/gcc484/lib64/libstdc++.so.6.0.19-gdb.py
> line to your configuration file "/home/oscar/.gdbinit".
> To completely disable this security protection add
>      set auto-load safe-path /
> line to your configuration file "/home/oscar/.gdbinit".
> For more information about this security protection see the
> "Auto-loading safe path" section in the GDB manual.  E.g., run from the 
> shell:
>      info "(gdb)Auto-loading safe path"
> 
> Program received signal SIGSEGV, Segmentation fault.
> 0x00007ffff314a7fe in kotgttc () from 
> /opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
> Missing separate debuginfos, use: debuginfo-install 
> bzip2-libs-1.0.5-7.el6_0.x86_64 cyrus-sasl-lib-2.1.23-15.el6_6.1.x86_64 
> geos-3.4.2-1.rhel6.x86_64 glibc-2.12-1.149.el6_6.5.x86_64 
> keyutils-libs-1.4-5.el6.x86_64 krb5-libs-1.10.3-33.el6.x86_64 
> libaio-0.3.107-10.el6.x86_64 libcom_err-1.41.12-21.el6.x86_64 
> libcurl-7.19.7-40.el6_6.4.x86_64 libidn-1.18-2.el6.x86_64 
> libjpeg-turbo-1.2.1-3.el6_5.x86_64 libpng-1.2.49-1.el6_2.x86_64 
> libselinux-2.0.94-5.8.el6.x86_64 libssh2-1.4.2-1.el6_6.1.x86_64 
> libtiff-3.9.4-10.el6_5.x86_64 libtool-ltdl-2.2.6-15.5.el6.x86_64 
> libxml2-2.7.6-17.el6_6.1.x86_64 nspr-4.10.6-1.el6_5.x86_64 
> nss-3.16.2.3-3.el6_6.x86_64 nss-softokn-freebl-3.14.3-22.el6_6.x86_64 
> nss-util-3.16.2.3-2.el6_6.x86_64 numactl-2.0.9-2.el6.x86_64 
> openldap-2.4.39-8.el6.x86_64 openssl-1.0.1e-30.el6_6.5.x86_64 
> pcre-7.8-6.el6.x86_64 proj-4.8.0-3.el6.x86_64 sqlite-3.6.20-1.el6.x86_64 
> unixODBC-2.2.14-14.el6.x86_64 zlib-1.2.3-29.el6.x86_64
> (gdb) bt
> #0  0x00007ffff314a7fe in kotgttc () from 
> /opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
> #1  0x00007ffff302d1cb in OCIObjectNew () from 
> /opt/oracle/product/12.1.0.2/lib/libclntsh.so.12.1
> #2  0x00007ffff6daec98 in OWConnection::CreateType(OCIColl**, OCIType*) 
> () from /home/oscar/sw/gdal-trunk/build/lib/libgdal.so
> #3  0x00007fffe9fe4ca5 in pdal::OciWriter::writeTile(pdal::PointBuffer 
> const&) ()
>     from /home/oscar/sw/PDAL-trunk/build/lib/libpdal_plugin_writer_oci.so
> #4  0x00007ffff7d06640 in 
> pdal::Writer::run(std::shared_ptr<pdal::PointBuffer>) () from 
> /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
> #5  0x00007ffff7ce2908 in pdal::Stage::execute(pdal::PointContext) () 
> from /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
> #6  0x00007ffff7da2a5e in pdal::PipelineKernel::execute() () from 
> /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
> #7  0x00007ffff7ca0d57 in pdal::Kernel::innerRun() () from 
> /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
> #8  0x00007ffff7ca0fa5 in pdal::Kernel::do_execution() () from 
> /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
> #9  0x00007ffff7ca12b4 in pdal::Kernel::run(int, char const**, 
> std::basic_string<char, std::char_traits<char>, std::allocator<char> > 
> const&) ()
>     from /home/oscar/sw/PDAL-trunk/build/lib/libpdalcpp.so
> #10 0x000000000040f96c in main ()
> 
> 
> On 23-02-15 00:23, Howard Butler wrote:
> >> On Feb 17, 2015, at 8:54 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
> >>
> >> Thanks guys! Still not working though
> >>
> >> To get rid of that message I recreated the DB (well the user) and create the base and blocks tables:
> >>
> >> create table blocks tablespace users pctfree 0 nologging
> >> lob(points) store as securefile (tablespace users nocompress
> >> cache reads nologging) as
> >> SELECT * FROM mdsys.SDO_PC_BLK_TABLE where 0 = 1;
> >>
> >> create table blocksbase (id number, pc sdo_pc) tablespace users pctfree 0 nologging;
> >>
> >> BTW, I had to add the ID to the base table (which I was not doing before).
> >>
> >> But when I run PDAL now I get a Segmentation fault (XML below)
> > $ gdb --args pdal pipeline -i myfile.xml --developer-debug
> >
> > Then press 'r' to run
> >
> > when crashes, press 'bt' for backtrace. Please report the traceback here.
> >
> > I just tested https://github.com/PDAL/PDAL/blob/master/test/data/oracle/write.xml with the autzen-dd.las file in test/data/autzen and it successfully loaded for me with no crash. If that one succeeds for you, we might be able to make some progress.
> >
> > Sorry for the challenges.
> >
> > Howard
> >
> 
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150225/e3e91a28/attachment-0001.html>

