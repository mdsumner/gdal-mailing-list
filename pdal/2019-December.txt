From jukka.rahkonen at latuviitta.fi  Mon Dec  2 06:22:04 2019
From: jukka.rahkonen at latuviitta.fi (Jukka Rahkonen)
Date: Mon, 02 Dec 2019 16:22:04 +0200
Subject: [pdal] How to help tindex to find a driver?
Message-ID: <4cad0d78254a2162554cdd8d0f85c7ab@webmail.suomicom.fi>

Hi,


I can read info from my xyz files by defining two extra options for the 
reader and header
pdal info --driver readers.text  --readers.text.header="x y z" 
point_data.xyz --boundary

How can I make tindex to use those two options? So far all my trials 
have been unsuccessful leading to error
PDAL: Cannot determine reader for input file: first_file.xyz

Here is an example about what I have tried:

pdal tindex create --tindex boundary.sqlite --driver readers.text 
--readers.text.header="x y z" --filespec *.xyz -f sqlite


-Jukka Rahkonen-

From andrew.bell.ia at gmail.com  Mon Dec  2 07:50:41 2019
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 2 Dec 2019 10:50:41 -0500
Subject: [pdal] How to help tindex to find a driver?
In-Reply-To: <4cad0d78254a2162554cdd8d0f85c7ab@webmail.suomicom.fi>
References: <4cad0d78254a2162554cdd8d0f85c7ab@webmail.suomicom.fi>
Message-ID: <CACJ51z3R1TFuKEwW0NfX9YPCgujh-kWCg-LT1NjtvjZE26Pdug@mail.gmail.com>

I don't see any reason why this wouldn't work.  If you could open an issue
on Github that would be great.

On Mon, Dec 2, 2019 at 9:28 AM Jukka Rahkonen <jukka.rahkonen at latuviitta.fi>
wrote:

> Hi,
>
>
> I can read info from my xyz files by defining two extra options for the
> reader and header
> pdal info --driver readers.text  --readers.text.header="x y z"
> point_data.xyz --boundary
>
> How can I make tindex to use those two options? So far all my trials
> have been unsuccessful leading to error
> PDAL: Cannot determine reader for input file: first_file.xyz
>
> Here is an example about what I have tried:
>
> pdal tindex create --tindex boundary.sqlite --driver readers.text
> --readers.text.header="x y z" --filespec *.xyz -f sqlite
>
>
> -Jukka Rahkonen-
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191202/53b11c2a/attachment.html>

From jukka.rahkonen at latuviitta.fi  Tue Dec  3 04:44:00 2019
From: jukka.rahkonen at latuviitta.fi (Jukka Rahkonen)
Date: Tue, 03 Dec 2019 14:44:00 +0200
Subject: [pdal] What's wrong with pdal density?
Message-ID: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>

Hi,

I have tried to repeat the example from 
https://pdal.io/workshop/exercises/analysis/density/density.html#density. 
I have prepared test data that opens with pdal info simply as "pdal info 
  testdata.txt". If I run now

pdal density testdata.txt -o output.sqlite -f sqlite --debug on
(PDAL Debug) Debugging...

just nothing seems to happen. Output file is not created but I don't get 
either error messages or more debug info. Pdal info --boundary works as 
expected.

PDAL version is pdal 1.8.0 (git-version: Release) from OSGeo4W.

-Jukka Rahkonen-

From howard at hobu.co  Tue Dec  3 06:26:42 2019
From: howard at hobu.co (Howard Butler)
Date: Tue, 3 Dec 2019 08:26:42 -0600
Subject: [pdal] What's wrong with pdal density?
In-Reply-To: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
References: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
Message-ID: <AE5CE7E7-63D6-4E02-B4D2-4E1E9D9CC806@hobu.co>

Jukka,

PDAL 1.8.0 is quite old. Can you grab a conda build and test there? I seem to remember a bug fix from a while ago on this topic.

Howard

> On Dec 3, 2019, at 6:44 AM, Jukka Rahkonen <jukka.rahkonen at latuviitta.fi> wrote:
> 
> Hi,
> 
> I have tried to repeat the example from https://pdal.io/workshop/exercises/analysis/density/density.html#density. I have prepared test data that opens with pdal info simply as "pdal info  testdata.txt". If I run now
> 
> pdal density testdata.txt -o output.sqlite -f sqlite --debug on
> (PDAL Debug) Debugging...
> 
> just nothing seems to happen. Output file is not created but I don't get either error messages or more debug info. Pdal info --boundary works as expected.
> 
> PDAL version is pdal 1.8.0 (git-version: Release) from OSGeo4W.
> 
> -Jukka Rahkonen-
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal


From michael.smith.erdc at gmail.com  Tue Dec  3 06:09:13 2019
From: michael.smith.erdc at gmail.com (Michael Smith)
Date: Tue, 3 Dec 2019 09:09:13 -0500
Subject: [pdal] What's wrong with pdal density?
In-Reply-To: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
References: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
Message-ID: <3DDB3B29-0356-4819-BD7C-0B65DB5F2CE3@gmail.com>

Jukka, for a text file, you probably need a header to map the dimensions. Does it work with pdal info?

Michael Smith

> On Dec 3, 2019, at 7:44 AM, Jukka Rahkonen <jukka.rahkonen at latuviitta.fi> wrote:
> 
> ï»¿Hi,
> 
> I have tried to repeat the example from https://pdal.io/workshop/exercises/analysis/density/density.html#density. I have prepared test data that opens with pdal info simply as "pdal info  testdata.txt". If I run now
> 
> pdal density testdata.txt -o output.sqlite -f sqlite --debug on
> (PDAL Debug) Debugging...
> 
> just nothing seems to happen. Output file is not created but I don't get either error messages or more debug info. Pdal info --boundary works as expected.
> 
> PDAL version is pdal 1.8.0 (git-version: Release) from OSGeo4W.
> 
> -Jukka Rahkonen-
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal

From jukka.rahkonen at latuviitta.fi  Tue Dec  3 09:59:26 2019
From: jukka.rahkonen at latuviitta.fi (Jukka Rahkonen)
Date: Tue, 03 Dec 2019 19:59:26 +0200
Subject: [pdal] What's wrong with pdal density?
In-Reply-To: <AE5CE7E7-63D6-4E02-B4D2-4E1E9D9CC806@hobu.co>
References: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
 <AE5CE7E7-63D6-4E02-B4D2-4E1E9D9CC806@hobu.co>
Message-ID: <31aeefb746f437a849a5d9624ba6bd7b@webmail.suomicom.fi>

Hi,

Thank you for encouraging me to try conda for the first time ever. Nice 
experience. Also good news, with version pdal 2.0.1 (git-version: 
Release) the density command worked fine.

You seem to be the maintainer of these packages 
http://download.osgeo.org/osgeo4w/x86_64/release/pdal/, I wonder if I 
dare to give a hint...

Regards,

-Jukka Rahkonen-

Howard Butler kirjoitti 2019-12-03 16:26:
> Jukka,
> 
> PDAL 1.8.0 is quite old. Can you grab a conda build and test there? I
> seem to remember a bug fix from a while ago on this topic.
> 
> Howard
> 
>> On Dec 3, 2019, at 6:44 AM, Jukka Rahkonen 
>> <jukka.rahkonen at latuviitta.fi> wrote:
>> 
>> Hi,
>> 
>> I have tried to repeat the example from 
>> https://pdal.io/workshop/exercises/analysis/density/density.html#density. 
>> I have prepared test data that opens with pdal info simply as "pdal 
>> info  testdata.txt". If I run now
>> 
>> pdal density testdata.txt -o output.sqlite -f sqlite --debug on
>> (PDAL Debug) Debugging...
>> 
>> just nothing seems to happen. Output file is not created but I don't 
>> get either error messages or more debug info. Pdal info --boundary 
>> works as expected.
>> 
>> PDAL version is pdal 1.8.0 (git-version: Release) from OSGeo4W.
>> 
>> -Jukka Rahkonen-
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal

From howard at hobu.co  Tue Dec  3 10:42:53 2019
From: howard at hobu.co (Howard Butler)
Date: Tue, 3 Dec 2019 12:42:53 -0600
Subject: [pdal] What's wrong with pdal density?
In-Reply-To: <31aeefb746f437a849a5d9624ba6bd7b@webmail.suomicom.fi>
References: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
 <AE5CE7E7-63D6-4E02-B4D2-4E1E9D9CC806@hobu.co>
 <31aeefb746f437a849a5d9624ba6bd7b@webmail.suomicom.fi>
Message-ID: <6BA1A3C6-962F-4F9C-84B2-03A50CCC2BB0@hobu.co>



> On Dec 3, 2019, at 11:59 AM, Jukka Rahkonen <jukka.rahkonen at latuviitta.fi> wrote:
> 
> Hi,
> 
> Thank you for encouraging me to try conda for the first time ever. Nice experience. Also good news, with version pdal 2.0.1 (git-version: Release) the density command worked fine.

Good to hear. QGIS is available on Conda Forge too, if that's what had you using OSGeo4W...

> 
> You seem to be the maintainer of these packages http://download.osgeo.org/osgeo4w/x86_64/release/pdal/, I wonder if I dare to give a hint...

The PDAL team no longer maintains any OSGeo4W packages. We found it too difficult to keep the dependencies controlled. Conda Forge-based builds are not so much better in that regard, but there is a much larger framework of libraries and developers using it. Conda binaries also give us distribution with all three primary platforms, and the conda platform is integrated into development environments quite cleanly (Visual Studio Code being a primary target for us).

I have not removed the OSGeo4W builds because I did not know what OSGeo4W software might have been using them.

Howard


From doug_newcomb at fws.gov  Tue Dec  3 11:12:01 2019
From: doug_newcomb at fws.gov (Newcomb, Doug)
Date: Tue, 3 Dec 2019 14:12:01 -0500
Subject: [pdal] [EXTERNAL] Re:  What's wrong with pdal density?
In-Reply-To: <6BA1A3C6-962F-4F9C-84B2-03A50CCC2BB0@hobu.co>
References: <08241373d762b007b50ba95a14962214@webmail.suomicom.fi>
 <AE5CE7E7-63D6-4E02-B4D2-4E1E9D9CC806@hobu.co>
 <31aeefb746f437a849a5d9624ba6bd7b@webmail.suomicom.fi>
 <6BA1A3C6-962F-4F9C-84B2-03A50CCC2BB0@hobu.co>
Message-ID: <CALQGVr0E4A1MP=umtCvo=wfRnaVO=js4TgJXzo3OEpy5XmqsAg@mail.gmail.com>

On Tue, Dec 3, 2019 at 1:43 PM Howard Butler <howard at hobu.co> wrote:

>
>
> > On Dec 3, 2019, at 11:59 AM, Jukka Rahkonen <
> jukka.rahkonen at latuviitta.fi> wrote:
> >
> > Hi,
> >
> > Thank you for encouraging me to try conda for the first time ever. Nice
> experience. Also good news, with version pdal 2.0.1 (git-version: Release)
> the density command worked fine.
>
> Good to hear. QGIS is available on Conda Forge too, if that's what had you
> using OSGeo4W...
>
> >
> > You seem to be the maintainer of these packages
> http://download.osgeo.org/osgeo4w/x86_64/release/pdal/, I wonder if I
> dare to give a hint...
>
> The PDAL team no longer maintains any OSGeo4W packages. We found it too
> difficult to keep the dependencies controlled. Conda Forge-based builds are
> not so much better in that regard, but there is a much larger framework of
> libraries and developers using it. Conda binaries also give us distribution
> with all three primary platforms, and the conda platform is integrated into
> development environments quite cleanly (Visual Studio Code being a primary
> target for us).
>
> I have not removed the OSGeo4W builds because I did not know what OSGeo4W
> software might have been using them.
>

I believe that GRASS may be using them, but that may be problematic with
the transition to proj 6 and gdal 3.





>
> Howard
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Doug Newcomb - Cartographer
USFWS
551F Pylon Dr
Raleigh, NC
919-856-4520 ext. 14 doug_newcomb at fws.gov
---------------------------------------------------------------------------------------------------------

*NOTE: This email correspondence and any attachments to and from this
sender is subject to the Freedom of Information Act (FOIA) and may be
disclosed to third parties.*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191203/55442141/attachment.html>

From jasonmcvay09 at gmail.com  Sun Dec  8 17:09:55 2019
From: jasonmcvay09 at gmail.com (Jason McVay)
Date: Sun, 8 Dec 2019 20:09:55 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
Message-ID: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>

I'm looking for some advice on the best way/how to loop in thousands of
bounding coordinates into a pdal pipeline.

I have a csv (and a geojson) of several thousand min/max x/y and a unique
ID. The AOI's are not very big, so the pipeline runs quickly, but there are
a lot of AOIs to capture! I'm querying an entwine dataset, the extent of
which is national, so I'm limiting the data with a bounding box of each AOI.

My pipeline currently runs HAG and Ferry Z filter, then uses the
gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
manually enter in a set of test coordinates. How can I scale this to loop
and update the bounds automatically?

I'm running this locally on a MacBook Pro.

Thank you, any advice is appreciated!


Jason McVay

MS Geography, Virginia Tech
BA Environmental Studies, University of Montana
www.linkedin.com/in/jasonmcvay86/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191208/b53e9788/attachment.html>

From nicolas.cadieux at archeotec.ca  Sun Dec  8 19:24:44 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Sun, 8 Dec 2019 22:24:44 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
Message-ID: <8AD1F8B5-2E0C-4E91-B399-B213585E79E5@archeotec.ca>

Hi,
I imagine you are working with Python? Sharing your script could help. I see multiple options but itâs hard to grasp what you need and how fare you are.
Nicolas

> Le 8 dÃ©c. 2019 Ã  20:10, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
> 
> ï»¿
> I'm looking for some advice on the best way/how to loop in thousands of bounding coordinates into a pdal pipeline.
> 
> I have a csv (and a geojson) of several thousand min/max x/y and a unique ID. The AOI's are not very big, so the pipeline runs quickly, but there are a lot of AOIs to capture! I'm querying an entwine dataset, the extent of which is national, so I'm limiting the data with a bounding box of each AOI.
> 
> My pipeline currently runs HAG and Ferry Z filter, then uses the gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I manually enter in a set of test coordinates. How can I scale this to loop and update the bounds automatically?
> 
> I'm running this locally on a MacBook Pro.
> 
> Thank you, any advice is appreciated!
> 
> 
> Jason McVay
> 
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/
> 
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191208/c8f63e65/attachment.html>

From jasonmcvay09 at gmail.com  Sun Dec  8 19:49:25 2019
From: jasonmcvay09 at gmail.com (Jason McVay)
Date: Sun, 8 Dec 2019 22:49:25 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <8AD1F8B5-2E0C-4E91-B399-B213585E79E5@archeotec.ca>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
 <8AD1F8B5-2E0C-4E91-B399-B213585E79E5@archeotec.ca>
Message-ID: <CAGHb013hjN5Yt+82HRFxZUundzhSXQjbW2kpghzRxsrref0Bdg@mail.gmail.com>

Hi Nicolas,

Thanks for your reply!

I'm attaching my pipeline here. So far I have been running the pipeline
through command line in a conda environment. I'm fairly comfortable with
python and have set up pdal to work with my python environment, but haven't
tried anything outside of the command line yet. I also have a csv with the
following columns [minx, maxx, miny, maxy, id].

Jason McVay

MS Geography, Virginia Tech
BA Environmental Studies, University of Montana
www.linkedin.com/in/jasonmcvay86/


On Sun, Dec 8, 2019 at 10:24 PM Nicolas Cadieux <
nicolas.cadieux at archeotec.ca> wrote:

> Hi,
> I imagine you are working with Python? Sharing your script could help. I
> see multiple options but itâs hard to grasp what you need and how fare you
> are.
> Nicolas
>
> Le 8 dÃ©c. 2019 Ã  20:10, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
>
> ï»¿
> I'm looking for some advice on the best way/how to loop in thousands of
> bounding coordinates into a pdal pipeline.
>
> I have a csv (and a geojson) of several thousand min/max x/y and a unique
> ID. The AOI's are not very big, so the pipeline runs quickly, but there are
> a lot of AOIs to capture! I'm querying an entwine dataset, the extent of
> which is national, so I'm limiting the data with a bounding box of each AOI.
>
> My pipeline currently runs HAG and Ferry Z filter, then uses the
> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
> manually enter in a set of test coordinates. How can I scale this to loop
> and update the bounds automatically?
>
> I'm running this locally on a MacBook Pro.
>
> Thank you, any advice is appreciated!
>
>
> Jason McVay
>
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191208/d6905aad/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: entwine_hag2dem_pipeline_example.json
Type: application/json
Size: 647 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191208/d6905aad/attachment.json>

From nicolas.cadieux at archeotec.ca  Sun Dec  8 19:56:50 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Sun, 8 Dec 2019 22:56:50 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb013hjN5Yt+82HRFxZUundzhSXQjbW2kpghzRxsrref0Bdg@mail.gmail.com>
References: <CAGHb013hjN5Yt+82HRFxZUundzhSXQjbW2kpghzRxsrref0Bdg@mail.gmail.com>
Message-ID: <8AC764CE-8542-42CC-84CA-F10107E3BC6D@archeotec.ca>

Ok, 

Running the command in a python script will be the next step in my opinion. This will permit the looping process.   Do you need to multithread the task to make it faster?  I will try to  look at this tomorrow.  I have some examples I can give you that will help.  

I am not a pdal guru but if you figured out the command, the rest is probably easy in Python.  Others, please help out if you have better ideas.

Nicolas

> Le 8 dÃ©c. 2019 Ã  22:49, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
> 
> ï»¿
> Hi Nicolas,
> 
> Thanks for your reply!
> 
> I'm attaching my pipeline here. So far I have been running the pipeline through command line in a conda environment. I'm fairly comfortable with python and have set up pdal to work with my python environment, but haven't tried anything outside of the command line yet. I also have a csv with the following columns [minx, maxx, miny, maxy, id].
> 
> Jason McVay
> 
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/
> 
> 
>> On Sun, Dec 8, 2019 at 10:24 PM Nicolas Cadieux <nicolas.cadieux at archeotec.ca> wrote:
>> Hi,
>> I imagine you are working with Python? Sharing your script could help. I see multiple options but itâs hard to grasp what you need and how fare you are.
>> Nicolas
>> 
>>>> Le 8 dÃ©c. 2019 Ã  20:10, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
>>>> 
>>> ï»¿
>>> I'm looking for some advice on the best way/how to loop in thousands of bounding coordinates into a pdal pipeline.
>>> 
>>> I have a csv (and a geojson) of several thousand min/max x/y and a unique ID. The AOI's are not very big, so the pipeline runs quickly, but there are a lot of AOIs to capture! I'm querying an entwine dataset, the extent of which is national, so I'm limiting the data with a bounding box of each AOI.
>>> 
>>> My pipeline currently runs HAG and Ferry Z filter, then uses the gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I manually enter in a set of test coordinates. How can I scale this to loop and update the bounds automatically?
>>> 
>>> I'm running this locally on a MacBook Pro.
>>> 
>>> Thank you, any advice is appreciated!
>>> 
>>> 
>>> Jason McVay
>>> 
>>> MS Geography, Virginia Tech
>>> BA Environmental Studies, University of Montana
>>> www.linkedin.com/in/jasonmcvay86/
>>> 
>>> _______________________________________________
>>> pdal mailing list
>>> pdal at lists.osgeo.org
>>> https://lists.osgeo.org/mailman/listinfo/pdal
> 
> <entwine_hag2dem_pipeline_example.json>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191208/5c975d51/attachment-0001.html>

From jasonmcvay09 at gmail.com  Sun Dec  8 20:02:33 2019
From: jasonmcvay09 at gmail.com (Jason McVay)
Date: Sun, 8 Dec 2019 23:02:33 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <8AC764CE-8542-42CC-84CA-F10107E3BC6D@archeotec.ca>
References: <CAGHb013hjN5Yt+82HRFxZUundzhSXQjbW2kpghzRxsrref0Bdg@mail.gmail.com>
 <8AC764CE-8542-42CC-84CA-F10107E3BC6D@archeotec.ca>
Message-ID: <B9618065-96DA-42D8-ADE1-A087D6081BC5@gmail.com>

Examples would be extremely helpful! Multithreading would be ideal, but not essential. 

Jason McVay
MS, Geography - Virginia Tech
BA, Environmental Studies - Montana

> On Dec 8, 2019, at 10:56 PM, Nicolas Cadieux <nicolas.cadieux at archeotec.ca> wrote:
> 
> Ok, 
> 
> Running the command in a python script will be the next step in my opinion. This will permit the looping process.   Do you need to multithread the task to make it faster?  I will try to  look at this tomorrow.  I have some examples I can give you that will help.  
> 
> I am not a pdal guru but if you figured out the command, the rest is probably easy in Python.  Others, please help out if you have better ideas.
> 
> Nicolas
> 
>> Le 8 dÃ©c. 2019 Ã  22:49, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
>> 
>> ï»¿
>> Hi Nicolas,
>> 
>> Thanks for your reply!
>> 
>> I'm attaching my pipeline here. So far I have been running the pipeline through command line in a conda environment. I'm fairly comfortable with python and have set up pdal to work with my python environment, but haven't tried anything outside of the command line yet. I also have a csv with the following columns [minx, maxx, miny, maxy, id].
>> 
>> Jason McVay
>> 
>> MS Geography, Virginia Tech
>> BA Environmental Studies, University of Montana
>> www.linkedin.com/in/jasonmcvay86/
>> 
>> 
>>> On Sun, Dec 8, 2019 at 10:24 PM Nicolas Cadieux <nicolas.cadieux at archeotec.ca> wrote:
>>> Hi,
>>> I imagine you are working with Python? Sharing your script could help. I see multiple options but itâs hard to grasp what you need and how fare you are.
>>> Nicolas
>>> 
>>>> Le 8 dÃ©c. 2019 Ã  20:10, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
>>>> 
>>>> ï»¿
>>>> I'm looking for some advice on the best way/how to loop in thousands of bounding coordinates into a pdal pipeline.
>>>> 
>>>> I have a csv (and a geojson) of several thousand min/max x/y and a unique ID. The AOI's are not very big, so the pipeline runs quickly, but there are a lot of AOIs to capture! I'm querying an entwine dataset, the extent of which is national, so I'm limiting the data with a bounding box of each AOI.
>>>> 
>>>> My pipeline currently runs HAG and Ferry Z filter, then uses the gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I manually enter in a set of test coordinates. How can I scale this to loop and update the bounds automatically?
>>>> 
>>>> I'm running this locally on a MacBook Pro.
>>>> 
>>>> Thank you, any advice is appreciated!
>>>> 
>>>> 
>>>> Jason McVay
>>>> 
>>>> MS Geography, Virginia Tech
>>>> BA Environmental Studies, University of Montana
>>>> www.linkedin.com/in/jasonmcvay86/
>>>> 
>>>> _______________________________________________
>>>> pdal mailing list
>>>> pdal at lists.osgeo.org
>>>> https://lists.osgeo.org/mailman/listinfo/pdal
>> 
>> <entwine_hag2dem_pipeline_example.json>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191208/c9b2004f/attachment.html>

From howard at hobu.co  Mon Dec  9 05:36:09 2019
From: howard at hobu.co (Howard Butler)
Date: Mon, 9 Dec 2019 07:36:09 -0600
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
Message-ID: <AEF2D524-35D1-48CC-94DD-AD902EDAEC59@hobu.co>



> On Dec 8, 2019, at 7:09 PM, Jason McVay <jasonmcvay09 at gmail.com> wrote:
> 
> I'm looking for some advice on the best way/how to loop in thousands of bounding coordinates into a pdal pipeline.
> 
> I have a csv (and a geojson) of several thousand min/max x/y and a unique ID. The AOI's are not very big, so the pipeline runs quickly, but there are a lot of AOIs to capture! I'm querying an entwine dataset, the extent of which is national, so I'm limiting the data with a bounding box of each AOI.
> 
> My pipeline currently runs HAG and Ferry Z filter, then uses the gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I manually enter in a set of test coordinates. How can I scale this to loop and update the bounds automatically?
> 
> I'm running this locally on a MacBook Pro.
> 
> Thank you, any advice is appreciated!

Jason,

PDAL doesn't multithread or operate in a parallel fashion for you. You must use external tools to do this yourself. I have had good success using GNU parallel or xargs on bash along with the Python multiprocessing library to achieve that.

You scenario would seem to fit that model quite well. Here's a GNU parallel example. In short, use your favorite scripting language (or sed/awk/cat) to write a script that contains all of the job entries you need to run (bounds entries are all the same in my example, but you should get the point:

> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_henry_co.tif"
> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_howard_co.tif"
> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_james_co.tif"
> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_mike_co.tif"


Then run that script:

> parallel -j 16 < jobs.txt

Filtering EPT resources with boundaries is a common desire. I recently added a pull request to master (not yet released) that allows you to specify filtering (for faster query) and cropping (eliminating an extra stage specification) for EPT resources. See https://github.com/PDAL/PDAL/pull/2771#issue-323371431 <https://github.com/PDAL/PDAL/pull/2771#issue-323371431> The goal with the approach in the pull request is to not have to change format of the bounding geometries to text simply to feed them into a pipeline. We may add similar capability to other drivers if it is indeed useful in other contexts. 

With the PR, you could express your query boundaries as an OGR query and then iterate through your EPT resources. The current PR implementation doesn't "split" by the polygons, however. We might need to add the same capability to filters.crop to achieve that. Feedback is appreciated so we can learn how people wish to use this.

Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191209/e1965f1a/attachment.html>

From andrew.bell.ia at gmail.com  Mon Dec  9 06:03:25 2019
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 9 Dec 2019 09:03:25 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb013hjN5Yt+82HRFxZUundzhSXQjbW2kpghzRxsrref0Bdg@mail.gmail.com>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
 <8AD1F8B5-2E0C-4E91-B399-B213585E79E5@archeotec.ca>
 <CAGHb013hjN5Yt+82HRFxZUundzhSXQjbW2kpghzRxsrref0Bdg@mail.gmail.com>
Message-ID: <CACJ51z3DhMxztVjdcx5sDXNrRc5VMvtys1VEu=bcpd5XpePwHQ@mail.gmail.com>

I'll just note that the ferry filter in your pipeline does nothing since
you explicitly write the HeightAboveGround dimension in your raster.

I think the answer to this is simply to write a script -- bash or something
similar should work fine.

On Sun, Dec 8, 2019 at 10:49 PM Jason McVay <jasonmcvay09 at gmail.com> wrote:

> Hi Nicolas,
>
> Thanks for your reply!
>
> I'm attaching my pipeline here. So far I have been running the pipeline
> through command line in a conda environment. I'm fairly comfortable with
> python and have set up pdal to work with my python environment, but haven't
> tried anything outside of the command line yet. I also have a csv with the
> following columns [minx, maxx, miny, maxy, id].
>
> Jason McVay
>
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/
>
>
> On Sun, Dec 8, 2019 at 10:24 PM Nicolas Cadieux <
> nicolas.cadieux at archeotec.ca> wrote:
>
>> Hi,
>> I imagine you are working with Python? Sharing your script could help. I
>> see multiple options but itâs hard to grasp what you need and how fare you
>> are.
>> Nicolas
>>
>> Le 8 dÃ©c. 2019 Ã  20:10, Jason McVay <jasonmcvay09 at gmail.com> a Ã©crit :
>>
>> ï»¿
>> I'm looking for some advice on the best way/how to loop in thousands of
>> bounding coordinates into a pdal pipeline.
>>
>> I have a csv (and a geojson) of several thousand min/max x/y and a unique
>> ID. The AOI's are not very big, so the pipeline runs quickly, but there are
>> a lot of AOIs to capture! I'm querying an entwine dataset, the extent of
>> which is national, so I'm limiting the data with a bounding box of each AOI.
>>
>> My pipeline currently runs HAG and Ferry Z filter, then uses the
>> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
>> manually enter in a set of test coordinates. How can I scale this to loop
>> and update the bounds automatically?
>>
>> I'm running this locally on a MacBook Pro.
>>
>> Thank you, any advice is appreciated!
>>
>>
>> Jason McVay
>>
>> MS Geography, Virginia Tech
>> BA Environmental Studies, University of Montana
>> www.linkedin.com/in/jasonmcvay86/
>>
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
>>
>> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191209/bf5349c5/attachment-0001.html>

From jasonmcvay09 at gmail.com  Mon Dec  9 12:41:51 2019
From: jasonmcvay09 at gmail.com (Jason McVay)
Date: Mon, 9 Dec 2019 15:41:51 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <AEF2D524-35D1-48CC-94DD-AD902EDAEC59@hobu.co>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
 <AEF2D524-35D1-48CC-94DD-AD902EDAEC59@hobu.co>
Message-ID: <CAGHb0113zZHeEYqBfmYc0jebH9aWZ04baeq_MOu9_DbynhLH9g@mail.gmail.com>

Thanks Howard! I think this is the way to go. I would be interested in
exploring the pull request version as well, but I may have to wait until
after the holiday break to get to that.
Jason McVay

MS Geography, Virginia Tech
BA Environmental Studies, University of Montana
www.linkedin.com/in/jasonmcvay86/
https://twitter.com/jasonmcvay

*"May your trails be crooked, winding, lonesome, dangerous, leading to the
most amazing view"*
- Ed Abbey


On Mon, Dec 9, 2019 at 8:36 AM Howard Butler <howard at hobu.co> wrote:

>
>
> On Dec 8, 2019, at 7:09 PM, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>
> I'm looking for some advice on the best way/how to loop in thousands of
> bounding coordinates into a pdal pipeline.
>
> I have a csv (and a geojson) of several thousand min/max x/y and a unique
> ID. The AOI's are not very big, so the pipeline runs quickly, but there are
> a lot of AOIs to capture! I'm querying an entwine dataset, the extent of
> which is national, so I'm limiting the data with a bounding box of each AOI.
>
> My pipeline currently runs HAG and Ferry Z filter, then uses the
> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
> manually enter in a set of test coordinates. How can I scale this to loop
> and update the bounds automatically?
>
> I'm running this locally on a MacBook Pro.
>
> Thank you, any advice is appreciated!
>
>
> Jason,
>
> PDAL doesn't multithread or operate in a parallel fashion for you. You
> must use external tools to do this yourself. I have had good success using
> GNU parallel or xargs on bash along with the Python multiprocessing library
> to achieve that.
>
> You scenario would seem to fit that model quite well. Here's a GNU
> parallel example. In short, use your favorite scripting language (or
> sed/awk/cat) to write a script that contains all of the job entries you
> need to run (bounds entries are all the same in my example, but you should
> get the point:
>
> pdal pipeline pipe.json --readers.ept.filename="
> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
> -10060190.36], [5038996.16, 5043062.79])"
> --writers.gdal.filename="hag_mean_henry_co.tif"
> pdal pipeline pipe.json --readers.ept.filename="
> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
> -10060190.36], [5038996.16, 5043062.79])"
> --writers.gdal.filename="hag_mean_howard_co.tif"
> pdal pipeline pipe.json --readers.ept.filename="
> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
> -10060190.36], [5038996.16, 5043062.79])"
> --writers.gdal.filename="hag_mean_james_co.tif"
> pdal pipeline pipe.json --readers.ept.filename="
> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
> -10060190.36], [5038996.16, 5043062.79])"
> --writers.gdal.filename="hag_mean_mike_co.tif"
>
>
>
> Then run that script:
>
> parallel -j 16 < jobs.txt
>
>
> Filtering EPT resources with boundaries is a common desire. I recently
> added a pull request to master (not yet released) that allows you to
> specify filtering (for faster query) and cropping (eliminating an extra
> stage specification) for EPT resources. See
> https://github.com/PDAL/PDAL/pull/2771#issue-323371431 The goal with the
> approach in the pull request is to not have to change format of the
> bounding geometries to text simply to feed them into a pipeline. We may add
> similar capability to other drivers if it is indeed useful in other
> contexts.
>
> With the PR, you could express your query boundaries as an OGR query and
> then iterate through your EPT resources. The current PR implementation
> doesn't "split" by the polygons, however. We might need to add the same
> capability to filters.crop to achieve that. Feedback is appreciated so we
> can learn how people wish to use this.
>
> Howard
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191209/c20cdd8e/attachment.html>

From adam.d.steer at gmail.com  Mon Dec  9 14:36:34 2019
From: adam.d.steer at gmail.com (adam steer)
Date: Tue, 10 Dec 2019 09:36:34 +1100
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb0113zZHeEYqBfmYc0jebH9aWZ04baeq_MOu9_DbynhLH9g@mail.gmail.com>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
 <AEF2D524-35D1-48CC-94DD-AD902EDAEC59@hobu.co>
 <CAGHb0113zZHeEYqBfmYc0jebH9aWZ04baeq_MOu9_DbynhLH9g@mail.gmail.com>
Message-ID: <CAFORoyjjaBQoHiEBhmdesSjdHiH8sE7-Vv9Josnp1Dx+TxBkUw@mail.gmail.com>

Hi Jason

Weighing in late here, itâs possible to cobble together fiona/shapely/pdal
to loop through a bunch of polygons (or process them in parallel) and do
what you need. Itâs a task thatâs on my list of things to do when I get
time :)

That way you can assemble a processing pipeline which goes straight from
some geometries to data, without waiting for the new PR..

Cheers,

Adam



On Tue, 10 Dec 2019 at 07:42, Jason McVay <jasonmcvay09 at gmail.com> wrote:

> Thanks Howard! I think this is the way to go. I would be interested in
> exploring the pull request version as well, but I may have to wait until
> after the holiday break to get to that.
> Jason McVay
>
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/
> https://twitter.com/jasonmcvay
>
> *"May your trails be crooked, winding, lonesome, dangerous, leading to the
> most amazing view"*
> - Ed Abbey
>
>
> On Mon, Dec 9, 2019 at 8:36 AM Howard Butler <howard at hobu.co> wrote:
>
>>
>>
>> On Dec 8, 2019, at 7:09 PM, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>>
>> I'm looking for some advice on the best way/how to loop in thousands of
>> bounding coordinates into a pdal pipeline.
>>
>> I have a csv (and a geojson) of several thousand min/max x/y and a unique
>> ID. The AOI's are not very big, so the pipeline runs quickly, but there are
>> a lot of AOIs to capture! I'm querying an entwine dataset, the extent of
>> which is national, so I'm limiting the data with a bounding box of each AOI.
>>
>> My pipeline currently runs HAG and Ferry Z filter, then uses the
>> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
>> manually enter in a set of test coordinates. How can I scale this to loop
>> and update the bounds automatically?
>>
>> I'm running this locally on a MacBook Pro.
>>
>> Thank you, any advice is appreciated!
>>
>>
>> Jason,
>>
>> PDAL doesn't multithread or operate in a parallel fashion for you. You
>> must use external tools to do this yourself. I have had good success using
>> GNU parallel or xargs on bash along with the Python multiprocessing library
>> to achieve that.
>>
>> You scenario would seem to fit that model quite well. Here's a GNU
>> parallel example. In short, use your favorite scripting language (or
>> sed/awk/cat) to write a script that contains all of the job entries you
>> need to run (bounds entries are all the same in my example, but you should
>> get the point:
>>
>> pdal pipeline pipe.json --readers.ept.filename="
>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>> -10060190.36], [5038996.16, 5043062.79])"
>> --writers.gdal.filename="hag_mean_henry_co.tif"
>> pdal pipeline pipe.json --readers.ept.filename="
>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>> -10060190.36], [5038996.16, 5043062.79])"
>> --writers.gdal.filename="hag_mean_howard_co.tif"
>> pdal pipeline pipe.json --readers.ept.filename="
>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>> -10060190.36], [5038996.16, 5043062.79])"
>> --writers.gdal.filename="hag_mean_james_co.tif"
>> pdal pipeline pipe.json --readers.ept.filename="
>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>> -10060190.36], [5038996.16, 5043062.79])"
>> --writers.gdal.filename="hag_mean_mike_co.tif"
>>
>>
>>
>> Then run that script:
>>
>> parallel -j 16 < jobs.txt
>>
>>
>> Filtering EPT resources with boundaries is a common desire. I recently
>> added a pull request to master (not yet released) that allows you to
>> specify filtering (for faster query) and cropping (eliminating an extra
>> stage specification) for EPT resources. See
>> https://github.com/PDAL/PDAL/pull/2771#issue-323371431 The goal with the
>> approach in the pull request is to not have to change format of the
>> bounding geometries to text simply to feed them into a pipeline. We may add
>> similar capability to other drivers if it is indeed useful in other
>> contexts.
>>
>> With the PR, you could express your query boundaries as an OGR query and
>> then iterate through your EPT resources. The current PR implementation
>> doesn't "split" by the polygons, however. We might need to add the same
>> capability to filters.crop to achieve that. Feedback is appreciated so we
>> can learn how people wish to use this.
>>
>> Howard
>>
>> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Dr. Adam Steer
http://spatialised.net
https://www.researchgate.net/profile/Adam_Steer
http://au.linkedin.com/in/adamsteer
http://orcid.org/0000-0003-0046-7236
+61 427 091 712 ::  @adamdsteer

Suits are bad for business: http://www.spatialised.net/business-penguins/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191210/081ec998/attachment.html>

From nicolas.cadieux at archeotec.ca  Mon Dec  9 15:09:11 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Mon, 9 Dec 2019 18:09:11 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAFORoyjjaBQoHiEBhmdesSjdHiH8sE7-Vv9Josnp1Dx+TxBkUw@mail.gmail.com>
References: <CAFORoyjjaBQoHiEBhmdesSjdHiH8sE7-Vv9Josnp1Dx+TxBkUw@mail.gmail.com>
Message-ID: <9A2AA79C-322D-4C8A-93E1-3035734C16C9@archeotec.ca>

Hi,
I will send him a similar python loop tomorrow for inspiration.  Did not have time to look at this today.
Nicolas 

> Le 9 dÃ©c. 2019 Ã  17:36, adam steer <adam.d.steer at gmail.com> a Ã©crit :
> 
> ï»¿
> Hi Jason
> 
> Weighing in late here, itâs possible to cobble together fiona/shapely/pdal to loop through a bunch of polygons (or process them in parallel) and do what you need. Itâs a task thatâs on my list of things to do when I get time :)
> 
> That way you can assemble a processing pipeline which goes straight from some geometries to data, without waiting for the new PR..
> 
> Cheers,
> 
> Adam
> 
> 
> 
>> On Tue, 10 Dec 2019 at 07:42, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>> Thanks Howard! I think this is the way to go. I would be interested in exploring the pull request version as well, but I may have to wait until after the holiday break to get to that.
>> Jason McVay
>> 
>> MS Geography, Virginia Tech
>> BA Environmental Studies, University of Montana
>> www.linkedin.com/in/jasonmcvay86/
>> https://twitter.com/jasonmcvay
>> 
>> "May your trails be crooked, winding, lonesome, dangerous, leading to the most amazing view"
>> - Ed Abbey
>> 
>> 
>>> On Mon, Dec 9, 2019 at 8:36 AM Howard Butler <howard at hobu.co> wrote:
>>> 
>>> 
>>>> On Dec 8, 2019, at 7:09 PM, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>>>> 
>>>> I'm looking for some advice on the best way/how to loop in thousands of bounding coordinates into a pdal pipeline.
>>>> 
>>>> I have a csv (and a geojson) of several thousand min/max x/y and a unique ID. The AOI's are not very big, so the pipeline runs quickly, but there are a lot of AOIs to capture! I'm querying an entwine dataset, the extent of which is national, so I'm limiting the data with a bounding box of each AOI.
>>>> 
>>>> My pipeline currently runs HAG and Ferry Z filter, then uses the gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I manually enter in a set of test coordinates. How can I scale this to loop and update the bounds automatically?
>>>> 
>>>> I'm running this locally on a MacBook Pro.
>>>> 
>>>> Thank you, any advice is appreciated!
>>> 
>>> Jason,
>>> 
>>> PDAL doesn't multithread or operate in a parallel fashion for you. You must use external tools to do this yourself. I have had good success using GNU parallel or xargs on bash along with the Python multiprocessing library to achieve that.
>>> 
>>> You scenario would seem to fit that model quite well. Here's a GNU parallel example. In short, use your favorite scripting language (or sed/awk/cat) to write a script that contains all of the job entries you need to run (bounds entries are all the same in my example, but you should get the point:
>>> 
>>>> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_henry_co.tif"
>>>> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_howard_co.tif"
>>>> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_james_co.tif"
>>>> pdal pipeline pipe.json --readers.ept.filename="ept://http://path/to/location" --readers.ept.bounds="([-10063436.56, -10060190.36], [5038996.16, 5043062.79])" --writers.gdal.filename="hag_mean_mike_co.tif"
>>> 
>>> 
>>> Then run that script:
>>> 
>>>> parallel -j 16 < jobs.txt
>>> 
>>> Filtering EPT resources with boundaries is a common desire. I recently added a pull request to master (not yet released) that allows you to specify filtering (for faster query) and cropping (eliminating an extra stage specification) for EPT resources. See https://github.com/PDAL/PDAL/pull/2771#issue-323371431 The goal with the approach in the pull request is to not have to change format of the bounding geometries to text simply to feed them into a pipeline. We may add similar capability to other drivers if it is indeed useful in other contexts. 
>>> 
>>> With the PR, you could express your query boundaries as an OGR query and then iterate through your EPT resources. The current PR implementation doesn't "split" by the polygons, however. We might need to add the same capability to filters.crop to achieve that. Feedback is appreciated so we can learn how people wish to use this.
>>> 
>>> Howard
>>> 
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
> 
> 
> -- 
> Dr. Adam Steer
> http://spatialised.net
> https://www.researchgate.net/profile/Adam_Steer
> http://au.linkedin.com/in/adamsteer
> http://orcid.org/0000-0003-0046-7236
> +61 427 091 712 ::  @adamdsteer
> 
> Suits are bad for business: http://www.spatialised.net/business-penguins/
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191209/109be19b/attachment-0001.html>

From jasonmcvay09 at gmail.com  Tue Dec 10 06:49:09 2019
From: jasonmcvay09 at gmail.com (Jason McVay)
Date: Tue, 10 Dec 2019 09:49:09 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <9A2AA79C-322D-4C8A-93E1-3035734C16C9@archeotec.ca>
References: <CAFORoyjjaBQoHiEBhmdesSjdHiH8sE7-Vv9Josnp1Dx+TxBkUw@mail.gmail.com>
 <9A2AA79C-322D-4C8A-93E1-3035734C16C9@archeotec.ca>
Message-ID: <CAGHb012+KGjVUVx7NknXACn8n7ODR3B0D5gZv0kQ0p+a=7KM2A@mail.gmail.com>

Hi Adam, and Nicolas,

I think I understand conceptually how using shapely/geopandas to loop in
coordinates to a pdal pipeline should work. But if you can pass along an
example that would be greatly appreciated!

Thanks again,

Jason McVay

MS Geography, Virginia Tech
BA Environmental Studies, University of Montana
www.linkedin.com/in/jasonmcvay86/
https://twitter.com/jasonmcvay


*"May your trails be crooked, winding, lonesome, dangerous, leading to the
most amazing view"*
- Ed Abbey


On Mon, Dec 9, 2019 at 6:09 PM Nicolas Cadieux <nicolas.cadieux at archeotec.ca>
wrote:

> Hi,
> I will send him a similar python loop tomorrow for inspiration.  Did not
> have time to look at this today.
> Nicolas
>
> Le 9 dÃ©c. 2019 Ã  17:36, adam steer <adam.d.steer at gmail.com> a Ã©crit :
>
> ï»¿
> Hi Jason
>
> Weighing in late here, itâs possible to cobble together fiona/shapely/pdal
> to loop through a bunch of polygons (or process them in parallel) and do
> what you need. Itâs a task thatâs on my list of things to do when I get
> time :)
>
> That way you can assemble a processing pipeline which goes straight from
> some geometries to data, without waiting for the new PR..
>
> Cheers,
>
> Adam
>
>
>
> On Tue, 10 Dec 2019 at 07:42, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>
>> Thanks Howard! I think this is the way to go. I would be interested in
>> exploring the pull request version as well, but I may have to wait until
>> after the holiday break to get to that.
>> Jason McVay
>>
>> MS Geography, Virginia Tech
>> BA Environmental Studies, University of Montana
>> www.linkedin.com/in/jasonmcvay86/
>> https://twitter.com/jasonmcvay
>>
>> *"May your trails be crooked, winding, lonesome, dangerous, leading to
>> the most amazing view"*
>> - Ed Abbey
>>
>>
>> On Mon, Dec 9, 2019 at 8:36 AM Howard Butler <howard at hobu.co> wrote:
>>
>>>
>>>
>>> On Dec 8, 2019, at 7:09 PM, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>>>
>>> I'm looking for some advice on the best way/how to loop in thousands of
>>> bounding coordinates into a pdal pipeline.
>>>
>>> I have a csv (and a geojson) of several thousand min/max x/y and a
>>> unique ID. The AOI's are not very big, so the pipeline runs quickly, but
>>> there are a lot of AOIs to capture! I'm querying an entwine dataset, the
>>> extent of which is national, so I'm limiting the data with a bounding box
>>> of each AOI.
>>>
>>> My pipeline currently runs HAG and Ferry Z filter, then uses the
>>> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
>>> manually enter in a set of test coordinates. How can I scale this to loop
>>> and update the bounds automatically?
>>>
>>> I'm running this locally on a MacBook Pro.
>>>
>>> Thank you, any advice is appreciated!
>>>
>>>
>>> Jason,
>>>
>>> PDAL doesn't multithread or operate in a parallel fashion for you. You
>>> must use external tools to do this yourself. I have had good success using
>>> GNU parallel or xargs on bash along with the Python multiprocessing library
>>> to achieve that.
>>>
>>> You scenario would seem to fit that model quite well. Here's a GNU
>>> parallel example. In short, use your favorite scripting language (or
>>> sed/awk/cat) to write a script that contains all of the job entries you
>>> need to run (bounds entries are all the same in my example, but you should
>>> get the point:
>>>
>>> pdal pipeline pipe.json --readers.ept.filename="
>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>> -10060190.36], [5038996.16, 5043062.79])"
>>> --writers.gdal.filename="hag_mean_henry_co.tif"
>>> pdal pipeline pipe.json --readers.ept.filename="
>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>> -10060190.36], [5038996.16, 5043062.79])"
>>> --writers.gdal.filename="hag_mean_howard_co.tif"
>>> pdal pipeline pipe.json --readers.ept.filename="
>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>> -10060190.36], [5038996.16, 5043062.79])"
>>> --writers.gdal.filename="hag_mean_james_co.tif"
>>> pdal pipeline pipe.json --readers.ept.filename="
>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>> -10060190.36], [5038996.16, 5043062.79])"
>>> --writers.gdal.filename="hag_mean_mike_co.tif"
>>>
>>>
>>>
>>> Then run that script:
>>>
>>> parallel -j 16 < jobs.txt
>>>
>>>
>>> Filtering EPT resources with boundaries is a common desire. I recently
>>> added a pull request to master (not yet released) that allows you to
>>> specify filtering (for faster query) and cropping (eliminating an extra
>>> stage specification) for EPT resources. See
>>> https://github.com/PDAL/PDAL/pull/2771#issue-323371431
>>> <https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=https%3a%2f%2fgithub.com%2fPDAL%2fPDAL%2fpull%2f2771%23issue%2d323371431&umid=1ef705ee-0b38-4b1b-9373-2ccf4d0eb417&auth=ab4b424674be62c9f8f9e1c1a31e433d534186a3-f8290d8713ab4ed5b3666d9bbdf34b2c63f8b5c8> The
>>> goal with the approach in the pull request is to not have to change format
>>> of the bounding geometries to text simply to feed them into a pipeline. We
>>> may add similar capability to other drivers if it is indeed useful in other
>>> contexts.
>>>
>>> With the PR, you could express your query boundaries as an OGR query and
>>> then iterate through your EPT resources. The current PR implementation
>>> doesn't "split" by the polygons, however. We might need to add the same
>>> capability to filters.crop to achieve that. Feedback is appreciated so we
>>> can learn how people wish to use this.
>>>
>>> Howard
>>>
>>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
>
>
>
> --
> Dr. Adam Steer
> http://spatialised.net
> <https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=http%3a%2f%2fspatialised.net&umid=73b42ec6-c163-4304-9ef2-a1d38eac8f79&auth=72ce7397d0db234fdd09ad1e9584ffcc03ba0336-066b12425d4ebeb1bf4522439ac18d619101f119>
> https://www.researchgate.net/profile/Adam_Steer
> http://au.linkedin.com/in/adamsteer
> http://orcid.org/0000-0003-0046-7236
> +61 427 091 712 ::  @adamdsteer
>
> Suits are bad for business: http://www.spatialised.net/business-penguins/
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191210/bd58f1b0/attachment.html>

From nicolas.cadieux at archeotec.ca  Tue Dec 10 10:10:33 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Tue, 10 Dec 2019 13:10:33 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
References: <CAGHb011VeJ21_uyRU5aXrpZ0fwMs0sS13X6BD6eJtYqkb3NPJw@mail.gmail.com>
Message-ID: <76733c84-67e9-96c6-efab-1536c7a54e6d@archeotec.ca>

Hi,

I am sending this small script as an inspiration.Â  This is a 
single-threaded the python program that

 1. Scans a directory for a list of .tif file and makes a list of those
    tif files.
 2. Creates an output directory
 3. Build a gdal command line (export the tif to a xyz file) inside the
    function called "gdal_translate2XYZ".
     1. shell = subprocess.Popen(r'c:\OSGeo4W64\OSGeo4W.bat',
        stdin=subprocess.PIPE)
     2. shell.communicate(gdal_translateCmd)
     3. These two above line basically send the command to the OSGeo4W
        shell. (Install Qgis if you don't have it).
 4. Runs this command in a loop (the loop is created by using "map" or
    "p.map" function that operates on the list of tif files)
 5. If you comment out the (if __name__ == '__main__': ) section, the
    commands will run in parallel depending on the size of the pool
    variable.Â  pool = 6 = 6 parallel commands.Â  It is easier to debug if
    youÂ  develop in single thread.

The idea is to build your script using python and to run it calling PDAL 
from python.Â  The Fiona python library with the Shapely library or the 
more complete geopandas library can help manipulate the shapefile.

Hope this helps!

Nicolas

https://fiona.readthedocs.io/en/stable/

https://shapely.readthedocs.io/en/stable/manual.html

http://geopandas.org/


On 2019-12-08 8:09 p.m., Jason McVay wrote:
> I'm looking for some advice on the best way/how to loop in thousands 
> of bounding coordinates into a pdal pipeline.
>
> I have a csv (and a geojson) of several thousand min/max x/y and a 
> unique ID. The AOI's are not very big, so the pipeline runs quickly, 
> but there are a lot of AOIs to capture! I'm querying an entwine 
> dataset, the extent of which is national, so I'm limiting the data 
> with a bounding box of each AOI.
>
> My pipeline currently runs HAG and Ferry Z filter, then uses the 
> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly 
> when I manually enter in a set of test coordinates. How can I scale 
> this to loop and update the bounds automatically?
>
> I'm running this locally on a MacBook Pro.
>
> Thank you, any advice is appreciated!
>
>
> Jason McVay
>
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/ 
> <http://www.linkedin.com/in/jasonmcvay86/>
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191210/7b0a0742/attachment-0001.html>
-------------- next part --------------
# -*- coding: utf-8 -*-
"""
Created on Thu Jan 17 14:40:41 2019
@author: Nicolas Cadieux
njacadieux.gitlab at gmail.com
"""
import os
import subprocess
from osgeo import gdal
from multiprocessing import Pool
import multiprocessing
import time
from collections import defaultdict
import gdalnumeric

#variable a changer dans script
startTime = time.time()
scanDirectory_and_Subdirectories = 'no' #no or yes
extensionFiltre = '.tif'
strFileFilter = '' # Mettre quelques chose si on veux trouver un string
inputPath = r'C:\temp'


def createDirectory(path):
    if os.path.isdir(path):
        pass
    else:
        try: os.mkdir(path)
        except (WindowsError):
            print 'WindowsError'
            
def gdal_translate2XYZ(inFilePath_Name):

    inFilePath = os.path.dirname(inFilePath_Name)
    inFileName = os.path.basename(inFilePath_Name)
    outFileName = inFileName [0:-4] + '.xyz'
    multipleOutPath = os.path.join(inFilePath,'xyz_output')
    outFilePath_Name = os.path.join(multipleOutPath, outFileName)
#    targetEPSG = sourceEPSG
    outputnoData = str(-32768)

    #create one output Directories per directory or a single Global Output directory
    createDirectory(multipleOutPath)
    #createDirectory()
    
    gdal_translateCmd = \
    'gdal_translate'\
    +' -a_nodata '+outputnoData\
    +' -of XYZ'\
    +' '+inFilePath_Name\
    +' '+outFilePath_Name+'\n'
    
    shell = subprocess.Popen(r'c:\OSGeo4W64\OSGeo4W.bat', stdin=subprocess.PIPE)
    shell.communicate(gdal_translateCmd)
#    return inFileName, 'Done'
#    return gdal_translateCmd

############################################################___MAIN___#####################    
shortNameList = []

for (dirPath, subDirectoriesList, fileNamesList) in os.walk(inputPath):
    for files in fileNamesList:
        if files.lower().endswith(extensionFiltre) and strFileFilter.lower() in files.lower():# and files.lower().startswith("variable")
            shortList = os.path.join(dirPath, files)
            shortNameList.append(shortList)

    if scanDirectory_and_Subdirectories == 'no':
        break #this break will exit the loop and limite to 1 directory only
    elif scanDirectory_and_Subdirectories == 'yes':
        pass
    else:
        raw_input(("You must choose '"'yes'"' or '"'no'"' in the scanDirectory_and_Subdirectories variable"))


#############NONE MULTITREADED OR TESTING############## 


map(gdal_translate2XYZ, shortNameList) #Single thread
print 'done in testing mode'
        
#Uncomment for multithearded
#if __name__ == '__main__':
#    p = Pool(6)
#    for x in p.imap_unordered(gdal_translate2XYZ, shortNameList):
#        print x
#    p.close()
#    p.join()
#    stopTime = time.time()
#    totalTime = (stopTime-startTime)/60
#    print 'done: ',totalTime, 'minutes'

From nicolas.cadieux at archeotec.ca  Tue Dec 10 10:43:54 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Tue, 10 Dec 2019 13:43:54 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <CAGHb012+KGjVUVx7NknXACn8n7ODR3B0D5gZv0kQ0p+a=7KM2A@mail.gmail.com>
References: <CAFORoyjjaBQoHiEBhmdesSjdHiH8sE7-Vv9Josnp1Dx+TxBkUw@mail.gmail.com>
 <9A2AA79C-322D-4C8A-93E1-3035734C16C9@archeotec.ca>
 <CAGHb012+KGjVUVx7NknXACn8n7ODR3B0D5gZv0kQ0p+a=7KM2A@mail.gmail.com>
Message-ID: <ef0e3efd-1edf-25eb-a2e1-5167101b87c6@archeotec.ca>

Hi,

This will print the bounds for each object in a shapefile.

Nicolas

On 2019-12-10 9:49 a.m., Jason McVay wrote:
> Hi Adam, and Nicolas,
>
> I think I understand conceptually how using shapely/geopandas to loop 
> in coordinates to a pdal pipeline should work. But if you can pass 
> along an example that would be greatly appreciated!
>
> Thanks again,
>
> Jason McVay
>
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/ 
> <http://www.linkedin.com/in/jasonmcvay86/>
> https://twitter.com/jasonmcvay
>
>
> /"May your trails be crooked, winding, lonesome, dangerous, leading to 
> the most amazing view"/
> - Ed Abbey
>
>
> On Mon, Dec 9, 2019 at 6:09 PM Nicolas Cadieux 
> <nicolas.cadieux at archeotec.ca <mailto:nicolas.cadieux at archeotec.ca>> 
> wrote:
>
>     Hi,
>     I will send him a similar python loop tomorrow for inspiration.Â 
>     Did not have time to look at this today.
>     Nicolas
>
>>     Le 9 dÃ©c. 2019 Ã  17:36, adam steer <adam.d.steer at gmail.com
>>     <mailto:adam.d.steer at gmail.com>> a Ã©critÂ :
>>
>>     ï»¿
>>     Hi Jason
>>
>>     Weighing in late here, itâs possible to cobble together
>>     fiona/shapely/pdal to loop through a bunch of polygons (or
>>     process them in parallel) and do what you need. Itâs a task
>>     thatâs on my list of things to do when I get time :)
>>
>>     That way you can assemble a processing pipeline which goes
>>     straight from some geometries to data, without waiting for the
>>     new PR..
>>
>>     Cheers,
>>
>>     Adam
>>
>>
>>
>>     On Tue, 10 Dec 2019 at 07:42, Jason McVay <jasonmcvay09 at gmail.com
>>     <mailto:jasonmcvay09 at gmail.com>> wrote:
>>
>>         Thanks Howard! I think this is the way to go. I would be
>>         interested in exploring the pull request version as well, but
>>         I may have to wait until after the holiday break to get to that.
>>         Jason McVay
>>
>>         MS Geography, Virginia Tech
>>         BA Environmental Studies, University of Montana
>>         www.linkedin.com/in/jasonmcvay86/
>>         <http://www.linkedin.com/in/jasonmcvay86/>
>>         https://twitter.com/jasonmcvay
>>
>>         /"May your trails be crooked, winding, lonesome, dangerous,
>>         leading to the most amazing view"/
>>         - Ed Abbey
>>
>>
>>         On Mon, Dec 9, 2019 at 8:36 AM Howard Butler <howard at hobu.co
>>         <mailto:howard at hobu.co>> wrote:
>>
>>
>>
>>>             On Dec 8, 2019, at 7:09 PM, Jason McVay
>>>             <jasonmcvay09 at gmail.com <mailto:jasonmcvay09 at gmail.com>>
>>>             wrote:
>>>
>>>             I'm looking for some advice on the best way/how to loop
>>>             in thousands of bounding coordinates into a pdal pipeline.
>>>
>>>             I have a csv (and a geojson) of several thousand min/max
>>>             x/y and a unique ID. The AOI's are not very big, so the
>>>             pipeline runs quickly, but there are a lot of AOIs to
>>>             capture! I'm querying an entwine dataset, the extent of
>>>             which is national, so I'm limiting the data with a
>>>             bounding box of each AOI.
>>>
>>>             My pipeline currently runs HAG and Ferry Z filter, then
>>>             uses the gdal.writer to make a GeoTiff at 1m resolution.
>>>             It works perfectly when I manually enter in a set of
>>>             test coordinates. How can I scale this to loop and
>>>             update the bounds automatically?
>>>
>>>             I'm running this locally on a MacBook Pro.
>>>
>>>             Thank you, any advice is appreciated!
>>
>>             Jason,
>>
>>             PDAL doesn't multithread or operate in a parallel fashion
>>             for you. You must use external tools to do this yourself.
>>             I have had good success using GNU parallel or xargs on
>>             bash along with the Python multiprocessing library to
>>             achieve that.
>>
>>             You scenario would seem to fit that model quite well.
>>             Here's a GNU parallel example. In short, use your
>>             favorite scripting language (or sed/awk/cat) to write a
>>             script that contains all of the job entries you need to
>>             run (bounds entries are all the same in my example, but
>>             you should get the point:
>>
>>>             pdal pipeline pipe.json
>>>             --readers.ept.filename="ept://http://path/to/location"
>>>             --readers.ept.bounds="([-10063436.56, -10060190.36],
>>>             [5038996.16, 5043062.79])"
>>>             --writers.gdal.filename="hag_mean_henry_co.tif"
>>>             pdal pipeline pipe.json
>>>             --readers.ept.filename="ept://http://path/to/location"
>>>             --readers.ept.bounds="([-10063436.56, -10060190.36],
>>>             [5038996.16, 5043062.79])"
>>>             --writers.gdal.filename="hag_mean_howard_co.tif"
>>>             pdal pipeline pipe.json
>>>             --readers.ept.filename="ept://http://path/to/location"
>>>             --readers.ept.bounds="([-10063436.56, -10060190.36],
>>>             [5038996.16, 5043062.79])"
>>>             --writers.gdal.filename="hag_mean_james_co.tif"
>>>             pdal pipeline pipe.json
>>>             --readers.ept.filename="ept://http://path/to/location"
>>>             --readers.ept.bounds="([-10063436.56, -10060190.36],
>>>             [5038996.16, 5043062.79])"
>>>             --writers.gdal.filename="hag_mean_mike_co.tif"
>>
>>
>>             Then run that script:
>>
>>>             parallel -j 16 < jobs.txt
>>
>>             Filtering EPT resources with boundaries is a common
>>             desire. I recently added a pull request to master (not
>>             yet released) that allows you to specify filtering (for
>>             faster query) and cropping (eliminating an extra stage
>>             specification) for EPT resources. See
>>             https://github.com/PDAL/PDAL/pull/2771#issue-323371431
>>             <https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=https%3a%2f%2fgithub.com%2fPDAL%2fPDAL%2fpull%2f2771%23issue%2d323371431&umid=1ef705ee-0b38-4b1b-9373-2ccf4d0eb417&auth=ab4b424674be62c9f8f9e1c1a31e433d534186a3-f8290d8713ab4ed5b3666d9bbdf34b2c63f8b5c8>Â The
>>             goal with the approach in the pull request is to not have
>>             to change format of the bounding geometries to text
>>             simply to feed them into a pipeline. We may add similar
>>             capability to other drivers if it is indeed useful in
>>             other contexts.
>>
>>             With the PR, you could express your query boundaries as
>>             an OGR query and then iterate through your EPT resources.
>>             The current PR implementation doesn't "split" by the
>>             polygons, however. We might need to add the same
>>             capability to filters.crop to achieve that. Feedback is
>>             appreciated so we can learn how people wish to use this.
>>
>>             Howard
>>
>>         _______________________________________________
>>         pdal mailing list
>>         pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>
>>         https://lists.osgeo.org/mailman/listinfo/pdal
>>
>>
>>
>>     -- 
>>     Dr. Adam Steer
>>     http://spatialised.net
>>     <https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=http%3a%2f%2fspatialised.net&umid=73b42ec6-c163-4304-9ef2-a1d38eac8f79&auth=72ce7397d0db234fdd09ad1e9584ffcc03ba0336-066b12425d4ebeb1bf4522439ac18d619101f119>
>>     https://www.researchgate.net/profile/Adam_Steer
>>     http://au.linkedin.com/in/adamsteer
>>     http://orcid.org/0000-0003-0046-7236
>>     +61 427 091 712 :: Â @adamdsteer
>>
>>     Suits are bad for business:
>>     http://www.spatialised.net/business-penguins/
>>     _______________________________________________
>>     pdal mailing list
>>     pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>
>>     https://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191210/91e80010/attachment-0001.html>
-------------- next part --------------
import fiona
import shapely
from shapely.geometry import shape

shpfile = fiona.open(r"C:\temp\Sample_data\INPUT_NETWORK_FILE_SHP_191105.shp")

for lines in shpfile:
    geoms = shape(lines['geometry'])
    print "\n"
    #print geoms #print the object geometry
    boundairies = geoms.bounds #print the object bounding box
    print boundairies
 

From jasonmcvay09 at gmail.com  Tue Dec 10 10:51:56 2019
From: jasonmcvay09 at gmail.com (Jason McVay)
Date: Tue, 10 Dec 2019 13:51:56 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL Pipeline
In-Reply-To: <ef0e3efd-1edf-25eb-a2e1-5167101b87c6@archeotec.ca>
References: <CAFORoyjjaBQoHiEBhmdesSjdHiH8sE7-Vv9Josnp1Dx+TxBkUw@mail.gmail.com>
 <9A2AA79C-322D-4C8A-93E1-3035734C16C9@archeotec.ca>
 <CAGHb012+KGjVUVx7NknXACn8n7ODR3B0D5gZv0kQ0p+a=7KM2A@mail.gmail.com>
 <ef0e3efd-1edf-25eb-a2e1-5167101b87c6@archeotec.ca>
Message-ID: <CAGHb010vAqf3jhpMcfvAsR-y8hSogHX54TJmCW=0A1OiwsoqVw@mail.gmail.com>

Thank you Nicolas!

Jason McVay

MS Geography, Virginia Tech
BA Environmental Studies, University of Montana
www.linkedin.com/in/jasonmcvay86/
https://twitter.com/jasonmcvay

*"May your trails be crooked, winding, lonesome, dangerous, leading to the
most amazing view"*
- Ed Abbey


On Tue, Dec 10, 2019 at 1:44 PM Nicolas Cadieux <
nicolas.cadieux at archeotec.ca> wrote:

> Hi,
>
> This will print the bounds for each object in a shapefile.
>
> Nicolas
> On 2019-12-10 9:49 a.m., Jason McVay wrote:
>
> Hi Adam, and Nicolas,
>
> I think I understand conceptually how using shapely/geopandas to loop in
> coordinates to a pdal pipeline should work. But if you can pass along an
> example that would be greatly appreciated!
>
> Thanks again,
>
> Jason McVay
>
> MS Geography, Virginia Tech
> BA Environmental Studies, University of Montana
> www.linkedin.com/in/jasonmcvay86/
> https://twitter.com/jasonmcvay
>
>
> *"May your trails be crooked, winding, lonesome, dangerous, leading to the
> most amazing view"*
> - Ed Abbey
>
>
> On Mon, Dec 9, 2019 at 6:09 PM Nicolas Cadieux <
> nicolas.cadieux at archeotec.ca> wrote:
>
>> Hi,
>> I will send him a similar python loop tomorrow for inspiration.  Did not
>> have time to look at this today.
>> Nicolas
>>
>> Le 9 dÃ©c. 2019 Ã  17:36, adam steer <adam.d.steer at gmail.com> a Ã©crit :
>>
>> ï»¿
>> Hi Jason
>>
>> Weighing in late here, itâs possible to cobble together
>> fiona/shapely/pdal to loop through a bunch of polygons (or process them in
>> parallel) and do what you need. Itâs a task thatâs on my list of things to
>> do when I get time :)
>>
>> That way you can assemble a processing pipeline which goes straight from
>> some geometries to data, without waiting for the new PR..
>>
>> Cheers,
>>
>> Adam
>>
>>
>>
>> On Tue, 10 Dec 2019 at 07:42, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>>
>>> Thanks Howard! I think this is the way to go. I would be interested in
>>> exploring the pull request version as well, but I may have to wait until
>>> after the holiday break to get to that.
>>> Jason McVay
>>>
>>> MS Geography, Virginia Tech
>>> BA Environmental Studies, University of Montana
>>> www.linkedin.com/in/jasonmcvay86/
>>> https://twitter.com/jasonmcvay
>>>
>>> *"May your trails be crooked, winding, lonesome, dangerous, leading to
>>> the most amazing view"*
>>> - Ed Abbey
>>>
>>>
>>> On Mon, Dec 9, 2019 at 8:36 AM Howard Butler <howard at hobu.co> wrote:
>>>
>>>>
>>>>
>>>> On Dec 8, 2019, at 7:09 PM, Jason McVay <jasonmcvay09 at gmail.com> wrote:
>>>>
>>>> I'm looking for some advice on the best way/how to loop in thousands of
>>>> bounding coordinates into a pdal pipeline.
>>>>
>>>> I have a csv (and a geojson) of several thousand min/max x/y and a
>>>> unique ID. The AOI's are not very big, so the pipeline runs quickly, but
>>>> there are a lot of AOIs to capture! I'm querying an entwine dataset, the
>>>> extent of which is national, so I'm limiting the data with a bounding box
>>>> of each AOI.
>>>>
>>>> My pipeline currently runs HAG and Ferry Z filter, then uses the
>>>> gdal.writer to make a GeoTiff at 1m resolution. It works perfectly when I
>>>> manually enter in a set of test coordinates. How can I scale this to loop
>>>> and update the bounds automatically?
>>>>
>>>> I'm running this locally on a MacBook Pro.
>>>>
>>>> Thank you, any advice is appreciated!
>>>>
>>>>
>>>> Jason,
>>>>
>>>> PDAL doesn't multithread or operate in a parallel fashion for you. You
>>>> must use external tools to do this yourself. I have had good success using
>>>> GNU parallel or xargs on bash along with the Python multiprocessing library
>>>> to achieve that.
>>>>
>>>> You scenario would seem to fit that model quite well. Here's a GNU
>>>> parallel example. In short, use your favorite scripting language (or
>>>> sed/awk/cat) to write a script that contains all of the job entries you
>>>> need to run (bounds entries are all the same in my example, but you should
>>>> get the point:
>>>>
>>>> pdal pipeline pipe.json --readers.ept.filename="
>>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>>> -10060190.36], [5038996.16, 5043062.79])"
>>>> --writers.gdal.filename="hag_mean_henry_co.tif"
>>>> pdal pipeline pipe.json --readers.ept.filename="
>>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>>> -10060190.36], [5038996.16, 5043062.79])"
>>>> --writers.gdal.filename="hag_mean_howard_co.tif"
>>>> pdal pipeline pipe.json --readers.ept.filename="
>>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>>> -10060190.36], [5038996.16, 5043062.79])"
>>>> --writers.gdal.filename="hag_mean_james_co.tif"
>>>> pdal pipeline pipe.json --readers.ept.filename="
>>>> ept://http://path/to/location" --readers.ept.bounds="([-10063436.56,
>>>> -10060190.36], [5038996.16, 5043062.79])"
>>>> --writers.gdal.filename="hag_mean_mike_co.tif"
>>>>
>>>>
>>>>
>>>> Then run that script:
>>>>
>>>> parallel -j 16 < jobs.txt
>>>>
>>>>
>>>> Filtering EPT resources with boundaries is a common desire. I recently
>>>> added a pull request to master (not yet released) that allows you to
>>>> specify filtering (for faster query) and cropping (eliminating an extra
>>>> stage specification) for EPT resources. See
>>>> https://github.com/PDAL/PDAL/pull/2771#issue-323371431
>>>> <https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=https%3a%2f%2fgithub.com%2fPDAL%2fPDAL%2fpull%2f2771%23issue%2d323371431&umid=1ef705ee-0b38-4b1b-9373-2ccf4d0eb417&auth=ab4b424674be62c9f8f9e1c1a31e433d534186a3-f8290d8713ab4ed5b3666d9bbdf34b2c63f8b5c8> The
>>>> goal with the approach in the pull request is to not have to change format
>>>> of the bounding geometries to text simply to feed them into a pipeline. We
>>>> may add similar capability to other drivers if it is indeed useful in other
>>>> contexts.
>>>>
>>>> With the PR, you could express your query boundaries as an OGR query
>>>> and then iterate through your EPT resources. The current PR implementation
>>>> doesn't "split" by the polygons, however. We might need to add the same
>>>> capability to filters.crop to achieve that. Feedback is appreciated so we
>>>> can learn how people wish to use this.
>>>>
>>>> Howard
>>>>
>>>> _______________________________________________
>>> pdal mailing list
>>> pdal at lists.osgeo.org
>>> https://lists.osgeo.org/mailman/listinfo/pdal
>>
>>
>>
>> --
>> Dr. Adam Steer
>> http://spatialised.net
>> <https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=http%3a%2f%2fspatialised.net&umid=73b42ec6-c163-4304-9ef2-a1d38eac8f79&auth=72ce7397d0db234fdd09ad1e9584ffcc03ba0336-066b12425d4ebeb1bf4522439ac18d619101f119>
>> https://www.researchgate.net/profile/Adam_Steer
>> http://au.linkedin.com/in/adamsteer
>> http://orcid.org/0000-0003-0046-7236
>> +61 427 091 712 ::  @adamdsteer
>>
>> Suits are bad for business: http://www.spatialised.net/business-penguins/
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191210/eeda7fac/attachment-0001.html>

From jedfrechette at gmail.com  Tue Dec 10 10:54:18 2019
From: jedfrechette at gmail.com (Jed Frechette)
Date: Tue, 10 Dec 2019 11:54:18 -0700
Subject: [pdal] looping multiple bounding coordinates in PDAL
In-Reply-To: <mailman.69035.1576001437.17185.pdal@lists.osgeo.org>
References: <mailman.69035.1576001437.17185.pdal@lists.osgeo.org>
Message-ID: <CAACeADZ8WgqxDUxF8ZK9oCO5wEEa7nY_izW7VrJc+AiC0==K_w@mail.gmail.com>

On Tue, 10 Dec 2019 13:10:33 -0500 Nicolas Cadieux
<nicolas.cadieux at archeotec.ca> wrote
>  4. Runs this command in a loop (the loop is created by using "map" or
>     "p.map" function that operates on the list of tif files)

To easily make this multithreaded you can use the multiprocessing
library. I've got a ton of code running similar types of command line
tasks in parallel that all boil down to something like the following.
In production, I tend to also keep a single threaded code path that
will run the function in a loop for debugging purposes.

from multiprocessing import Pool

def do_task():
    """Perform what ever standalone task you want to do here."""
    pass

pool = Pool()
results = pool.apply_async(do_task)
pool.close()
pool.join()


-- 
Jed Frechette

From nicolas.cadieux at archeotec.ca  Tue Dec 10 11:09:24 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Tue, 10 Dec 2019 14:09:24 -0500
Subject: [pdal] looping multiple bounding coordinates in PDAL
In-Reply-To: <CAACeADZ8WgqxDUxF8ZK9oCO5wEEa7nY_izW7VrJc+AiC0==K_w@mail.gmail.com>
References: <mailman.69035.1576001437.17185.pdal@lists.osgeo.org>
 <CAACeADZ8WgqxDUxF8ZK9oCO5wEEa7nY_izW7VrJc+AiC0==K_w@mail.gmail.com>
Message-ID: <0d589c70-badd-3c67-3f9f-5e83b7d0ff91@archeotec.ca>

Yes very easy,

That section is commented out for now in the script. By removing the #, 
you will be able to multi-thread.

Nicolas

On 2019-12-10 1:54 p.m., Jed Frechette wrote:
> On Tue, 10 Dec 2019 13:10:33 -0500 Nicolas Cadieux
> <nicolas.cadieux at archeotec.ca> wrote
>>   4. Runs this command in a loop (the loop is created by using "map" or
>>      "p.map" function that operates on the list of tif files)
> To easily make this multithreaded you can use the multiprocessing
> library. I've got a ton of code running similar types of command line
> tasks in parallel that all boil down to something like the following.
> In production, I tend to also keep a single threaded code path that
> will run the function in a loop for debugging purposes.
>
> from multiprocessing import Pool
>
> def do_task():
>      """Perform what ever standalone task you want to do here."""
>      pass
>
> pool = Pool()
> results = pool.apply_async(do_task)
> pool.close()
> pool.join()
>
>

From jrhickey6 at gmail.com  Wed Dec 11 11:21:28 2019
From: jrhickey6 at gmail.com (JR Hickey)
Date: Wed, 11 Dec 2019 14:21:28 -0500
Subject: [pdal] Pdal writers.ept_addon question
Message-ID: <CAJgzRTYHdPDwY378jDazjKyF2BAzw9b6RA_rqEpuK3LEVuzDfA@mail.gmail.com>

Hi,

I canât seem to get pdalâs writers.ept_addon to add the Classification
dimension to my existing ept data set.

Let me explain my current workflow (I know it is not optimal, but we are
working on it). 1) First a field team gathers Lidar data; then does a first
pass to convert the Raw to las data. 2) Then the data is added to an ept
structure. 3) Eventually (weeks or months after) another team will extract
part of the data and do a manual classification. 4) Now I would like to add
the classification information to the existing ept structure.

I have looked at the examples online (pdal.writers.ept_addon and FOSS4G
2019 Bucharest slides) and still canât seem to make it work.

My pipeline is this as follows

[{             âtypeâ:âreaders.eptâ,

                âfilenameâ:â~/entwine/existing_data/ept.jsonâ

},

{              âtypeâ:âwriters.ept_addonâ,

                âaddonsâ:{â~/entwine/Classified_dataâ: âClassificationâ}

]

The process takes a little time and I get no error messages. But when I
extract the dataset to laz, there is no classification information.

Something of note, in the entwine ept-data of the Classified_data, for each
x-x-x-x.laz file, there is a x-x-x-x.bin that was created. Is this normal,
what is in the bin?

Another bit of information, I have previously sorted (using GPStime) the
data to ensure that the octrees contain the same points in the
existing_data and Classified_data.

Thanks for any help. I am really stumped on this one.

JR
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191211/06cf89e0/attachment.html>

From connor at hobu.co  Wed Dec 11 11:59:17 2019
From: connor at hobu.co (Connor Manning)
Date: Wed, 11 Dec 2019 13:59:17 -0600
Subject: [pdal] Pdal writers.ept_addon question
In-Reply-To: <CAJgzRTYHdPDwY378jDazjKyF2BAzw9b6RA_rqEpuK3LEVuzDfA@mail.gmail.com>
References: <CAJgzRTYHdPDwY378jDazjKyF2BAzw9b6RA_rqEpuK3LEVuzDfA@mail.gmail.com>
Message-ID: <CAO=FyjJDpuTJo17KcYSzrhN5qTxWDPVQwbkrZjTpdRS5Ly8cXw@mail.gmail.com>

I'd have to see your reader pipeline to make sure, but make sure that after
you've created the addon with the EPT-addon-writer, that you use the
"addons" option of the EPT *reader* during subsequent reads to dynamically
map these addons into the dataset.

See the "addons" option of the EPT reader here:
https://pdal.io/stages/readers.ept.html
And also see the last example pipeline from the EPT addon writer here which
shows the usage of an addon:
https://pdal.io/stages/writers.ept_addon.html#writers-ept-addon

Note that when *reading* the addons with the EPT reader, the "addons"
option is reversed from the addon-writer option to map the existing addon
directory path into a dimension.

- Connor

On Wed, Dec 11, 2019 at 1:20 PM JR Hickey <jrhickey6 at gmail.com> wrote:

> Hi,
>
> I canât seem to get pdalâs writers.ept_addon to add the Classification
> dimension to my existing ept data set.
>
> Let me explain my current workflow (I know it is not optimal, but we are
> working on it). 1) First a field team gathers Lidar data; then does a first
> pass to convert the Raw to las data. 2) Then the data is added to an ept
> structure. 3) Eventually (weeks or months after) another team will extract
> part of the data and do a manual classification. 4) Now I would like to add
> the classification information to the existing ept structure.
>
> I have looked at the examples online (pdal.writers.ept_addon and FOSS4G
> 2019 Bucharest slides) and still canât seem to make it work.
>
> My pipeline is this as follows
>
> [{             âtypeâ:âreaders.eptâ,
>
>                 âfilenameâ:â~/entwine/existing_data/ept.jsonâ
>
> },
>
> {              âtypeâ:âwriters.ept_addonâ,
>
>                 âaddonsâ:{â~/entwine/Classified_dataâ: âClassificationâ}
>
> ]
>
> The process takes a little time and I get no error messages. But when I
> extract the dataset to laz, there is no classification information.
>
> Something of note, in the entwine ept-data of the Classified_data, for
> each x-x-x-x.laz file, there is a x-x-x-x.bin that was created. Is this
> normal, what is in the bin?
>
> Another bit of information, I have previously sorted (using GPStime) the
> data to ensure that the octrees contain the same points in the
> existing_data and Classified_data.
>
> Thanks for any help. I am really stumped on this one.
>
> JR
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191211/f92030cb/attachment.html>

From jukka.rahkonen at latuviitta.fi  Thu Dec 12 00:26:12 2019
From: jukka.rahkonen at latuviitta.fi (Jukka Rahkonen)
Date: Thu, 12 Dec 2019 10:26:12 +0200
Subject: [pdal] Fixing the topology of the hexagon coverage from density
Message-ID: <ca40832a89eeb156b4528c033b9241c7@webmail.suomicom.fi>

Hi,

I noticed that the vertices of the hexagon cells that "pdal density" 
writes out do not match exactly. It means that it is not easy to union 
the output into one polygon with GIS tools. The issue can be fixed by 
reducing the precision of coordinates with the PostGIS ST_Snap or 
similar tool. With a projected CRS it was enough to round the 
coordinates into 5 decimal places. It might be good to have a coordinate 
rounding option directly in the density tool.

-Jukka Rahkonen-

From andrew.bell.ia at gmail.com  Thu Dec 12 04:38:51 2019
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Thu, 12 Dec 2019 07:38:51 -0500
Subject: [pdal] Fixing the topology of the hexagon coverage from density
In-Reply-To: <ca40832a89eeb156b4528c033b9241c7@webmail.suomicom.fi>
References: <ca40832a89eeb156b4528c033b9241c7@webmail.suomicom.fi>
Message-ID: <CACJ51z2upYuPsR5Hny1vbgOnpOouUk0=M6_mAxnzuaWfDgM=0A@mail.gmail.com>

You should be able to do this by passing the precision argument to the
hexbin filter.  For example: `--filters.hexbin.density=5`.

If this doesn't work, please let me know.

On Thu, Dec 12, 2019 at 3:26 AM Jukka Rahkonen <jukka.rahkonen at latuviitta.fi>
wrote:

> Hi,
>
> I noticed that the vertices of the hexagon cells that "pdal density"
> writes out do not match exactly. It means that it is not easy to union
> the output into one polygon with GIS tools. The issue can be fixed by
> reducing the precision of coordinates with the PostGIS ST_Snap or
> similar tool. With a projected CRS it was enough to round the
> coordinates into 5 decimal places. It might be good to have a coordinate
> rounding option directly in the density tool.
>
> -Jukka Rahkonen-
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20191212/e0c7d141/attachment.html>

From jukka.rahkonen at latuviitta.fi  Thu Dec 12 08:01:08 2019
From: jukka.rahkonen at latuviitta.fi (Jukka Rahkonen)
Date: Thu, 12 Dec 2019 18:01:08 +0200
Subject: [pdal] Fixing the topology of the hexagon coverage from density
In-Reply-To: <CACJ51z2upYuPsR5Hny1vbgOnpOouUk0=M6_mAxnzuaWfDgM=0A@mail.gmail.com>
References: <ca40832a89eeb156b4528c033b9241c7@webmail.suomicom.fi>
 <CACJ51z2upYuPsR5Hny1vbgOnpOouUk0=M6_mAxnzuaWfDgM=0A@mail.gmail.com>
Message-ID: <0624889ff069fe5c07802eef826c9761@webmail.suomicom.fi>

Hi,

I did a test with command

pdal density --driver readers.text  --readers.text.header="x y z" 
--filters.hexbin.precision=4 test.csv 4prec.shp

Precision option is documented to set the minimum precision and so it 
seems to be. Here are three adjacent polygons as an example.

POLYGON ((590196.8408004533 6855474.9200985655, 590181.6192204552 
6855501.2846485, 590196.8408004533 6855527.649198435, 590227.2839604495 
6855527.649198435, 590242.5055404477 6855501.2846485, 590227.2839604495 
6855474.9200985655, 590196.8408004533 6855474.9200985655))

POLYGON ((590196.8408004533 6855527.649198434, 590181.6192204552 
6855554.013748369, 590196.8408004533 6855580.378298304, 
590227.2839604495 6855580.378298304, 590242.5055404477 
6855554.013748369, 590227.2839604495 6855527.649198434, 
590196.8408004533 6855527.649198434))

POLYGON ((590151.1760604589 6855501.2846485, 590135.9544804607 
6855527.649198435, 590151.1760604589 6855554.01374837, 590181.6192204551 
6855554.01374837, 590196.8408004532 6855527.649198435, 590181.6192204551 
6855501.2846485, 590151.1760604589 6855501.2846485))

Polygons have one small gap and two overlaps around here because of 
non-snapped vertices:


Kohteen ID: 187271
[       0:2] POINT (590196.8408004533 6855527.649198435)
Kohteen ID: 187272
[       0:0] POINT (590196.8408004533 6855527.649198434)
Kohteen ID: 187273
[       0:4] POINT (590196.8408004532 6855527.649198435)



-Jukka Rahkonen-


Andrew Bell kirjoitti 2019-12-12 14:38:
> You should be able to do this by passing the precision argument to the
> hexbin filter.  For example: `--filters.hexbin.density=5`.
> 
> If this doesn't work, please let me know.
> 
> On Thu, Dec 12, 2019 at 3:26 AM Jukka Rahkonen
> <jukka.rahkonen at latuviitta.fi> wrote:
> 
>> Hi,
>> 
>> I noticed that the vertices of the hexagon cells that "pdal density"
>> 
>> writes out do not match exactly. It means that it is not easy to
>> union
>> the output into one polygon with GIS tools. The issue can be fixed
>> by
>> reducing the precision of coordinates with the PostGIS ST_Snap or
>> similar tool. With a projected CRS it was enough to round the
>> coordinates into 5 decimal places. It might be good to have a
>> coordinate
>> rounding option directly in the density tool.
>> 
>> -Jukka Rahkonen-
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
> 
> --
> Andrew Bell
> andrew.bell.ia at gmail.com

