From o.martinezrubi at tudelft.nl  Tue May  6 06:53:18 2014
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Tue, 06 May 2014 15:53:18 +0200
Subject: [pdal] PDAL decrease performance after hardware change
Message-ID: <5368E94E.6050705@tudelft.nl>

Hi guys,

I have two problems that are driving me quite crazy. The first one is 
related to compilation of PDAL:

I can not manage to compile the current version in the repository. It 
crashes during compilation. The error I get is (I used embed_boost):

[ 48%] Building CXX object src/CMakeFiles/pdalcpp.dir/StageFactory.cpp.o
In file included from 
/home/oscar/sw/PDAL/src/../include/pdal/drivers/bpf/BpfReader.hpp:37,
from /home/oscar/sw/PDAL/src/../include/pdal/Drivers.hpp:46,
from /home/oscar/sw/PDAL/src/StageFactory.cpp:43:
/home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp: In member function 
?std::istream* pdal::IStream::popStream()?:
/home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp:78: error: ?nullptr? 
was not declared in this scope
/home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp: In member function 
?pdal::ILeStream& pdal::ILeStream::operator>>(float&)?:
/home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp:173: warning: 
dereferencing type-punned pointer will break strict-aliasing rules
/home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp: In member function 
?pdal::ILeStream& pdal::ILeStream::operator>>(double&)?:
/home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp:181: warning: 
dereferencing type-punned pointer will break strict-aliasing rules
In file included from 
/home/oscar/sw/PDAL/boost/boost/interprocess/detail/managed_open_or_create_impl.hpp:15,
from 
/home/oscar/sw/PDAL/boost/boost/interprocess/managed_shared_memory.hpp:22,
from /home/oscar/sw/PDAL/src/../include/pdal/PointBuffer.hpp:44,
from /home/oscar/sw/PDAL/src/../include/pdal/drivers/sbet/Reader.hpp:38,
from /home/oscar/sw/PDAL/src/../include/pdal/Drivers.hpp:48,
from /home/oscar/sw/PDAL/src/StageFactory.cpp:43:
/home/oscar/sw/PDAL/boost/boost/interprocess/detail/os_thread_functions.hpp: 
In function ?int 
pdalboost::interprocess::ipcdetail::thread_launch(pdalboost::interprocess::ipcdetail::OS_thread_t&, 
F)?:
/home/oscar/sw/PDAL/boost/boost/interprocess/detail/os_thread_functions.hpp:554: 
warning: ?auto_ptr? is deprecated (declared at 
/usr/lib/gcc/x86_64-redhat-linux/4.4.7/../../../../include/c++/4.4.7/backward/auto_ptr.h:86)
make[2]: *** [src/CMakeFiles/pdalcpp.dir/StageFactory.cpp.o] Error 1
make[1]: *** [src/CMakeFiles/pdalcpp.dir/all] Error 2
make: *** [all] Error 2

I also tried without embed boost but also crashed.

It compiles fine if I use the tag 0.9.8 though. I do not know if anybody 
else is having this issue or whether you are already aware of this (if 
that is the case I am sorry!)

I also tried the PDAL in https://github.com/pramsey/PDAL/ since I want 
to use PDAL for pointcloud in postgres (actually what is the difference 
between the two repositories?). In this one I manage to compile the 
latest but I always get the error Caught PDAL exception: 
drivers.pgpointcloud.writer num_points > m_patch_capacity! when loading 
files.

If I use a previous version of the code in the pramsey repository, for 
example revision 50ed6d4 (git reset --hard 50ed6d4) then it works fine.

Any help?

The second problem I have is a decrease of PDAL performance after a 
hardware/software change on my main testing server.

This RedHat 6.5 server had originally a RAID 6 with 80TB. We have this 
test to load 20M points in postgres pointcloud from a LAZ file. It took 
80 seconds. Another test is to load them in a flat table (using las2txt 
piped with psql -c 'copy from') which takes 600 seconds (PDAL rocks!).

Then, we changed the hardware. Now we have two RAID systems of 40TB 
each. The idea was to use one for reading the LAZ files and the other to 
write to the DB. We also upgraded Postgres and Postgis and PDAL with 
latest versions (well PDAL I had to use a previous revision). After the 
upgrade the time of the PDAL loading was 130 seconds (instead of 80)! 
But the time of the flat table loading is still the same (600 secs). So, 
something have changed that affects only PDAL.

I am also testing using Oracle (not with PDAL) and MonetDB to load point 
clouds and these other systems are not affected by hardware change 
(actually they improve)

I have some virtual machines (centos 6.4) in another server. I tried 
different combinations of Postgres, PostGIS, PDAL, GDAL to see if I saw 
some combination that was worse than the rest but they are more or less 
the same (which is expected). So, essentially I could not reproduce the 
same performance decrease in a different system which is very annoying.

Anyway, I tried to install back in the main testing server the same 
Postgres, PostGIS, PDAL software that I originally had with no luck. The 
time is still around 130 seconds (for something that should take 80 
seconds).

Any idea why could this happen? Excuses because I know that something 
that is nor reproducible is very tricky to correct but I am quite 
desperate here! Any idea/hint would be very appreciated.

Thanks a lot in advance and sorry for long mail!

Regards,

Oscar

From howard at hobu.co  Tue May  6 12:54:02 2014
From: howard at hobu.co (Howard Butler)
Date: Tue, 6 May 2014 15:54:02 -0400
Subject: [pdal] PDAL decrease performance after hardware change
In-Reply-To: <5368E94E.6050705@tudelft.nl>
References: <5368E94E.6050705@tudelft.nl>
Message-ID: <AD0F5DFB-E5A3-4D29-B336-4502F95F61E0@hobu.co>


On May 6, 2014, at 9:53 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:

> Hi guys,
> 
> I have two problems that are driving me quite crazy. The first one is related to compilation of PDAL:

> /home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp: In member function ?std::istream* pdal::IStream::popStream()?:
> /home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp:78: error: ?nullptr? was not declared in this scope

We have been stretching things out recently, and and PDAL probably requires a gcc 4.6 or clang 3.4+ on linux for now. I expect that we will back off of that to something approaching gcc 4.6 to get many, but not necessarily all, C++11 features

> I also tried without embed boost but also crashed.
> 
> It compiles fine if I use the tag 0.9.8 though. I do not know if anybody else is having this issue or whether you are already aware of this (if that is the case I am sorry!)

Try a sha somewhere about a02bca202afcb26ea694c8f864d292794944dadd or thereabouts near the end of February. At that time is when some of the C++11 features started creeping in.


> I also tried the PDAL in https://github.com/pramsey/PDAL/ since I want to use PDAL for pointcloud in postgres (actually what is the difference between the two repositories?). In this one I manage to compile the latest but I always get the error Caught PDAL exception: drivers.pgpointcloud.writer num_points > m_patch_capacity! when loading files.

> 
> If I use a previous version of the code in the pramsey repository, for example revision 50ed6d4 (git reset --hard 50ed6d4) then it works fine.
> 
> Any help?
> 
> The second problem I have is a decrease of PDAL performance after a hardware/software change on my main testing server.

The first thing to check is your CMAKE_BUILD_TYPE configuration. If it is Debug instead of Release, you will see at least a 2x performance penalty. That would be the first thing to check. The second thing to check is the configuration of your filters.cache in your pipeline. You want its options to be only

>    <Filter type="filters.cache">
>                 <Option name="max_cache_blocks">1</Option> 

> Thanks a lot in advance and sorry for long mail!

Good luck, and please report back if you continue to have trouble.

Howard

From howard at hobu.co  Tue May  6 19:16:10 2014
From: howard at hobu.co (Howard Butler)
Date: Tue, 6 May 2014 22:16:10 -0400
Subject: [pdal] Quit copying yourself
Message-ID: <838C38F3-DD40-4033-A143-185E149F8F9F@hobu.co>

All,

Andrew Bell has been revisiting some of the architectural choices of PDAL after recently implementing a reasonably complex driver. This email is a head's up about some planned changes we've discussed that are coming to PDAL. We hope they will make things more simple, allow us to chuck a lot of things that might be beside the point, and make it easier for someone to learn a fewer bits and pieces to be able to make progress developing software with the library. 

The way we thought we'd use PDAL when Michael Gerlek started laying things out, and how it's actually used today are a little bit different. One area where this incongruity has become apparent is the limitations of using PointBuffer as the substrate for moving data back and forth throughout PDAL. The PointBuffer as it is currently implemented assumes a data storage arrangement in addition to an access pattern, and this causes Stages to have to move/copy data around to satisfy the requirements imposed by the PointBuffer when a Stage looking to rearrange data. 

To alleviate this pressure, we going to hide the data layout and storage of the PointBuffer behind a PointContext. Raw byte mucking with the PointBuffer is going to be discouraged or possibly not allowed anymore. In exchange for this limitation, Stage implementors will be able to interact with a single PointContext that hides the data storage and allows you to make PointBuffers that are simply views. No more making little PointBuffers, copying them onto bigger PointBuffers, or using hard-to-use and not-implemented-everywhere randomIterator to skip/hop around in the Stage. A filter like filters.chipper or filters.tiler will be able to simply chop up the data into a bunch of smaller PointBuffers, organizing the data however they want, with each simply being a view into the single PointContext.

If you have your own code that does a lot of composition of PDAL major objects, we are interested in hearing about it. Note that the pipeline XML stuff shouldn't have to change at all.

Howard   

From o.martinezrubi at tudelft.nl  Wed May  7 02:12:47 2014
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 07 May 2014 11:12:47 +0200
Subject: [pdal] PDAL decrease performance after hardware change
In-Reply-To: <AD0F5DFB-E5A3-4D29-B336-4502F95F61E0@hobu.co>
References: <5368E94E.6050705@tudelft.nl>
	<AD0F5DFB-E5A3-4D29-B336-4502F95F61E0@hobu.co>
Message-ID: <5369F90F.1040808@tudelft.nl>

Dear Howard,

Thanks a lot for your suggestion.

Following your advise I am using the SHA 
a02bca202afcb26ea694c8f864d292794944dadd. This one compiles fine but if 
shows the error num_points > m_patch_capacity if I use a block size 
higher than 400 points.

If I build with Release and without embed boost I manage to get almost 
the same performance than before! It is still slightly slower but that 
maybe only "noise"...

Well, thanks a lot for your help!

Regards,

Oscar.



On 06-05-14 21:54, Howard Butler wrote:
> On May 6, 2014, at 9:53 AM, Oscar Martinez Rubi <O.MartinezRubi at tudelft.nl> wrote:
>
>> Hi guys,
>>
>> I have two problems that are driving me quite crazy. The first one is related to compilation of PDAL:
>> /home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp: In member function ?std::istream* pdal::IStream::popStream()?:
>> /home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp:78: error: ?nullptr? was not declared in this scope
> We have been stretching things out recently, and and PDAL probably requires a gcc 4.6 or clang 3.4+ on linux for now. I expect that we will back off of that to something approaching gcc 4.6 to get many, but not necessarily all, C++11 features
>
>> I also tried without embed boost but also crashed.
>>
>> It compiles fine if I use the tag 0.9.8 though. I do not know if anybody else is having this issue or whether you are already aware of this (if that is the case I am sorry!)
> Try a sha somewhere about a02bca202afcb26ea694c8f864d292794944dadd or thereabouts near the end of February. At that time is when some of the C++11 features started creeping in.
>
>
>> I also tried the PDAL in https://github.com/pramsey/PDAL/ since I want to use PDAL for pointcloud in postgres (actually what is the difference between the two repositories?). In this one I manage to compile the latest but I always get the error Caught PDAL exception: drivers.pgpointcloud.writer num_points > m_patch_capacity! when loading files.
>> If I use a previous version of the code in the pramsey repository, for example revision 50ed6d4 (git reset --hard 50ed6d4) then it works fine.
>>
>> Any help?
>>
>> The second problem I have is a decrease of PDAL performance after a hardware/software change on my main testing server.
> The first thing to check is your CMAKE_BUILD_TYPE configuration. If it is Debug instead of Release, you will see at least a 2x performance penalty. That would be the first thing to check. The second thing to check is the configuration of your filters.cache in your pipeline. You want its options to be only
>
>>     <Filter type="filters.cache">
>>                  <Option name="max_cache_blocks">1</Option>
>> Thanks a lot in advance and sorry for long mail!
> Good luck, and please report back if you continue to have trouble.
>
> Howard


From o.martinezrubi at tudelft.nl  Wed May  7 04:16:08 2014
From: o.martinezrubi at tudelft.nl (Oscar Martinez Rubi)
Date: Wed, 07 May 2014 13:16:08 +0200
Subject: [pdal] PDAL decrease performance after hardware change
In-Reply-To: <5369F90F.1040808@tudelft.nl>
References: <5368E94E.6050705@tudelft.nl>
	<AD0F5DFB-E5A3-4D29-B336-4502F95F61E0@hobu.co>
	<5369F90F.1040808@tudelft.nl>
Message-ID: <536A15F8.5070206@tudelft.nl>

Hi again,

I am testing with SHA a02bca202afcb26ea694c8f864d292794944dadd with 
different files. In addition to the block size limitation, the LAS files 
version 1.0 are giving the following error when loading them:

0Caught PDAL exception: Dimension data type unable to be scaled in index 
filter

I am also testing with LAS 1.2 and LAZ 1.2 and they are fine. I also 
have installed the PDAL in pramsey repository (50ed6d4) and LAS 1.0 work 
there. The problem, using pramsey repository,  is that is slower than 
using the other one (at least in my server...)

Best Regards,

Oscar.



On 07-05-14 11:12, Oscar Martinez Rubi wrote:
> Dear Howard,
>
> Thanks a lot for your suggestion.
>
> Following your advise I am using the SHA 
> a02bca202afcb26ea694c8f864d292794944dadd. This one compiles fine but 
> if shows the error num_points > m_patch_capacity if I use a block size 
> higher than 400 points.
>
> If I build with Release and without embed boost I manage to get almost 
> the same performance than before! It is still slightly slower but that 
> maybe only "noise"...
>
> Well, thanks a lot for your help!
>
> Regards,
>
> Oscar.
>
>
>
> On 06-05-14 21:54, Howard Butler wrote:
>> On May 6, 2014, at 9:53 AM, Oscar Martinez Rubi 
>> <O.MartinezRubi at tudelft.nl> wrote:
>>
>>> Hi guys,
>>>
>>> I have two problems that are driving me quite crazy. The first one 
>>> is related to compilation of PDAL:
>>> /home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp: In member 
>>> function ?std::istream* pdal::IStream::popStream()?:
>>> /home/oscar/sw/PDAL/src/../include/pdal/IStream.hpp:78: error: 
>>> ?nullptr? was not declared in this scope
>> We have been stretching things out recently, and and PDAL probably 
>> requires a gcc 4.6 or clang 3.4+ on linux for now. I expect that we 
>> will back off of that to something approaching gcc 4.6 to get many, 
>> but not necessarily all, C++11 features
>>
>>> I also tried without embed boost but also crashed.
>>>
>>> It compiles fine if I use the tag 0.9.8 though. I do not know if 
>>> anybody else is having this issue or whether you are already aware 
>>> of this (if that is the case I am sorry!)
>> Try a sha somewhere about a02bca202afcb26ea694c8f864d292794944dadd or 
>> thereabouts near the end of February. At that time is when some of 
>> the C++11 features started creeping in.
>>
>>
>>> I also tried the PDAL in https://github.com/pramsey/PDAL/ since I 
>>> want to use PDAL for pointcloud in postgres (actually what is the 
>>> difference between the two repositories?). In this one I manage to 
>>> compile the latest but I always get the error Caught PDAL exception: 
>>> drivers.pgpointcloud.writer num_points > m_patch_capacity! when 
>>> loading files.
>>> If I use a previous version of the code in the pramsey repository, 
>>> for example revision 50ed6d4 (git reset --hard 50ed6d4) then it 
>>> works fine.
>>>
>>> Any help?
>>>
>>> The second problem I have is a decrease of PDAL performance after a 
>>> hardware/software change on my main testing server.
>> The first thing to check is your CMAKE_BUILD_TYPE configuration. If 
>> it is Debug instead of Release, you will see at least a 2x 
>> performance penalty. That would be the first thing to check. The 
>> second thing to check is the configuration of your filters.cache in 
>> your pipeline. You want its options to be only
>>
>>>     <Filter type="filters.cache">
>>>                  <Option name="max_cache_blocks">1</Option>
>>> Thanks a lot in advance and sorry for long mail!
>> Good luck, and please report back if you continue to have trouble.
>>
>> Howard
>


From andrew.bell.ia at gmail.com  Mon May 12 15:14:13 2014
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 12 May 2014 17:14:13 -0500
Subject: [pdal] PointBuffer/Stage Modifications
Message-ID: <CACJ51z2jSYVQPP75JJS5GazyB4qZbeTBhmzZnJ+VcTtMhaBAjw@mail.gmail.com>

All,

I've got a branch going that begins to implement a new storage mechanism
for points in PDAL.  The primary goal of the the change is to greatly
reduce the copying of data as it moves through the library.  The essential
notion is that once data is read by a Reader, it never moves and never
needs to be copied.  In addition, the changes should allow us to remove all
of the random iterators and the Cache filter.

In order to facilitate this change, I introduced a few new classes that
isolate the PointBuffers from the actual points.  They're very simple for
now, but here's a brief description:

RawPtBuf: This is the actual storage for the points.  Nobody should touch
this other than the PointBuffer.  It's not "public" as such.  Currently
data is stored in the same manner as it used to be stored in a PointBuffer

PointContext: Provides a container for information about a Schema and
RawPtBuffer.  A PointContext should be created for each set of points to be
dealt with in a pipeline.  Most uses of PDAL should require a single
PointContext.  Applications like "diff" and "delta" require two, as they
are comparing two sets of points.  PointContext objects are very simple and
can be treated as POD.

Changes of Note:

A PointBuffer will no longer store point data.  Instead, it contains a
simple index (currently, just a vector), into the RawPtBuffer.  When you
create a point buffer, you provide it a PointContext, which ties the
PointBuffer to the RawPtBuffer and Schema.  Right now, you can create a
PointContext with the old constructor.  In that case, it will use a
PointContext created in the GlobalEnvironment and things will probably
break if you aren't careful.  This is just a stopgap until we can get
things modified.

Stages no longer accept a prevStage or prevStages argument.  After a Stage
is created, you can call setInput(Stage *) or setInput(vector<Stage *>) to
create a pipeline by hand.  I'm thinking this will change, but for now this
is how things work.

In the old code, you would call initialize() on the end stage before
reading points.  The notion of initialization has been replaced with
preparation.  Where you would have called "initialize()", you now call
"prepare(PointContext)".  prepare is a public function on a Stage which
calls private functions processOptions(Options&), initialize(), and
buildSchema(Schema *) on each of the stages in a pipeline.  You no longer
need to invoke the base class's initialization from a Filter/Reader/etc.
 buildSchema is the single opportunity that a stage has to add dimensions
to the schema.  You shouldn't try to do this in an iterator (as some stages
currently do).  appendDimension() now returns a pointer to the actual
Dimension that's stored in the schema in case a stage needs to store that
away for later use.

In the old code, you would read a specific number of points by creating a
PointBuffer with a capacity equal to the number of points you wanted to
read and pass that to read().  PointBuffers no longer have capacity (though
it's still hanging around for the time being).  In order to read N points
from an iterator into a PointBuffer, you just call read(PointBuffer, N).
 When you use this form of read(), readBegin(), readBufferBegin(),
readEnd() and readBufferEnd() are not called.  In order for this not to
throw an error, you must implement readImpl(PointBuffer, point_count_t) in
your Reader/Filter.

I created two types that should be used as things get modified:

point_count_t (currently uint32_t) is an equivalent to size_t for PDAL
points.  If we ever want to allow more than 2^32 points, this should save a
ton of time.

PointId (currently uin32_t) is essentially a point number, but this may
change.


Implementing readImpl():

When changing/copying readBufferImpl() to readImpl(), there are a couple of
things to note:

1) You should call PointBuffer().size() in order to determine the starting
index at which to write data to the PointBuffer -- don't start from 0.
 This allows a point buffer to be reused without having its data
overwritten by subsequent calls to read().

2) You don't need to tell the PointBuffer how many points are read -- this
is tracked automatically.  setNumPoints() will go away soon.

3) You can no longer copy data from some raw buffer into a PointBuffer.
 You should assume that you have no control over the way point data are
stored.  Call setField()/getField().

4) You can't treat a PointBuffer as random-access for writing.  You must
call setField on point N-1 before you can call setField on point N.  This
shouldn't be a real limitation as far as I can see.

This is a lot.  Thanks for reading.  If you're going to tackle
modifications to drivers/filters, you can look at BPF and the LAS reader,
as I've changed them along with the associated tests to work the new way.
 If you're going to work on converting things, open a ticket or let me know
so that we keep duplicate effort to a minimum.

Let me know if you have questions/comments.

Thanks!

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20140512/52d8a3cf/attachment.html>

From aminelamrani2 at hotmail.com  Tue May 27 07:24:37 2014
From: aminelamrani2 at hotmail.com (Amine el amrani)
Date: Tue, 27 May 2014 16:24:37 +0200
Subject: [pdal] LAS reader, P2G and pdal
Message-ID: <DUB127-W779366C07E80FFC6F6A9A6E73A0@phx.gbl>

Hi guys ,
I'm working on creating DEMs using LiDAR data for orthophoto
      creation purposes. The ultimate goal is to insert these
      orthorectification algorithms in an open source French spatial
      image processing library called Orfeo Tool Box (OTB).
      http://orfeo-toolbox.org/otb/

      

      Since there was no official release of pdal, I'm spending a lot of
      time deciphering the code to understand the methods used in each
      class and it's quite intricate some times. (I'm a beginner)

      

      So I have a couple of questions if you have time to answer them
      quickly :

      

      - After reading a LiDAR set of points, I want to remove all the
      points that are not last returns. Is this method already
      implemented in the LASReader class ? Otherwise, do you have an
      idea how to proceed ? It should be noted that I can't use Liblas
      in this project as the OTB development team decided not to.

      

      - P2G gives me some odd results when interpolating. Some points
      are completely aberrants (a 2000m height isolated
      points where all the surrounding area is about 900 m height). Note
      that my LiDAR files are of high quality (French government data). 
      I highly suspect the multiple returns issue to have something to
      do with it. Note that the "den" output format gives me some
      extremely noisy results (barely meaningful) 

      

      - The method "getStreamFactory" doesn't work because it contains
      pure virtual methods, and I don't know how to resolve this.


      Thanks in advance, 
Amine  		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20140527/9c8d789b/attachment.html>

From howard at hobu.co  Tue May 27 07:37:42 2014
From: howard at hobu.co (Howard Butler)
Date: Tue, 27 May 2014 10:37:42 -0400
Subject: [pdal] LAS reader, P2G and pdal
In-Reply-To: <DUB127-W779366C07E80FFC6F6A9A6E73A0@phx.gbl>
References: <DUB127-W779366C07E80FFC6F6A9A6E73A0@phx.gbl>
Message-ID: <EC9B3A14-AE5E-48DA-B8EA-921A2899A3BE@hobu.co>

Amine,

We're hoping to have an official release soon, but we're currently in the middle of some refactoring that we want to settle down before doing so. The refactoring effort [1] will make things work more smoothly with better performance in many situations. I don't have a timeframe for the actual release, however.

[1] http://lists.osgeo.org/pipermail/pdal/2014-May/000417.html

Other comments inline.


On May 27, 2014, at 10:24 AM, Amine el amrani <aminelamrani2 at hotmail.com> wrote:

> Hi guys ,
> 
> I'm working on creating DEMs using LiDAR data for orthophoto creation purposes. The ultimate goal is to insert these orthorectification algorithms in an open source French spatial image processing library called Orfeo Tool Box (OTB).http://orfeo-toolbox.org/otb/
> 
> Since there was no official release of pdal, I'm spending a lot of time deciphering the code to understand the methods used in each class and it's quite intricate some times. (I'm a beginner)


> 
> So I have a couple of questions if you have time to answer them quickly :
> 
> - After reading a LiDAR set of points, I want to remove all the points that are not last returns. Is this method already implemented in the LASReader class ? Otherwise, do you have an idea how to proceed ? It should be noted that I can't use Liblas in this project as the OTB development team decided not to.

The way to do this in PDAL would be to use a Python 'filters.predicate' filter. https://github.com/PDAL/PDAL/blob/master/test/data/plang/predicate-keep-last-return.xml is an example of a Last Return filter, and you could adapt this to do First Return or whatever other data culling you would like.

> 
> - P2G gives me some odd results when interpolating. Some points are completely aberrants (a 2000m height isolated points where all the surrounding area is about 900 m height). Note that my LiDAR files are of high quality (French government data).  I highly suspect the multiple returns issue to have something to do with it. Note that the "den" output format gives me some extremely noisy results (barely meaningful) 

One noisy point is likely to cause a lot of interpolation grief. You must filter your data before handing it off to P2G, as I believe it doesn't do any noise filtering and simply interpolates what it sees. You could try the 'filters.predicate' approach above, and the PCLBlock [2] filtering capability includes a statistical noise filter that could be adapted as well.

[2] http://www.pdal.io/stages/filters.pclblock.html

> - The method "getStreamFactory" doesn't work because it contains pure virtual methods, and I don't know how to resolve this.

I'm not sure what you mean by this point. Can you please file a ticket with an example or compiler error message?

Howard

