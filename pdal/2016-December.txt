From andrew.bell.ia at gmail.com  Fri Dec  2 12:21:18 2016
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Fri, 2 Dec 2016 14:21:18 -0600
Subject: [pdal] Source Code Reorganization
Message-ID: <CACJ51z2++rbaXK+WDcw-4aaYjUGZnh=fvj42caXXZG7wXdF9Pg@mail.gmail.com>

In order to ease some issues related to the build process, we're planning
on reorganizing the source code of PDAL.  Here's what's happening:

All source code in subdirectories of the io directory will be moved to the
io directory itself.  All existing subdirectories of io will be removed as
will io/CMakeLists.txt.

All source code in subdirectories of the filters directory will be moved to
the filters directory itself.  All existing subdirectories of filters will
be removed as will filters/CMakeLists.txt.

All source code in subdirectories of the kernels directory will be moved to
the kernels directory itself.  All existing subdirectories of kernels will
be removed as will io/CMakeLists.txt.

The source code in the src directory and the include/pdal directory will be
moved to a directory called pdal.  The src and include directories will be
removed.

This change also facilitates a change in installation that may have proved
problematic when attempting to build the install PDAL headers.  We will
install the headers in the io/filters/kernels/plang and utils
subdirectories in the source tree into the same relative places in the
installation include directory.

For most PDAL users, this change should be transparent.

Please let me know if you have questions or concerns.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161202/4730a436/attachment.html>

From mateusz at loskot.net  Sat Dec  3 12:16:35 2016
From: mateusz at loskot.net (Mateusz Loskot)
Date: Sat, 3 Dec 2016 21:16:35 +0100
Subject: [pdal] First stab at Coverity Scan
In-Reply-To: <CABUeae_-PZbCZLv=qGGRhZ0PcEZCUj1MJNZnyW4jOHfQy1th_g@mail.gmail.com>
References: <CABUeae_+g9Je1t0oPDQ2rf=11nzydbFxNkA273moQrLC+A2eqQ@mail.gmail.com>
 <3E78EFA5-C38B-4FAB-A4E5-7B5DDC997807@hobu.co>
 <CABUeae-fpx-Lgdu7HmZ7Z8sW2Ot6M+hh+-Y=fAKF5gwu2+paPQ@mail.gmail.com>
 <CABUeae_-PZbCZLv=qGGRhZ0PcEZCUj1MJNZnyW4jOHfQy1th_g@mail.gmail.com>
Message-ID: <CABUeae9-nV=Pwn2fyj0RccprRLsKyQp_3POC+yaPmDp8Ou3==A@mail.gmail.com>

On 1 December 2016 at 00:39, Mateusz Loskot <mateusz at loskot.net> wrote:
>
> Build succeeded but Coverity Scan did not due to build configuration issue
>
> https://travis-ci.org/PDAL/PDAL/jobs/180236279#L506
>
> To be solved.

FYI, it seems tricky to run Coverity Scan against build on docker image.

https://travis-ci.org/PDAL/PDAL/jobs/180991085#L4324

Travis CI runs the scanner which is looking for the generated files in
the local build directory.
So, the scanner is failing to collect anything.

Ideally, if PDAL for the Coverity Scan is built w/o docker,
but then the required dependencies are the issue.

Alternatively, it might be possible to run Coverity Scan tools on
docker as well.

I might give the latter a go if I have a moment.

Best regards,
-- 
Mateusz Loskot, http://mateusz.loskot.net

From howard at hobu.co  Sun Dec  4 08:12:41 2016
From: howard at hobu.co (Howard Butler)
Date: Sun, 4 Dec 2016 10:12:41 -0600
Subject: [pdal] First stab at Coverity Scan
In-Reply-To: <CABUeae9-nV=Pwn2fyj0RccprRLsKyQp_3POC+yaPmDp8Ou3==A@mail.gmail.com>
References: <CABUeae_+g9Je1t0oPDQ2rf=11nzydbFxNkA273moQrLC+A2eqQ@mail.gmail.com>
 <3E78EFA5-C38B-4FAB-A4E5-7B5DDC997807@hobu.co>
 <CABUeae-fpx-Lgdu7HmZ7Z8sW2Ot6M+hh+-Y=fAKF5gwu2+paPQ@mail.gmail.com>
 <CABUeae_-PZbCZLv=qGGRhZ0PcEZCUj1MJNZnyW4jOHfQy1th_g@mail.gmail.com>
 <CABUeae9-nV=Pwn2fyj0RccprRLsKyQp_3POC+yaPmDp8Ou3==A@mail.gmail.com>
Message-ID: <013417A5-A39A-4EA5-B780-74D90D605956@hobu.co>


> On Dec 3, 2016, at 2:16 PM, Mateusz Loskot <mateusz at loskot.net> wrote:
> 
> I might give the latter a go if I have a moment.

Thanks for working through this. Coverity scans will be nice to have once we get over the docker hump.

Howard

From mike.skaug at nsidc.org  Thu Dec  8 07:42:18 2016
From: mike.skaug at nsidc.org (Mike Skaug)
Date: Thu, 8 Dec 2016 08:42:18 -0700
Subject: [pdal] readers.pgpointcloud
Message-ID: <ea912a74-a240-7d74-5bb1-d23eafc78a52@nsidc.org>

I'm working on a project where we are using pdal to ingest lidar data 
into a pgpointcloud enabled PostgreSQL database and then reading the 
data out into another format. At least that's the idea.

We set up a simple pipeline to write the data into the database:
{
     "pipeline":[
"/data/ILATM1B.002/2013.03.20/ILATM1B_20130320_141441.ATM4BT4.h5",
         {
             "type": "filters.chipper",
             "capacity": 500
         },
         {
             "type":"writers.pgpointcloud",
             "connection":"host='valkyrie-db' dbname='valkyrie' 
user='valkyrie' password='valkyrie'",
             "table":"patches"
         }
     ]
}

This reads a single file, chips it and writes it into the database. This 
works as expected.

However, this pipeline taken almost verbatim from the example: 
http://www.pdal.io/stages/readers.pgpointcloud.html, which is intended 
to read the data out of the database, fails:

{
     "pipeline":[
         {
             "type":"readers.pgpointcloud",
             "connection":"host='valkyrie-db' dbname='valkyrie' 
user='valkyrie' password='valkyrie'",
             "table":"patches",
             "column":"pa",
             "where":"PC_Explode(PC_Intersection(pa, 
'SRID=4326;POLYGON((-160.000 80.000, -20.000 80.00, -20.000 85.000, 
-160.000 85.000, -160.000 80.000))'::geometry))"
         },
         {
           "type":"writers.text",
           "filename":"output.txt"
         }
     ]
}

The error is `PDAL: JSON pipeline: Can't find file ' ' to open with 
'readers.pgpointcloud'.`

This seems to suggest that pdal is looking for an input file? Or might I 
get this error if it is not connecting to the database? (I assume that 
the database connection is fine because it is using the same 
`connection` option as the successful "writers.pgpointcloud" given above.)

Thanks for any suggestions.
--Mike

From andrew.bell.ia at gmail.com  Thu Dec  8 08:01:23 2016
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Thu, 8 Dec 2016 10:01:23 -0600
Subject: [pdal] readers.pgpointcloud
In-Reply-To: <ea912a74-a240-7d74-5bb1-d23eafc78a52@nsidc.org>
References: <ea912a74-a240-7d74-5bb1-d23eafc78a52@nsidc.org>
Message-ID: <CACJ51z1PWqGCrc7x3M1VyFfmsTPpLtHA8E3obJshPmddtJR+FQ@mail.gmail.com>

This was a bug that I believe has been fixed.  Either use the release
version (1.3) or update to the latest contents of the master branch.

On Thu, Dec 8, 2016 at 9:42 AM, Mike Skaug <mike.skaug at nsidc.org> wrote:

> I'm working on a project where we are using pdal to ingest lidar data into
> a pgpointcloud enabled PostgreSQL database and then reading the data out
> into another format. At least that's the idea.
>
> We set up a simple pipeline to write the data into the database:
> {
>     "pipeline":[
> "/data/ILATM1B.002/2013.03.20/ILATM1B_20130320_141441.ATM4BT4.h5",
>         {
>             "type": "filters.chipper",
>             "capacity": 500
>         },
>         {
>             "type":"writers.pgpointcloud",
>             "connection":"host='valkyrie-db' dbname='valkyrie'
> user='valkyrie' password='valkyrie'",
>             "table":"patches"
>         }
>     ]
> }
>
> This reads a single file, chips it and writes it into the database. This
> works as expected.
>
> However, this pipeline taken almost verbatim from the example:
> http://www.pdal.io/stages/readers.pgpointcloud.html, which is intended to
> read the data out of the database, fails:
>
> {
>     "pipeline":[
>         {
>             "type":"readers.pgpointcloud",
>             "connection":"host='valkyrie-db' dbname='valkyrie'
> user='valkyrie' password='valkyrie'",
>             "table":"patches",
>             "column":"pa",
>             "where":"PC_Explode(PC_Intersection(pa,
> 'SRID=4326;POLYGON((-160.000 80.000, -20.000 80.00, -20.000 85.000,
> -160.000 85.000, -160.000 80.000))'::geometry))"
>         },
>         {
>           "type":"writers.text",
>           "filename":"output.txt"
>         }
>     ]
> }
>
> The error is `PDAL: JSON pipeline: Can't find file ' ' to open with
> 'readers.pgpointcloud'.`
>
> This seems to suggest that pdal is looking for an input file? Or might I
> get this error if it is not connecting to the database? (I assume that the
> database connection is fine because it is using the same `connection`
> option as the successful "writers.pgpointcloud" given above.)
>
> Thanks for any suggestions.
> --Mike
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal




-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161208/031cc65d/attachment.html>

From daniel at georepublic.de  Thu Dec  8 17:15:45 2016
From: daniel at georepublic.de (Daniel Kastl)
Date: Fri, 9 Dec 2016 10:15:45 +0900
Subject: [pdal] Does Entwine support LAS format?
Message-ID: <CABXBSH_wrGTDvPSsEwUUN_sMiwVKr1LznQoJO7Jv7CkCULhm2Q@mail.gmail.com>

Hi,

I'm trying to convert a LAS file and I'm receiving the following error:

docker run -it -v $HOME:/opt/data connormanning/entwine \
    entwine build \
        -i /opt/data/JCT01.las
        -o /opt/data/entwine/JCT

Performing dataset inference...
1 / 1: /opt/data/JCT01.las
Exception caught in pool task: Unable to open stream for
'/opt/data/JCT01.las' with error 'No such file or directory'
Encountered an error: Zero points found
Exiting.

The LAS file "/opt/data/JCT01.las" exists in the specified directory.

When I try the LAZ example from the documentation it seems to work.

docker run -it -v $HOME:/opt/data connormanning/entwine \
    entwine build \
        -i https://entwine.io/sample-data/red-rocks.laz \
        -o /opt/data/entwine/red-rocks


Now I would like to ask, if the problem is, that LAS format isn't supported
or if I need to search for another reason.

Thanks,
Daniel


-- 
Georepublic UG & Georepublic Japan
eMail: daniel.kastl at georepublic.de
Web: https://georepublic.info
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161209/a60dd872/attachment.html>

From smercier at mapgears.com  Thu Dec  8 19:24:21 2016
From: smercier at mapgears.com (Simon Mercier)
Date: Thu, 8 Dec 2016 22:24:21 -0500
Subject: [pdal] Does Entwine support LAS format?
In-Reply-To: <CABXBSH_wrGTDvPSsEwUUN_sMiwVKr1LznQoJO7Jv7CkCULhm2Q@mail.gmail.com>
References: <CABXBSH_wrGTDvPSsEwUUN_sMiwVKr1LznQoJO7Jv7CkCULhm2Q@mail.gmail.com>
Message-ID: <3C9C8C73-6D77-444B-85EA-F95F2487AF70@mapgears.com>

Daniel, your las file need to be in your $home.  entwine container look into his /opt/data which point to $home on your host.

https://docs.docker.com/engine/reference/run/#/volume-shared-filesystems <https://docs.docker.com/engine/reference/run/#/volume-shared-filesystems>


-- 
Simon Mercier
mapgears.com



> On Dec 8, 2016, at 8:15 PM, Daniel Kastl <daniel at georepublic.de> wrote:
> 
> Hi,
> 
> I'm trying to convert a LAS file and I'm receiving the following error:
> 
> docker run -it -v $HOME:/opt/data connormanning/entwine \
>     entwine build \
>         -i /opt/data/JCT01.las 
>         -o /opt/data/entwine/JCT
> 
> Performing dataset inference...
> 1 / 1: /opt/data/JCT01.las
> Exception caught in pool task: Unable to open stream for '/opt/data/JCT01.las' with error 'No such file or directory'
> Encountered an error: Zero points found
> Exiting.
> The LAS file "/opt/data/JCT01.las" exists in the specified directory.
> 
> When I try the LAZ example from the documentation it seems to work.
> 
> docker run -it -v $HOME:/opt/data connormanning/entwine \
>     entwine build \
>         -i https://entwine.io/sample-data/red-rocks.laz <https://entwine.io/sample-data/red-rocks.laz> \
>         -o /opt/data/entwine/red-rocks
> 
> Now I would like to ask, if the problem is, that LAS format isn't supported or if I need to search for another reason.
> 
> Thanks,
> Daniel
> 
> 
> -- 
> Georepublic UG & Georepublic Japan
> eMail: daniel.kastl at georepublic.de <mailto:daniel.kastl at georepublic.de>
> Web: https://georepublic.info <https://georepublic.info/>
> 
> 
> 
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161208/b1f61879/attachment.html>

From daniel at georepublic.de  Thu Dec  8 19:41:21 2016
From: daniel at georepublic.de (Daniel Kastl)
Date: Fri, 9 Dec 2016 12:41:21 +0900
Subject: [pdal] Does Entwine support LAS format?
In-Reply-To: <3C9C8C73-6D77-444B-85EA-F95F2487AF70@mapgears.com>
References: <CABXBSH_wrGTDvPSsEwUUN_sMiwVKr1LznQoJO7Jv7CkCULhm2Q@mail.gmail.com>
 <3C9C8C73-6D77-444B-85EA-F95F2487AF70@mapgears.com>
Message-ID: <CABXBSH_ZeNUqrR0=jEFUtVQNoK_u=Kq9WWwtwKCMQQ5CO1P1MA@mail.gmail.com>

Thank you, Simon!

It's the Docker argument, you're right.
Now it's working.

Daniel



On Fri, Dec 9, 2016 at 12:24 PM, Simon Mercier <smercier at mapgears.com>
wrote:

> Daniel, your las file need to be in your $home.  entwine container look
> into his /opt/data which point to $home on your host.
>
> https://docs.docker.com/engine/reference/run/#/volume-shared-filesystems
>
>
> --
> Simon Mercier
> mapgears.com
>
>
>
> On Dec 8, 2016, at 8:15 PM, Daniel Kastl <daniel at georepublic.de> wrote:
>
> Hi,
>
> I'm trying to convert a LAS file and I'm receiving the following error:
>
> docker run -it -v $HOME:/opt/data connormanning/entwine \
>     entwine build \
>         -i /opt/data/JCT01.las
>         -o /opt/data/entwine/JCT
>
> Performing dataset inference...
> 1 / 1: /opt/data/JCT01.las
> Exception caught in pool task: Unable to open stream for '/opt/data/JCT01.las' with error 'No such file or directory'
> Encountered an error: Zero points found
> Exiting.
>
> The LAS file "/opt/data/JCT01.las" exists in the specified directory.
>
> When I try the LAZ example from the documentation it seems to work.
>
> docker run -it -v $HOME:/opt/data connormanning/entwine \
>     entwine build \
>         -i https://entwine.io/sample-data/red-rocks.laz \
>         -o /opt/data/entwine/red-rocks
>
>
> Now I would like to ask, if the problem is, that LAS format isn't
> supported or if I need to search for another reason.
>
> Thanks,
> Daniel
>
>
> --
> Georepublic UG & Georepublic Japan
> eMail: daniel.kastl at georepublic.de
> Web: https://georepublic.info
>
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>
>
>


-- 
Georepublic UG & Georepublic Japan
eMail: daniel.kastl at georepublic.de
Web: https://georepublic.info
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161209/4f755abb/attachment.html>

From Mats.Hogstrom at slu.se  Mon Dec 12 05:13:53 2016
From: Mats.Hogstrom at slu.se (=?utf-8?B?TWF0cyBIw7Znc3Ryw7Zt?=)
Date: Mon, 12 Dec 2016 13:13:53 +0000
Subject: [pdal] Compare/update metadata in a las file?
Message-ID: <1A46EC4E-70F5-4618-841B-E1C8D837D214@slu.se>

Greetings,

I just started using pdal and have a very basic question. How does pdal report metadata, and can it be updated? I want to do the same things you can do with LAStools/lasinfo:

> "Reports the contents of the header and a short summary of the
>   points. Warns when there is a difference between the header
>   information and the point content. When run with option '-cd'
>   or '-compute_density', lasinfo will compute the point density.
> 
>   All differences can be repaired with the '-repair' option. The
>   option '-repair_bb' will only repair (or tighten) the bounding
>   box while '-repair_counters' will only repair wrong reported
>   number of points.”

Is this possible with pdal?

Best regards.

/mats

Mats Högström
GIS manager SLU

Sveriges lantbruksuniversitet
Swedish University of Agricultural Sciences

Dept of Forest Resource Management
Remote Sensing
SE-901 83 UMEÅ
Visiting address: Skogsmarksgränd
Phone: +46 90 - 786 83 63
mats.hogstrom at slu.se www.slu.se/srh


From howard at hobu.co  Mon Dec 12 05:37:29 2016
From: howard at hobu.co (Howard Butler)
Date: Mon, 12 Dec 2016 07:37:29 -0600
Subject: [pdal] Compare/update metadata in a las file?
In-Reply-To: <1A46EC4E-70F5-4618-841B-E1C8D837D214@slu.se>
References: <1A46EC4E-70F5-4618-841B-E1C8D837D214@slu.se>
Message-ID: <595CC831-7F4A-4027-9473-842F1F82B986@hobu.co>


> On Dec 12, 2016, at 7:13 AM, Mats Högström <Mats.Hogstrom at slu.se> wrote:
> 
> Greetings,
> 
> I just started using pdal and have a very basic question. How does pdal report metadata, and can it be updated? I want to do the same things you can do with LAStools/lasinfo:
> 
>> "Reports the contents of the header and a short summary of the
>>  points. Warns when there is a difference between the header
>>  information and the point content. When run with option '-cd'
>>  or '-compute_density', lasinfo will compute the point density.

$ pdal info myfile.las --all

will get you a rough density measure, but it requires that you have the hexbin filter enabled. If you are running the PDAL docker containers, this should all be in place for you.

>> 
>>  All differences can be repaired with the '-repair' option. The
>>  option '-repair_bb' will only repair (or tighten) the bounding
>>  box while '-repair_counters' will only repair wrong reported
>>  number of points.”
> 
> Is this possible with pdal?

PDAL does not support in-place editing of data because it is designed to operate on many more formats. "repair" is possible in the context of writing a new file, but it is not possible to do so as a single in-place file operation.


From howard at hobu.co  Thu Dec 15 11:00:12 2016
From: howard at hobu.co (Howard Butler)
Date: Thu, 15 Dec 2016 13:00:12 -0600
Subject: [pdal] PDAL 1.4.0 Released
Message-ID: <DCC0A369-42AE-40A6-ADF0-414D84C9DFDF@hobu.co>

It is my pleasure to announce the release of PDAL 1.4.0. Numerous features, bug fixes, and enhancements have been added since the 1.3.0 release in August. I would like to especially thank Andrew Bell and Brad Chambers for their significant enhancements to this release. Andrew coordinated the development of 'writers.gdal', which is a much more flexible points2grid replacement that does not require any external library. Brad refactored many of the PCL-dependent filters into stock PDAL ones, and he added a ton more capability for those looking to use PDAL in algorithm processing chains.

PDAL 1.4.0  also significantly enhances other language extensions with a preview Java/JNI binding by Rob Emanuel and Grisha Pomadchin of Azavea, and a significant refactor of the Python extension https://pypi.python.org/pypi/PDAL

Full release notes with descriptions of additions, enhancements, and bug fixes are available at https://github.com/PDAL/PDAL/releases/tag/1.4.0 See a list of pull requests  merged in to 1.4.0 at https://github.com/PDAL/PDAL/milestone/8?closed=1 

Download of 1.4.0 source is available at the usual location http://www.pdal.io/download.html and the docker container at 'pdal/pdal:1.4' is up-to-date and ready to use.


Release Notes
------------------------
 https://github.com/PDAL/PDAL/releases/tag/1.4.0 

Download
------------------------
http://www.pdal.io/download.html

Docker
------------------------
pdal/pdal:1.4

From howard at hobu.co  Tue Dec 20 11:01:11 2016
From: howard at hobu.co (Howard Butler)
Date: Tue, 20 Dec 2016 13:01:11 -0600
Subject: [pdal] PDAL Pipeline Extensibility
Message-ID: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>

I'd like to find out if people see the need to be able to extend PDAL's pipeline JSON syntax, and if they do, what uses the ability to extend it would allow you that you do not have currently. Consider the following pipeline that uses the writers.gdal to interpolate a raster surface from the 255.laz file. At the moment with 1.4, if any of the attributes of a stage are not known, PDAL (rightly) complains with an error telling you it didn't recognize it.

> {
>   "pipeline":[
>     {
>         "type":"readers.las",
>         "filename":"/data/255.laz"
>     },
>     {
>         "type":"writers.gdal",
>         "radius":10.5,
>         "resolution":6,
>         "filename":"/data/dem.tif"
>     }
>   ]
> }


I would like to modify PDAL's Pipeline to support any stage having an 'application' node:

> {
>   "pipeline":[
>     {
>     "type" : "readers.las",
>     "filename" : "/data/255.laz",
>     "application": {
>         "something": 42,
>         "something_else": {"key":"value"},
>         "lots_of_things":[1,2,4,8]
>     }
>     },
>     {
>         "type":"writers.gdal",
>         "radius":10.5,
>         "resolution":6,
>         "filename":"/data/dem.tif",
>         "application": {
>             "comment": "a string",
>             "my_app": {"key":"value"},
>             "user_who_made_this": "howard",
>             "center_point":{ "type": "Point", "coordinates": [100.0, 0.0] },
>             "box":{ "type": "Polygon", "coordinates": [[ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ]]}
>         }
>     }
>  ]
> }

The idea is applications can use this 'application' node to transmit and communicate their own information through PDAL pipelines. I have three questions:

1) Is this useful enough to support?
2) Do you have a better name than 'application'?
3) Is the a standard convention that people use in JSON to do this kind of thing?

Thanks,

Howard

From Adam.Steer at anu.edu.au  Wed Dec 21 16:05:15 2016
From: Adam.Steer at anu.edu.au (Adam Steer)
Date: Thu, 22 Dec 2016 00:05:15 +0000
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
Message-ID: <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>

Just trying to unpack this idea: is the thinking around enabling some external program - for example some bespoke, super efficient, parallelised, on-the-fly classifer; or some other point modifier that isn’t, or won’t/can’t be in PDAL - to modify points as they’re read/written?

Without having actually had a need to use such a capacity, it seems pretty handy and might open doors to a whole host of new capabilities in PDAL.

So:
q1: without having actually had a need to use such a capacity, it seems useful
q2: keeping mind the answer to q1 - nope. ‘application’ seems to be a good label for that particular box
q3: will need to defer to others - I consider myself a PDAL/JSON beginner

Standing back a bit, probably being quite ignorant about a bunch of stuff, and thinking about supporting PDAL in N years time - I see a small risk of slowing some feature development in PDAL (maybe? can I think of a case of how? possibly developer X’s killer app never makes it into PDAL as a feature because it no longer needs to?) and based on this a small risk of making more dependency issues (using developer X’s killer app, now anyone deploying it has to maintain versions of two things). However, in this scenario it is also reasonable to expect that an organisation relying on an OSS project would contribute some resources in order to mitigate those issues.

Hope that helps - and I hope more experienced folk chime in!



>> {
>>  "pipeline":[
>>    {
>>    "type" : "readers.las",
>>    "filename" : "/data/255.laz”,
>>    "application": {
>>        "something": 42,
>>        "something_else": {"key":"value"},
>>        "lots_of_things":[1,2,4,8]
>>    }
>>    },
>>    {
>>        "type":"writers.gdal",
>>        "radius":10.5,
>>        "resolution":6,
>>        "filename":"/data/dem.tif",
>>        "application": {
>>            "comment": "a string",
>>            "my_app": {"key":"value"},
>>            "user_who_made_this": "howard",
>>            "center_point":{ "type": "Point", "coordinates": [100.0, 0.0] },
>>            "box":{ "type": "Polygon", "coordinates": [[ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ]]}
>>        }
>>    }
>> ]
>> }
> 


> The idea is applications can use this 'application' node to transmit and communicate their own information through PDAL pipelines. I have three questions:
> 
> 1) Is this useful enough to support?
> 2) Do you have a better name than 'application'?
> 3) Is the a standard convention that people use in JSON to do this kind of thing?
> 
> Thanks,
> 
> Howard
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal


From rdemanuele at gmail.com  Wed Dec 21 19:36:01 2016
From: rdemanuele at gmail.com (Rob Emanuele)
Date: Wed, 21 Dec 2016 22:36:01 -0500
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
Message-ID: <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>

I haven't had a need for it, but I'll comment on this: "application" is a
confusing term, and at first blush I read it as "shelling out to some
external application". Re-reading your description, I believe what this
feature would enable is to allow for JSON to be inserted into pipeline
stages that PDAL will completely ignore but not complain about. So in case
I was parsing the pipeline, or programmatically creating it/reading from it
in my own application outside of PDAL, I could insert any JSON I wanted to
and PDAL wouldn't have a problem with it (and not do anything with it). Is
that a correct read?

If that's correct, I would say instead of "application", some better terms
would be "tags", "userData", "userTags", or something along those lines.


On Wed, Dec 21, 2016 at 7:05 PM, Adam Steer <Adam.Steer at anu.edu.au> wrote:

> Just trying to unpack this idea: is the thinking around enabling some
> external program - for example some bespoke, super efficient, parallelised,
> on-the-fly classifer; or some other point modifier that isn’t, or
> won’t/can’t be in PDAL - to modify points as they’re read/written?
>
> Without having actually had a need to use such a capacity, it seems pretty
> handy and might open doors to a whole host of new capabilities in PDAL.
>
> So:
> q1: without having actually had a need to use such a capacity, it seems
> useful
> q2: keeping mind the answer to q1 - nope. ‘application’ seems to be a good
> label for that particular box
> q3: will need to defer to others - I consider myself a PDAL/JSON beginner
>
> Standing back a bit, probably being quite ignorant about a bunch of stuff,
> and thinking about supporting PDAL in N years time - I see a small risk of
> slowing some feature development in PDAL (maybe? can I think of a case of
> how? possibly developer X’s killer app never makes it into PDAL as a
> feature because it no longer needs to?) and based on this a small risk of
> making more dependency issues (using developer X’s killer app, now anyone
> deploying it has to maintain versions of two things). However, in this
> scenario it is also reasonable to expect that an organisation relying on an
> OSS project would contribute some resources in order to mitigate those
> issues.
>
> Hope that helps - and I hope more experienced folk chime in!
>
>
>
> >> {
> >>  "pipeline":[
> >>    {
> >>    "type" : "readers.las",
> >>    "filename" : "/data/255.laz”,
> >>    "application": {
> >>        "something": 42,
> >>        "something_else": {"key":"value"},
> >>        "lots_of_things":[1,2,4,8]
> >>    }
> >>    },
> >>    {
> >>        "type":"writers.gdal",
> >>        "radius":10.5,
> >>        "resolution":6,
> >>        "filename":"/data/dem.tif",
> >>        "application": {
> >>            "comment": "a string",
> >>            "my_app": {"key":"value"},
> >>            "user_who_made_this": "howard",
> >>            "center_point":{ "type": "Point", "coordinates": [100.0,
> 0.0] },
> >>            "box":{ "type": "Polygon", "coordinates": [[ [100.0, 0.0],
> [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ]]}
> >>        }
> >>    }
> >> ]
> >> }
> >
>
>
> > The idea is applications can use this 'application' node to transmit and
> communicate their own information through PDAL pipelines. I have three
> questions:
> >
> > 1) Is this useful enough to support?
> > 2) Do you have a better name than 'application'?
> > 3) Is the a standard convention that people use in JSON to do this kind
> of thing?
> >
> > Thanks,
> >
> > Howard
> > _______________________________________________
> > pdal mailing list
> > pdal at lists.osgeo.org
> > http://lists.osgeo.org/mailman/listinfo/pdal
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161221/e110d25b/attachment.html>

From howard at hobu.co  Thu Dec 22 08:51:50 2016
From: howard at hobu.co (Howard Butler)
Date: Thu, 22 Dec 2016 10:51:50 -0600
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
 <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
Message-ID: <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>


> On Dec 21, 2016, at 9:36 PM, Rob Emanuele <rdemanuele at gmail.com> wrote:
> 
> If that's correct, I would say instead of "application", some better terms would be "tags", "userData", "userTags", or something along those lines.

Yes, I was hoping for a better name here. I was also hoping there was a standard way that people were extending JSON like this, and that we would just support it. I haven't found anything thus far though.

Howard

From howard at hobu.co  Thu Dec 29 10:44:42 2016
From: howard at hobu.co (Howard Butler)
Date: Thu, 29 Dec 2016 12:44:42 -0600
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
 <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
 <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>
Message-ID: <050BE338-FDB3-4D61-8539-183B83149DC2@hobu.co>


> On Dec 22, 2016, at 10:51 AM, Howard Butler <howard at hobu.co> wrote:
> 
> 
>> On Dec 21, 2016, at 9:36 PM, Rob Emanuele <rdemanuele at gmail.com> wrote:
>> 
>> If that's correct, I would say instead of "application", some better terms would be "tags", "userData", "userTags", or something along those lines.
> 
> Yes, I was hoping for a better name here. I was also hoping there was a standard way that people were extending JSON like this, and that we would just support it. I haven't found anything thus far though.

I renamed it to 'userData'. Thanks for the feedback.

Howard

From kreve at sdfe.dk  Thu Dec 29 13:16:46 2016
From: kreve at sdfe.dk (Kristian Evers)
Date: Thu, 29 Dec 2016 21:16:46 +0000
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <050BE338-FDB3-4D61-8539-183B83149DC2@hobu.co>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
 <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
 <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>
 <050BE338-FDB3-4D61-8539-183B83149DC2@hobu.co>
Message-ID: <2E885BB293AF0448A0181138489E9A0E89CD367F@S000014.PROD.SITAD.DK>

Howard,

Recently I have had a need for feeding user data to the programmable filter. I have an application that creates a PDAL pipeline based on the input and various settings determine the output. In some cases I use the programmable filter to do something that is outside the current scope of PDAL. If it were possible to access the pipeline JSON, and the userData section of the pipeline, from the Python function behind the filter I would be able to make more generic filters.
A recent example is that I wanted to create a vertical gridshift filter (similar to what Proj.4 does). I would have liked to pass the grid name to the programmable filter as a PDAL pipeline parameter but that is not possible. Instead I ended up hard coding it. It did the job but wasn't a very satisfying solution. I have since realized that I can in fact use the reprojection filter to do this (via Proj.4). This is just the example that came to mind – I have been in similar situations before but the exact details escape my memory.

The Python function prototype will have to be changed. It is best demonstrated with an example. I have extended the multiply_z function from the filters.programmable doc page with my suggestion:

          import numpy as np

          def multiply_z(ins, outs, pipeline):
              f = pipeline[1]['userData']['z_factor']
              Z = ins['Z']
              Z = Z * f
              outs['Z'] = Z
              return True

Info about the other stages in a pipeline should also be available. For the above case the pipeline dictionary would be constructed with:

        with open(‘pipeline.json’) as json_file:
            pipeline = json.load(json_file)[‘pipeline’]



It is not exactly what you are asking about here but I think it is a nice addition to the "userData" concept that you are introducing. My suggestion can of course be extended to filters.predicate as well.

/Kristian


> -----Oprindelig meddelelse-----
> Fra: pdal [mailto:pdal-bounces at lists.osgeo.org] På vegne af Howard Butler
> Sendt: 29. december 2016 19:45
> Til: pdal
> Emne: Re: [pdal] PDAL Pipeline Extensibility
>
>
> > On Dec 22, 2016, at 10:51 AM, Howard Butler <howard at hobu.co<mailto:howard at hobu.co>> wrote:
> >
> >
> >> On Dec 21, 2016, at 9:36 PM, Rob Emanuele <rdemanuele at gmail.com<mailto:rdemanuele at gmail.com>>
> wrote:
> >>
> >> If that's correct, I would say instead of "application", some better terms
> would be "tags", "userData", "userTags", or something along those lines.
> >
> > Yes, I was hoping for a better name here. I was also hoping there was a
> standard way that people were extending JSON like this, and that we would
> just support it. I haven't found anything thus far though.
>
> I renamed it to 'userData'. Thanks for the feedback.
>
> Howard
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>
> http://lists.osgeo.org/mailman/listinfo/pdal

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20161229/617ea115/attachment.html>

From howard at hobu.co  Fri Dec 30 07:53:25 2016
From: howard at hobu.co (Howard Butler)
Date: Fri, 30 Dec 2016 09:53:25 -0600
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <2E885BB293AF0448A0181138489E9A0E89CD367F@S000014.PROD.SITAD.DK>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
 <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
 <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>
 <050BE338-FDB3-4D61-8539-183B83149DC2@hobu.co>
 <2E885BB293AF0448A0181138489E9A0E89CD367F@S000014.PROD.SITAD.DK>
Message-ID: <D822B747-8536-471E-A173-2C5A420D03EC@hobu.co>


> On Dec 29, 2016, at 3:16 PM, Kristian Evers <kreve at sdfe.dk> wrote:
> 
> Recently I have had a need for feeding user data to the programmable filter. I have an application that creates a PDAL pipeline based on the input and various settings determine the output. In some cases I use the programmable filter to do something that is outside the current scope of PDAL. If it were possible to access the pipeline JSON, and the userData section of the pipeline, from the Python function behind the filter I would be able to make more generic filters.

This is a good idea.

I'll make a dict of globals called 'pipeline' available to both filters.programmable and filters.predicate that represent the following:

pipeline['schema'] -> json dict 
pipeline['metadata'] -> json dict 
pipeline['pipeline'] -> json dict 
pipelien['log'] -> writeable log stream


> A recent example is that I wanted to create a vertical gridshift filter (similar to what Proj.4 does). I would have liked to pass the grid name to the programmable filter as a PDAL pipeline parameter but that is not possible. Instead I ended up hard coding it. It did the job but wasn't a very satisfying solution. I have since realized that I can in fact use the reprojection filter to do this (via Proj.4). This is just the example that came to mind – I have been in similar situations before but the exact details escape my memory.

Thanks for your documentation update that demonstrates how to do gridshifts and proj.4 strings in PDAL http://www.pdal.io/stages/filters.reprojection.html#examle-2 . I guess I assumed people familiar with GDAL's SRS handling tools would just know that the same skills and techniques would transfer.

Howard

From kreve at sdfe.dk  Fri Dec 30 13:39:11 2016
From: kreve at sdfe.dk (Kristian Evers)
Date: Fri, 30 Dec 2016 21:39:11 +0000
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <D822B747-8536-471E-A173-2C5A420D03EC@hobu.co>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
 <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
 <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>
 <050BE338-FDB3-4D61-8539-183B83149DC2@hobu.co>
 <2E885BB293AF0448A0181138489E9A0E89CD367F@S000014.PROD.SITAD.DK>
 <D822B747-8536-471E-A173-2C5A420D03EC@hobu.co>
Message-ID: <2E885BB293AF0448A0181138489E9A0E89CD4DF3@S000014.PROD.SITAD.DK>

Also a good idea to extend it to include schema, metadata etc. Hadn't even crossed my mind! What about just calling the dictionary globals? The way you intend to implement it, it is more than just the pipeline and pipeline['pipeline'] is repeating itself.

About the SRS definition, that's what I eventually figured out because I knew that GDAL and Proj.4 is powering coordinate transformation. Maybe this should be added to the docs as well? Ideally with a link to a relevant section of GDAL documentation.

/Kristian 

> -----Oprindelig meddelelse-----
> Fra: pdal [mailto:pdal-bounces at lists.osgeo.org] På vegne af Howard Butler
> Sendt: 30. december 2016 16:53
> Til: Kristian Evers
> Cc: pdal at lists.osgeo.org
> Emne: Re: [pdal] PDAL Pipeline Extensibility
> 
> 
> > On Dec 29, 2016, at 3:16 PM, Kristian Evers <kreve at sdfe.dk> wrote:
> >
> > Recently I have had a need for feeding user data to the programmable
> filter. I have an application that creates a PDAL pipeline based on the input
> and various settings determine the output. In some cases I use the
> programmable filter to do something that is outside the current scope of
> PDAL. If it were possible to access the pipeline JSON, and the userData
> section of the pipeline, from the Python function behind the filter I would be
> able to make more generic filters.
> 
> This is a good idea.
> 
> I'll make a dict of globals called 'pipeline' available to both
> filters.programmable and filters.predicate that represent the following:
> 
> pipeline['schema'] -> json dict
> pipeline['metadata'] -> json dict
> pipeline['pipeline'] -> json dict
> pipelien['log'] -> writeable log stream
>
> 
> > A recent example is that I wanted to create a vertical gridshift filter (similar
> to what Proj.4 does). I would have liked to pass the grid name to the
> programmable filter as a PDAL pipeline parameter but that is not possible.
> Instead I ended up hard coding it. It did the job but wasn't a very satisfying
> solution. I have since realized that I can in fact use the reprojection filter to
> do this (via Proj.4). This is just the example that came to mind – I have been
> in similar situations before but the exact details escape my memory.
> 
> Thanks for your documentation update that demonstrates how to do
> gridshifts and proj.4 strings in PDAL
> http://www.pdal.io/stages/filters.reprojection.html#examle-2 . I guess I
> assumed people familiar with GDAL's SRS handling tools would just know that
> the same skills and techniques would transfer.
> 
> Howard
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal

From howard at hobu.co  Fri Dec 30 13:42:53 2016
From: howard at hobu.co (Howard Butler)
Date: Fri, 30 Dec 2016 15:42:53 -0600
Subject: [pdal] PDAL Pipeline Extensibility
In-Reply-To: <2E885BB293AF0448A0181138489E9A0E89CD4DF3@S000014.PROD.SITAD.DK>
References: <F1F40C65-9FCA-479E-A42C-8B0511397EC9@hobu.co>
 <FF9F724C-FD93-480A-BB67-1D1C8C547361@anu.edu.au>
 <CAFPWJ6eMqoCVPoAAfDQ5YQgdnXNd4RPac4VND9f3uaSsHvEqXw@mail.gmail.com>
 <DFB4A300-637D-4486-B930-93738A70EAB9@hobu.co>
 <050BE338-FDB3-4D61-8539-183B83149DC2@hobu.co>
 <2E885BB293AF0448A0181138489E9A0E89CD367F@S000014.PROD.SITAD.DK>
 <D822B747-8536-471E-A173-2C5A420D03EC@hobu.co>
 <2E885BB293AF0448A0181138489E9A0E89CD4DF3@S000014.PROD.SITAD.DK>
Message-ID: <729C9F66-71AC-4A16-951B-56E25A7F9334@hobu.co>

After thinking about it a bit, my plan is to put everything in the kwargs dict of the function and simply call the function with it. This would allow you to set things like the stage metadata via this mechanism as well.

Please make a PR where you think the docs are deficient about GDAL + Proj.4. I'll happily merge stuff in that makes navigating that fog bank any easier.

Howard



> On Dec 30, 2016, at 3:39 PM, Kristian Evers <kreve at sdfe.dk> wrote:
> 
> Also a good idea to extend it to include schema, metadata etc. Hadn't even crossed my mind! What about just calling the dictionary globals? The way you intend to implement it, it is more than just the pipeline and pipeline['pipeline'] is repeating itself.
> 
> About the SRS definition, that's what I eventually figured out because I knew that GDAL and Proj.4 is powering coordinate transformation. Maybe this should be added to the docs as well? Ideally with a link to a relevant section of GDAL documentation.
> 
> /Kristian 
> 
>> -----Oprindelig meddelelse-----
>> Fra: pdal [mailto:pdal-bounces at lists.osgeo.org] På vegne af Howard Butler
>> Sendt: 30. december 2016 16:53
>> Til: Kristian Evers
>> Cc: pdal at lists.osgeo.org
>> Emne: Re: [pdal] PDAL Pipeline Extensibility
>> 
>> 
>>> On Dec 29, 2016, at 3:16 PM, Kristian Evers <kreve at sdfe.dk> wrote:
>>> 
>>> Recently I have had a need for feeding user data to the programmable
>> filter. I have an application that creates a PDAL pipeline based on the input
>> and various settings determine the output. In some cases I use the
>> programmable filter to do something that is outside the current scope of
>> PDAL. If it were possible to access the pipeline JSON, and the userData
>> section of the pipeline, from the Python function behind the filter I would be
>> able to make more generic filters.
>> 
>> This is a good idea.
>> 
>> I'll make a dict of globals called 'pipeline' available to both
>> filters.programmable and filters.predicate that represent the following:
>> 
>> pipeline['schema'] -> json dict
>> pipeline['metadata'] -> json dict
>> pipeline['pipeline'] -> json dict
>> pipelien['log'] -> writeable log stream
>> 
>> 
>>> A recent example is that I wanted to create a vertical gridshift filter (similar
>> to what Proj.4 does). I would have liked to pass the grid name to the
>> programmable filter as a PDAL pipeline parameter but that is not possible.
>> Instead I ended up hard coding it. It did the job but wasn't a very satisfying
>> solution. I have since realized that I can in fact use the reprojection filter to
>> do this (via Proj.4). This is just the example that came to mind – I have been
>> in similar situations before but the exact details escape my memory.
>> 
>> Thanks for your documentation update that demonstrates how to do
>> gridshifts and proj.4 strings in PDAL
>> http://www.pdal.io/stages/filters.reprojection.html#examle-2 . I guess I
>> assumed people familiar with GDAL's SRS handling tools would just know that
>> the same skills and techniques would transfer.
>> 
>> Howard
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/pdal


