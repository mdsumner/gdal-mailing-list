From mninoruiz at gmail.com  Tue Aug  4 18:07:00 2015
From: mninoruiz at gmail.com (Marcos Nino-Ruiz)
Date: Wed, 5 Aug 2015 11:07:00 +1000
Subject: [pdal] problem with PDAL install from github,
 PDAL: LASzip is not enabled. Can't read LAZ data
Message-ID: <CAB1N3fcaEeu+5fCa-ihW3qR_SA=YpfLb92zy=BcU-Z1KEGjoMQ@mail.gmail.com>

Hi all,

I'm developer trying to get a grasp of lidar data, and you library is of
great help, thanks! Hopefully soon I will be able to contribute some...
But so far I have had the following issue after installation:

Using the binary from osgeo4w, I have no problem reading (pdal info) a .laz
file, however, after following the lengthy compilation with dependencies
(successfully)

marcos at kubuntu14-10:~/ pdal --version
------------------------------------------------------------
------------------------------
pdal (PDAL 1.0.0.b1 (f52b08) with GeoTIFF 1.4.0 GDAL 1.10.1)

marcos at kubuntu14-10:$ pdal info splits/L01_classed_1.laz
PDAL: LASzip is not enabled.  Can't read LAZ data.

But I know the file is correct and lazlib is in the path because lasinfo
works:

marcos at kubuntu14-10:~/ lasinfo splits/L01_classed_1.laz
lasinfo for splits/L01_classed_1.laz
reporting all LAS header entries:
...

What could I possibly be missing? thanks a lot for your time... regards,
Dr. Marcos Nino-Ruiz
Geospatial e-Enabler
AURIN - www.aurin.org.au
The University of Melbourne
Victoria 3010
Australia
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150805/b14443a8/attachment.html>

From andrew.bell.ia at gmail.com  Tue Aug  4 19:04:23 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 4 Aug 2015 21:04:23 -0500
Subject: [pdal] problem with PDAL install from github,
 PDAL: LASzip is not enabled. Can't read LAZ data
In-Reply-To: <CAB1N3fcaEeu+5fCa-ihW3qR_SA=YpfLb92zy=BcU-Z1KEGjoMQ@mail.gmail.com>
References: <CAB1N3fcaEeu+5fCa-ihW3qR_SA=YpfLb92zy=BcU-Z1KEGjoMQ@mail.gmail.com>
Message-ID: <CACJ51z0S89x1X+S9Z-WY9mDfjtO5+EWcBMrDoWLUdn7iMSauzQ@mail.gmail.com>

On Tue, Aug 4, 2015 at 8:07 PM, Marcos Nino-Ruiz <mninoruiz at gmail.com>
wrote:

>
> Hi all,
>
> I'm developer trying to get a grasp of lidar data, and you library is of
> great help, thanks! Hopefully soon I will be able to contribute some...
> But so far I have had the following issue after installation:
>
> Using the binary from osgeo4w, I have no problem reading (pdal info) a
> .laz file, however, after following the lengthy compilation with
> dependencies (successfully)
>
> marcos at kubuntu14-10:~/ pdal --version
> ------------------------------------------------------------
> ------------------------------
> pdal (PDAL 1.0.0.b1 (f52b08) with GeoTIFF 1.4.0 GDAL 1.10.1)
>
> marcos at kubuntu14-10:$ pdal info splits/L01_classed_1.laz
> PDAL: LASzip is not enabled.  Can't read LAZ data.
>
> But I know the file is correct and lazlib is in the path because lasinfo
> works:
>
> marcos at kubuntu14-10:~/ lasinfo splits/L01_classed_1.laz
> lasinfo for splits/L01_classed_1.laz
> reporting all LAS header entries:
>

Please check your CMakeCache.txt to make sure you have:
WITH_LASZIP:BOOL=ON

If so, confirm also that you have lines in the same file similar to:
//Path to a file.
LASZIP_INCLUDE_DIR:PATH=/usr/local/include

//Path to a library.
LASZIP_LIBRARY:FILEPATH=/usr/local/lib/liblaszip.dylib

If you re-run cmake, it should also report whether LASZIP was enabled and
found:

-- The following RECOMMENDED packages have been found:

 * LASzip
   Provides LASzip compression

Hope this helps,

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150804/efdb05d2/attachment.html>

From mninoruiz at gmail.com  Wed Aug  5 01:27:40 2015
From: mninoruiz at gmail.com (Marcos Nino-Ruiz)
Date: Wed, 5 Aug 2015 18:27:40 +1000
Subject: [pdal] problem with PDAL install from github,
 PDAL: LASzip is not enabled. Can't read LAZ data
In-Reply-To: <CACJ51z0S89x1X+S9Z-WY9mDfjtO5+EWcBMrDoWLUdn7iMSauzQ@mail.gmail.com>
References: <CAB1N3fcaEeu+5fCa-ihW3qR_SA=YpfLb92zy=BcU-Z1KEGjoMQ@mail.gmail.com>
	<CACJ51z0S89x1X+S9Z-WY9mDfjtO5+EWcBMrDoWLUdn7iMSauzQ@mail.gmail.com>
Message-ID: <CAB1N3fdYXFef5HKK0Uc8-tPL+f3Q9x1wgX4uYUSLKBT+pXbdQA@mail.gmail.com>

thank you very muchAndrew, I checked and  LASZIP_INLCUDE_DIR was not found.

The problem was that the include path for laszip.hpp in cmake assumes I got
the original repo:
https://github.com/LASzip/LASzip.git
so that it can find under : LASzip/include

I was using the whole:
https://github.com/LAStools/LAStools

which also has the laszip.hpp, but not in the path that is required by PDAL
(laszip/laszip.hpp as opposed to src/laszip.hpp)

 I pull that repo, re run cmake with the new include dir and is working
wonders, thanks!

Marcos Nino-Ruiz, PhD.
Geospatial e-Enabler
AURIN - The University of Melbourne
Victoria 3010
Australia

On Wed, Aug 5, 2015 at 12:04 PM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

> On Tue, Aug 4, 2015 at 8:07 PM, Marcos Nino-Ruiz <mninoruiz at gmail.com>
> wrote:
>
>>
>> Hi all,
>>
>> I'm developer trying to get a grasp of lidar data, and you library is of
>> great help, thanks! Hopefully soon I will be able to contribute some...
>> But so far I have had the following issue after installation:
>>
>> Using the binary from osgeo4w, I have no problem reading (pdal info) a
>> .laz file, however, after following the lengthy compilation with
>> dependencies (successfully)
>>
>> marcos at kubuntu14-10:~/ pdal --version
>> ------------------------------------------------------------
>> ------------------------------
>> pdal (PDAL 1.0.0.b1 (f52b08) with GeoTIFF 1.4.0 GDAL 1.10.1)
>>
>> marcos at kubuntu14-10:$ pdal info splits/L01_classed_1.laz
>> PDAL: LASzip is not enabled.  Can't read LAZ data.
>>
>> But I know the file is correct and lazlib is in the path because lasinfo
>> works:
>>
>> marcos at kubuntu14-10:~/ lasinfo splits/L01_classed_1.laz
>> lasinfo for splits/L01_classed_1.laz
>> reporting all LAS header entries:
>>
>
> Please check your CMakeCache.txt to make sure you have:
> WITH_LASZIP:BOOL=ON
>
> If so, confirm also that you have lines in the same file similar to:
> //Path to a file.
> LASZIP_INCLUDE_DIR:PATH=/usr/local/include
>
> //Path to a library.
> LASZIP_LIBRARY:FILEPATH=/usr/local/lib/liblaszip.dylib
>
> If you re-run cmake, it should also report whether LASZIP was enabled and
> found:
>
> -- The following RECOMMENDED packages have been found:
>
>  * LASzip
>    Provides LASzip compression
>
> Hope this helps,
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150805/16fc614f/attachment.html>

From o.rubi at esciencecenter.nl  Wed Aug  5 03:26:44 2015
From: o.rubi at esciencecenter.nl (Oscar Martinez Rubi)
Date: Wed, 5 Aug 2015 12:26:44 +0200
Subject: [pdal] Oracle PDAL queries not scaling
Message-ID: <55C1E4E4.6080100@esciencecenter.nl>

Hi,

I did a test to see how good Oracle with PDAL scale with bigger data 
sets. I had 3 datasets that are self-contained with 20M, 210M and 2201M 
points. I loaded them in different Oracle DBs with PDAL and laz-perf. 
And, for each of them I ran 7 queries (via a pdal pipeline that 
preselects blocks, applies a crop and then write to a LAS file)

The results are in the attached file.

Regarding the loading, for the 20M I only used one core (it is only one 
file) while for the others I used 16 cores, i.e. 16 simult. PDAL 
instances loading data to Oracle. I opened an issue in GitHub because I 
noticed that in some of the runs the size that I got was too large, and 
I do not know what caused that. The attached numbers are when everything 
seemed to work and the sizes were as expected.

This message, though, is about the queries. Each query is run twice in 
each DB. As you can see in the results file, for 10x more points in the 
data set the queries are 10x slower, at least for the first run (with 
the 2201M the second run is much faster but this does not happen with 
the 210M).

Find also attached one of the XML that i used for the queries (example 
is for query1). Note that the geometry is previously inserted in oracle 
so I can use to pre-filter blocks with the query option in oci reader

First I though that maybe the query option in the oci reader in the XML 
was ignored and that all the blocks of the dataset were being processed 
by PDAL (that would explain 10x more points 10x slower queries) but I 
ran a pdal pipeline for query1 with verbose and I saw that the crop 
filter "only" processed 120000 points which makes sense taking into 
account that region of query 1 only has 74818 points. Or maybe the crop 
still process all the blocks extents but only opens and decompress the 
points of the overlapping ones?

Any idea what is happening?

Regards,

O.
-------------- next part --------------
LOAD
####
Approach      Total[s]    Init.[s]    Load[s]    Close[s]    Total[MB]    Index[MB]      Points    Points/s    Points/MB
----------  ----------  ----------  ---------  ----------  -----------  -----------  ----------  ----------  -----------
pdal20M          36.2         0.91      34.9         0.39           82         0.23    20165862      557068       245925
pdal210M         54.61        0.72      52.86        1.03          700         0.48   210631597     3857015       300902
pdal2201M       371.24        6.05     360.2         4.99         7165         3.43  2201135689     5929145       307207


QUERY
#####

Time[s]      pdal20M    pdal210M    pdal2201M
---------  ---------  ----------  -----------
01_0            0.8         3.4         33.23
01_1            0.52        3.44         0.21
02_0            1.38        4.16        34.22
02_1            1.25        4.14         0.96
03_0            0.55        4.06        39.15
03_1            0.61        4.14         0.18
04_0            2.03        9.78        90.38
04_1            1.95        9.67         1.1
05_0            0.86        3.64        32.3
05_1            0.81        3.67         0.51
06_0            2.44       13.43       123.03
06_1            2.33       13.57         1.23
07_0            1.71        4.52         1.41
07_1            1.63        4.68         1.43


NumPts      pdal20M    pdal210M    pdal2201M
--------  ---------  ----------  -----------
01_0          74818       74818        74818
01_1          74818       74818        74818
02_0         717869      717869       717869
02_1         717869      717869       717869
03_0          34667       34667        34667
03_1          34667       34667        34667
04_0         563013      563013       563013
04_1         563013      563013       563013
05_0         182861      182861       182861
05_1         182861      182861       182861
06_0         387134      387135       387134
06_1         387134      387135       387134
07_0          45813       45813        45813
07_1          45813       45813        45813

-------------- next part --------------
A non-text attachment was scrubbed...
Name: query1.xml
Type: text/xml
Size: 948 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150805/dbee18ff/attachment-0001.xml>

From remi.cura at gmail.com  Fri Aug  7 13:06:34 2015
From: remi.cura at gmail.com (=?UTF-8?Q?R=C3=A9mi_Cura?=)
Date: Fri, 7 Aug 2015 22:06:34 +0200
Subject: [pdal] text ascii (csv) reader?
Message-ID: <CAJvUf_tG9NfzVMZ0KqnYzYR4AL897scLBWQ7G3QFcMS3trUwXA@mail.gmail.com>

Hey,
I found the csv writer, but not the csv reader.
DOes it exist?
Cheers,
R?mi-C
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150807/102b4826/attachment.html>

From andrew.bell.ia at gmail.com  Fri Aug  7 13:20:43 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Fri, 7 Aug 2015 15:20:43 -0500
Subject: [pdal] text ascii (csv) reader?
In-Reply-To: <CAJvUf_tG9NfzVMZ0KqnYzYR4AL897scLBWQ7G3QFcMS3trUwXA@mail.gmail.com>
References: <CAJvUf_tG9NfzVMZ0KqnYzYR4AL897scLBWQ7G3QFcMS3trUwXA@mail.gmail.com>
Message-ID: <CACJ51z0V3fvGrytu9BccLDoAX3xymxRpfTTxQMGFkZD3tWm0bg@mail.gmail.com>

On Fri, Aug 7, 2015 at 3:06 PM, R?mi Cura <remi.cura at gmail.com> wrote:

> Hey,
> I found the csv writer, but not the csv reader.
> DOes it exist?
> Cheers,
>

Sorry, no.  It's on our todo list, or if you would like to contribute... :)

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150807/5dffe439/attachment.html>

From remi.cura at gmail.com  Sat Aug  8 03:51:29 2015
From: remi.cura at gmail.com (=?UTF-8?Q?R=C3=A9mi_Cura?=)
Date: Sat, 8 Aug 2015 12:51:29 +0200
Subject: [pdal] text ascii (csv) reader?
In-Reply-To: <CACJ51z0V3fvGrytu9BccLDoAX3xymxRpfTTxQMGFkZD3tWm0bg@mail.gmail.com>
References: <CAJvUf_tG9NfzVMZ0KqnYzYR4AL897scLBWQ7G3QFcMS3trUwXA@mail.gmail.com>
	<CACJ51z0V3fvGrytu9BccLDoAX3xymxRpfTTxQMGFkZD3tWm0bg@mail.gmail.com>
Message-ID: <CAJvUf_sCMxNWiKZMenhFyjLfYbhPUU-1jc6vzcsadvKVr=Y3Fw@mail.gmail.com>

Thank you for the answer.
I had trouble believing it, csv being the ultimate portable format for
anything in my opinion.
Cheers,
R?mi-C

2015-08-07 22:20 GMT+02:00 Andrew Bell <andrew.bell.ia at gmail.com>:

> On Fri, Aug 7, 2015 at 3:06 PM, R?mi Cura <remi.cura at gmail.com> wrote:
>
>> Hey,
>> I found the csv writer, but not the csv reader.
>> DOes it exist?
>> Cheers,
>>
>
> Sorry, no.  It's on our todo list, or if you would like to contribute... :)
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150808/a6100432/attachment.html>

From stefan.ziegler.de at gmail.com  Mon Aug 10 11:41:35 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Mon, 10 Aug 2015 20:41:35 +0200
Subject: [pdal] pdal translate: reprojection error
Message-ID: <CAJvo+18jgkQ-mjd7376P8bupWrJHkCZcn+1KnOYMefz1w0VqQA@mail.gmail.com>

Hi

I'm trying to reproject some laz files with the pdal translate command:

pdal translate --input LAS_594217_LV95_shift.laz --output
LAS_594217_LV95_shift_v2.laz --compress --a_srs EPSG:21781 --t_srs EPSG:2056

I'm ending up with an error:

PDAL: Stage filters.reprojection missing required option 'out_srs'.

Replacing "translateOptions" with "readerOptions" on line 220 in
https://github.com/PDAL/PDAL/blob/12ff867990c0176de5aa121e90b23ec1fe5b7c0d/kernels/translate/TranslateKernel.cpp
solves the problem. Not sure if this REALLY solves the problem but the
reprojection works. I do not dare to make a pull request because the
"translateOptions" parameter now seems obsolete? And I don't understand the
process behind all this stage etc stuff ;)

Would be great if anyone could have a look.

best regards
Stefan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150810/34dae554/attachment.html>

From albert.godfrind at oracle.com  Mon Aug 10 09:40:08 2015
From: albert.godfrind at oracle.com (Albert Godfrind)
Date: Mon, 10 Aug 2015 18:40:08 +0200
Subject: [pdal] Oracle PDAL queries not scaling
In-Reply-To: <55C1E4E4.6080100@esciencecenter.nl>
References: <55C1E4E4.6080100@esciencecenter.nl>
Message-ID: <8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>

Like many tools that access an Oracle database, we lack the ability to see what actually happens in the database at a detailed level, i.e. which actual queries are sent, and how the database executes them in terms of CPU use, logical and physical I/Os, network throughput and latency.

So I think it is important to add some debugging / tracing facility to let me see what happens:

1) An option to make PDAL (actually the OCI driver here) log each SQL statement it executes, together with the elapsed time and the number of rows (blocks) fetched. Obviously we have that statement in the input XML file, but a trace would put everything in a single log and include proper measurements.

2) More important: an option to make the OCI driver enable SQL tracing at the database side. This is simple to do by just issuing an ?ALTER SESSION ?? statement before running the queries. The resulting trace will show all details about execution times as well as resource consumption (CPU and IO) and wait times. That could be added as an option in the XML file. Or maybe extend the XML file with the option to specify a SQ statement to be performed before each query (we could then use that to manually add the ALTER SESSION statement.

The resulting trace can help isolate the bottleneck as one of:

1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
2) the network time to pass the blocks to the PDAL client (network throughput and latency)
3) the time to process the blocks in the PDAL client (mostly CPU)

Albert

> On 5-Aug-2015, at 12:26, Oscar Martinez Rubi <o.rubi at esciencecenter.nl> wrote:
> 
> Hi,
> 
> I did a test to see how good Oracle with PDAL scale with bigger data sets. I had 3 datasets that are self-contained with 20M, 210M and 2201M points. I loaded them in different Oracle DBs with PDAL and laz-perf. And, for each of them I ran 7 queries (via a pdal pipeline that preselects blocks, applies a crop and then write to a LAS file)
> 
> The results are in the attached file.
> 
> Regarding the loading, for the 20M I only used one core (it is only one file) while for the others I used 16 cores, i.e. 16 simult. PDAL instances loading data to Oracle. I opened an issue in GitHub because I noticed that in some of the runs the size that I got was too large, and I do not know what caused that. The attached numbers are when everything seemed to work and the sizes were as expected.
> 
> This message, though, is about the queries. Each query is run twice in each DB. As you can see in the results file, for 10x more points in the data set the queries are 10x slower, at least for the first run (with the 2201M the second run is much faster but this does not happen with the 210M).
> 
> Find also attached one of the XML that i used for the queries (example is for query1). Note that the geometry is previously inserted in oracle so I can use to pre-filter blocks with the query option in oci reader
> 
> First I though that maybe the query option in the oci reader in the XML was ignored and that all the blocks of the dataset were being processed by PDAL (that would explain 10x more points 10x slower queries) but I ran a pdal pipeline for query1 with verbose and I saw that the crop filter "only" processed 120000 points which makes sense taking into account that region of query 1 only has 74818 points. Or maybe the crop still process all the blocks extents but only opens and decompress the points of the overlapping ones?
> 
> Any idea what is happening?
> 
> Regards,
> 
> O.
> <results.txt><query1.xml>

--
 <http://www.oracle.com/>
Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67 | Mobile: +33 6 09 97 27 23 | Skype: albert-godfrind <skype:albert-godfrind>
Oracle Server Technologies
400 Av. Roumanille, BP 309  | 06906 Sophia Antipolis cedex | France
Everything you ever wanted to know about Oracle Spatial <http://www.apress.com/9781590598993>
 <http://www.locationintelligence.net/dc/>


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150810/4439ae3b/attachment.html>

From andrew.bell.ia at gmail.com  Mon Aug 10 13:37:28 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 10 Aug 2015 15:37:28 -0500
Subject: [pdal] pdal translate: reprojection error
In-Reply-To: <CAJvo+18jgkQ-mjd7376P8bupWrJHkCZcn+1KnOYMefz1w0VqQA@mail.gmail.com>
References: <CAJvo+18jgkQ-mjd7376P8bupWrJHkCZcn+1KnOYMefz1w0VqQA@mail.gmail.com>
Message-ID: <CACJ51z3_V6BzeLN9zcEDYuxR=YFyrU83D1qeFKXB35CwROLD6g@mail.gmail.com>

Yes, thanks for this.  I'll take care of it once I confirm the intent of
operation.

On Mon, Aug 10, 2015 at 1:41 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com
> wrote:

> Hi
>
> I'm trying to reproject some laz files with the pdal translate command:
>
> pdal translate --input LAS_594217_LV95_shift.laz --output
> LAS_594217_LV95_shift_v2.laz --compress --a_srs EPSG:21781 --t_srs EPSG:2056
>
> I'm ending up with an error:
>
> PDAL: Stage filters.reprojection missing required option 'out_srs'.
>
> Replacing "translateOptions" with "readerOptions" on line 220 in
> https://github.com/PDAL/PDAL/blob/12ff867990c0176de5aa121e90b23ec1fe5b7c0d/kernels/translate/TranslateKernel.cpp
> solves the problem. Not sure if this REALLY solves the problem but the
> reprojection works. I do not dare to make a pull request because the
> "translateOptions" parameter now seems obsolete? And I don't understand the
> process behind all this stage etc stuff ;)
>
> Would be great if anyone could have a look.
>
> best regards
> Stefan
>
>
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150810/f9a468c9/attachment.html>

From o.rubi at esciencecenter.nl  Tue Aug 11 07:26:36 2015
From: o.rubi at esciencecenter.nl (Oscar Martinez Rubi)
Date: Tue, 11 Aug 2015 16:26:36 +0200
Subject: [pdal] Oracle PDAL queries not scaling
In-Reply-To: <8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
Message-ID: <55CA061C.5080603@esciencecenter.nl>

Hi,

I have investigated a bit more this issue.

I wanted to see what data does the OCI reader actually reads, so I 
executed the pre-selection query out of PDAL, in python. So I run the 
attached script (freshly after loading the data).

The script runs the same exact query as done in PDAL twice and prints 
for each run the number of returned blocks, time spent in the query and 
time spent to fetch the results.

the exact query is:

SELECT
     l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN", 
l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS", 
l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM",  l."POINTS", b.pc
FROM
     AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
WHERE
     l.obj_id = b.id
     AND
     SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;

The results I get are:

20M run 1:
     #blocks: 12
     query time[s]: 0.113833904266
     fetch time[s]: *0.571593046188*
20M run 2:
     #blocks: 12
     query time[s]: 0.000102996826172
     fetch time[s]: *0.500910997391*
210M run 1:
     #blocks: 13
     query time[s]: 0.0586049556732
     fetch time[s]: *5.09832000732*
210M run 2:
     #blocks: 13
     query time[s]: 0.000245094299316
     fetch time[s]: *5.05038785934*
2201M run 1:
     #blocks: 13
     query time[s]: 0.070690870285
     fetch time[s]: *52.4960811138*
2201M run 2:
     #blocks: 13
     query time[s]: 0.000225067138672
     fetch time[s]: *53.1006689072*

So, even though the query times and the number of returned blocks are 
similar the fetch times are the not. We can see the scaling issue there. 
Somehow the fetching is much more expensive (10x) when points are 10x.

I also noticed that after a while doing queries the times get much 
better and scalable even when I do new queries with other polygons. So, 
the first queries suffer of scaling issues but later it gets better.

Any idea why?

Regards,

O.




On 10-08-15 18:40, Albert Godfrind wrote:
> Like many tools that access an Oracle database, we lack the ability to 
> see what actually happens in the database at a detailed level, i.e. 
> which actual queries are sent, and how the database executes them in 
> terms of CPU use, logical and physical I/Os, network throughput and 
> latency.
>
> So I think it is important to add some debugging / tracing facility to 
> let me see what happens:
>
> 1) An option to make PDAL (actually the OCI driver here) log each SQL 
> statement it executes, together with the elapsed time and the number 
> of rows (blocks) fetched. Obviously we have that statement in the 
> input XML file, but a trace would put everything in a single log and 
> include proper measurements.
>
> 2) More important: an option to make the OCI driver enable SQL tracing 
> at the database side. This is simple to do by just issuing an ?ALTER 
> SESSION ?? statement before running the queries. The resulting trace 
> will show all details about execution times as well as resource 
> consumption (CPU and IO) and wait times. That could be added as an 
> option in the XML file. Or maybe extend the XML file with the option 
> to specify a SQ statement to be performed before each query (we could 
> then use that to manually add the ALTER SESSION statement.
>
> The resulting trace can help isolate the bottleneck as one of:
>
> 1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
> 2) the network time to pass the blocks to the PDAL client (network 
> throughput and latency)
> 3) the time to process the blocks in the PDAL client (mostly CPU)
>
> Albert
>
>> On 5-Aug-2015, at 12:26, Oscar Martinez Rubi 
>> <o.rubi at esciencecenter.nl <mailto:o.rubi at esciencecenter.nl>> wrote:
>>
>> Hi,
>>
>> I did a test to see how good Oracle with PDAL scale with bigger data 
>> sets. I had 3 datasets that are self-contained with 20M, 210M and 
>> 2201M points. I loaded them in different Oracle DBs with PDAL and 
>> laz-perf. And, for each of them I ran 7 queries (via a pdal pipeline 
>> that preselects blocks, applies a crop and then write to a LAS file)
>>
>> The results are in the attached file.
>>
>> Regarding the loading, for the 20M I only used one core (it is only 
>> one file) while for the others I used 16 cores, i.e. 16 simult. PDAL 
>> instances loading data to Oracle. I opened an issue in GitHub because 
>> I noticed that in some of the runs the size that I got was too large, 
>> and I do not know what caused that. The attached numbers are when 
>> everything seemed to work and the sizes were as expected.
>>
>> This message, though, is about the queries. Each query is run twice 
>> in each DB. As you can see in the results file, for 10x more points 
>> in the data set the queries are 10x slower, at least for the first 
>> run (with the 2201M the second run is much faster but this does not 
>> happen with the 210M).
>>
>> Find also attached one of the XML that i used for the queries 
>> (example is for query1). Note that the geometry is previously 
>> inserted in oracle so I can use to pre-filter blocks with the query 
>> option in oci reader
>>
>> First I though that maybe the query option in the oci reader in the 
>> XML was ignored and that all the blocks of the dataset were being 
>> processed by PDAL (that would explain 10x more points 10x slower 
>> queries) but I ran a pdal pipeline for query1 with verbose and I saw 
>> that the crop filter "only" processed 120000 points which makes sense 
>> taking into account that region of query 1 only has 74818 points. Or 
>> maybe the crop still process all the blocks extents but only opens 
>> and decompress the points of the overlapping ones?
>>
>> Any idea what is happening?
>>
>> Regards,
>>
>> O.
>> <results.txt><query1.xml>
>
> --
> ORACLE <http://www.oracle.com>
> Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67| 
> Mobile: +33 6 09 97 27 23| Skype:albert-godfrind <skype:albert-godfrind>
> OracleServer Technologies
> 400 Av. Roumanille,BP 309 |06906 Sophia Antipolis cedex|France
> Everything you ever wanted to know about Oracle Spatial 
> <http://www.apress.com/9781590598993>
>
> <http://www.locationintelligence.net/dc/>
>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/263a71ba/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.py
Type: text/x-python
Size: 1907 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/263a71ba/attachment-0001.py>

From o.rubi at esciencecenter.nl  Tue Aug 11 08:04:10 2015
From: o.rubi at esciencecenter.nl (Oscar Martinez Rubi)
Date: Tue, 11 Aug 2015 17:04:10 +0200
Subject: [pdal] Oracle PDAL queries not scaling
In-Reply-To: <55CA0C0C.6090700@tudelft.nl>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
	<55CA061C.5080603@esciencecenter.nl> <55CA0C0C.6090700@tudelft.nl>
Message-ID: <55CA0EEA.3030904@esciencecenter.nl>

Hi,

What I did now is to force statistics gathering, so:

ANALYZE TABLE AHN_BLCK compute system statistics for table;
BEGIN
dbms_stats.gather_table_stats('PDAL20M','AHN_BLCK',NULL,NULL,FALSE,'FOR 
ALL COLUMNS SIZE AUTO',8,'ALL');
END;

And after doing this the queries are scalable, so in this way I do not 
need to wait for the DB to learn...

Regards,

O.


On 11-08-15 16:51, Peter van Oosterom wrote:
> Hi Oscar,
>
> It feels like when you fetch the data, this is based on a query 
> execution plan that does a full table scan to get the blocks. Even if 
> there is an index, the database may not use this. However, the 
> database may notice that the actual query execution was disappointing 
> (collecting statistics), and that after repeating the same tests, the 
> database behaviour changed its behaviour and does scale well.
>
> [others: this was not in email of Oscar, but after repeating the test 
> the data was fetched in about 0.02 seconds for all sizes 20M, 210M and 
> 2201M. So, also the fetching in case of small dataset becomes 
> significantly faster form 0.5 vs. 0.02 seconds.]
>
> Would be good to see the actual query execution plain or force the 
> database to use the index (with an hint). My hand-on practical Oracle 
> syntax knowledge is too low to give exact hits how to do this, but 
> perhaps others can help here.
>
> Kind regards, Peter.
>
>
> On 11-8-2015 16:26, Oscar Martinez Rubi wrote:
>> Hi,
>>
>> I have investigated a bit more this issue.
>>
>> I wanted to see what data does the OCI reader actually reads, so I 
>> executed the pre-selection query out of PDAL, in python. So I run the 
>> attached script (freshly after loading the data).
>>
>> The script runs the same exact query as done in PDAL twice and prints 
>> for each run the number of returned blocks, time spent in the query 
>> and time spent to fetch the results.
>>
>> the exact query is:
>>
>> SELECT
>>     l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN", 
>> l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS", 
>> l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM",  l."POINTS", b.pc
>> FROM
>>     AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
>> WHERE
>>     l.obj_id = b.id
>>     AND
>>     SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;
>>
>> The results I get are:
>>
>> 20M run 1:
>>     #blocks: 12
>>     query time[s]: 0.113833904266
>>     fetch time[s]: *0.571593046188*
>> 20M run 2:
>>     #blocks: 12
>>     query time[s]: 0.000102996826172
>>     fetch time[s]: *0.500910997391*
>> 210M run 1:
>>     #blocks: 13
>>     query time[s]: 0.0586049556732
>>     fetch time[s]: *5.09832000732*
>> 210M run 2:
>>     #blocks: 13
>>     query time[s]: 0.000245094299316
>>     fetch time[s]: *5.05038785934*
>> 2201M run 1:
>>     #blocks: 13
>>     query time[s]: 0.070690870285
>>     fetch time[s]: *52.4960811138*
>> 2201M run 2:
>>     #blocks: 13
>>     query time[s]: 0.000225067138672
>>     fetch time[s]: *53.1006689072*
>>
>> So, even though the query times and the number of returned blocks are 
>> similar the fetch times are the not. We can see the scaling issue 
>> there. Somehow the fetching is much more expensive (10x) when points 
>> are 10x.
>>
>> I also noticed that after a while doing queries the times get much 
>> better and scalable even when I do new queries with other polygons. 
>> So, the first queries suffer of scaling issues but later it gets better.
>>
>> Any idea why?
>>
>> Regards,
>>
>> O.
>>
>>
>>
>>
>> On 10-08-15 18:40, Albert Godfrind wrote:
>>> Like many tools that access an Oracle database, we lack the ability 
>>> to see what actually happens in the database at a detailed level, 
>>> i.e. which actual queries are sent, and how the database executes 
>>> them in terms of CPU use, logical and physical I/Os, network 
>>> throughput and latency.
>>>
>>> So I think it is important to add some debugging / tracing facility 
>>> to let me see what happens:
>>>
>>> 1) An option to make PDAL (actually the OCI driver here) log each 
>>> SQL statement it executes, together with the elapsed time and the 
>>> number of rows (blocks) fetched. Obviously we have that statement in 
>>> the input XML file, but a trace would put everything in a single log 
>>> and include proper measurements.
>>>
>>> 2) More important: an option to make the OCI driver enable SQL 
>>> tracing at the database side. This is simple to do by just issuing 
>>> an ?ALTER SESSION ?? statement before running the queries. The 
>>> resulting trace will show all details about execution times as well 
>>> as resource consumption (CPU and IO) and wait times. That could be 
>>> added as an option in the XML file. Or maybe extend the XML file 
>>> with the option to specify a SQ statement to be performed before 
>>> each query (we could then use that to manually add the ALTER SESSION 
>>> statement.
>>>
>>> The resulting trace can help isolate the bottleneck as one of:
>>>
>>> 1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
>>> 2) the network time to pass the blocks to the PDAL client (network 
>>> throughput and latency)
>>> 3) the time to process the blocks in the PDAL client (mostly CPU)
>>>
>>> Albert
>>>
>>>> On 5-Aug-2015, at 12:26, Oscar Martinez Rubi 
>>>> <o.rubi at esciencecenter.nl <mailto:o.rubi at esciencecenter.nl>> wrote:
>>>>
>>>> Hi,
>>>>
>>>> I did a test to see how good Oracle with PDAL scale with bigger 
>>>> data sets. I had 3 datasets that are self-contained with 20M, 210M 
>>>> and 2201M points. I loaded them in different Oracle DBs with PDAL 
>>>> and laz-perf. And, for each of them I ran 7 queries (via a pdal 
>>>> pipeline that preselects blocks, applies a crop and then write to a 
>>>> LAS file)
>>>>
>>>> The results are in the attached file.
>>>>
>>>> Regarding the loading, for the 20M I only used one core (it is only 
>>>> one file) while for the others I used 16 cores, i.e. 16 simult. 
>>>> PDAL instances loading data to Oracle. I opened an issue in GitHub 
>>>> because I noticed that in some of the runs the size that I got was 
>>>> too large, and I do not know what caused that. The attached numbers 
>>>> are when everything seemed to work and the sizes were as expected.
>>>>
>>>> This message, though, is about the queries. Each query is run twice 
>>>> in each DB. As you can see in the results file, for 10x more points 
>>>> in the data set the queries are 10x slower, at least for the first 
>>>> run (with the 2201M the second run is much faster but this does not 
>>>> happen with the 210M).
>>>>
>>>> Find also attached one of the XML that i used for the queries 
>>>> (example is for query1). Note that the geometry is previously 
>>>> inserted in oracle so I can use to pre-filter blocks with the query 
>>>> option in oci reader
>>>>
>>>> First I though that maybe the query option in the oci reader in the 
>>>> XML was ignored and that all the blocks of the dataset were being 
>>>> processed by PDAL (that would explain 10x more points 10x slower 
>>>> queries) but I ran a pdal pipeline for query1 with verbose and I 
>>>> saw that the crop filter "only" processed 120000 points which makes 
>>>> sense taking into account that region of query 1 only has 74818 
>>>> points. Or maybe the crop still process all the blocks extents but 
>>>> only opens and decompress the points of the overlapping ones?
>>>>
>>>> Any idea what is happening?
>>>>
>>>> Regards,
>>>>
>>>> O.
>>>> <results.txt><query1.xml>
>>>
>>> --
>>> ORACLE <http://www.oracle.com>
>>> Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67| 
>>> Mobile: +33 6 09 97 27 23| Skype:albert-godfrind <skype:albert-godfrind>
>>> OracleServer Technologies
>>> 400 Av. Roumanille,BP 309 |06906 Sophia Antipolis cedex|France
>>> Everything you ever wanted to know about Oracle Spatial 
>>> <http://www.apress.com/9781590598993>
>>>
>>> <http://www.locationintelligence.net/dc/>
>>>
>>>
>>>
>>
>
>
> -- 
> Peter van OosteromP.J.M.vanOosterom at tudelft.nl
> Section GIS technology      (room 00-west-520) Department OTB
> Faculty of Architecture and the Built Environment, TU Delft
> tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
> fax (+31) 15 2784422        P.O. Box 5043, 2600 GA Delft, NL
> http://geomatics.tudelft.nl  MSc Geomatics
> http://www.msc-gima.nl       MSc GIMA (Geo-Info Management&Appl)
> http://www.gdmc.nl  
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/ef6b8d9c/attachment-0001.html>

From albert.godfrind at oracle.com  Tue Aug 11 08:43:21 2015
From: albert.godfrind at oracle.com (Albert Godfrind)
Date: Tue, 11 Aug 2015 17:43:21 +0200
Subject: [pdal] Oracle PDAL queries not scaling
In-Reply-To: <55CA061C.5080603@esciencecenter.nl>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
	<55CA061C.5080603@esciencecenter.nl>
Message-ID: <F2D6386F-55F8-4BD0-83F6-768CD6CB0641@oracle.com>

I wonder if the count of blocks returned is correct.  If it is indeed the same then the only explanation is that the blocks are bigger (occupy more space) - 10 times bigger for each test. 

First repeat the query but just return the size of each block: replace l.points with length(l.points).

Or just get the count of blocks and the total size for each test. Just have the select return "count(*), sum(length(l.points))/1024/1024 as mb". 

The fact that the times get 10x longer as the amount of data to fetch also gets 10x larger is reassuring. Getting 2.2GB out of the database in 55 seconds is not bad. 

Is this done on the database server ? Is the connection done via TCP/IP or is it via a direct local (BEQ) connection ?

Albert
--
Albert Godfrind
+33 6 09 97 27 23
Sent from my iPhone

> On 11 ao?t 2015, at 16:26, Oscar Martinez Rubi <o.rubi at esciencecenter.nl> wrote:
> 
> Hi,
> 
> I have investigated a bit more this issue.
> 
> I wanted to see what data does the OCI reader actually reads, so I executed the pre-selection query out of PDAL, in python. So I run the attached script (freshly after loading the data).
> 
> The script runs the same exact query as done in PDAL twice and prints for each run the number of returned blocks, time spent in the query and time spent to fetch the results.
> 
> the exact query is:
> 
> SELECT 
>     l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN", l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS", l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM",  l."POINTS", b.pc
> FROM 
>     AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
> WHERE
>     l.obj_id = b.id
>     AND
>     SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;
> 
> The results I get are:
> 
> 20M run 1:                                            
>     #blocks: 12
>     query time[s]: 0.113833904266
>     fetch time[s]: 0.571593046188
> 20M run 2:                                            
>     #blocks: 12
>     query time[s]: 0.000102996826172
>     fetch time[s]: 0.500910997391
> 210M run 1:  
>     #blocks: 13
>     query time[s]: 0.0586049556732
>     fetch time[s]: 5.09832000732
> 210M run 2:  
>     #blocks: 13
>     query time[s]: 0.000245094299316
>     fetch time[s]: 5.05038785934
> 2201M run 1:  
>     #blocks: 13
>     query time[s]: 0.070690870285
>     fetch time[s]: 52.4960811138
> 2201M run 2:  
>     #blocks: 13
>     query time[s]: 0.000225067138672
>     fetch time[s]: 53.1006689072
> 
> So, even though the query times and the number of returned blocks are similar the fetch times are the not. We can see the scaling issue there. Somehow the fetching is much more expensive (10x) when points are 10x.
> 
> I also noticed that after a while doing queries the times get much better and scalable even when I do new queries with other polygons. So, the first queries suffer of scaling issues but later it gets better. 
> 
> Any idea why?
> 
> Regards,
> 
> O.
> 
> 
> 
> 
>> On 10-08-15 18:40, Albert Godfrind wrote:
>> Like many tools that access an Oracle database, we lack the ability to see what actually happens in the database at a detailed level, i.e. which actual queries are sent, and how the database executes them in terms of CPU use, logical and physical I/Os, network throughput and latency.
>> 
>> So I think it is important to add some debugging / tracing facility to let me see what happens:
>> 
>> 1) An option to make PDAL (actually the OCI driver here) log each SQL statement it executes, together with the elapsed time and the number of rows (blocks) fetched. Obviously we have that statement in the input XML file, but a trace would put everything in a single log and include proper measurements.
>> 
>> 2) More important: an option to make the OCI driver enable SQL tracing at the database side. This is simple to do by just issuing an ?ALTER SESSION ?? statement before running the queries. The resulting trace will show all details about execution times as well as resource consumption (CPU and IO) and wait times. That could be added as an option in the XML file. Or maybe extend the XML file with the option to specify a SQ statement to be performed before each query (we could then use that to manually add the ALTER SESSION statement.
>> 
>> The resulting trace can help isolate the bottleneck as one of:
>> 
>> 1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
>> 2) the network time to pass the blocks to the PDAL client (network throughput and latency)
>> 3) the time to process the blocks in the PDAL client (mostly CPU)
>> 
>> Albert
>> 
>>> On 5-Aug-2015, at 12:26, Oscar Martinez Rubi <o.rubi at esciencecenter.nl> wrote:
>>> 
>>> Hi,
>>> 
>>> I did a test to see how good Oracle with PDAL scale with bigger data sets. I had 3 datasets that are self-contained with 20M, 210M and 2201M points. I loaded them in different Oracle DBs with PDAL and laz-perf. And, for each of them I ran 7 queries (via a pdal pipeline that preselects blocks, applies a crop and then write to a LAS file)
>>> 
>>> The results are in the attached file.
>>> 
>>> Regarding the loading, for the 20M I only used one core (it is only one file) while for the others I used 16 cores, i.e. 16 simult. PDAL instances loading data to Oracle. I opened an issue in GitHub because I noticed that in some of the runs the size that I got was too large, and I do not know what caused that. The attached numbers are when everything seemed to work and the sizes were as expected.
>>> 
>>> This message, though, is about the queries. Each query is run twice in each DB. As you can see in the results file, for 10x more points in the data set the queries are 10x slower, at least for the first run (with the 2201M the second run is much faster but this does not happen with the 210M).
>>> 
>>> Find also attached one of the XML that i used for the queries (example is for query1). Note that the geometry is previously inserted in oracle so I can use to pre-filter blocks with the query option in oci reader
>>> 
>>> First I though that maybe the query option in the oci reader in the XML was ignored and that all the blocks of the dataset were being processed by PDAL (that would explain 10x more points 10x slower queries) but I ran a pdal pipeline for query1 with verbose and I saw that the crop filter "only" processed 120000 points which makes sense taking into account that region of query 1 only has 74818 points. Or maybe the crop still process all the blocks extents but only opens and decompress the points of the overlapping ones?
>>> 
>>> Any idea what is happening?
>>> 
>>> Regards,
>>> 
>>> O.
>>> <results.txt><query1.xml>
>> 
>> --
>> 
>> Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67 | Mobile: +33 6 09 97 27 23 | Skype: albert-godfrind
>> Oracle Server Technologies
>> 400 Av. Roumanille, BP 309  | 06906 Sophia Antipolis cedex | France
>> Everything you ever wanted to know about Oracle Spatial
>> 
>> 
>> 
>> 
> 
> <test.py>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/6f98e695/attachment.html>

From stefan.ziegler.de at gmail.com  Tue Aug 11 12:38:56 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Tue, 11 Aug 2015 21:38:56 +0200
Subject: [pdal] pdal tindex error with las files w/o spatial reference
Message-ID: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>

Hi

when creating a tileindex for las files pdal gdal complains about not
finding an appropriate proj4 string for an empty srs:

PDAL: GDAL Failure number =6: No translation for an empty SRS to PROJ.4
format is known.

Find attached an attempt of a patch. As far as I understand the --a_srs was
not considered.

best regards
Stefan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/607ed390/attachment-0001.html>
-------------- next part --------------
diff --git a/kernels/tindex/TIndexKernel.cpp b/kernels/tindex/TIndexKernel.cpp
index 6639322..74953c3 100644
--- a/kernels/tindex/TIndexKernel.cpp
+++ b/kernels/tindex/TIndexKernel.cpp
@@ -484,7 +484,6 @@ bool TIndexKernel::createFeature(const FieldIndexes& indexes,
             "reference '" << fileInfo.m_srs << "' for file '" <<
             fileInfo.m_filename << "'" << std::endl;
     }
-
     // We have a limit of like 254 characters in some formats (notably
     // shapefile), so try to get the condensed version of the SRS.
 
@@ -554,6 +553,9 @@ TIndexKernel::FileInfo TIndexKernel::getFileInfo(KernelFactory& factory,
         polygon << "))";
         fileInfo.m_boundary = polygon.str();
         fileInfo.m_srs = qi.m_srs.getWKT();
+        if (fileInfo.m_srs.empty()) {
+            fileInfo.m_srs = m_assignSrsString;
+        }
     }
     else
     {
@@ -577,6 +579,9 @@ TIndexKernel::FileInfo TIndexKernel::getFileInfo(KernelFactory& factory,
         fileInfo.m_boundary =
             table.metadata().findChild("filters.hexbin:boundary").value();
         fileInfo.m_srs = table.spatialRef().getWKT();
+        if (fileInfo.m_srs.empty()) {
+            fileInfo.m_srs = m_assignSrsString;
+        }
     }
 
     FileUtils::fileTimes(filename, &fileInfo.m_ctime, &fileInfo.m_mtime);

From andrew.bell.ia at gmail.com  Tue Aug 11 12:44:16 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 11 Aug 2015 14:44:16 -0500
Subject: [pdal] pdal translate: reprojection error
In-Reply-To: <CACJ51z3_V6BzeLN9zcEDYuxR=YFyrU83D1qeFKXB35CwROLD6g@mail.gmail.com>
References: <CAJvo+18jgkQ-mjd7376P8bupWrJHkCZcn+1KnOYMefz1w0VqQA@mail.gmail.com>
	<CACJ51z3_V6BzeLN9zcEDYuxR=YFyrU83D1qeFKXB35CwROLD6g@mail.gmail.com>
Message-ID: <CACJ51z1Cf1eqs5mxo1Dx9X0iRcwaPC3TQQZWoyf216ezHDojzQ@mail.gmail.com>

This should be fixed in the current codebase.

On Mon, Aug 10, 2015 at 3:37 PM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

> Yes, thanks for this.  I'll take care of it once I confirm the intent of
> operation.
>
> On Mon, Aug 10, 2015 at 1:41 PM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
>
>> Hi
>>
>> I'm trying to reproject some laz files with the pdal translate command:
>>
>> pdal translate --input LAS_594217_LV95_shift.laz --output
>> LAS_594217_LV95_shift_v2.laz --compress --a_srs EPSG:21781 --t_srs EPSG:2056
>>
>> I'm ending up with an error:
>>
>> PDAL: Stage filters.reprojection missing required option 'out_srs'.
>>
>> Replacing "translateOptions" with "readerOptions" on line 220 in
>> https://github.com/PDAL/PDAL/blob/12ff867990c0176de5aa121e90b23ec1fe5b7c0d/kernels/translate/TranslateKernel.cpp
>> solves the problem. Not sure if this REALLY solves the problem but the
>> reprojection works. I do not dare to make a pull request because the
>> "translateOptions" parameter now seems obsolete? And I don't understand the
>> process behind all this stage etc stuff ;)
>>
>> Would be great if anyone could have a look.
>>
>> best regards
>> Stefan
>>
>>
>>
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/pdal
>>
>
>
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/427cb1b5/attachment.html>

From andrew.bell.ia at gmail.com  Tue Aug 11 12:54:04 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 11 Aug 2015 14:54:04 -0500
Subject: [pdal] pdal tindex error with las files w/o spatial reference
In-Reply-To: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>
References: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>
Message-ID: <CACJ51z0Zgi+iB7XjanKUXgLs22JBGtsS9tuBrYHWZy0_f2SHew@mail.gmail.com>

Can you please provide the command line you used that caused the problem
you are reporting?

Thanks,

On Tue, Aug 11, 2015 at 2:38 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com
> wrote:

> Hi
>
> when creating a tileindex for las files pdal gdal complains about not
> finding an appropriate proj4 string for an empty srs:
>
> PDAL: GDAL Failure number =6: No translation for an empty SRS to PROJ.4
> format is known.
>
> Find attached an attempt of a patch. As far as I understand the --a_srs
> was not considered.
>
> best regards
> Stefan
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/90533119/attachment.html>

From stefan.ziegler.de at gmail.com  Tue Aug 11 13:08:10 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Tue, 11 Aug 2015 22:08:10 +0200
Subject: [pdal] pdal tindex error with las files w/o spatial reference
In-Reply-To: <CACJ51z0Zgi+iB7XjanKUXgLs22JBGtsS9tuBrYHWZy0_f2SHew@mail.gmail.com>
References: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>
	<CACJ51z0Zgi+iB7XjanKUXgLs22JBGtsS9tuBrYHWZy0_f2SHew@mail.gmail.com>
Message-ID: <CAJvo+19_zprSXTu9CSXVX+4hoObOQQZQ=tn7qpia=GKmbMJb3w@mail.gmail.com>

Here we go:

pdal tindex --a_srs EPSG:21781 index.shp LAS_594217.laz

and

pdal tindex --a_srs EPSG:21781 --fast_boundary index.shp LAS_594217.laz

regards
Stefan

On Tue, Aug 11, 2015 at 9:54 PM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

>
> Can you please provide the command line you used that caused the problem
> you are reporting?
>
> Thanks,
>
> On Tue, Aug 11, 2015 at 2:38 PM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
>
>> Hi
>>
>> when creating a tileindex for las files pdal gdal complains about not
>> finding an appropriate proj4 string for an empty srs:
>>
>> PDAL: GDAL Failure number =6: No translation for an empty SRS to PROJ.4
>> format is known.
>>
>> Find attached an attempt of a patch. As far as I understand the --a_srs
>> was not considered.
>>
>> best regards
>> Stefan
>>
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/pdal
>>
>
>
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/8c662500/attachment.html>

From andrew.bell.ia at gmail.com  Tue Aug 11 15:22:14 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 11 Aug 2015 17:22:14 -0500
Subject: [pdal] pdal tindex error with las files w/o spatial reference
In-Reply-To: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>
References: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>
Message-ID: <CACJ51z0yVDH-9hLb1qrAB-FZ7PgsoSJ=gB3Ya+DArRyOTA2Dhw@mail.gmail.com>

This should now be fixed.

On Tue, Aug 11, 2015 at 2:38 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com
> wrote:

> Hi
>
> when creating a tileindex for las files pdal gdal complains about not
> finding an appropriate proj4 string for an empty srs:
>
> PDAL: GDAL Failure number =6: No translation for an empty SRS to PROJ.4
> format is known.
>
> Find attached an attempt of a patch. As far as I understand the --a_srs
> was not considered.
>
> best regards
> Stefan
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/d3866441/attachment.html>

From Michael.Smith at erdc.dren.mil  Tue Aug 11 15:30:51 2015
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Tue, 11 Aug 2015 22:30:51 +0000
Subject: [pdal] [EXTERNAL] Re:  Oracle PDAL queries not scaling
In-Reply-To: <55CA0EEA.3030904@esciencecenter.nl>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
	<55CA061C.5080603@esciencecenter.nl> <55CA0C0C.6090700@tudelft.nl>
	<55CA0EEA.3030904@esciencecenter.nl>
Message-ID: <D1EFEDEF.1172ED%michael.smith@erdc.dren.mil>

The statistics should actually auto gather (unless you've disabled that part). Its done as part of the DBMS Auto tasks and should gather when the tables are stale. Although this is more for a production type operation. If you are doing testing, you absolutely should make sure your statistics are up to date otherwise you will get bad access plans.

Its also recommended to set a unique index on your Block table on the Obj_ID/Blk_ID (although this is primarily used to individually select pointclouds).  The more info you can give the optimizer, the better your query will perform.

You can run (and should) explain plan's on your data access queries and see what estimates the optimizer returns. If they don't match what you expect, then you're probably feeding bad information to the optimizer.

Mike

----
Michael Smith
US Army Corps
Remote Sensing GIS/Center
michael.smith at usace.army.mil


From: <pdal-bounces at lists.osgeo.org<mailto:pdal-bounces at lists.osgeo.org>> on behalf of Oscar Martinez Rubi <o.rubi at esciencecenter.nl<mailto:o.rubi at esciencecenter.nl>>
Date: Tuesday, August 11, 2015 at 11:04 AM
To: Peter van Oosterom <P.J.M.vanOosterom at tudelft.nl<mailto:P.J.M.vanOosterom at tudelft.nl>>, Albert Godfrind <albert.godfrind at oracle.com<mailto:albert.godfrind at oracle.com>>, "pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>" <pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>>
Cc: Theo Tijssen <T.P.M.Tijssen at tudelft.nl<mailto:T.P.M.Tijssen at tudelft.nl>>, "mike.horhammer at oracle.com<mailto:mike.horhammer at oracle.com>" <mike.horhammer at oracle.com<mailto:mike.horhammer at oracle.com>>
Subject: [EXTERNAL] Re: [pdal] Oracle PDAL queries not scaling
Resent-From: Michael Smith <michael.smith at usace.army.mil<mailto:michael.smith at usace.army.mil>>

Hi,

What I did now is to force statistics gathering, so:

ANALYZE TABLE AHN_BLCK compute system statistics for table;
BEGIN
    dbms_stats.gather_table_stats('PDAL20M','AHN_BLCK',NULL,NULL,FALSE,'FOR ALL COLUMNS SIZE AUTO',8,'ALL');
END;

And after doing this the queries are scalable, so in this way I do not need to wait for the DB to learn...

Regards,

O.


On 11-08-15 16:51, Peter van Oosterom wrote:
Hi Oscar,

It feels like when you fetch the data, this is based on a query execution plan that does a full table scan to get the blocks. Even if there is an index, the database may not use this. However, the database may notice that the actual query execution was disappointing (collecting statistics), and that after repeating the same tests, the database behaviour changed its behaviour and does scale well.

[others: this was not in email of Oscar, but after repeating the test the data was fetched in about 0.02 seconds for all sizes 20M, 210M and 2201M. So, also the fetching in case of small dataset becomes significantly faster form 0.5 vs. 0.02 seconds.]

Would be good to see the actual query execution plain or force the database to use the index (with an hint). My hand-on practical Oracle syntax knowledge is too low to give exact hits how to do this, but perhaps others can help here.

Kind regards, Peter.


On 11-8-2015 16:26, Oscar Martinez Rubi wrote:
Hi,

I have investigated a bit more this issue.

I wanted to see what data does the OCI reader actually reads, so I executed the pre-selection query out of PDAL, in python. So I run the attached script (freshly after loading the data).

The script runs the same exact query as done in PDAL twice and prints for each run the number of returned blocks, time spent in the query and time spent to fetch the results.

the exact query is:

SELECT
    l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN", l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS", l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM",  l."POINTS", b.pc
FROM
    AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
WHERE
    l.obj_id = b.id
    AND
    SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;

The results I get are:

20M run 1:
    #blocks: 12
    query time[s]: 0.113833904266
    fetch time[s]: 0.571593046188
20M run 2:
    #blocks: 12
    query time[s]: 0.000102996826172
    fetch time[s]: 0.500910997391
210M run 1:
    #blocks: 13
    query time[s]: 0.0586049556732
    fetch time[s]: 5.09832000732
210M run 2:
    #blocks: 13
    query time[s]: 0.000245094299316
    fetch time[s]: 5.05038785934
2201M run 1:
    #blocks: 13
    query time[s]: 0.070690870285
    fetch time[s]: 52.4960811138
2201M run 2:
    #blocks: 13
    query time[s]: 0.000225067138672
    fetch time[s]: 53.1006689072

So, even though the query times and the number of returned blocks are similar the fetch times are the not. We can see the scaling issue there. Somehow the fetching is much more expensive (10x) when points are 10x.

I also noticed that after a while doing queries the times get much better and scalable even when I do new queries with other polygons. So, the first queries suffer of scaling issues but later it gets better.

Any idea why?

Regards,

O.




On 10-08-15 18:40, Albert Godfrind wrote:
Like many tools that access an Oracle database, we lack the ability to see what actually happens in the database at a detailed level, i.e. which actual queries are sent, and how the database executes them in terms of CPU use, logical and physical I/Os, network throughput and latency.

So I think it is important to add some debugging / tracing facility to let me see what happens:

1) An option to make PDAL (actually the OCI driver here) log each SQL statement it executes, together with the elapsed time and the number of rows (blocks) fetched. Obviously we have that statement in the input XML file, but a trace would put everything in a single log and include proper measurements.

2) More important: an option to make the OCI driver enable SQL tracing at the database side. This is simple to do by just issuing an ?ALTER SESSION ?? statement before running the queries. The resulting trace will show all details about execution times as well as resource consumption (CPU and IO) and wait times. That could be added as an option in the XML file. Or maybe extend the XML file with the option to specify a SQ statement to be performed before each query (we could then use that to manually add the ALTER SESSION statement.

The resulting trace can help isolate the bottleneck as one of:

1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
2) the network time to pass the blocks to the PDAL client (network throughput and latency)
3) the time to process the blocks in the PDAL client (mostly CPU)

Albert

On 5-Aug-2015, at 12:26, Oscar Martinez Rubi <o.rubi at esciencecenter.nl<mailto:o.rubi at esciencecenter.nl>> wrote:

Hi,

I did a test to see how good Oracle with PDAL scale with bigger data sets. I had 3 datasets that are self-contained with 20M, 210M and 2201M points. I loaded them in different Oracle DBs with PDAL and laz-perf. And, for each of them I ran 7 queries (via a pdal pipeline that preselects blocks, applies a crop and then write to a LAS file)

The results are in the attached file.

Regarding the loading, for the 20M I only used one core (it is only one file) while for the others I used 16 cores, i.e. 16 simult. PDAL instances loading data to Oracle. I opened an issue in GitHub because I noticed that in some of the runs the size that I got was too large, and I do not know what caused that. The attached numbers are when everything seemed to work and the sizes were as expected.

This message, though, is about the queries. Each query is run twice in each DB. As you can see in the results file, for 10x more points in the data set the queries are 10x slower, at least for the first run (with the 2201M the second run is much faster but this does not happen with the 210M).

Find also attached one of the XML that i used for the queries (example is for query1). Note that the geometry is previously inserted in oracle so I can use to pre-filter blocks with the query option in oci reader

First I though that maybe the query option in the oci reader in the XML was ignored and that all the blocks of the dataset were being processed by PDAL (that would explain 10x more points 10x slower queries) but I ran a pdal pipeline for query1 with verbose and I saw that the crop filter "only" processed 120000 points which makes sense taking into account that region of query 1 only has 74818 points. Or maybe the crop still process all the blocks extents but only opens and decompress the points of the overlapping ones?

Any idea what is happening?

Regards,

O.
<results.txt><query1.xml>

--
[ORACLE]<BLOCKEDoracle.comBLOCKED>
Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67 | Mobile: +33 6 09 97 27 23 | Skype: albert-godfrind<skype:albert-godfrind>
Oracle Server Technologies
400 Av. Roumanille, BP 309  | 06906 Sophia Antipolis cedex | France
Everything you ever wanted to know about Oracle Spatial<BLOCKEDapress.com/9781590598993BLOCKED>

<BLOCKEDlocationintelligence.net/dc/BLOCKED>







--
Peter van Oosterom          P.J.M.vanOosterom at tudelft.nl<mailto:P.J.M.vanOosterom at tudelft.nl>
Section GIS technology      (room 00-west-520) Department OTB
Faculty of Architecture and the Built Environment, TU Delft
tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
fax (+31) 15 2784422        P.O. Box 5043, 2600 GA Delft, NL
BLOCKEDgeomatics.tudelft.nlBLOCKED MSc Geomatics
BLOCKEDmsc-gima.nlBLOCKED      MSc GIMA (Geo-Info Management&Appl)
BLOCKEDgdmc.nlBLOCKED



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/596b83fa/attachment-0001.html>

From Michael.Smith at erdc.dren.mil  Tue Aug 11 15:22:22 2015
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Tue, 11 Aug 2015 22:22:22 +0000
Subject: [pdal] [EXTERNAL] Re:  Oracle PDAL queries not scaling
In-Reply-To: <8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
Message-ID: <D1EFED15.1172E4%michael.smith@erdc.dren.mil>

Albert,


  1.  The only sql statement that PDAL executes is the query to return blocks, that?s it.
  2.  There are already doTrace option (although its just on the writer). There is also pre and post sql.

----
Michael Smith
US Army Corps
Remote Sensing GIS/Center
michael.smith at usace.army.mil


From: <pdal-bounces at lists.osgeo.org<mailto:pdal-bounces at lists.osgeo.org>> on behalf of Albert Godfrind <albert.godfrind at oracle.com<mailto:albert.godfrind at oracle.com>>
Date: Monday, August 10, 2015 at 12:40 PM
To: "pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>" <pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>>
Cc: Peter van Oosterom <P.J.M.vanOosterom at tudelft.nl<mailto:P.J.M.vanOosterom at tudelft.nl>>, Theo Tijssen <T.P.M.Tijssen at tudelft.nl<mailto:T.P.M.Tijssen at tudelft.nl>>, "mike.horhammer at oracle.com<mailto:mike.horhammer at oracle.com>" <mike.horhammer at oracle.com<mailto:mike.horhammer at oracle.com>>
Subject: [EXTERNAL] Re: [pdal] Oracle PDAL queries not scaling
Resent-From: Michael Smith <michael.smith at usace.army.mil<mailto:michael.smith at usace.army.mil>>

Like many tools that access an Oracle database, we lack the ability to see what actually happens in the database at a detailed level, i.e. which actual queries are sent, and how the database executes them in terms of CPU use, logical and physical I/Os, network throughput and latency.

So I think it is important to add some debugging / tracing facility to let me see what happens:

1) An option to make PDAL (actually the OCI driver here) log each SQL statement it executes, together with the elapsed time and the number of rows (blocks) fetched. Obviously we have that statement in the input XML file, but a trace would put everything in a single log and include proper measurements.

2) More important: an option to make the OCI driver enable SQL tracing at the database side. This is simple to do by just issuing an ?ALTER SESSION ?? statement before running the queries. The resulting trace will show all details about execution times as well as resource consumption (CPU and IO) and wait times. That could be added as an option in the XML file. Or maybe extend the XML file with the option to specify a SQ statement to be performed before each query (we could then use that to manually add the ALTER SESSION statement.

The resulting trace can help isolate the bottleneck as one of:

1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
2) the network time to pass the blocks to the PDAL client (network throughput and latency)
3) the time to process the blocks in the PDAL client (mostly CPU)

Albert

On 5-Aug-2015, at 12:26, Oscar Martinez Rubi <o.rubi at esciencecenter.nl<mailto:o.rubi at esciencecenter.nl>> wrote:

Hi,

I did a test to see how good Oracle with PDAL scale with bigger data sets. I had 3 datasets that are self-contained with 20M, 210M and 2201M points. I loaded them in different Oracle DBs with PDAL and laz-perf. And, for each of them I ran 7 queries (via a pdal pipeline that preselects blocks, applies a crop and then write to a LAS file)

The results are in the attached file.

Regarding the loading, for the 20M I only used one core (it is only one file) while for the others I used 16 cores, i.e. 16 simult. PDAL instances loading data to Oracle. I opened an issue in GitHub because I noticed that in some of the runs the size that I got was too large, and I do not know what caused that. The attached numbers are when everything seemed to work and the sizes were as expected.

This message, though, is about the queries. Each query is run twice in each DB. As you can see in the results file, for 10x more points in the data set the queries are 10x slower, at least for the first run (with the 2201M the second run is much faster but this does not happen with the 210M).

Find also attached one of the XML that i used for the queries (example is for query1). Note that the geometry is previously inserted in oracle so I can use to pre-filter blocks with the query option in oci reader

First I though that maybe the query option in the oci reader in the XML was ignored and that all the blocks of the dataset were being processed by PDAL (that would explain 10x more points 10x slower queries) but I ran a pdal pipeline for query1 with verbose and I saw that the crop filter "only" processed 120000 points which makes sense taking into account that region of query 1 only has 74818 points. Or maybe the crop still process all the blocks extents but only opens and decompress the points of the overlapping ones?

Any idea what is happening?

Regards,

O.
<results.txt><query1.xml>

--
[ORACLE]<BLOCKEDoracle.comBLOCKED>
Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67 | Mobile: +33 6 09 97 27 23 | Skype: albert-godfrind<skype:albert-godfrind>
Oracle Server Technologies
400 Av. Roumanille, BP 309  | 06906 Sophia Antipolis cedex | France
Everything you ever wanted to know about Oracle Spatial<BLOCKEDapress.com/9781590598993BLOCKED>

<BLOCKEDlocationintelligence.net/dc/BLOCKED>



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150811/bdd103d0/attachment.html>

From stefan.ziegler.de at gmail.com  Tue Aug 11 20:42:38 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Wed, 12 Aug 2015 05:42:38 +0200
Subject: [pdal] pdal tindex error with las files w/o spatial reference
In-Reply-To: <CACJ51z0yVDH-9hLb1qrAB-FZ7PgsoSJ=gB3Ya+DArRyOTA2Dhw@mail.gmail.com>
References: <CAJvo+1-KAokXSa-cVHGySr9h2TKXGjbeFv4w=hCBBgZ1b3OQvw@mail.gmail.com>
	<CACJ51z0yVDH-9hLb1qrAB-FZ7PgsoSJ=gB3Ya+DArRyOTA2Dhw@mail.gmail.com>
Message-ID: <6473A26C-0672-4D51-9AFC-8702113C7C86@gmail.com>

Thanks.

Stefan

Sent from my iPhone

> On 12 Aug 2015, at 00:22, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> 
> This should now be fixed.
> 
>> On Tue, Aug 11, 2015 at 2:38 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com> wrote:
>> Hi 
>> 
>> when creating a tileindex for las files pdal gdal complains about not finding an appropriate proj4 string for an empty srs:
>> 
>> PDAL: GDAL Failure number =6: No translation for an empty SRS to PROJ.4 format is known.
>> 
>> Find attached an attempt of a patch. As far as I understand the --a_srs was not considered.
>> 
>> best regards
>> Stefan 
>> 
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/pdal
> 
> 
> 
> -- 
> Andrew Bell
> andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/607a5ecb/attachment.html>

From stefan.ziegler.de at gmail.com  Wed Aug 12 00:37:41 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Wed, 12 Aug 2015 09:37:41 +0200
Subject: [pdal] PDAL Python bindings
Message-ID: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>

Hi

The project goals are mentioning Python bindings for PDAL:

http://www.pdal.io/development/goals.html

Are there any bindings available? If not, could this be sponsered?

best regards
Stefan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/4015a46c/attachment.html>

From o.rubi at esciencecenter.nl  Wed Aug 12 02:53:59 2015
From: o.rubi at esciencecenter.nl (Oscar Martinez Rubi)
Date: Wed, 12 Aug 2015 11:53:59 +0200
Subject: [pdal] [EXTERNAL] Re:  Oracle PDAL queries not scaling
In-Reply-To: <D1EFEDEF.1172ED%michael.smith@erdc.dren.mil>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
	<55CA061C.5080603@esciencecenter.nl> <55CA0C0C.6090700@tudelft.nl>
	<55CA0EEA.3030904@esciencecenter.nl>
	<D1EFEDEF.1172ED%michael.smith@erdc.dren.mil>
Message-ID: <55CB17B7.5040907@esciencecenter.nl>

Hi,

When you say that statistics are auto-gathered...by who? PDAL or Oracle?
  - In PDAL OCIWritter I do not see anything to do the analyze and 
gather_stats. I would maybe put it just after creating the indexes, and 
also optional as the indexes creation, because you only want to do that 
after the loading of the last file.
  - In Oracle itself I have not disabled anything (as far as I remember) 
and they are indeed computed automatically after a while, the problem is 
how long is "this while", to be sure, and as you recommend, it is maybe 
just better to do it your own once you know the loading is over.

So, bottom line: I do the loading of all the files (with pdal) with 
deactivated indexing. And then, the stuff I do after the last pdal 
loading is:

  - Create primary key on obj_id/blk_id. This is the one you suggest
  - Insert info in USER_SDO_GEOM_METADATA of the whole extent of all the 
loaded data (from different files and in different PDAL runs)
  - Create the spatial index
  - Analyze and gather stats

The SQL commands for that are:

ALTER TABLE AHN_BLCK ADD CONSTRAINT AHN_BLCK_PK PRIMARY KEY (OBJ_ID, 
BLK_ID) USING INDEX TABLESPACE INDX;

INSERT INTO USER_SDO_GEOM_METADATA VALUES ('AHN_BLCK','BLK_EXTENT',
SDO_DIM_ARRAY(SDO_DIM_ELEMENT('X',60000.0,100000.0,0.0001),
               SDO_DIM_ELEMENT('Y',425000.0,475000.0,0.0001)),28992);

CREATE INDEX AHN_BLCK_SIDX ON AHN_BLCK (BLK_EXTENT) INDEXTYPE IS 
MDSYS.SPATIAL_INDEX PARAMETERS ('TABLESPACE=INDX WORK_TABLESPACE=PCWORK 
LAYER_GTYPE=POLYGON SDO_INDX_DIMS=2 SDO_RTR_PCTFREE=0') PARALLEL 16 ;

ANALYZE TABLE AHN_BLCK  COMPUTE SYSTEM STATISTICS FOR TABLE;

BEGIN
DBMS_STATS.GATHER_TABLE_STATS('PDAL23090M','AHN_BLCK',NULL,NULL,FALSE,'FOR 
ALL COLUMNS SIZE AUTO',8,'ALL');
END;

After the doing all these steps the query times are as expected so I am 
going to assume those are the exact proper steps. The times are now 
scalable and quite nice (right now still busy with the 23 billion 
dataset but I guess it is safe to assume they will also be fine ;) )!

Time[s]      pdal20M    pdal210M    pdal2201M  pdal23090M
---------  ---------  ----------  -----------  ------------
01_0            0.63        0.37         0.41  -
01_1            0.18        0.2          0.22  -
02_0            1.18        1.51         1.54  -
02_1            0.96        0.96         0.93  -
03_0            0.24        0.25         0.25  -
03_1            0.18        0.18         0.18  -
04_0            1.49        1.53         1.44  -
04_1            1.05        1.07         1.06  -
05_0            0.66        0.78         0.76  -
05_1            0.49        0.51         0.49  -
06_0            1.42        1.61         1.64  -
06_1            1.17        1.2          1.21  -
07_0            1.6         2.12         2.15  -
07_1            1.62        1.35         1.43  -

Thanks for your help and suggestions!

Regards,

O.


On 12-08-15 00:30, Smith, Michael ERDC-RDE-CRREL-NH wrote:
> The statistics should actually auto gather (unless you've disabled 
> that part). Its done as part of the DBMS Auto tasks and should gather 
> when the tables are stale. Although this is more for a production type 
> operation. If you are doing testing, you absolutely should make sure 
> your statistics are up to date otherwise you will get bad access plans.
>
> Its also recommended to set a unique index on your Block table on the 
> Obj_ID/Blk_ID (although this is primarily used to individually select 
> pointclouds).  The more info you can give the optimizer, the better 
> your query will perform.
>
> You can run (and should) explain plan's on your data access queries 
> and see what estimates the optimizer returns. If they don't match what 
> you expect, then you're probably feeding bad information to the optimizer.
>
> Mike
>
> ----
> Michael Smith
> US Army Corps
> Remote Sensing GIS/Center
> michael.smith at usace.army.mil
>
>
> From: <pdal-bounces at lists.osgeo.org 
> <mailto:pdal-bounces at lists.osgeo.org>> on behalf of Oscar Martinez 
> Rubi <o.rubi at esciencecenter.nl <mailto:o.rubi at esciencecenter.nl>>
> Date: Tuesday, August 11, 2015 at 11:04 AM
> To: Peter van Oosterom <P.J.M.vanOosterom at tudelft.nl 
> <mailto:P.J.M.vanOosterom at tudelft.nl>>, Albert Godfrind 
> <albert.godfrind at oracle.com <mailto:albert.godfrind at oracle.com>>, 
> "pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>" 
> <pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>>
> Cc: Theo Tijssen <T.P.M.Tijssen at tudelft.nl 
> <mailto:T.P.M.Tijssen at tudelft.nl>>, "mike.horhammer at oracle.com 
> <mailto:mike.horhammer at oracle.com>" <mike.horhammer at oracle.com 
> <mailto:mike.horhammer at oracle.com>>
> Subject: [EXTERNAL] Re: [pdal] Oracle PDAL queries not scaling
> Resent-From: Michael Smith <michael.smith at usace.army.mil 
> <mailto:michael.smith at usace.army.mil>>
>
>     Hi,
>
>     What I did now is to force statistics gathering, so:
>
>     ANALYZE TABLE AHN_BLCK compute system statistics for table;
>     BEGIN
>     dbms_stats.gather_table_stats('PDAL20M','AHN_BLCK',NULL,NULL,FALSE,'FOR
>     ALL COLUMNS SIZE AUTO',8,'ALL');
>     END;
>
>     And after doing this the queries are scalable, so in this way I do
>     not need to wait for the DB to learn...
>
>     Regards,
>
>     O.
>
>
>     On 11-08-15 16:51, Peter van Oosterom wrote:
>>     Hi Oscar,
>>
>>     It feels like when you fetch the data, this is based on a query
>>     execution plan that does a full table scan to get the blocks.
>>     Even if there is an index, the database may not use this.
>>     However, the database may notice that the actual query execution
>>     was disappointing (collecting statistics), and that after
>>     repeating the same tests, the database behaviour changed its
>>     behaviour and does scale well.
>>
>>     [others: this was not in email of Oscar, but after repeating the
>>     test the data was fetched in about 0.02 seconds for all sizes
>>     20M, 210M and 2201M. So, also the fetching in case of small
>>     dataset becomes significantly faster form 0.5 vs. 0.02 seconds.]
>>
>>     Would be good to see the actual query execution plain or force
>>     the database to use the index (with an hint). My hand-on
>>     practical Oracle syntax knowledge is too low to give exact hits
>>     how to do this, but perhaps others can help here.
>>
>>     Kind regards, Peter.
>>
>>
>>     On 11-8-2015 16:26, Oscar Martinez Rubi wrote:
>>>     Hi,
>>>
>>>     I have investigated a bit more this issue.
>>>
>>>     I wanted to see what data does the OCI reader actually reads, so
>>>     I executed the pre-selection query out of PDAL, in python. So I
>>>     run the attached script (freshly after loading the data).
>>>
>>>     The script runs the same exact query as done in PDAL twice and
>>>     prints for each run the number of returned blocks, time spent in
>>>     the query and time spent to fetch the results.
>>>
>>>     the exact query is:
>>>
>>>     SELECT
>>>         l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN",
>>>     l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS",
>>>     l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM",  l."POINTS", b.pc
>>>     FROM
>>>         AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
>>>     WHERE
>>>         l.obj_id = b.id
>>>         AND
>>>         SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;
>>>
>>>     The results I get are:
>>>
>>>     20M run 1:
>>>         #blocks: 12
>>>         query time[s]: 0.113833904266
>>>         fetch time[s]: *0.571593046188*
>>>     20M run 2:
>>>         #blocks: 12
>>>         query time[s]: 0.000102996826172
>>>         fetch time[s]: *0.500910997391*
>>>     210M run 1:
>>>         #blocks: 13
>>>         query time[s]: 0.0586049556732
>>>         fetch time[s]: *5.09832000732*
>>>     210M run 2:
>>>         #blocks: 13
>>>         query time[s]: 0.000245094299316
>>>         fetch time[s]: *5.05038785934*
>>>     2201M run 1:
>>>         #blocks: 13
>>>         query time[s]: 0.070690870285
>>>         fetch time[s]: *52.4960811138*
>>>     2201M run 2:
>>>         #blocks: 13
>>>         query time[s]: 0.000225067138672
>>>         fetch time[s]: *53.1006689072*
>>>
>>>     So, even though the query times and the number of returned
>>>     blocks are similar the fetch times are the not. We can see the
>>>     scaling issue there. Somehow the fetching is much more expensive
>>>     (10x) when points are 10x.
>>>
>>>     I also noticed that after a while doing queries the times get
>>>     much better and scalable even when I do new queries with other
>>>     polygons. So, the first queries suffer of scaling issues but
>>>     later it gets better.
>>>
>>>     Any idea why?
>>>
>>>     Regards,
>>>
>>>     O.
>>>
>>>
>>>
>>>
>>>     On 10-08-15 18:40, Albert Godfrind wrote:
>>>>     Like many tools that access an Oracle database, we lack the
>>>>     ability to see what actually happens in the database at a
>>>>     detailed level, i.e. which actual queries are sent, and how the
>>>>     database executes them in terms of CPU use, logical and
>>>>     physical I/Os, network throughput and latency.
>>>>
>>>>     So I think it is important to add some debugging / tracing
>>>>     facility to let me see what happens:
>>>>
>>>>     1) An option to make PDAL (actually the OCI driver here) log
>>>>     each SQL statement it executes, together with the elapsed time
>>>>     and the number of rows (blocks) fetched. Obviously we have that
>>>>     statement in the input XML file, but a trace would put
>>>>     everything in a single log and include proper measurements.
>>>>
>>>>     2) More important: an option to make the OCI driver enable SQL
>>>>     tracing at the database side. This is simple to do by just
>>>>     issuing an ?ALTER SESSION ?? statement before running the
>>>>     queries. The resulting trace will show all details about
>>>>     execution times as well as resource consumption (CPU and IO)
>>>>     and wait times. That could be added as an option in the XML
>>>>     file. Or maybe extend the XML file with the option to specify a
>>>>     SQ statement to be performed before each query (we could then
>>>>     use that to manually add the ALTER SESSION statement.
>>>>
>>>>     The resulting trace can help isolate the bottleneck as one of:
>>>>
>>>>     1) the I/Os in the database, to fetch the blocks from disk
>>>>     (mostly I/O)
>>>>     2) the network time to pass the blocks to the PDAL client
>>>>     (network throughput and latency)
>>>>     3) the time to process the blocks in the PDAL client (mostly CPU)
>>>>
>>>>     Albert
>>>>
>>>>>     On 5-Aug-2015, at 12:26, Oscar Martinez Rubi
>>>>>     <o.rubi at esciencecenter.nl <mailto:o.rubi at esciencecenter.nl>>
>>>>>     wrote:
>>>>>
>>>>>     Hi,
>>>>>
>>>>>     I did a test to see how good Oracle with PDAL scale with
>>>>>     bigger data sets. I had 3 datasets that are self-contained
>>>>>     with 20M, 210M and 2201M points. I loaded them in different
>>>>>     Oracle DBs with PDAL and laz-perf. And, for each of them I ran
>>>>>     7 queries (via a pdal pipeline that preselects blocks, applies
>>>>>     a crop and then write to a LAS file)
>>>>>
>>>>>     The results are in the attached file.
>>>>>
>>>>>     Regarding the loading, for the 20M I only used one core (it is
>>>>>     only one file) while for the others I used 16 cores, i.e. 16
>>>>>     simult. PDAL instances loading data to Oracle. I opened an
>>>>>     issue in GitHub because I noticed that in some of the runs the
>>>>>     size that I got was too large, and I do not know what caused
>>>>>     that. The attached numbers are when everything seemed to work
>>>>>     and the sizes were as expected.
>>>>>
>>>>>     This message, though, is about the queries. Each query is run
>>>>>     twice in each DB. As you can see in the results file, for 10x
>>>>>     more points in the data set the queries are 10x slower, at
>>>>>     least for the first run (with the 2201M the second run is much
>>>>>     faster but this does not happen with the 210M).
>>>>>
>>>>>     Find also attached one of the XML that i used for the queries
>>>>>     (example is for query1). Note that the geometry is previously
>>>>>     inserted in oracle so I can use to pre-filter blocks with the
>>>>>     query option in oci reader
>>>>>
>>>>>     First I though that maybe the query option in the oci reader
>>>>>     in the XML was ignored and that all the blocks of the dataset
>>>>>     were being processed by PDAL (that would explain 10x more
>>>>>     points 10x slower queries) but I ran a pdal pipeline for
>>>>>     query1 with verbose and I saw that the crop filter "only"
>>>>>     processed 120000 points which makes sense taking into account
>>>>>     that region of query 1 only has 74818 points. Or maybe the
>>>>>     crop still process all the blocks extents but only opens and
>>>>>     decompress the points of the overlapping ones?
>>>>>
>>>>>     Any idea what is happening?
>>>>>
>>>>>     Regards,
>>>>>
>>>>>     O.
>>>>>     <results.txt><query1.xml>
>>>>
>>>>     --
>>>>     ORACLE <BLOCKEDoracle.comBLOCKED>
>>>>     Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80
>>>>     67| Mobile: +33 6 09 97 27 23| Skype:albert-godfrind
>>>>     <skype:albert-godfrind>
>>>>     OracleServer Technologies
>>>>     400 Av. Roumanille,BP 309 |06906 Sophia Antipolis cedex|France
>>>>     Everything you ever wanted to know about Oracle Spatial
>>>>     <BLOCKEDapress.com/9781590598993BLOCKED>
>>>>
>>>>     <BLOCKEDlocationintelligence.net/dc/BLOCKED>
>>>>
>>>>
>>>>
>>>
>>
>>
>>     -- 
>>     Peter van OosteromP.J.M.vanOosterom at tudelft.nl
>>     Section GIS technology      (room 00-west-520) Department OTB
>>     Faculty of Architecture and the Built Environment, TU Delft
>>     tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
>>     fax (+31) 15 2784422        P.O. Box 5043, 2600 GA Delft, NL
>>     BLOCKEDgeomatics.tudelft.nlBLOCKED  MSc Geomatics
>>     BLOCKEDmsc-gima.nlBLOCKED       MSc GIMA (Geo-Info Management&Appl)
>>     BLOCKEDgdmc.nlBLOCKED  
>>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/7899e143/attachment-0001.html>

From o.rubi at esciencecenter.nl  Wed Aug 12 03:40:40 2015
From: o.rubi at esciencecenter.nl (Oscar Martinez Rubi)
Date: Wed, 12 Aug 2015 12:40:40 +0200
Subject: [pdal] [EXTERNAL] Re:  Oracle PDAL queries not scaling
In-Reply-To: <55CB1A05.603@tudelft.nl>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
	<55CA061C.5080603@esciencecenter.nl> <55CA0C0C.6090700@tudelft.nl>
	<55CA0EEA.3030904@esciencecenter.nl>
	<D1EFEDEF.1172ED%michael.smith@erdc.dren.mil>
	<55CB17B7.5040907@esciencecenter.nl> <55CB1A05.603@tudelft.nl>
Message-ID: <55CB22A8.6080806@esciencecenter.nl>

Hi,

Is not quite significant. For example the 23090M data set loading just 
finished.

Total time was 3816 seconds.
  - Loading 1400 files (16 simult. process) took 3660 seconds.
  - Create primary index (obj_id/blk_id) took 2 seconds
  - Insert into USER_SDO_GEOM_METADATA was less than 1 second
  - Create spatial index was 35 seconds
  - Analyse table was 4 seconds
  - Gather_table_stats was 112 seconds

So, it is reasonable

O.

On 12-08-15 12:03, Peter van Oosterom wrote:
> Hi Oscar,
>
> Great that PDAL/Oracle now scales well!
>
> It might be that for large datasets analyze+stats may get expensive 
> part of load time.
> To avoid this step, an alternative would be to add hint for query 
> optimizer to use index.
>
> However, perhaps the analyze+stats at block level are not too 
> expensive (as it would
> be at point level) and in that case the needed time might be 
> neglectable, and in that
> case better to do so (as in your script now and without hit).
>
> Good to check how much time these steps take and then we know what to do
> (especially for loading complete ahn with 640 billion points).
>
> Kind regards, Peter.
>
> Oscar Martinez Rubi schreef op 12-8-2015 om 11:53:
>> Hi,
>>
>> When you say that statistics are auto-gathered...by who? PDAL or Oracle?
>>  - In PDAL OCIWritter I do not see anything to do the analyze and 
>> gather_stats. I would maybe put it just after creating the indexes, 
>> and also optional as the indexes creation, because you only want to 
>> do that after the loading of the last file.
>>  - In Oracle itself I have not disabled anything (as far as I 
>> remember) and they are indeed computed automatically after a while, 
>> the problem is how long is "this while", to be sure, and as you 
>> recommend, it is maybe just better to do it your own once you know 
>> the loading is over.
>>
>> So, bottom line: I do the loading of all the files (with pdal) with 
>> deactivated indexing. And then, the stuff I do after the last pdal 
>> loading is:
>>
>>  - Create primary key on obj_id/blk_id. This is the one you suggest
>>  - Insert info in USER_SDO_GEOM_METADATA of the whole extent of all 
>> the loaded data (from different files and in different PDAL runs)
>>  - Create the spatial index
>>  - Analyze and gather stats
>>
>> The SQL commands for that are:
>>
>> ALTER TABLE AHN_BLCK ADD CONSTRAINT AHN_BLCK_PK PRIMARY KEY (OBJ_ID, 
>> BLK_ID) USING INDEX TABLESPACE INDX;
>>
>> INSERT INTO USER_SDO_GEOM_METADATA VALUES ('AHN_BLCK','BLK_EXTENT',
>> SDO_DIM_ARRAY(SDO_DIM_ELEMENT('X',60000.0,100000.0,0.0001),
>> SDO_DIM_ELEMENT('Y',425000.0,475000.0,0.0001)),28992);
>>
>> CREATE INDEX AHN_BLCK_SIDX ON AHN_BLCK (BLK_EXTENT) INDEXTYPE IS 
>> MDSYS.SPATIAL_INDEX PARAMETERS ('TABLESPACE=INDX 
>> WORK_TABLESPACE=PCWORK LAYER_GTYPE=POLYGON SDO_INDX_DIMS=2 
>> SDO_RTR_PCTFREE=0') PARALLEL 16 ;
>>
>> ANALYZE TABLE AHN_BLCK  COMPUTE SYSTEM STATISTICS FOR TABLE;
>>
>> BEGIN
>> DBMS_STATS.GATHER_TABLE_STATS('PDAL23090M','AHN_BLCK',NULL,NULL,FALSE,'FOR 
>> ALL COLUMNS SIZE AUTO',8,'ALL');
>> END;
>>
>> After the doing all these steps the query times are as expected so I 
>> am going to assume those are the exact proper steps. The times are 
>> now scalable and quite nice (right now still busy with the 23 billion 
>> dataset but I guess it is safe to assume they will also be fine ;) )!
>>
>> Time[s]      pdal20M    pdal210M    pdal2201M  pdal23090M
>> ---------  ---------  ----------  ----------- ------------
>> 01_0            0.63        0.37         0.41  -
>> 01_1            0.18        0.2          0.22  -
>> 02_0            1.18        1.51         1.54  -
>> 02_1            0.96        0.96         0.93  -
>> 03_0            0.24        0.25         0.25  -
>> 03_1            0.18        0.18         0.18  -
>> 04_0            1.49        1.53         1.44  -
>> 04_1            1.05        1.07         1.06  -
>> 05_0            0.66        0.78         0.76  -
>> 05_1            0.49        0.51         0.49  -
>> 06_0            1.42        1.61         1.64  -
>> 06_1            1.17        1.2          1.21  -
>> 07_0            1.6         2.12         2.15  -
>> 07_1            1.62        1.35         1.43  -
>>
>> Thanks for your help and suggestions!
>>
>> Regards,
>>
>> O.
>>
>>
>> On 12-08-15 00:30, Smith, Michael ERDC-RDE-CRREL-NH wrote:
>>> The statistics should actually auto gather (unless you've disabled 
>>> that part). Its done as part of the DBMS Auto tasks and should 
>>> gather when the tables are stale. Although this is more for a 
>>> production type operation. If you are doing testing, you absolutely 
>>> should make sure your statistics are up to date otherwise you will 
>>> get bad access plans.
>>>
>>> Its also recommended to set a unique index on your Block table on 
>>> the Obj_ID/Blk_ID (although this is primarily used to individually 
>>> select pointclouds).  The more info you can give the optimizer, the 
>>> better your query will perform.
>>>
>>> You can run (and should) explain plan's on your data access queries 
>>> and see what estimates the optimizer returns. If they don't match 
>>> what you expect, then you're probably feeding bad information to the 
>>> optimizer.
>>>
>>> Mike
>>>
>>> ----
>>> Michael Smith
>>> US Army Corps
>>> Remote Sensing GIS/Center
>>> michael.smith at usace.army.mil
>>>
>>>
>>> From: <pdal-bounces at lists.osgeo.org 
>>> <mailto:pdal-bounces at lists.osgeo.org>> on behalf of Oscar Martinez 
>>> Rubi <o.rubi at esciencecenter.nl <mailto:o.rubi at esciencecenter.nl>>
>>> Date: Tuesday, August 11, 2015 at 11:04 AM
>>> To: Peter van Oosterom <P.J.M.vanOosterom at tudelft.nl 
>>> <mailto:P.J.M.vanOosterom at tudelft.nl>>, Albert Godfrind 
>>> <albert.godfrind at oracle.com <mailto:albert.godfrind at oracle.com>>, 
>>> "pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>" 
>>> <pdal at lists.osgeo.org <mailto:pdal at lists.osgeo.org>>
>>> Cc: Theo Tijssen <T.P.M.Tijssen at tudelft.nl 
>>> <mailto:T.P.M.Tijssen at tudelft.nl>>, "mike.horhammer at oracle.com 
>>> <mailto:mike.horhammer at oracle.com>" <mike.horhammer at oracle.com 
>>> <mailto:mike.horhammer at oracle.com>>
>>> Subject: [EXTERNAL] Re: [pdal] Oracle PDAL queries not scaling
>>> Resent-From: Michael Smith <michael.smith at usace.army.mil 
>>> <mailto:michael.smith at usace.army.mil>>
>>>
>>>     Hi,
>>>
>>>     What I did now is to force statistics gathering, so:
>>>
>>>     ANALYZE TABLE AHN_BLCK compute system statistics for table;
>>>     BEGIN
>>>     dbms_stats.gather_table_stats('PDAL20M','AHN_BLCK',NULL,NULL,FALSE,'FOR
>>>     ALL COLUMNS SIZE AUTO',8,'ALL');
>>>     END;
>>>
>>>     And after doing this the queries are scalable, so in this way I
>>>     do not need to wait for the DB to learn...
>>>
>>>     Regards,
>>>
>>>     O.
>>>
>>>
>>>     On 11-08-15 16:51, Peter van Oosterom wrote:
>>>>     Hi Oscar,
>>>>
>>>>     It feels like when you fetch the data, this is based on a query
>>>>     execution plan that does a full table scan to get the blocks.
>>>>     Even if there is an index, the database may not use this.
>>>>     However, the database may notice that the actual query
>>>>     execution was disappointing (collecting statistics), and that
>>>>     after repeating the same tests, the database behaviour changed
>>>>     its behaviour and does scale well.
>>>>
>>>>     [others: this was not in email of Oscar, but after repeating
>>>>     the test the data was fetched in about 0.02 seconds for all
>>>>     sizes 20M, 210M and 2201M. So, also the fetching in case of
>>>>     small dataset becomes significantly faster form 0.5 vs. 0.02
>>>>     seconds.]
>>>>
>>>>     Would be good to see the actual query execution plain or force
>>>>     the database to use the index (with an hint). My hand-on
>>>>     practical Oracle syntax knowledge is too low to give exact hits
>>>>     how to do this, but perhaps others can help here.
>>>>
>>>>     Kind regards, Peter.
>>>>
>>>>
>>>>     On 11-8-2015 16:26, Oscar Martinez Rubi wrote:
>>>>>     Hi,
>>>>>
>>>>>     I have investigated a bit more this issue.
>>>>>
>>>>>     I wanted to see what data does the OCI reader actually reads,
>>>>>     so I executed the pre-selection query out of PDAL, in python.
>>>>>     So I run the attached script (freshly after loading the data).
>>>>>
>>>>>     The script runs the same exact query as done in PDAL twice and
>>>>>     prints for each run the number of returned blocks, time spent
>>>>>     in the query and time spent to fetch the results.
>>>>>
>>>>>     the exact query is:
>>>>>
>>>>>     SELECT
>>>>>         l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN",
>>>>>     l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS",
>>>>>     l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM", l."POINTS", b.pc
>>>>>     FROM
>>>>>         AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
>>>>>     WHERE
>>>>>         l.obj_id = b.id
>>>>>         AND
>>>>>         SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;
>>>>>
>>>>>     The results I get are:
>>>>>
>>>>>     20M run 1:
>>>>>         #blocks: 12
>>>>>         query time[s]: 0.113833904266
>>>>>         fetch time[s]: *0.571593046188*
>>>>>     20M run 2:
>>>>>         #blocks: 12
>>>>>         query time[s]: 0.000102996826172
>>>>>         fetch time[s]: *0.500910997391*
>>>>>     210M run 1:
>>>>>         #blocks: 13
>>>>>         query time[s]: 0.0586049556732
>>>>>         fetch time[s]: *5.09832000732*
>>>>>     210M run 2:
>>>>>         #blocks: 13
>>>>>         query time[s]: 0.000245094299316
>>>>>         fetch time[s]: *5.05038785934*
>>>>>     2201M run 1:
>>>>>         #blocks: 13
>>>>>         query time[s]: 0.070690870285
>>>>>         fetch time[s]: *52.4960811138*
>>>>>     2201M run 2:
>>>>>         #blocks: 13
>>>>>         query time[s]: 0.000225067138672
>>>>>         fetch time[s]: *53.1006689072*
>>>>>
>>>>>     So, even though the query times and the number of returned
>>>>>     blocks are similar the fetch times are the not. We can see the
>>>>>     scaling issue there. Somehow the fetching is much more
>>>>>     expensive (10x) when points are 10x.
>>>>>
>>>>>     I also noticed that after a while doing queries the times get
>>>>>     much better and scalable even when I do new queries with other
>>>>>     polygons. So, the first queries suffer of scaling issues but
>>>>>     later it gets better.
>>>>>
>>>>>     Any idea why?
>>>>>
>>>>>     Regards,
>>>>>
>>>>>     O.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>     On 10-08-15 18:40, Albert Godfrind wrote:
>>>>>>     Like many tools that access an Oracle database, we lack the
>>>>>>     ability to see what actually happens in the database at a
>>>>>>     detailed level, i.e. which actual queries are sent, and how
>>>>>>     the database executes them in terms of CPU use, logical and
>>>>>>     physical I/Os, network throughput and latency.
>>>>>>
>>>>>>     So I think it is important to add some debugging / tracing
>>>>>>     facility to let me see what happens:
>>>>>>
>>>>>>     1) An option to make PDAL (actually the OCI driver here) log
>>>>>>     each SQL statement it executes, together with the elapsed
>>>>>>     time and the number of rows (blocks) fetched. Obviously we
>>>>>>     have that statement in the input XML file, but a trace would
>>>>>>     put everything in a single log and include proper measurements.
>>>>>>
>>>>>>     2) More important: an option to make the OCI driver enable
>>>>>>     SQL tracing at the database side. This is simple to do by
>>>>>>     just issuing an ?ALTER SESSION ?? statement before running
>>>>>>     the queries. The resulting trace will show all details about
>>>>>>     execution times as well as resource consumption (CPU and IO)
>>>>>>     and wait times. That could be added as an option in the XML
>>>>>>     file. Or maybe extend the XML file with the option to specify
>>>>>>     a SQ statement to be performed before each query (we could
>>>>>>     then use that to manually add the ALTER SESSION statement.
>>>>>>
>>>>>>     The resulting trace can help isolate the bottleneck as one of:
>>>>>>
>>>>>>     1) the I/Os in the database, to fetch the blocks from disk
>>>>>>     (mostly I/O)
>>>>>>     2) the network time to pass the blocks to the PDAL client
>>>>>>     (network throughput and latency)
>>>>>>     3) the time to process the blocks in the PDAL client (mostly CPU)
>>>>>>
>>>>>>     Albert
>>>>>>
>>>>>>>     On 5-Aug-2015, at 12:26, Oscar Martinez Rubi
>>>>>>>     <o.rubi at esciencecenter.nl <mailto:o.rubi at esciencecenter.nl>>
>>>>>>>     wrote:
>>>>>>>
>>>>>>>     Hi,
>>>>>>>
>>>>>>>     I did a test to see how good Oracle with PDAL scale with
>>>>>>>     bigger data sets. I had 3 datasets that are self-contained
>>>>>>>     with 20M, 210M and 2201M points. I loaded them in different
>>>>>>>     Oracle DBs with PDAL and laz-perf. And, for each of them I
>>>>>>>     ran 7 queries (via a pdal pipeline that preselects blocks,
>>>>>>>     applies a crop and then write to a LAS file)
>>>>>>>
>>>>>>>     The results are in the attached file.
>>>>>>>
>>>>>>>     Regarding the loading, for the 20M I only used one core (it
>>>>>>>     is only one file) while for the others I used 16 cores, i.e.
>>>>>>>     16 simult. PDAL instances loading data to Oracle. I opened
>>>>>>>     an issue in GitHub because I noticed that in some of the
>>>>>>>     runs the size that I got was too large, and I do not know
>>>>>>>     what caused that. The attached numbers are when everything
>>>>>>>     seemed to work and the sizes were as expected.
>>>>>>>
>>>>>>>     This message, though, is about the queries. Each query is
>>>>>>>     run twice in each DB. As you can see in the results file,
>>>>>>>     for 10x more points in the data set the queries are 10x
>>>>>>>     slower, at least for the first run (with the 2201M the
>>>>>>>     second run is much faster but this does not happen with the
>>>>>>>     210M).
>>>>>>>
>>>>>>>     Find also attached one of the XML that i used for the
>>>>>>>     queries (example is for query1). Note that the geometry is
>>>>>>>     previously inserted in oracle so I can use to pre-filter
>>>>>>>     blocks with the query option in oci reader
>>>>>>>
>>>>>>>     First I though that maybe the query option in the oci reader
>>>>>>>     in the XML was ignored and that all the blocks of the
>>>>>>>     dataset were being processed by PDAL (that would explain 10x
>>>>>>>     more points 10x slower queries) but I ran a pdal pipeline
>>>>>>>     for query1 with verbose and I saw that the crop filter
>>>>>>>     "only" processed 120000 points which makes sense taking into
>>>>>>>     account that region of query 1 only has 74818 points. Or
>>>>>>>     maybe the crop still process all the blocks extents but only
>>>>>>>     opens and decompress the points of the overlapping ones?
>>>>>>>
>>>>>>>     Any idea what is happening?
>>>>>>>
>>>>>>>     Regards,
>>>>>>>
>>>>>>>     O.
>>>>>>>     <results.txt><query1.xml>
>>>>>>
>>>>>>     --
>>>>>>     ORACLE <BLOCKEDoracle.comBLOCKED>
>>>>>>     Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00
>>>>>>     80 67| Mobile: +33 6 09 97 27 23| Skype:albert-godfrind
>>>>>>     <skype:albert-godfrind>
>>>>>>     OracleServer Technologies
>>>>>>     400 Av. Roumanille,BP 309 |06906 Sophia Antipolis cedex|France
>>>>>>     Everything you ever wanted to know about Oracle Spatial
>>>>>>     <BLOCKEDapress.com/9781590598993BLOCKED>
>>>>>>
>>>>>>     <BLOCKEDlocationintelligence.net/dc/BLOCKED>
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>
>>>>
>>>>     -- 
>>>>     Peter van OosteromP.J.M.vanOosterom at tudelft.nl
>>>>     Section GIS technology      (room 00-west-520) Department OTB
>>>>     Faculty of Architecture and the Built Environment, TU Delft
>>>>     tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
>>>>     fax (+31) 15 2784422        P.O. Box 5043, 2600 GA Delft, NL
>>>>     BLOCKEDgeomatics.tudelft.nlBLOCKED  MSc Geomatics
>>>>     BLOCKEDmsc-gima.nlBLOCKED       MSc GIMA (Geo-Info Management&Appl)
>>>>     BLOCKEDgdmc.nlBLOCKED  
>>>>
>>>
>>
>
>
> -- 
> Peter van OosteromP.J.M.vanOosterom at tudelft.nl
> Section GIS technology      Department OTB
> Faculty of Architecture and the Built Environment, TU Delft
> tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
> fax (+31) 15 2784422        P.O. Box 5030, 2600 GA Delft, NL
> http://geomatics.tudelft.nl  MSc Geomatics
> http://www.msc-gima.nl       MSc GIMA (Geo-Info Management&Appl)
> http://www.gdmc.nl  
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/240f1ec0/attachment-0001.html>

From albert.godfrind at oracle.com  Wed Aug 12 05:38:29 2015
From: albert.godfrind at oracle.com (Albert Godfrind)
Date: Wed, 12 Aug 2015 14:38:29 +0200
Subject: [pdal] [EXTERNAL] Re:  Oracle PDAL queries not scaling
In-Reply-To: <55CB1A05.603@tudelft.nl>
References: <55C1E4E4.6080100@esciencecenter.nl>
	<8CDC3A42-0C98-461B-9569-33CB19E7D94E@oracle.com>
	<55CA061C.5080603@esciencecenter.nl> <55CA0C0C.6090700@tudelft.nl>
	<55CA0EEA.3030904@esciencecenter.nl>
	<D1EFEDEF.1172ED%michael.smith@erdc.dren.mil>
	<55CB17B7.5040907@esciencecenter.nl> <55CB1A05.603@tudelft.nl>
Message-ID: <DF67E9C1-1AD8-486C-9991-559DEA387189@oracle.com>

By default stats gathering happens on a statistical sample of the data, and it does typically not take very long.

It is done automatically by the database. It runs a daily job to collect stats for those tables whose cardinality had significantly changed. By default the job runs at 22:00. But your DBA may have changed that or even disabled it.

I still wonder why the lack of stats impacts that query. We do not keep statistics for spatial distribution before 12c, and use a fixed selectivity that makes the spatial index appealing to the optimizer in pretty much all cases, especially for such simple filter queries. Stats start playing a role when queries join multiple tables and multiple selection criteria. 

But then having up to date statistics is a better solution than forcing a query through hints. 

Albert

--
Albert Godfrind
+33 6 09 97 27 23
Sent from my iPhone

> On 12 ao?t 2015, at 12:03, Peter van Oosterom <P.J.M.vanOosterom at tudelft.nl> wrote:
> 
> Hi Oscar,
> 
> Great that PDAL/Oracle now scales well!
> 
> It might be that for large datasets analyze+stats may get expensive part of load time.
> To avoid this step, an alternative would be to add hint for query optimizer to use index.
> 
> However, perhaps the analyze+stats at block level are not too expensive (as it would
> be at point level) and in that case the needed time might be neglectable, and in that
> case better to do so (as in your script now and without hit).
> 
> Good to check how much time these steps take and then we know what to do
> (especially for loading complete ahn with 640 billion points).
> 
> Kind regards, Peter.
> 
> Oscar Martinez Rubi schreef op 12-8-2015 om 11:53:
>> Hi,
>> 
>> When you say that statistics are auto-gathered...by who? PDAL or Oracle? 
>>  - In PDAL OCIWritter I do not see anything to do the analyze and gather_stats. I would maybe put it just after creating the indexes, and also optional as the indexes creation, because you only want to do that after the loading of the last file.
>>  - In Oracle itself I have not disabled anything (as far as I remember) and they are indeed computed automatically after a while, the problem is how long is "this while", to be sure, and as you recommend, it is maybe just better to do it your own once you know the loading is over.
>> 
>> So, bottom line: I do the loading of all the files (with pdal) with deactivated indexing. And then, the stuff I do after the last pdal loading is:
>> 
>>  - Create primary key on obj_id/blk_id. This is the one you suggest
>>  - Insert info in USER_SDO_GEOM_METADATA of the whole extent of all the loaded data (from different files and in different PDAL runs)
>>  - Create the spatial index
>>  - Analyze and gather stats
>> 
>> The SQL commands for that are:
>> 
>> ALTER TABLE AHN_BLCK ADD CONSTRAINT AHN_BLCK_PK PRIMARY KEY (OBJ_ID, BLK_ID) USING INDEX TABLESPACE INDX;
>> 
>> INSERT INTO USER_SDO_GEOM_METADATA VALUES ('AHN_BLCK','BLK_EXTENT',
>>                SDO_DIM_ARRAY(SDO_DIM_ELEMENT('X',60000.0,100000.0,0.0001),
>>               SDO_DIM_ELEMENT('Y',425000.0,475000.0,0.0001)),28992);
>> 
>> CREATE INDEX AHN_BLCK_SIDX ON AHN_BLCK (BLK_EXTENT) INDEXTYPE IS MDSYS.SPATIAL_INDEX PARAMETERS ('TABLESPACE=INDX WORK_TABLESPACE=PCWORK LAYER_GTYPE=POLYGON SDO_INDX_DIMS=2 SDO_RTR_PCTFREE=0') PARALLEL 16 ;
>> 
>> ANALYZE TABLE AHN_BLCK  COMPUTE SYSTEM STATISTICS FOR TABLE;
>> 
>> BEGIN
>>     DBMS_STATS.GATHER_TABLE_STATS('PDAL23090M','AHN_BLCK',NULL,NULL,FALSE,'FOR ALL COLUMNS SIZE AUTO',8,'ALL');
>> END;
>> 
>> After the doing all these steps the query times are as expected so I am going to assume those are the exact proper steps. The times are now scalable and quite nice (right now still busy with the 23 billion dataset but I guess it is safe to assume they will also be fine ;) )!
>> 
>> Time[s]      pdal20M    pdal210M    pdal2201M  pdal23090M
>> ---------  ---------  ----------  -----------  ------------
>> 01_0            0.63        0.37         0.41  -
>> 01_1            0.18        0.2          0.22  -
>> 02_0            1.18        1.51         1.54  -
>> 02_1            0.96        0.96         0.93  -
>> 03_0            0.24        0.25         0.25  -
>> 03_1            0.18        0.18         0.18  -
>> 04_0            1.49        1.53         1.44  -
>> 04_1            1.05        1.07         1.06  -
>> 05_0            0.66        0.78         0.76  -
>> 05_1            0.49        0.51         0.49  -
>> 06_0            1.42        1.61         1.64  -
>> 06_1            1.17        1.2          1.21  -
>> 07_0            1.6         2.12         2.15  -
>> 07_1            1.62        1.35         1.43  -
>> 
>> Thanks for your help and suggestions!
>> 
>> Regards,
>> 
>> O.
>> 
>> 
>>> On 12-08-15 00:30, Smith, Michael ERDC-RDE-CRREL-NH wrote:
>>> The statistics should actually auto gather (unless you've disabled that part). Its done as part of the DBMS Auto tasks and should gather when the tables are stale. Although this is more for a production type operation. If you are doing testing, you absolutely should make sure your statistics are up to date otherwise you will get bad access plans. 
>>> 
>>> Its also recommended to set a unique index on your Block table on the Obj_ID/Blk_ID (although this is primarily used to individually select pointclouds).  The more info you can give the optimizer, the better your query will perform. 
>>> 
>>> You can run (and should) explain plan's on your data access queries and see what estimates the optimizer returns. If they don't match what you expect, then you're probably feeding bad information to the optimizer.
>>> 
>>> Mike
>>> 
>>> ----
>>> Michael Smith
>>> US Army Corps
>>> Remote Sensing GIS/Center
>>> michael.smith at usace.army.mil
>>> 
>>> 
>>> From: <pdal-bounces at lists.osgeo.org> on behalf of Oscar Martinez Rubi <o.rubi at esciencecenter.nl>
>>> Date: Tuesday, August 11, 2015 at 11:04 AM
>>> To: Peter van Oosterom <P.J.M.vanOosterom at tudelft.nl>, Albert Godfrind <albert.godfrind at oracle.com>, "pdal at lists.osgeo.org" <pdal at lists.osgeo.org>
>>> Cc: Theo Tijssen <T.P.M.Tijssen at tudelft.nl>, "mike.horhammer at oracle.com" <mike.horhammer at oracle.com>
>>> Subject: [EXTERNAL] Re: [pdal] Oracle PDAL queries not scaling
>>> Resent-From: Michael Smith <michael.smith at usace.army.mil>
>>> 
>>> Hi,
>>> 
>>> What I did now is to force statistics gathering, so:
>>> 
>>> ANALYZE TABLE AHN_BLCK compute system statistics for table;
>>> BEGIN
>>>     dbms_stats.gather_table_stats('PDAL20M','AHN_BLCK',NULL,NULL,FALSE,'FOR ALL COLUMNS SIZE AUTO',8,'ALL');
>>> END;
>>> 
>>> And after doing this the queries are scalable, so in this way I do not need to wait for the DB to learn...
>>> 
>>> Regards,
>>> 
>>> O.
>>> 
>>> 
>>>> On 11-08-15 16:51, Peter van Oosterom wrote:
>>>> Hi Oscar,
>>>> 
>>>> It feels like when you fetch the data, this is based on a query execution plan that does a full table scan to get the blocks. Even if there is an index, the database may not use this. However, the database may notice that the actual query execution was disappointing (collecting statistics), and that after repeating the same tests, the database behaviour changed its behaviour and does scale well. 
>>>> 
>>>> [others: this was not in email of Oscar, but after repeating the test the data was fetched in about 0.02 seconds for all sizes 20M, 210M and 2201M. So, also the fetching in case of small dataset becomes significantly faster form 0.5 vs. 0.02 seconds.]
>>>> 
>>>> Would be good to see the actual query execution plain or force the database to use the index (with an hint). My hand-on practical Oracle syntax knowledge is too low to give exact hits how to do this, but perhaps others can help here.
>>>> 
>>>> Kind regards, Peter.
>>>> 
>>>> 
>>>>> On 11-8-2015 16:26, Oscar Martinez Rubi wrote:
>>>>> Hi,
>>>>> 
>>>>> I have investigated a bit more this issue.
>>>>> 
>>>>> I wanted to see what data does the OCI reader actually reads, so I executed the pre-selection query out of PDAL, in python. So I run the attached script (freshly after loading the data).
>>>>> 
>>>>> The script runs the same exact query as done in PDAL twice and prints for each run the number of returned blocks, time spent in the query and time spent to fetch the results.
>>>>> 
>>>>> the exact query is:
>>>>> 
>>>>> SELECT 
>>>>>     l."OBJ_ID", l."BLK_ID", l."BLK_EXTENT", l."BLK_DOMAIN", l."PCBLK_MIN_RES", l."PCBLK_MAX_RES", l."NUM_POINTS", l."NUM_UNSORTED_POINTS", l."PT_SORT_DIM",  l."POINTS", b.pc
>>>>> FROM 
>>>>>     AHN_BLCK l, AHN_BASE b, QUERY_POLYGONS g
>>>>> WHERE
>>>>>     l.obj_id = b.id
>>>>>     AND
>>>>>     SDO_FILTER(l.blk_extent,g.geom) = 'TRUE' AND g.id = 1;
>>>>> 
>>>>> The results I get are:
>>>>> 
>>>>> 20M run 1:                                            
>>>>>     #blocks: 12
>>>>>     query time[s]: 0.113833904266
>>>>>     fetch time[s]: 0.571593046188
>>>>> 20M run 2:                                            
>>>>>     #blocks: 12
>>>>>     query time[s]: 0.000102996826172
>>>>>     fetch time[s]: 0.500910997391
>>>>> 210M run 1:  
>>>>>     #blocks: 13
>>>>>     query time[s]: 0.0586049556732
>>>>>     fetch time[s]: 5.09832000732
>>>>> 210M run 2:  
>>>>>     #blocks: 13
>>>>>     query time[s]: 0.000245094299316
>>>>>     fetch time[s]: 5.05038785934
>>>>> 2201M run 1:  
>>>>>     #blocks: 13
>>>>>     query time[s]: 0.070690870285
>>>>>     fetch time[s]: 52.4960811138
>>>>> 2201M run 2:  
>>>>>     #blocks: 13
>>>>>     query time[s]: 0.000225067138672
>>>>>     fetch time[s]: 53.1006689072
>>>>> 
>>>>> So, even though the query times and the number of returned blocks are similar the fetch times are the not. We can see the scaling issue there. Somehow the fetching is much more expensive (10x) when points are 10x.
>>>>> 
>>>>> I also noticed that after a while doing queries the times get much better and scalable even when I do new queries with other polygons. So, the first queries suffer of scaling issues but later it gets better. 
>>>>> 
>>>>> Any idea why?
>>>>> 
>>>>> Regards,
>>>>> 
>>>>> O.
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>>> On 10-08-15 18:40, Albert Godfrind wrote:
>>>>>> Like many tools that access an Oracle database, we lack the ability to see what actually happens in the database at a detailed level, i.e. which actual queries are sent, and how the database executes them in terms of CPU use, logical and physical I/Os, network throughput and latency.
>>>>>> 
>>>>>> So I think it is important to add some debugging / tracing facility to let me see what happens:
>>>>>> 
>>>>>> 1) An option to make PDAL (actually the OCI driver here) log each SQL statement it executes, together with the elapsed time and the number of rows (blocks) fetched. Obviously we have that statement in the input XML file, but a trace would put everything in a single log and include proper measurements.
>>>>>> 
>>>>>> 2) More important: an option to make the OCI driver enable SQL tracing at the database side. This is simple to do by just issuing an ?ALTER SESSION ?? statement before running the queries. The resulting trace will show all details about execution times as well as resource consumption (CPU and IO) and wait times. That could be added as an option in the XML file. Or maybe extend the XML file with the option to specify a SQ statement to be performed before each query (we could then use that to manually add the ALTER SESSION statement.
>>>>>> 
>>>>>> The resulting trace can help isolate the bottleneck as one of:
>>>>>> 
>>>>>> 1) the I/Os in the database, to fetch the blocks from disk (mostly I/O)
>>>>>> 2) the network time to pass the blocks to the PDAL client (network throughput and latency)
>>>>>> 3) the time to process the blocks in the PDAL client (mostly CPU)
>>>>>> 
>>>>>> Albert
>>>>>> 
>>>>>>> On 5-Aug-2015, at 12:26, Oscar Martinez Rubi <o.rubi at esciencecenter.nl> wrote:
>>>>>>> 
>>>>>>> Hi,
>>>>>>> 
>>>>>>> I did a test to see how good Oracle with PDAL scale with bigger data sets. I had 3 datasets that are self-contained with 20M, 210M and 2201M points. I loaded them in different Oracle DBs with PDAL and laz-perf. And, for each of them I ran 7 queries (via a pdal pipeline that preselects blocks, applies a crop and then write to a LAS file)
>>>>>>> 
>>>>>>> The results are in the attached file.
>>>>>>> 
>>>>>>> Regarding the loading, for the 20M I only used one core (it is only one file) while for the others I used 16 cores, i.e. 16 simult. PDAL instances loading data to Oracle. I opened an issue in GitHub because I noticed that in some of the runs the size that I got was too large, and I do not know what caused that. The attached numbers are when everything seemed to work and the sizes were as expected.
>>>>>>> 
>>>>>>> This message, though, is about the queries. Each query is run twice in each DB. As you can see in the results file, for 10x more points in the data set the queries are 10x slower, at least for the first run (with the 2201M the second run is much faster but this does not happen with the 210M).
>>>>>>> 
>>>>>>> Find also attached one of the XML that i used for the queries (example is for query1). Note that the geometry is previously inserted in oracle so I can use to pre-filter blocks with the query option in oci reader
>>>>>>> 
>>>>>>> First I though that maybe the query option in the oci reader in the XML was ignored and that all the blocks of the dataset were being processed by PDAL (that would explain 10x more points 10x slower queries) but I ran a pdal pipeline for query1 with verbose and I saw that the crop filter "only" processed 120000 points which makes sense taking into account that region of query 1 only has 74818 points. Or maybe the crop still process all the blocks extents but only opens and decompress the points of the overlapping ones?
>>>>>>> 
>>>>>>> Any idea what is happening?
>>>>>>> 
>>>>>>> Regards,
>>>>>>> 
>>>>>>> O.
>>>>>>> <results.txt><query1.xml>
>>>>>> 
>>>>>> --
>>>>>> 
>>>>>> Albert Godfrind | Geospatial technologies | Tel: +33 4 93 00 80 67 | Mobile: +33 6 09 97 27 23 | Skype: albert-godfrind
>>>>>> Oracle Server Technologies
>>>>>> 400 Av. Roumanille, BP 309  | 06906 Sophia Antipolis cedex | France
>>>>>> Everything you ever wanted to know about Oracle Spatial
>>>> 
>>>> 
>>>> -- 
>>>> Peter van Oosterom          P.J.M.vanOosterom at tudelft.nl
>>>> Section GIS technology      (room 00-west-520) Department OTB
>>>> Faculty of Architecture and the Built Environment, TU Delft
>>>> tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
>>>> fax (+31) 15 2784422        P.O. Box 5043, 2600 GA Delft, NL
>>>> BLOCKEDgeomatics.tudelft.nlBLOCKED MSc Geomatics
>>>> BLOCKEDmsc-gima.nlBLOCKED      MSc GIMA (Geo-Info Management&Appl)
>>>> BLOCKEDgdmc.nlBLOCKED 
>>>> 
> 
> 
> -- 
> Peter van Oosterom          P.J.M.vanOosterom at tudelft.nl
> Section GIS technology      Department OTB
> Faculty of Architecture and the Built Environment, TU Delft
> tel (+31) 15 2786950        Julianalaan 134, 2628 BL Delft, NL
> fax (+31) 15 2784422        P.O. Box 5030, 2600 GA Delft, NL
> http://geomatics.tudelft.nl MSc Geomatics
> http://www.msc-gima.nl      MSc GIMA (Geo-Info Management&Appl)
> http://www.gdmc.nl 
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/6ae2ac78/attachment-0001.html>

From howard at hobu.co  Wed Aug 12 07:21:30 2015
From: howard at hobu.co (Howard Butler)
Date: Wed, 12 Aug 2015 10:21:30 -0400
Subject: [pdal] PDAL Python bindings
In-Reply-To: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
References: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
Message-ID: <B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>


> On Aug 12, 2015, at 3:37 AM, Stefan Ziegler <stefan.ziegler.de at gmail.com> wrote:
> 
> Hi 
> 
> The project goals are mentioning Python bindings for PDAL:
> 
> http://www.pdal.io/development/goals.html
> 
> Are there any bindings available? If not, could this be sponsered?

There was some effort in creating some SWIG bindings for PDAL, but I'm not sure it's the right approach. With the programmable and predicate filters, you have most of the Python capability you would need, and the only thing I can think of that isn't there yet is the ability to execute a pipeline into a Numpy array (a Python writer, if you will).

What exactly did you want to achieve with Python bindings for PDAL?

Howard

From stefan.ziegler.de at gmail.com  Wed Aug 12 10:04:20 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Wed, 12 Aug 2015 19:04:20 +0200
Subject: [pdal] PDAL Python bindings
In-Reply-To: <B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>
References: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
	<B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>
Message-ID: <CAJvo+1_t2NkrLQ-YhTnTHqp89SzOp8saCNq0uvG-2D1kMmm4kQ@mail.gmail.com>

Use case 1: We have approx. 1000 tiles (one sqkm each) and need to
reproject them. Afterwards we nee to adjust the bounding boxes to "nice"
coordinates again. Let's say the source bbox is something like
620'000/240'000, 621'000/241'000. After reprojecting it will be
2'620'000.55/1'240'000.34, 2'621'000.58/1'241'000.37. But we want a bbox
like this: 2'620'000/1'240'000, 2'621'000/1'241'000. I can achieve this
with available pdal features (tindex, translate etc.) and some python
script for the loop with system calls (for pdal).

Use case 2: Some small (wsgi) webservice like requesting lidar data with a
bounding/polygon as parameter value. Again I could do this wie os.system().

Any hints are welcomed if I do not see the wood for the trees :)

regards
Stefan

On Wed, Aug 12, 2015 at 4:21 PM, Howard Butler <howard at hobu.co> wrote:

>
> > On Aug 12, 2015, at 3:37 AM, Stefan Ziegler <stefan.ziegler.de at gmail.com>
> wrote:
> >
> > Hi
> >
> > The project goals are mentioning Python bindings for PDAL:
> >
> > http://www.pdal.io/development/goals.html
> >
> > Are there any bindings available? If not, could this be sponsered?
>
> There was some effort in creating some SWIG bindings for PDAL, but I'm not
> sure it's the right approach. With the programmable and predicate filters,
> you have most of the Python capability you would need, and the only thing I
> can think of that isn't there yet is the ability to execute a pipeline into
> a Numpy array (a Python writer, if you will).
>
> What exactly did you want to achieve with Python bindings for PDAL?
>
> Howard
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/a2c0bcca/attachment.html>

From andrew.bell.ia at gmail.com  Wed Aug 12 11:36:35 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 12 Aug 2015 13:36:35 -0500
Subject: [pdal] PDAL Python bindings
In-Reply-To: <CAJvo+1_t2NkrLQ-YhTnTHqp89SzOp8saCNq0uvG-2D1kMmm4kQ@mail.gmail.com>
References: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
	<B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>
	<CAJvo+1_t2NkrLQ-YhTnTHqp89SzOp8saCNq0uvG-2D1kMmm4kQ@mail.gmail.com>
Message-ID: <CACJ51z07WMbfpk4ukuzr=CKxmKQehi1ZED0F5Bvu_vOJXepapg@mail.gmail.com>

On Wed, Aug 12, 2015 at 12:04 PM, Stefan Ziegler <
stefan.ziegler.de at gmail.com> wrote:

> Use case 1: We have approx. 1000 tiles (one sqkm each) and need to
> reproject them. Afterwards we nee to adjust the bounding boxes to "nice"
> coordinates again. Let's say the source bbox is something like
> 620'000/240'000, 621'000/241'000. After reprojecting it will be
> 2'620'000.55/1'240'000.34, 2'621'000.58/1'241'000.37. But we want a bbox
> like this: 2'620'000/1'240'000, 2'621'000/1'241'000. I can achieve this
> with available pdal features (tindex, translate etc.) and some python
> script for the loop with system calls (for pdal).
>

Are you just saying that you want to write python instead of some shell to
invoke pdal?  Not sure how a python API would help with that.  This is
probably best done with a pipeline (XML) that you could invoke with `pdal
pipeline`, but maybe I'm not understanding.


> Use case 2: Some small (wsgi) webservice like requesting lidar data with a
> bounding/polygon as parameter value. Again I could do this wie os.system().
>

There are lots of tools out there to do this in various ways.  Hobu Inc.
makes greyhound (not sure on its release status), which can serve a single
file of data based on a query, but we'll have something much fancier and
more efficient shortly.  I still don't understand what kind of an API would
be beneficial for this.  You may have to explain a bit more.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/2b31c096/attachment.html>

From stefan.ziegler.de at gmail.com  Wed Aug 12 12:02:25 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Wed, 12 Aug 2015 21:02:25 +0200
Subject: [pdal] PDAL Python bindings
In-Reply-To: <CACJ51z07WMbfpk4ukuzr=CKxmKQehi1ZED0F5Bvu_vOJXepapg@mail.gmail.com>
References: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
	<B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>
	<CAJvo+1_t2NkrLQ-YhTnTHqp89SzOp8saCNq0uvG-2D1kMmm4kQ@mail.gmail.com>
	<CACJ51z07WMbfpk4ukuzr=CKxmKQehi1ZED0F5Bvu_vOJXepapg@mail.gmail.com>
Message-ID: <CAJvo+18GJDfAXr7c_+2v7CQbyc=KT=iFJeUU=w2HamVWPLT_RA@mail.gmail.com>

If you want retile a mosaic from 1 sqkm tiles to e.g. 750 m * 750 m tiles,
I would use python for calculating the new bounding boxes and invoke pdal.
Just the same as with GDAL. I can also make system calls but I prefer
gdal/ogr python bindings.

Stefan

On Wed, Aug 12, 2015 at 8:36 PM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

> On Wed, Aug 12, 2015 at 12:04 PM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
>
>> Use case 1: We have approx. 1000 tiles (one sqkm each) and need to
>> reproject them. Afterwards we nee to adjust the bounding boxes to "nice"
>> coordinates again. Let's say the source bbox is something like
>> 620'000/240'000, 621'000/241'000. After reprojecting it will be
>> 2'620'000.55/1'240'000.34, 2'621'000.58/1'241'000.37. But we want a bbox
>> like this: 2'620'000/1'240'000, 2'621'000/1'241'000. I can achieve this
>> with available pdal features (tindex, translate etc.) and some python
>> script for the loop with system calls (for pdal).
>>
>
> Are you just saying that you want to write python instead of some shell to
> invoke pdal?  Not sure how a python API would help with that.  This is
> probably best done with a pipeline (XML) that you could invoke with `pdal
> pipeline`, but maybe I'm not understanding.
>
>
>> Use case 2: Some small (wsgi) webservice like requesting lidar data with
>> a bounding/polygon as parameter value. Again I could do this wie
>> os.system().
>>
>
> There are lots of tools out there to do this in various ways.  Hobu Inc.
> makes greyhound (not sure on its release status), which can serve a single
> file of data based on a query, but we'll have something much fancier and
> more efficient shortly.  I still don't understand what kind of an API would
> be beneficial for this.  You may have to explain a bit more.
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/612387b3/attachment.html>

From Michael.Smith at erdc.dren.mil  Wed Aug 12 12:22:43 2015
From: Michael.Smith at erdc.dren.mil (Smith, Michael ERDC-RDE-CRREL-NH)
Date: Wed, 12 Aug 2015 19:22:43 +0000
Subject: [pdal] [EXTERNAL] Re:  PDAL Python bindings
In-Reply-To: <CAJvo+18GJDfAXr7c_+2v7CQbyc=KT=iFJeUU=w2HamVWPLT_RA@mail.gmail.com>
References: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
	<B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>
	<CAJvo+1_t2NkrLQ-YhTnTHqp89SzOp8saCNq0uvG-2D1kMmm4kQ@mail.gmail.com>
	<CACJ51z07WMbfpk4ukuzr=CKxmKQehi1ZED0F5Bvu_vOJXepapg@mail.gmail.com>
	<CAJvo+18GJDfAXr7c_+2v7CQbyc=KT=iFJeUU=w2HamVWPLT_RA@mail.gmail.com>
Message-ID: <D1F114C0.1173AC%michael.smith@erdc.dren.mil>

Stefan,

You can actually do that with the pdal split command. You can create a tile index and then feed that to the split command and set the length parameter on the split command.

Mike


----
Michael Smith
US Army Corps
Remote Sensing GIS/Center
michael.smith at usace.army.mil


From: <pdal-bounces at lists.osgeo.org<mailto:pdal-bounces at lists.osgeo.org>> on behalf of Stefan Ziegler <stefan.ziegler.de at gmail.com<mailto:stefan.ziegler.de at gmail.com>>
Date: Wednesday, August 12, 2015 at 3:02 PM
To: Andrew Bell <andrew.bell.ia at gmail.com<mailto:andrew.bell.ia at gmail.com>>
Cc: "pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>" <pdal at lists.osgeo.org<mailto:pdal at lists.osgeo.org>>
Subject: [EXTERNAL] Re: [pdal] PDAL Python bindings
Resent-From: Michael Smith <michael.smith at usace.army.mil<mailto:michael.smith at usace.army.mil>>

If you want retile a mosaic from 1 sqkm tiles to e.g. 750 m * 750 m tiles, I would use python for calculating the new bounding boxes and invoke pdal. Just the same as with GDAL. I can also make system calls but I prefer gdal/ogr python bindings.

Stefan

On Wed, Aug 12, 2015 at 8:36 PM, Andrew Bell <andrew.bell.ia at gmail.com<mailto:andrew.bell.ia at gmail.com>> wrote:
On Wed, Aug 12, 2015 at 12:04 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com<mailto:stefan.ziegler.de at gmail.com>> wrote:
Use case 1: We have approx. 1000 tiles (one sqkm each) and need to reproject them. Afterwards we nee to adjust the bounding boxes to "nice" coordinates again. Let's say the source bbox is something like 620'000/240'000, 621'000/241'000. After reprojecting it will be 2'620'000.55/1'240'000.34, 2'621'000.58/1'241'000.37. But we want a bbox like this: 2'620'000/1'240'000, 2'621'000/1'241'000. I can achieve this with available pdal features (tindex, translate etc.) and some python script for the loop with system calls (for pdal).

Are you just saying that you want to write python instead of some shell to invoke pdal?  Not sure how a python API would help with that.  This is probably best done with a pipeline (XML) that you could invoke with `pdal pipeline`, but maybe I'm not understanding.

Use case 2: Some small (wsgi) webservice like requesting lidar data with a bounding/polygon as parameter value. Again I could do this wie os.system().

There are lots of tools out there to do this in various ways.  Hobu Inc. makes greyhound (not sure on its release status), which can serve a single file of data based on a query, but we'll have something much fancier and more efficient shortly.  I still don't understand what kind of an API would be beneficial for this.  You may have to explain a bit more.

--
Andrew Bell
andrew.bell.ia at gmail.com<mailto:andrew.bell.ia at gmail.com>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/494ec77f/attachment.html>

From stefan.ziegler.de at gmail.com  Wed Aug 12 12:25:47 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Wed, 12 Aug 2015 21:25:47 +0200
Subject: [pdal] [EXTERNAL] Re:  PDAL Python bindings
In-Reply-To: <D1F114C0.1173AC%michael.smith@erdc.dren.mil>
References: <CAJvo+1-rJUr5D2U8S58ti63W57HqMF44qDkSydXfNhFqtEZM5w@mail.gmail.com>
	<B2FB03A9-1185-4CCE-9337-67952B5F522C@hobu.co>
	<CAJvo+1_t2NkrLQ-YhTnTHqp89SzOp8saCNq0uvG-2D1kMmm4kQ@mail.gmail.com>
	<CACJ51z07WMbfpk4ukuzr=CKxmKQehi1ZED0F5Bvu_vOJXepapg@mail.gmail.com>
	<CAJvo+18GJDfAXr7c_+2v7CQbyc=KT=iFJeUU=w2HamVWPLT_RA@mail.gmail.com>
	<D1F114C0.1173AC%michael.smith@erdc.dren.mil>
Message-ID: <CAJvo+1-d5_RzCGBJ6ZMvTmgVWHYXiu34FzPqtoN=0i=26XYHtg@mail.gmail.com>

Thanks, I "knew" that there is some magic :) Gonna try that.

Stefan

On Wed, Aug 12, 2015 at 9:22 PM, Smith, Michael ERDC-RDE-CRREL-NH <
Michael.Smith at erdc.dren.mil> wrote:

> Stefan,
>
> You can actually do that with the pdal split command. You can create a
> tile index and then feed that to the split command and set the length
> parameter on the split command.
>
> Mike
>
>
> ----
> Michael Smith
> US Army Corps
> Remote Sensing GIS/Center
> michael.smith at usace.army.mil
>
>
> From: <pdal-bounces at lists.osgeo.org> on behalf of Stefan Ziegler <
> stefan.ziegler.de at gmail.com>
> Date: Wednesday, August 12, 2015 at 3:02 PM
> To: Andrew Bell <andrew.bell.ia at gmail.com>
> Cc: "pdal at lists.osgeo.org" <pdal at lists.osgeo.org>
> Subject: [EXTERNAL] Re: [pdal] PDAL Python bindings
> Resent-From: Michael Smith <michael.smith at usace.army.mil>
>
> If you want retile a mosaic from 1 sqkm tiles to e.g. 750 m * 750 m tiles,
> I would use python for calculating the new bounding boxes and invoke pdal.
> Just the same as with GDAL. I can also make system calls but I prefer
> gdal/ogr python bindings.
>
> Stefan
>
> On Wed, Aug 12, 2015 at 8:36 PM, Andrew Bell <andrew.bell.ia at gmail.com>
> wrote:
>
>> On Wed, Aug 12, 2015 at 12:04 PM, Stefan Ziegler <
>> stefan.ziegler.de at gmail.com> wrote:
>>
>>> Use case 1: We have approx. 1000 tiles (one sqkm each) and need to
>>> reproject them. Afterwards we nee to adjust the bounding boxes to "nice"
>>> coordinates again. Let's say the source bbox is something like
>>> 620'000/240'000, 621'000/241'000. After reprojecting it will be
>>> 2'620'000.55/1'240'000.34, 2'621'000.58/1'241'000.37. But we want a bbox
>>> like this: 2'620'000/1'240'000, 2'621'000/1'241'000. I can achieve this
>>> with available pdal features (tindex, translate etc.) and some python
>>> script for the loop with system calls (for pdal).
>>>
>>
>> Are you just saying that you want to write python instead of some shell
>> to invoke pdal?  Not sure how a python API would help with that.  This is
>> probably best done with a pipeline (XML) that you could invoke with `pdal
>> pipeline`, but maybe I'm not understanding.
>>
>>
>>> Use case 2: Some small (wsgi) webservice like requesting lidar data with
>>> a bounding/polygon as parameter value. Again I could do this wie
>>> os.system().
>>>
>>
>> There are lots of tools out there to do this in various ways.  Hobu Inc.
>> makes greyhound (not sure on its release status), which can serve a single
>> file of data based on a query, but we'll have something much fancier and
>> more efficient shortly.  I still don't understand what kind of an API would
>> be beneficial for this.  You may have to explain a bit more.
>>
>> --
>> Andrew Bell
>> andrew.bell.ia at gmail.com
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150812/e372355a/attachment.html>

From stefan.ziegler.de at gmail.com  Thu Aug 13 12:46:14 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Thu, 13 Aug 2015 21:46:14 +0200
Subject: [pdal] pdal tindex --merge problem with polygon clippping
Message-ID: <CAJvo+1-ZcZ3_9hqnj5VXa1yn3K1dctq=B3uLUPFt+wzBomkk-g@mail.gmail.com>

Hi

I'm trying to merge some las files with the following command:

pdal tindex --merge /home/stefan/tmp/lidar/srs/tileindex.gpkg --lyr_name
tileindex tmp.las

The input las files have an srs assigned (EPSG:21781). But the merged one
is EPSG:4326.

When I want to clip with --polygon parameter:

pdal tindex --merge /home/stefan/tmp/lidar/srs/tileindex.gpkg --lyr_name
tileindex --polygon "POLYGON ((593000 227000, 594000 227000, 594000 228000,
593000 228000, 593000 227000))" tmp.las

I get an empy las file. The polygon is the bounding box of one of the las
files.

Whe using pdal tindex --merge one is not allowed to use --t_srs. But the
variable is used in the mergeFile() method. So I'm a bit lost...

regards
Stefan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150813/de2751e1/attachment.html>

From stefan.ziegler.de at gmail.com  Thu Aug 13 21:16:43 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Fri, 14 Aug 2015 06:16:43 +0200
Subject: [pdal] pdal tindex --merge problem with polygon clippping
In-Reply-To: <CACJ51z2VSWPv5Va_d+DyBR=CZxsro=j_fN5uC5kUpAFnURw1CQ@mail.gmail.com>
References: <CAJvo+1-ZcZ3_9hqnj5VXa1yn3K1dctq=B3uLUPFt+wzBomkk-g@mail.gmail.com>
	<CACJ51z2VSWPv5Va_d+DyBR=CZxsro=j_fN5uC5kUpAFnURw1CQ@mail.gmail.com>
Message-ID: <CAJvo+1_F3rXo9S4GiQEf6zeDyif8p+UJ7W4P3w54wSesMr2m_A@mail.gmail.com>

find . -iname "*.laz" | pdal tindex tileindex.shp --a_srs EPSG:21781
--t_srs EPSG:21781 --fast_boundary --stdin

ogrinfo -al tileindex.shp:

Layer name: tileindex
Geometry: Polygon
Feature Count: 6
Extent: (592000.000000, 226000.000000) - (594000.000000, 230000.000000)
Layer SRS WKT:
PROJCS["CH1903_LV03",
    GEOGCS["GCS_CH1903",
        DATUM["CH1903",
            SPHEROID["Bessel_1841",6377397.155,299.1528128]],
        PRIMEM["Greenwich",0],
        UNIT["Degree",0.017453292519943295]],
    PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],
    PARAMETER["latitude_of_center",46.95240555555556],
    PARAMETER["longitude_of_center",7.439583333333333],
    PARAMETER["azimuth",90],
    PARAMETER["scale_factor",1],
    PARAMETER["false_easting",600000],
    PARAMETER["false_northing",200000],
    PARAMETER["rectified_grid_angle",90],
    UNIT["Meter",1]]
location: String (254.0)
srs: String (254.0)
modified: Date (10.0)
created: Date (10.0)
OGRFeature(tileindex):0
  location (String) = /home/stefan/tmp/lidar/srs/./LAS_593227.laz
  srs (String) = EPSG:21781
  modified (Date) = 2015/08/13
  created (Date) = 2015/08/13
  POLYGON ((593000 227000,593000 228000,594000 228000,594000 227000,593000
227000))

pdal info LAS_593227.laz --metadata:

{
  "filename": "LAS_593227.laz",
  "metadata":
  {
    "comp_spatialreference": "PROJCS[\"CH1903 /
LV03\",GEOGCS[\"CH1903\",DATUM[\"CH1903\",SPHEROID[\"Bessel
1841\",6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],TOWGS84[674.4,15.1,405.3,0,0,0,0],AUTHORITY[\"EPSG\",\"6149\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4149\"]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"latitude_of_center\",46.95240555555556],PARAMETER[\"longitude_of_center\",7.439583333333333],PARAMETER[\"azimuth\",90],PARAMETER[\"rectified_grid_angle\",90],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",200000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Y\",EAST],AXIS[\"X\",NORTH],AUTHORITY[\"EPSG\",\"21781\"]]",
    "compressed": true,
    "count": 14724002,
    "creation_doy": 224,
    "creation_year": 2015,
    "dataformat_id": 3,
    "dataoffset": 2181,
    "filesource_id": 0,
    "global_encoding": "AAA=",
    "header_size": 227,
    "major_version": 1,
    "maxx": 593999.98999999999,
    "maxy": 227999.98999999999,
    "maxz": 1667.6600000000001,
    "minor_version": 2,
    "minx": 593000,
    "miny": 227000,
    "minz": 622.80000000000007,
    "offset_x": 0,
    "offset_y": 0,
    "offset_z": 0,
    "project_id": "00000000-0000-0000-0000-000000000000",
    "scale_x": 0.01,
    "scale_y": 0.01,
    "scale_z": 0.01,
    "software_id": "PDAL 1.0.0.b1 (e412bd)",
    "spatialreference": "PROJCS[\"CH1903 /
LV03\",GEOGCS[\"CH1903\",DATUM[\"CH1903\",SPHEROID[\"Bessel
1841\",6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],TOWGS84[674.4,15.1,405.3,0,0,0,0],AUTHORITY[\"EPSG\",\"6149\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4149\"]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"latitude_of_center\",46.95240555555556],PARAMETER[\"longitude_of_center\",7.439583333333333],PARAMETER[\"azimuth\",90],PARAMETER[\"rectified_grid_angle\",90],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",200000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Y\",EAST],AXIS[\"X\",NORTH],AUTHORITY[\"EPSG\",\"21781\"]]",
    "system_id": "PDAL"
  },
  "pdal_version": "PDAL 1.0.0.b1 (e412bd)"
}

In the mergeFile() method on line 413 you assign the output srs for the
reprojection stage. But this cannot be set by the user and will therefore
always be EPSG:4326. As far as I understand.

regards
Stefan




On Fri, Aug 14, 2015 at 12:10 AM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

> On Thu, Aug 13, 2015 at 2:46 PM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
>
>> Hi
>>
>> I'm trying to merge some las files with the following command:
>>
>> pdal tindex --merge /home/stefan/tmp/lidar/srs/tileindex.gpkg --lyr_name
>> tileindex tmp.las
>>
>> The input las files have an srs assigned (EPSG:21781). But the merged one
>> is EPSG:4326.
>>
>
> Can you use ogrinfo to verify the SRS of the layer?  Can you provide the
> command used to create the index file?
>
> Thanks,
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150814/0ba499f1/attachment.html>

From stefan.ziegler.de at gmail.com  Fri Aug 14 04:01:14 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Fri, 14 Aug 2015 13:01:14 +0200
Subject: [pdal] pdal tindex --merge problem with polygon clippping
In-Reply-To: <CAJvo+1_F3rXo9S4GiQEf6zeDyif8p+UJ7W4P3w54wSesMr2m_A@mail.gmail.com>
References: <CAJvo+1-ZcZ3_9hqnj5VXa1yn3K1dctq=B3uLUPFt+wzBomkk-g@mail.gmail.com>
	<CACJ51z2VSWPv5Va_d+DyBR=CZxsro=j_fN5uC5kUpAFnURw1CQ@mail.gmail.com>
	<CAJvo+1_F3rXo9S4GiQEf6zeDyif8p+UJ7W4P3w54wSesMr2m_A@mail.gmail.com>
Message-ID: <CAJvo+1-vK-1rPDTD18=u_H643iCpjR2T7zdEER=9gAAQ7Fpxew@mail.gmail.com>

Hi

I created a small test case here:

http://www.catais.org/tmp/pdal_tindex.zip

It contains a small las file and the tileindex file. This is what I've done:

1) Create tileindex:

find . -iname "*.las" | pdal tindex tileindex.shp --a_srs EPSG:21781
--t_srs EPSG:21781  --fast_boundary --stdin

2) Commented out line 161 to allow "--t_srs". Pdal now does *not* reproject
data anymore to EPSG:4326. But when trying to write the las file it stops
with the following error:

PDAL: Unable to convert scaled value (2.04e+10) to int32 for dimension 'X'
when writing LAS/LAZ file tmp.las.

3) Commented out writerOptions.add() methods for scales and offsets on line
445 - 450 and added setCommonOptions(writerOptions).

Now I get the desired result by executing:

pdal tindex --scale "1 1 1" --merge tileindex.shp --lyr_name tileindex
--a_srs EPSG:21781 --t_srs EPSG:21781 tmp.las

So, this works for me but definitely introduces some evil stuff :) See also
attached patch to exactly see what I've done.

regards
Stefan


On Fri, Aug 14, 2015 at 6:16 AM, Stefan Ziegler <stefan.ziegler.de at gmail.com
> wrote:

> find . -iname "*.laz" | pdal tindex tileindex.shp --a_srs EPSG:21781
> --t_srs EPSG:21781 --fast_boundary --stdin
>
> ogrinfo -al tileindex.shp:
>
> Layer name: tileindex
> Geometry: Polygon
> Feature Count: 6
> Extent: (592000.000000, 226000.000000) - (594000.000000, 230000.000000)
> Layer SRS WKT:
> PROJCS["CH1903_LV03",
>     GEOGCS["GCS_CH1903",
>         DATUM["CH1903",
>             SPHEROID["Bessel_1841",6377397.155,299.1528128]],
>         PRIMEM["Greenwich",0],
>         UNIT["Degree",0.017453292519943295]],
>     PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],
>     PARAMETER["latitude_of_center",46.95240555555556],
>     PARAMETER["longitude_of_center",7.439583333333333],
>     PARAMETER["azimuth",90],
>     PARAMETER["scale_factor",1],
>     PARAMETER["false_easting",600000],
>     PARAMETER["false_northing",200000],
>     PARAMETER["rectified_grid_angle",90],
>     UNIT["Meter",1]]
> location: String (254.0)
> srs: String (254.0)
> modified: Date (10.0)
> created: Date (10.0)
> OGRFeature(tileindex):0
>   location (String) = /home/stefan/tmp/lidar/srs/./LAS_593227.laz
>   srs (String) = EPSG:21781
>   modified (Date) = 2015/08/13
>   created (Date) = 2015/08/13
>   POLYGON ((593000 227000,593000 228000,594000 228000,594000 227000,593000
> 227000))
>
> pdal info LAS_593227.laz --metadata:
>
> {
>   "filename": "LAS_593227.laz",
>   "metadata":
>   {
>     "comp_spatialreference": "PROJCS[\"CH1903 /
> LV03\",GEOGCS[\"CH1903\",DATUM[\"CH1903\",SPHEROID[\"Bessel
> 1841\",6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],TOWGS84[674.4,15.1,405.3,0,0,0,0],AUTHORITY[\"EPSG\",\"6149\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4149\"]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"latitude_of_center\",46.95240555555556],PARAMETER[\"longitude_of_center\",7.439583333333333],PARAMETER[\"azimuth\",90],PARAMETER[\"rectified_grid_angle\",90],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",200000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Y\",EAST],AXIS[\"X\",NORTH],AUTHORITY[\"EPSG\",\"21781\"]]",
>     "compressed": true,
>     "count": 14724002,
>     "creation_doy": 224,
>     "creation_year": 2015,
>     "dataformat_id": 3,
>     "dataoffset": 2181,
>     "filesource_id": 0,
>     "global_encoding": "AAA=",
>     "header_size": 227,
>     "major_version": 1,
>     "maxx": 593999.98999999999,
>     "maxy": 227999.98999999999,
>     "maxz": 1667.6600000000001,
>     "minor_version": 2,
>     "minx": 593000,
>     "miny": 227000,
>     "minz": 622.80000000000007,
>     "offset_x": 0,
>     "offset_y": 0,
>     "offset_z": 0,
>     "project_id": "00000000-0000-0000-0000-000000000000",
>     "scale_x": 0.01,
>     "scale_y": 0.01,
>     "scale_z": 0.01,
>     "software_id": "PDAL 1.0.0.b1 (e412bd)",
>     "spatialreference": "PROJCS[\"CH1903 /
> LV03\",GEOGCS[\"CH1903\",DATUM[\"CH1903\",SPHEROID[\"Bessel
> 1841\",6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],TOWGS84[674.4,15.1,405.3,0,0,0,0],AUTHORITY[\"EPSG\",\"6149\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4149\"]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"latitude_of_center\",46.95240555555556],PARAMETER[\"longitude_of_center\",7.439583333333333],PARAMETER[\"azimuth\",90],PARAMETER[\"rectified_grid_angle\",90],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",200000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Y\",EAST],AXIS[\"X\",NORTH],AUTHORITY[\"EPSG\",\"21781\"]]",
>     "system_id": "PDAL"
>   },
>   "pdal_version": "PDAL 1.0.0.b1 (e412bd)"
> }
>
> In the mergeFile() method on line 413 you assign the output srs for the
> reprojection stage. But this cannot be set by the user and will therefore
> always be EPSG:4326. As far as I understand.
>
> regards
> Stefan
>
>
>
>
> On Fri, Aug 14, 2015 at 12:10 AM, Andrew Bell <andrew.bell.ia at gmail.com>
> wrote:
>
>> On Thu, Aug 13, 2015 at 2:46 PM, Stefan Ziegler <
>> stefan.ziegler.de at gmail.com> wrote:
>>
>>> Hi
>>>
>>> I'm trying to merge some las files with the following command:
>>>
>>> pdal tindex --merge /home/stefan/tmp/lidar/srs/tileindex.gpkg --lyr_name
>>> tileindex tmp.las
>>>
>>> The input las files have an srs assigned (EPSG:21781). But the merged
>>> one is EPSG:4326.
>>>
>>
>> Can you use ogrinfo to verify the SRS of the layer?  Can you provide the
>> command used to create the index file?
>>
>> Thanks,
>>
>> --
>> Andrew Bell
>> andrew.bell.ia at gmail.com
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150814/3dc57517/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: TIndexKernel.patch
Type: text/x-patch
Size: 1365 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150814/3dc57517/attachment-0001.bin>

From howard at hobu.co  Fri Aug 14 05:40:23 2015
From: howard at hobu.co (Howard Butler)
Date: Fri, 14 Aug 2015 07:40:23 -0500
Subject: [pdal] pdal tindex --merge problem with polygon clippping
In-Reply-To: <CAJvo+1-vK-1rPDTD18=u_H643iCpjR2T7zdEER=9gAAQ7Fpxew@mail.gmail.com>
References: <CAJvo+1-ZcZ3_9hqnj5VXa1yn3K1dctq=B3uLUPFt+wzBomkk-g@mail.gmail.com>
	<CACJ51z2VSWPv5Va_d+DyBR=CZxsro=j_fN5uC5kUpAFnURw1CQ@mail.gmail.com>
	<CAJvo+1_F3rXo9S4GiQEf6zeDyif8p+UJ7W4P3w54wSesMr2m_A@mail.gmail.com>
	<CAJvo+1-vK-1rPDTD18=u_H643iCpjR2T7zdEER=9gAAQ7Fpxew@mail.gmail.com>
Message-ID: <882D2F80-5DF5-4ED2-8710-A113E02540FE@hobu.co>

Stefan,

Indeed there was some hackery in the tindex command before. I was using it for EPSG:4326 only, and I had made some changes to support just that.

I think tindex should be updated support what you want to do, as this is the common workflow pattern that gdaltindex uses which we are aiming to copy. One caveat with the merge scenario is that it will not be memory efficient for very large merges. You might need to do multi-stage operations if you are reading many billions of points to then merge. Currently, only the bounds of the WKT are used as a spatial filter (and passed down to OGR) to limit the amount of data to be merged. We should add another option to add typical OGR layer attribute filters as well.

Can you file a ticket with this stuff and we'll take it on?

Thanks,

Howard
> On Aug 14, 2015, at 6:01 AM, Stefan Ziegler <stefan.ziegler.de at gmail.com> wrote:
> 
> Hi
> 
> I created a small test case here:
> 
> http://www.catais.org/tmp/pdal_tindex.zip
> 
> It contains a small las file and the tileindex file. This is what I've done:
> 
> 1) Create tileindex: 
> 
> find . -iname "*.las" | pdal tindex tileindex.shp --a_srs EPSG:21781 --t_srs EPSG:21781  --fast_boundary --stdin
> 
> 2) Commented out line 161 to allow "--t_srs". Pdal now does *not* reproject data anymore to EPSG:4326. But when trying to write the las file it stops with the following error:
> 
> PDAL: Unable to convert scaled value (2.04e+10) to int32 for dimension 'X' when writing LAS/LAZ file tmp.las.
> 
> 3) Commented out writerOptions.add() methods for scales and offsets on line 445 - 450 and added setCommonOptions(writerOptions).  
> 
> Now I get the desired result by executing:
> 
> pdal tindex --scale "1 1 1" --merge tileindex.shp --lyr_name tileindex --a_srs EPSG:21781 --t_srs EPSG:21781 tmp.las
> 
> So, this works for me but definitely introduces some evil stuff :) See also attached patch to exactly see what I've done.
> 
> regards
> Stefan
> 
> 
> On Fri, Aug 14, 2015 at 6:16 AM, Stefan Ziegler <stefan.ziegler.de at gmail.com> wrote:
> find . -iname "*.laz" | pdal tindex tileindex.shp --a_srs EPSG:21781 --t_srs EPSG:21781 --fast_boundary --stdin
> 
> ogrinfo -al tileindex.shp:
> 
> Layer name: tileindex
> Geometry: Polygon
> Feature Count: 6
> Extent: (592000.000000, 226000.000000) - (594000.000000, 230000.000000)
> Layer SRS WKT:
> PROJCS["CH1903_LV03",
>     GEOGCS["GCS_CH1903",
>         DATUM["CH1903",
>             SPHEROID["Bessel_1841",6377397.155,299.1528128]],
>         PRIMEM["Greenwich",0],
>         UNIT["Degree",0.017453292519943295]],
>     PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],
>     PARAMETER["latitude_of_center",46.95240555555556],
>     PARAMETER["longitude_of_center",7.439583333333333],
>     PARAMETER["azimuth",90],
>     PARAMETER["scale_factor",1],
>     PARAMETER["false_easting",600000],
>     PARAMETER["false_northing",200000],
>     PARAMETER["rectified_grid_angle",90],
>     UNIT["Meter",1]]
> location: String (254.0)
> srs: String (254.0)
> modified: Date (10.0)
> created: Date (10.0)
> OGRFeature(tileindex):0
>   location (String) = /home/stefan/tmp/lidar/srs/./LAS_593227.laz
>   srs (String) = EPSG:21781
>   modified (Date) = 2015/08/13
>   created (Date) = 2015/08/13
>   POLYGON ((593000 227000,593000 228000,594000 228000,594000 227000,593000 227000))
> 
> pdal info LAS_593227.laz --metadata:
> 
> {
>   "filename": "LAS_593227.laz",
>   "metadata":
>   {
>     "comp_spatialreference": "PROJCS[\"CH1903 / LV03\",GEOGCS[\"CH1903\",DATUM[\"CH1903\",SPHEROID[\"Bessel 1841\",6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],TOWGS84[674.4,15.1,405.3,0,0,0,0],AUTHORITY[\"EPSG\",\"6149\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4149\"]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"latitude_of_center\",46.95240555555556],PARAMETER[\"longitude_of_center\",7.439583333333333],PARAMETER[\"azimuth\",90],PARAMETER[\"rectified_grid_angle\",90],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",200000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Y\",EAST],AXIS[\"X\",NORTH],AUTHORITY[\"EPSG\",\"21781\"]]",
>     "compressed": true,
>     "count": 14724002,
>     "creation_doy": 224,
>     "creation_year": 2015,
>     "dataformat_id": 3,
>     "dataoffset": 2181,
>     "filesource_id": 0,
>     "global_encoding": "AAA=",
>     "header_size": 227,
>     "major_version": 1,
>     "maxx": 593999.98999999999,
>     "maxy": 227999.98999999999,
>     "maxz": 1667.6600000000001,
>     "minor_version": 2,
>     "minx": 593000,
>     "miny": 227000,
>     "minz": 622.80000000000007,
>     "offset_x": 0,
>     "offset_y": 0,
>     "offset_z": 0,
>     "project_id": "00000000-0000-0000-0000-000000000000",
>     "scale_x": 0.01,
>     "scale_y": 0.01,
>     "scale_z": 0.01,
>     "software_id": "PDAL 1.0.0.b1 (e412bd)",
>     "spatialreference": "PROJCS[\"CH1903 / LV03\",GEOGCS[\"CH1903\",DATUM[\"CH1903\",SPHEROID[\"Bessel 1841\",6377397.155,299.1528128,AUTHORITY[\"EPSG\",\"7004\"]],TOWGS84[674.4,15.1,405.3,0,0,0,0],AUTHORITY[\"EPSG\",\"6149\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4149\"]],PROJECTION[\"Hotine_Oblique_Mercator_Azimuth_Center\"],PARAMETER[\"latitude_of_center\",46.95240555555556],PARAMETER[\"longitude_of_center\",7.439583333333333],PARAMETER[\"azimuth\",90],PARAMETER[\"rectified_grid_angle\",90],PARAMETER[\"scale_factor\",1],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",200000],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Y\",EAST],AXIS[\"X\",NORTH],AUTHORITY[\"EPSG\",\"21781\"]]",
>     "system_id": "PDAL"
>   },
>   "pdal_version": "PDAL 1.0.0.b1 (e412bd)"
> }
> 
> In the mergeFile() method on line 413 you assign the output srs for the reprojection stage. But this cannot be set by the user and will therefore always be EPSG:4326. As far as I understand.
> 
> regards
> Stefan
> 
> 
> 
> 
> On Fri, Aug 14, 2015 at 12:10 AM, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> On Thu, Aug 13, 2015 at 2:46 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com> wrote:
> Hi
> 
> I'm trying to merge some las files with the following command:
> 
> pdal tindex --merge /home/stefan/tmp/lidar/srs/tileindex.gpkg --lyr_name tileindex tmp.las
> 
> The input las files have an srs assigned (EPSG:21781). But the merged one is EPSG:4326.
> 
> Can you use ogrinfo to verify the SRS of the layer?  Can you provide the command used to create the index file?
> 
> Thanks,
>  
> -- 
> Andrew Bell
> andrew.bell.ia at gmail.com
> 
> 
> <TIndexKernel.patch>_______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal


From stefan.ziegler.de at gmail.com  Fri Aug 14 11:55:53 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Fri, 14 Aug 2015 20:55:53 +0200
Subject: [pdal] pdal translate cropping problem/question
Message-ID: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>

Hi

I noticed that I get different results when I translate a las file with or
without cropping with its own boundary:

pdal translate -i LAS_593227.laz -o LAS_593227_t.laz

Same count of points and same metadata for input and output file.

pdal translate -i LAS_593227.laz -o LAS_593227_t.laz  --polygon "Polygon
((593000 227000, 594000 227000, 594000 228000, 593000 228000, 593000
227000))"

Less points because minx=593000.01 and miny=227000.01. Scale is 0.01.

Is this the expected behaviour? If so I can easily enlarge the polygon.

best regards
Stefan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150814/b582db09/attachment.html>

From andrew.bell.ia at gmail.com  Mon Aug 17 04:48:12 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 17 Aug 2015 06:48:12 -0500
Subject: [pdal] pdal translate cropping problem/question
In-Reply-To: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>
References: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>
Message-ID: <CACJ51z2yZVkoSDW6_Yr_=z3zx2Zp+U0nosw0DysH8keLZWY9CA@mail.gmail.com>

On Fri, Aug 14, 2015 at 1:55 PM, Stefan Ziegler <stefan.ziegler.de at gmail.com
> wrote:

> Hi
>
> I noticed that I get different results when I translate a las file with or
> without cropping with its own boundary:
>
> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz
>
> Same count of points and same metadata for input and output file.
>
> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz  --polygon "Polygon
> ((593000 227000, 594000 227000, 594000 228000, 593000 228000, 593000
> 227000))"
>
> Less points because minx=593000.01 and miny=227000.01. Scale is 0.01.
>

I don't understand the issue.  What are the coordinates of the points that
aren't in the cropped output?

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150817/8e66ae16/attachment.html>

From stefan.ziegler.de at gmail.com  Mon Aug 17 06:28:15 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Mon, 17 Aug 2015 15:28:15 +0200
Subject: [pdal] pdal translate cropping problem/question
In-Reply-To: <CACJ51z2yZVkoSDW6_Yr_=z3zx2Zp+U0nosw0DysH8keLZWY9CA@mail.gmail.com>
References: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>
	<CACJ51z2yZVkoSDW6_Yr_=z3zx2Zp+U0nosw0DysH8keLZWY9CA@mail.gmail.com>
Message-ID: <CAJvo+1_TC0Yp=xBVNQRrNTksH8=2F53HvQGCHSeS3RDJa_4ibw@mail.gmail.com>

I've done the same with las2las:

las2las -i LAS_593227.laz -o LAS_593227_t.laz -e
593000,227000,594000,228000
las2las -i LAS_593227.laz -o LAS_593227_t.laz

Same count of points of input and output file with both versions.

Stefan




On Mon, Aug 17, 2015 at 1:48 PM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

> On Fri, Aug 14, 2015 at 1:55 PM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
>
>> Hi
>>
>> I noticed that I get different results when I translate a las file with
>> or without cropping with its own boundary:
>>
>> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz
>>
>> Same count of points and same metadata for input and output file.
>>
>> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz  --polygon "Polygon
>> ((593000 227000, 594000 227000, 594000 228000, 593000 228000, 593000
>> 227000))"
>>
>> Less points because minx=593000.01 and miny=227000.01. Scale is 0.01.
>>
>
> I don't understand the issue.  What are the coordinates of the points that
> aren't in the cropped output?
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150817/f68e169c/attachment.html>

From stefan.ziegler.de at gmail.com  Mon Aug 17 12:33:09 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Mon, 17 Aug 2015 21:33:09 +0200
Subject: [pdal] pdal translate cropping problem/question
In-Reply-To: <CACJ51z2Ov7YN61LFTdKw8Y6PWKXxPWoN4WCOdtp1OxdhwKSK4g@mail.gmail.com>
References: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>
	<CACJ51z2yZVkoSDW6_Yr_=z3zx2Zp+U0nosw0DysH8keLZWY9CA@mail.gmail.com>
	<CAJvo+1_S+jMrEDUv2W+-hKUUFwd=tn3SMVOBBvCw4jLjFd7iFA@mail.gmail.com>
	<CACJ51z2Ov7YN61LFTdKw8Y6PWKXxPWoN4WCOdtp1OxdhwKSK4g@mail.gmail.com>
Message-ID: <CAJvo+19AD7dKRzzTRNrYdV5o_b7cir7vekyVxP-5buG+LNBoDA@mail.gmail.com>

Then I get:

PDAL: the argument ('([593000, 594000], [227000, 228000])') for option
'--bounds' is invalid


Looking at the source: pdal translate wants a BOX3D, the crop filter a
BOX2D. Is this the reason for this error message?

regards
Stefan

On Mon, Aug 17, 2015 at 8:33 PM, Andrew Bell <andrew.bell.ia at gmail.com>
wrote:

> Do you get the same behavior if you specify the bounds box explicitly,
> rather than specifying as a polygon?
>
> As in:
>
> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz  --bounds "([593000,
> 594000], [227000, 228000])"
>
>
>
> On Mon, Aug 17, 2015 at 8:04 AM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
>
>> I'd guess they lie near the border. The polygon is the boundary generated
>> with "pdal tindex" for this las file so this is why I think it's strange
>> that cropping a las file with its own boundary delivers not all points in
>> this las file.
>>
>> Like you would "gdal_translate -projwin" some raster where -projwin is
>> the bbox of the raster and get not the whole raster.
>>
>> Stefan
>>
>> On Mon, Aug 17, 2015 at 1:48 PM, Andrew Bell <andrew.bell.ia at gmail.com>
>> wrote:
>>
>>> On Fri, Aug 14, 2015 at 1:55 PM, Stefan Ziegler <
>>> stefan.ziegler.de at gmail.com> wrote:
>>>
>>>> Hi
>>>>
>>>> I noticed that I get different results when I translate a las file with
>>>> or without cropping with its own boundary:
>>>>
>>>> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz
>>>>
>>>> Same count of points and same metadata for input and output file.
>>>>
>>>> pdal translate -i LAS_593227.laz -o LAS_593227_t.laz  --polygon
>>>> "Polygon ((593000 227000, 594000 227000, 594000 228000, 593000 228000,
>>>> 593000 227000))"
>>>>
>>>> Less points because minx=593000.01 and miny=227000.01. Scale is 0.01.
>>>>
>>>
>>> I don't understand the issue.  What are the coordinates of the points
>>> that aren't in the cropped output?
>>>
>>> --
>>> Andrew Bell
>>> andrew.bell.ia at gmail.com
>>>
>>
>>
>
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150817/33c1a8dc/attachment.html>

From stefan.ziegler.de at gmail.com  Wed Aug 19 12:22:35 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Wed, 19 Aug 2015 21:22:35 +0200
Subject: [pdal] pdal translate cropping problem/question
In-Reply-To: <48871E54-B42C-49F8-97DE-6D6EA0EFD839@hobu.co>
References: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>
	<CACJ51z2yZVkoSDW6_Yr_=z3zx2Zp+U0nosw0DysH8keLZWY9CA@mail.gmail.com>
	<CAJvo+1_S+jMrEDUv2W+-hKUUFwd=tn3SMVOBBvCw4jLjFd7iFA@mail.gmail.com>
	<CACJ51z0KBZ1J7rpRx8VE+XeTENo4HSg-wKnKD0i81cqu_fKTug@mail.gmail.com>
	<825E15A3-4164-401A-A621-806D68E88452@gmail.com>
	<CACJ51z30adwFPLWjMDh73uz3N_z8ojwXWUEsLYRJ-wsS1sFKNQ@mail.gmail.com>
	<CAJvo+19SEhRqGMYM8fnzwP62tHZK2_LBS54mMwvSrf=LWLnGqA@mail.gmail.com>
	<48871E54-B42C-49F8-97DE-6D6EA0EFD839@hobu.co>
Message-ID: <CAJvo+1_z6DA76BTFVMznQPjz8g2Yfu6YTsSJvOdLm3S7D40cog@mail.gmail.com>

The "pdal tindex --merge" command still requires a BOX3D. Could this also
be changed to 2D to be more consistent?

regards
Stefan

On Tue, Aug 18, 2015 at 2:44 PM, Howard Butler <howard at hobu.co> wrote:

> Absolutely. It has to do much less comparison and indexing work, and it
> doesn't have to light up GEOS.
>
> > On Aug 18, 2015, at 6:31 AM, Stefan Ziegler <stefan.ziegler.de at gmail.com>
> wrote:
> >
> > Is --bounds faster than --polygon?
> >
> > Stefan
> >
> > On Mon, Aug 17, 2015 at 11:30 PM, Andrew Bell <andrew.bell.ia at gmail.com>
> wrote:
> > I've recreated the problem.  I don't have any trouble when using
> --bounds.  We're passing the points through to GEOS to filter based on the
> provided polygon.  I'll have to research further.  On-the-line should count
> as in.
> >
> > On Mon, Aug 17, 2015 at 3:32 PM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
> > Yes.
> >
> > Stefan
> >
> > Sent from my iPhone
> >
> > On 17 Aug 2015, at 22:03, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> >
> >> On Mon, Aug 17, 2015 at 8:04 AM, Stefan Ziegler <
> stefan.ziegler.de at gmail.com> wrote:
> >> I'd guess they lie near the border. The polygon is the boundary
> generated with "pdal tindex" for this las file so this is why I think it's
> strange that cropping a las file with its own boundary delivers not all
> points in this las file.
> >>
> >> Are you using --fast-boundary when you generate the index file?
> >>
> >> --
> >> Andrew Bell
> >> andrew.bell.ia at gmail.com
> >
> >
> >
> > --
> > Andrew Bell
> > andrew.bell.ia at gmail.com
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150819/4b14c657/attachment.html>

From andrew.bell.ia at gmail.com  Wed Aug 19 14:30:05 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 19 Aug 2015 16:30:05 -0500
Subject: [pdal] pdal translate cropping problem/question
In-Reply-To: <CAJvo+1_z6DA76BTFVMznQPjz8g2Yfu6YTsSJvOdLm3S7D40cog@mail.gmail.com>
References: <CAJvo+1-Zab9AVpNwjx8TNLcrP280GpLOB7WfX8strefV3pd0aw@mail.gmail.com>
	<CACJ51z2yZVkoSDW6_Yr_=z3zx2Zp+U0nosw0DysH8keLZWY9CA@mail.gmail.com>
	<CAJvo+1_S+jMrEDUv2W+-hKUUFwd=tn3SMVOBBvCw4jLjFd7iFA@mail.gmail.com>
	<CACJ51z0KBZ1J7rpRx8VE+XeTENo4HSg-wKnKD0i81cqu_fKTug@mail.gmail.com>
	<825E15A3-4164-401A-A621-806D68E88452@gmail.com>
	<CACJ51z30adwFPLWjMDh73uz3N_z8ojwXWUEsLYRJ-wsS1sFKNQ@mail.gmail.com>
	<CAJvo+19SEhRqGMYM8fnzwP62tHZK2_LBS54mMwvSrf=LWLnGqA@mail.gmail.com>
	<48871E54-B42C-49F8-97DE-6D6EA0EFD839@hobu.co>
	<CAJvo+1_z6DA76BTFVMznQPjz8g2Yfu6YTsSJvOdLm3S7D40cog@mail.gmail.com>
Message-ID: <CACJ51z1Sm=hb7_KyDJ8gTbqewf8KzXMAw+pZWKwqLv2uRkEYNg@mail.gmail.com>

Fixed.

On Wed, Aug 19, 2015 at 2:22 PM, Stefan Ziegler
<stefan.ziegler.de at gmail.com> wrote:
> The "pdal tindex --merge" command still requires a BOX3D. Could this also be
> changed to 2D to be more consistent?
>
> regards
> Stefan
>
> On Tue, Aug 18, 2015 at 2:44 PM, Howard Butler <howard at hobu.co> wrote:
>>
>> Absolutely. It has to do much less comparison and indexing work, and it
>> doesn't have to light up GEOS.
>>
>> > On Aug 18, 2015, at 6:31 AM, Stefan Ziegler
>> > <stefan.ziegler.de at gmail.com> wrote:
>> >
>> > Is --bounds faster than --polygon?
>> >
>> > Stefan
>> >
>> > On Mon, Aug 17, 2015 at 11:30 PM, Andrew Bell <andrew.bell.ia at gmail.com>
>> > wrote:
>> > I've recreated the problem.  I don't have any trouble when using
>> > --bounds.  We're passing the points through to GEOS to filter based on the
>> > provided polygon.  I'll have to research further.  On-the-line should count
>> > as in.
>> >
>> > On Mon, Aug 17, 2015 at 3:32 PM, Stefan Ziegler
>> > <stefan.ziegler.de at gmail.com> wrote:
>> > Yes.
>> >
>> > Stefan
>> >
>> > Sent from my iPhone
>> >
>> > On 17 Aug 2015, at 22:03, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
>> >
>> >> On Mon, Aug 17, 2015 at 8:04 AM, Stefan Ziegler
>> >> <stefan.ziegler.de at gmail.com> wrote:
>> >> I'd guess they lie near the border. The polygon is the boundary
>> >> generated with "pdal tindex" for this las file so this is why I think it's
>> >> strange that cropping a las file with its own boundary delivers not all
>> >> points in this las file.
>> >>
>> >> Are you using --fast-boundary when you generate the index file?
>> >>
>> >> --
>> >> Andrew Bell
>> >> andrew.bell.ia at gmail.com
>> >
>> >
>> >
>> > --
>> > Andrew Bell
>> > andrew.bell.ia at gmail.com
>> >
>>
>



-- 
Andrew Bell
andrew.bell.ia at gmail.com

From stefan.ziegler.de at gmail.com  Fri Aug 21 09:08:16 2015
From: stefan.ziegler.de at gmail.com (Stefan Ziegler)
Date: Fri, 21 Aug 2015 18:08:16 +0200
Subject: [pdal] pdal translate --polygon not working anymore
Message-ID: <CAJvo+1__T_FyTtQOqQ-TS1v9HcpAfEw13P+gZTy+fs5tOhRfnw@mail.gmail.com>

Hi

it seems that with commit
https://github.com/PDAL/PDAL/commit/69a0d342615c4c71d8e9ac5b764dff7a3d7d91f2
the --polygon option is not considered anymore?

regards
Stefan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150821/0ebd73a2/attachment.html>

From andrew.bell.ia at gmail.com  Fri Aug 21 10:08:33 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Fri, 21 Aug 2015 12:08:33 -0500
Subject: [pdal] pdal translate --polygon not working anymore
In-Reply-To: <CAJvo+1__T_FyTtQOqQ-TS1v9HcpAfEw13P+gZTy+fs5tOhRfnw@mail.gmail.com>
References: <CAJvo+1__T_FyTtQOqQ-TS1v9HcpAfEw13P+gZTy+fs5tOhRfnw@mail.gmail.com>
Message-ID: <CACJ51z3ZU67sLKX5aVkmLsW_mt67htXmOHDQoBBWALZvBuQL=A@mail.gmail.com>

Fixed, I think.  No tests.

On Fri, Aug 21, 2015 at 11:08 AM, Stefan Ziegler <
stefan.ziegler.de at gmail.com> wrote:

> Hi
>
> it seems that with commit
> https://github.com/PDAL/PDAL/commit/69a0d342615c4c71d8e9ac5b764dff7a3d7d91f2
> the --polygon option is not considered anymore?
>
> regards
> Stefan
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/pdal
>



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150821/6a407bdb/attachment.html>

From howard at hobu.co  Tue Aug 25 06:50:16 2015
From: howard at hobu.co (Howard Butler)
Date: Tue, 25 Aug 2015 08:50:16 -0500
Subject: [pdal] [GRASS-dev] New Mac binaries uploaded
In-Reply-To: <CALQGVr1e8PNVdG2XFrMo8RquNr3hi4OEi9m9ezw62YE=jg7pQQ@mail.gmail.com>
References: <3DFE874F-D2FA-4A47-A3EB-600F694B00AF@asu.edu>
	<CAE0EDEpNz-zmtGdzneq4F-4+ZxnaHrcFGK9Bxe=JygkD8aWo1A@mail.gmail.com>
	<AE42CC6F-FE93-40D2-B791-97278747EE2A@asu.edu>
	<5A372C57-152D-4B96-AB9D-E95C52C31B03@kyngchaos.com>
	<B4DB4800-D98B-41AE-97EF-856CA0394AB4@asu.edu>
	<CALQGVr3hFe1RRArTfLZEm8CwG8C6Kg5RpipdCwbqDmDRw85KfA@mail.gmail.com>
	<1A03319E-78EC-437C-9F61-61F65F408467@asu.edu>
	<CABo5uVvmhAuh3ua7UGVs=Wq8euFqps_-vDWXszXj+iWvp+7PXQ@mail.gmail.com>
	<E4B9A709-D0D4-47ED-BD02-3B7889A8C97F@asu.edu>
	<4CECDADA-19CB-4F0B-9B34-0B9F240B06E6@asu.edu>
	<0C18124E-7B5A-4ECE-9B45-D39F5735BEAF@kyngchaos.com>
	<85526F73-5930-43DB-BA62-77360EB570A7@asu.edu>
	<CALQGVr1e8PNVdG2XFrMo8RquNr3hi4OEi9m9ezw62YE=jg7pQQ@mail.gmail.com>
Message-ID: <8C625B66-D899-4595-BF04-E7392497AA22@hobu.co>

Doug,

Thanks for the bump. Here's the case for using PDAL in GRASS:

1) It has full LAS 1.4 support (libLAS stops at 1.2) (LASlib has full 1.4 support too)
2) It is entirely open source without LAStools'/LASlib's somewhat confusing licensing. It is also BSD if that matters to you.
3) It is developed by a group of developers, and it is developed on github with pull requests and typical open source methodology. If you have changes to make, you can start having impact right away.
4) It's GDAL for point clouds and supports reading at least 16 different point cloud formats and writing at least 14
5) It is composeable. Using its VRT-like Pipeline syntax, you can stack together reader, filter, and writer operations into a data flow that can be executed via simple command line tools or embedded into applications
6) It supports extension with Python. Using the predicate [1] and programmable [2] filters, you can write software that interacts with the points without having to develop C/C++. This is very useful for rapid prototyping of algorithms (you have the full expressiveness of numpy available to you).
7) It supports PCL integration. Advanced exploitive techniques [3] developed in that environment are available to utilize in processing pipelines via simple JSON configuration.
8) It has full coordinate system support through GeoTIFF/GDAL/proj.4. This is a big missing feature of LASlib.

With regard to PDAL's boost dependency, we are working to remove that. It's not gone at the moment, but it is really close. We recognize that Boost is a pain for many folks, and the C++11 standard added most of the features from boost PDAL was depending upon anyway. The most significant boost reliance at the moment is PDAL's use of program_options, but we are working around it. 

PDAL will be having its 1.0.0 release before FOSS4G 2015 in September. If you will be attending FOSS4G 2015, make sure to attend Michael Smith's presentation at 14:40 on Thursday where he will give examples and background on how to use PDAL for point cloud data processing and management.

We have PDAL packages for OSGeo4W64 and OSGeo4Mac. These are maintained by the developers of the software. We recognize that without packages, many folks cannot use the code, and we will be maintaining these packages as best we can going forward. We will leave the Linux packaging to the experts, however, and the official release will be the signal to those folks to bring it off the lab bench.

Hope this helps,

Howard


[1] http://www.pdal.io/stages/filters.predicate.html
[2] http://www.pdal.io/stages/filters.programmable.html
[3] http://www.pdal.io/stages/filters.pclblock.html#implemented-filters


> On Aug 25, 2015, at 8:15 AM, Newcomb, Doug <doug_newcomb at fws.gov> wrote:
> 
> The free tools of LASlib are licensed under the LGPL and cover LAS versions 1.0-1.3 .  I don't think LAS 1.4 is covered yet ( I could be wrong) .  LAS format up to 1.3  is limited to 4.2 billion points per file ( 32 bit integer) LAS 1.4 uses a 64 bit integer identifier. 
> 
> LASlib is also maintained by a single developer.
> 
> The principle author of Liblas ( Howard Butler)  has moved on with others to develop the pdal software, http://www.pdal.io/.  I've cc'ed Howard in case he would like to weigh in on the technical differences.
> 
> Doug  
> 
> On Mon, Aug 24, 2015 at 11:45 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
> That would be wonderful. I sort of got that impression too. But will the GRASS lidar tools be able to use LASlib instead of Liblas?
> 
> Michael
> ____________________
> C. Michael Barton
> Director, Center for Social Dynamics & Complexity
> Professor of Anthropology, School of Human Evolution & Social Change
> Head, Graduate Faculty in Complex Adaptive Systems Science
> Arizona State University
> 
> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> > On Aug 24, 2015, at 8:40 PM, William Kyngesburye <woklist at kyngchaos.com> wrote:
> >
> > I looked at LAS this spring.  From what I found, libLAS is superceded by LASlib, found in LAStools.  laslib and some of the tools are still opensource, but other tools are not.
> >
> > Laslib does not have a configure, it's a simple makefile that needs a little tweaking for OS X.  And there appears to be no dependence on BOOST or Geotiff, or anything else.
> >
> > For laslib, all I needed to do was edit laslib/src/makefile and change these lines:
> >
> > COPTS     = -Os -Wall -Wno-deprecated -DNDEBUG -DUNORDERED -arch x86_64 -isysroot /Developer/SDKs/MacOSX10.7.sdk
> > COMPILER  = clang++
> >
> > And in the liblas.a target, add a line after the cp line (tha's a tab at the start):
> >
> >       ranlib ../lib/$@
> >
> > Also delete the precompiled Windows lib in laslib/lib.
> >
> > You should be able to use the library right from the source, it's static so it will be built into GRASS without needing a copy of the laslib.  For GRASS configuration, the library will be in that lib folder and includes in the laslib/inc folder.
> >
> > On Aug 24, 2015, at 3:47 PM, Michael Barton <michael.barton at asu.edu> wrote:
> >
> >> For LASlib compliing, I managed to get past the GEOTIFF problem with the following:
> >>
> >> cmake -G "Unix Makefiles" -D CMAKE_OSX_ARCHITECTURES="i386;x86_64? \
> >> -D CMAKE_OSX_SYSROOT="/Developer/SDKs/MacOSX10.7.sdk? \
> >> -D GDAL_CONFIG=/Library/Frameworks/GDAL.framework/Programs/gdal-config \
> >> -D GEOTIFF_INCLUDE_DIR=/Library/Frameworks/UnixImageIO.framework/unix/include \
> >> -D GEOTIFF_LIBRARY=/Library/Frameworks/UnixImageIO.framework/unix/lib/libgeotiff.dylib \
> >> ../
> >>
> >> But now cmake is complaining about the CMAKE_OSX_ARCHITECTURES flag. I don?t know if this harkens back to the similar problem with boost or if this is new. I?ve tried both i386 and x86_64 individually and it still won?t compile.
> >>
> >> Michael
> >> ____________________
> >> C. Michael Barton
> >> Director, Center for Social Dynamics & Complexity
> >> Professor of Anthropology, School of Human Evolution & Social Change
> >> Head, Graduate Faculty in Complex Adaptive Systems Science
> >> Arizona State University
> >>
> >> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
> >> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
> >> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >>> On Aug 24, 2015, at 1:30 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
> >>>
> >>> I?ve started trying to recompile liblas using the notes from last time (I think William provided considerable help on this). So far it is not working.
> >>>
> >>> 1 Recompiling boost 1.5.4
> >>>
> >>> cd /Users/Shared/grass_dev/boost_1_54_0 ##note that I did not do anything to clean up my original compilation. Should I? How with C++?
> >>>
> >>> edit /Users/Shared/grass_dev/boost_1_54_0/tools/build/v2/tools/darwin.jam to delete -gdwarf-2  ## already done
> >>>
> >>> export CXXFLAGS=-stdlib=libstdc++
> >>> ./bootstrap.sh --prefix=/Users/cmbarton/Dropbox/GRASS_dropbox/compiling/boost-snow --without-libraries=python
> >>>
> >>> ## this worked several years ago but now fails. I DO have the OS X 10.7 SDK FWIW
> >>> ./bjam variant=release link=static --without-mpi -j4 macosx-version=10.7 macosx-version-min=10.7 architecture=x86 address-model=32_64 install
> >>>
> >>> ## So I tried without specifying the minimum OS and address model. This compiled but could be incorrect
> >>> ./bjam variant=release link=static --without-mpi -j4 install
> >>>
> >>> ## This was in my notes but does not seem needed
> >>> Need to manually delete the comma at the end of the list on line 117 of /boost-snow/include/boost/interprocess/errors.hpp
> >>>
> >>> 3. Then follow instructions at: http://www.liblas.org/compilation.html#using-xcode-on-os-x for standard install (not xcode)
> >>> from libLAS folder...
> >>>
> >>> cd to liblas source folder
> >>> mkdir makefiles
> >>> cd makefiles
> >>>
> >>> export BOOST_ROOT="/Users/cmbarton/Dropbox/GRASS_dropbox/compiling/boost-snow"
> >>>
> >>> cmake -G "Unix Makefiles" -D CMAKE_OSX_ARCHITECTURES="i386;x86_64" -D CMAKE_OSX_SYSROOT="/Developer/SDKs/MacOSX10.7.sdk" ../
> >>>
> >>> ## fails because it can?t find geotiff libraries. But it does find geotiff libraries. So that?s weird. Also cannot find laszip. I can?t tell if this is required or optional. I didn?t need it before.
> >>> ## here is the error?
> >>>
> >>> Searching for LASzip 2.0.1+ library
> >>> -- Could NOT find LASzip (missing:  LASZIP_LIBRARY LASZIP_INCLUDE_DIR) (Required is at least version "2.0.1")
> >>> -- Searching for GDAL 1.7.0+ library
> >>> -- Found acceptable GDAL version 1.11.2
> >>> -- Searching for GeoTIFF 1.2.5+ library
> >>> -- Found GeoTIFF version: 1.4.0
> >>> -- Could NOT find GeoTIFF (missing:  GEOTIFF_LIBRARY) (Required is at least version "1.2.5")
> >>> CMake Error at CMakeLists.txt:262 (message):
> >>>  GDAL support requires GeoTIFF library which was not found
> >>>
> >>>
> >>>
> >>> So this is where I?m stuck currently. Any suggestions would be appreciated.
> >>>
> >>> Michael
> >>>
> >>>
> >>> ____________________
> >>> C. Michael Barton
> >>> Director, Center for Social Dynamics & Complexity
> >>> Professor of Anthropology, School of Human Evolution & Social Change
> >>> Head, Graduate Faculty in Complex Adaptive Systems Science
> >>> Arizona State University
> >>>
> >>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
> >>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
> >>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>> On Aug 24, 2015, at 10:50 AM, Vaclav Petras <wenzeslaus at gmail.com> wrote:
> >>>>
> >>>>
> >>>>
> >>>> On Mon, Aug 24, 2015 at 1:40 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
> >>>> If I am understanding the compiling instructions correctly, it installs binaries of the open source LAStools and Liblas too. But I may misunderstand. The GRASS LAS tool set needs both I believe.
> >>>>
> >>>> GRASS GIS is fine just with the library. The expected library libLAS (http://www.liblas.org/) as far as I know.
> >>>>
> >>>> I'm not sure what "open source LAStools" would be, some of the LAStools are perhaps open source but some are definitively not. In any case, GRASS GIS does not depend on any tools -- the ones related to libLAS nor the ones related LASlib.
> >>>>
> >>>> Vaclav
> >>>>
> >>>>
> >>>> Michael
> >>>> ____________________
> >>>> C. Michael Barton
> >>>> Director, Center for Social Dynamics & Complexity
> >>>> Professor of Anthropology, School of Human Evolution & Social Change
> >>>> Head, Graduate Faculty in Complex Adaptive Systems Science
> >>>> Arizona State University
> >>>>
> >>>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
> >>>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
> >>>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>> On Aug 24, 2015, at 10:29 AM, Newcomb, Doug <doug_newcomb at fws.gov> wrote:
> >>>>>
> >>>>> Liblas or LASTools?
> >>>>>
> >>>>> Doug
> >>>>>
> >>>>> On Mon, Aug 24, 2015 at 1:08 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
> >>>>> Yes. The LAS tools are compiled for GDAL 1.10. They were a royal pain to compile. The instructions to the newest LAStools source code makes it sound like it is much easier now. Does anyone have any experience with the current version? I was going to try it but wanted to make sure I had a GRASS version out with at least a clunky working version before risking it.
> >>>>>
> >>>>> Michael
> >>>>> ____________________
> >>>>> C. Michael Barton
> >>>>> Director, Center for Social Dynamics & Complexity
> >>>>> Professor of Anthropology, School of Human Evolution & Social Change
> >>>>> Head, Graduate Faculty in Complex Adaptive Systems Science
> >>>>> Arizona State University
> >>>>>
> >>>>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
> >>>>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
> >>>>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>> On Aug 24, 2015, at 9:56 AM, William Kyngesburye <woklist at kyngchaos.com> wrote:
> >>>>>>
> >>>>>> Michael, you may need to recompile your las tools to use the current GDAL, this is separate from GRASS compilation.
> >>>>>>
> >>>>>> On Aug 24, 2015, at 10:31 AM, Michael Barton <Michael.Barton at asu.edu> wrote:
> >>>>>>
> >>>>>>> Anna,
> >>>>>>>
> >>>>>>> These work for me and at least some of my students here. So we need to find out why they don't work for you. I'm teaching spatial tech this fall and want to make sure others don't run into trouble. 7.0.1 was a completely fresh checkout and 7.1 was compiled after a make distclean.
> >>>>>>>
> >>>>>>> Do you have any idea what causes this error? Did you install a new gdal? I compiled with William's most current version. I am still using stock Mac Python and wx version 2.8.12. Have you installed anything newer in the testing I saw on the list?
> >>>>>>>
> >>>>>>> Michael Barton
> >>>>>>> School of Human Evolution &Social Change
> >>>>>>> Center for Social Dynamics & Complexity
> >>>>>>> Arizona State University
> >>>>>>>
> >>>>>>> ...Sent from my iPad
> >>>>>>>
> >>>>>>> On Aug 24, 2015, at 7:43 AM, Anna Petr??ov? <kratochanna at gmail.com> wrote:
> >>>>>>>
> >>>>>>>> Hi Michael,
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> sorry to report but the new binaries (70 and 71) don't work, the gui doesn't open with this error. I already saw this error multiple times and it might be enough just to make distclean and recompile or fresh svn checkout.
> >>>>>>>> GRASS 7.1.svn (loc_ncarolina_spm_base0.3.1):~ > Traceback (most recent call last):
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 140, in <module>
> >>>>>>>>
> >>>>>>>>   sys.exit(main())
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 132, in main
> >>>>>>>>
> >>>>>>>>   app = GMApp(workspaceFile)
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 46, in __init__
> >>>>>>>>
> >>>>>>>>   wx.App.__init__(self, False)
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/etc/python/wx/_core.py", line 7981, in __init__
> >>>>>>>>
> >>>>>>>>   self._BootstrapApp()
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/etc/python/wx/_core.py", line 7555, in _BootstrapApp
> >>>>>>>>
> >>>>>>>>   return _core_.PyApp__BootstrapApp(*args, **kwargs)
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 79, in OnInit
> >>>>>>>>
> >>>>>>>>   from lmgr.frame import GMFrame
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/lmgr/frame.py", line 50, in <module>
> >>>>>>>>
> >>>>>>>>   from lmgr.layertree        import LayerTree, LMIcons
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/lmgr/layertree.py", line 37, in <module>
> >>>>>>>>
> >>>>>>>>   from mapdisp.frame        import MapFrame
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/mapdisp/frame.py", line 34, in <module>
> >>>>>>>>
> >>>>>>>>   from vdigit.toolbars    import VDigitToolbar
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/vdigit/toolbars.py", line 30, in <module>
> >>>>>>>>
> >>>>>>>>   from iclass.digit       import IClassVDigit
> >>>>>>>>
> >>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/iclass/digit.py", line 23, in <module>
> >>>>>>>>
> >>>>>>>>   from vdigit.wxdisplay import DisplayDriver, TYPE_AREA
> >>>>>>>>
> >>>>>>>> ImportError: cannot import name TYPE_AREA
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Also, v.in.lidar or las2las (anything using liblas) doesn't work. I don't have GDAL 1.10, but 1.11.
> >>>>>>>>
> >>>>>>>> dyld: Library not loaded: /Library/Frameworks/GDAL.framework/Versions/1.10/GDAL
> >>>>>>>>
> >>>>>>>> Referenced from: /Applications/GRASS-7.1.app/Contents/MacOS/lib/liblas.2.2.0.dylib
> >>>>>>>>
> >>>>>>>> Reason: image not found
> >>>>>>>>
> >>>>>>>> Trace/BPT trap: 5
> >>>>>>>>
> >>>>>>>> If you don't have time to look at it now, could you please post the GRASS 7.0.0 binary which I believe worked.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Thank you,
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Anna
> >>>>>>>>
> >>>>>>
> >>>>>> -----
> >>>>>> William Kyngesburye <kyngchaos*at*kyngchaos*dot*com>
> >>>>>> http://www.kyngchaos.com/
> >>>>>>
> >>>>>> First Pogril: Why is life like sticking your head in a bucket filled with hyena offal?
> >>>>>> Second Pogril: I don't know.  Why IS life like sticking your head in a bucket filled with hyena offal?
> >>>>>> First Pogril: I don't know either.  Wretched, isn't it?
> >>>>>>
> >>>>>> -HitchHiker's Guide to the Galaxy
> >>>>>
> >>>>> _______________________________________________
> >>>>> grass-dev mailing list
> >>>>> grass-dev at lists.osgeo.org
> >>>>> http://lists.osgeo.org/mailman/listinfo/grass-dev
> >>>>>
> >>>>>
> >>>>>
> >>>>> --
> >>>>> Doug Newcomb
> >>>>> USFWS
> >>>>> Raleigh, NC
> >>>>> 919-856-4520 ext. 14 doug_newcomb at fws.gov
> >>>>> ---------------------------------------------------------------------------------------------------------
> >>>>> The opinions I express are my own and are not representative of the official policy of the U.S.Fish and Wildlife Service or Dept. of the Interior.   Life is too short for undocumented, proprietary data formats.
> >>>>
> >>>>
> >>>> _______________________________________________
> >>>> grass-dev mailing list
> >>>> grass-dev at lists.osgeo.org
> >>>> http://lists.osgeo.org/mailman/listinfo/grass-dev
> >>>
> >>
> >> _______________________________________________
> >> grass-dev mailing list
> >> grass-dev at lists.osgeo.org
> >> http://lists.osgeo.org/mailman/listinfo/grass-dev
> >
> > -----
> > William Kyngesburye <kyngchaos*at*kyngchaos*dot*com>
> > http://www.kyngchaos.com/
> >
> > "Time is an illusion - lunchtime doubly so."
> >
> > - Ford Prefect
> >
> >
> 
> _______________________________________________
> grass-dev mailing list
> grass-dev at lists.osgeo.org
> http://lists.osgeo.org/mailman/listinfo/grass-dev
> 
> 
> 
> -- 
> Doug Newcomb
> USFWS
> Raleigh, NC
> 919-856-4520 ext. 14 doug_newcomb at fws.gov
> ---------------------------------------------------------------------------------------------------------
> The opinions I express are my own and are not representative of the official policy of the U.S.Fish and Wildlife Service or Dept. of the Interior.   Life is too short for undocumented, proprietary data formats.


From Michael.Barton at asu.edu  Thu Aug 27 12:25:11 2015
From: Michael.Barton at asu.edu (Michael Barton)
Date: Thu, 27 Aug 2015 19:25:11 +0000
Subject: [pdal] [GRASS-dev] New Mac binaries uploaded
In-Reply-To: <8C625B66-D899-4595-BF04-E7392497AA22@hobu.co>
References: <3DFE874F-D2FA-4A47-A3EB-600F694B00AF@asu.edu>
	<CAE0EDEpNz-zmtGdzneq4F-4+ZxnaHrcFGK9Bxe=JygkD8aWo1A@mail.gmail.com>
	<AE42CC6F-FE93-40D2-B791-97278747EE2A@asu.edu>
	<5A372C57-152D-4B96-AB9D-E95C52C31B03@kyngchaos.com>
	<B4DB4800-D98B-41AE-97EF-856CA0394AB4@asu.edu>
	<CALQGVr3hFe1RRArTfLZEm8CwG8C6Kg5RpipdCwbqDmDRw85KfA@mail.gmail.com>
	<1A03319E-78EC-437C-9F61-61F65F408467@asu.edu>
	<CABo5uVvmhAuh3ua7UGVs=Wq8euFqps_-vDWXszXj+iWvp+7PXQ@mail.gmail.com>
	<E4B9A709-D0D4-47ED-BD02-3B7889A8C97F@asu.edu>
	<4CECDADA-19CB-4F0B-9B34-0B9F240B06E6@asu.edu>
	<0C18124E-7B5A-4ECE-9B45-D39F5735BEAF@kyngchaos.com>
	<85526F73-5930-43DB-BA62-77360EB570A7@asu.edu>
	<CALQGVr1e8PNVdG2XFrMo8RquNr3hi4OEi9m9ezw62YE=jg7pQQ@mail.gmail.com>
	<8C625B66-D899-4595-BF04-E7392497AA22@hobu.co>
Message-ID: <495D59F9-B3AA-4F5F-A24C-C5D000ECDC30@asu.edu>

This looks like a very good direction for GRASS in the future from a practical and conceptual standpoint. It will probably take some rewriting of the existing LiDAR tools of course. This will be much easier if we can compile it more simply (without Boost). I took a look at the tools on the website. Having a good ?ground? module will be very important, since that is one of the proprietary LAS tools now. But I didn?t see the equivalent of las2las. Are these capabilities included in other tools that I didn?t see?

Michael
____________________
C. Michael Barton
Director, Center for Social Dynamics & Complexity 
Professor of Anthropology, School of Human Evolution & Social Change
Head, Graduate Faculty in Complex Adaptive Systems Science
Arizona State University

voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu



> On Aug 25, 2015, at 6:50 AM, Howard Butler <howard at hobu.co> wrote:
> 
> Doug,
> 
> Thanks for the bump. Here's the case for using PDAL in GRASS:
> 
> 1) It has full LAS 1.4 support (libLAS stops at 1.2) (LASlib has full 1.4 support too)
> 2) It is entirely open source without LAStools'/LASlib's somewhat confusing licensing. It is also BSD if that matters to you.
> 3) It is developed by a group of developers, and it is developed on github with pull requests and typical open source methodology. If you have changes to make, you can start having impact right away.
> 4) It's GDAL for point clouds and supports reading at least 16 different point cloud formats and writing at least 14
> 5) It is composeable. Using its VRT-like Pipeline syntax, you can stack together reader, filter, and writer operations into a data flow that can be executed via simple command line tools or embedded into applications
> 6) It supports extension with Python. Using the predicate [1] and programmable [2] filters, you can write software that interacts with the points without having to develop C/C++. This is very useful for rapid prototyping of algorithms (you have the full expressiveness of numpy available to you).
> 7) It supports PCL integration. Advanced exploitive techniques [3] developed in that environment are available to utilize in processing pipelines via simple JSON configuration.
> 8) It has full coordinate system support through GeoTIFF/GDAL/proj.4. This is a big missing feature of LASlib.
> 
> With regard to PDAL's boost dependency, we are working to remove that. It's not gone at the moment, but it is really close. We recognize that Boost is a pain for many folks, and the C++11 standard added most of the features from boost PDAL was depending upon anyway. The most significant boost reliance at the moment is PDAL's use of program_options, but we are working around it. 
> 
> PDAL will be having its 1.0.0 release before FOSS4G 2015 in September. If you will be attending FOSS4G 2015, make sure to attend Michael Smith's presentation at 14:40 on Thursday where he will give examples and background on how to use PDAL for point cloud data processing and management.
> 
> We have PDAL packages for OSGeo4W64 and OSGeo4Mac. These are maintained by the developers of the software. We recognize that without packages, many folks cannot use the code, and we will be maintaining these packages as best we can going forward. We will leave the Linux packaging to the experts, however, and the official release will be the signal to those folks to bring it off the lab bench.
> 
> Hope this helps,
> 
> Howard
> 
> 
> [1] http://www.pdal.io/stages/filters.predicate.html
> [2] http://www.pdal.io/stages/filters.programmable.html
> [3] http://www.pdal.io/stages/filters.pclblock.html#implemented-filters
> 
> 
>> On Aug 25, 2015, at 8:15 AM, Newcomb, Doug <doug_newcomb at fws.gov> wrote:
>> 
>> The free tools of LASlib are licensed under the LGPL and cover LAS versions 1.0-1.3 .  I don't think LAS 1.4 is covered yet ( I could be wrong) .  LAS format up to 1.3  is limited to 4.2 billion points per file ( 32 bit integer) LAS 1.4 uses a 64 bit integer identifier. 
>> 
>> LASlib is also maintained by a single developer.
>> 
>> The principle author of Liblas ( Howard Butler)  has moved on with others to develop the pdal software, http://www.pdal.io/.  I've cc'ed Howard in case he would like to weigh in on the technical differences.
>> 
>> Doug  
>> 
>> On Mon, Aug 24, 2015 at 11:45 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
>> That would be wonderful. I sort of got that impression too. But will the GRASS lidar tools be able to use LASlib instead of Liblas?
>> 
>> Michael
>> ____________________
>> C. Michael Barton
>> Director, Center for Social Dynamics & Complexity
>> Professor of Anthropology, School of Human Evolution & Social Change
>> Head, Graduate Faculty in Complex Adaptive Systems Science
>> Arizona State University
>> 
>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>>> On Aug 24, 2015, at 8:40 PM, William Kyngesburye <woklist at kyngchaos.com> wrote:
>>> 
>>> I looked at LAS this spring.  From what I found, libLAS is superceded by LASlib, found in LAStools.  laslib and some of the tools are still opensource, but other tools are not.
>>> 
>>> Laslib does not have a configure, it's a simple makefile that needs a little tweaking for OS X.  And there appears to be no dependence on BOOST or Geotiff, or anything else.
>>> 
>>> For laslib, all I needed to do was edit laslib/src/makefile and change these lines:
>>> 
>>> COPTS     = -Os -Wall -Wno-deprecated -DNDEBUG -DUNORDERED -arch x86_64 -isysroot /Developer/SDKs/MacOSX10.7.sdk
>>> COMPILER  = clang++
>>> 
>>> And in the liblas.a target, add a line after the cp line (tha's a tab at the start):
>>> 
>>>      ranlib ../lib/$@
>>> 
>>> Also delete the precompiled Windows lib in laslib/lib.
>>> 
>>> You should be able to use the library right from the source, it's static so it will be built into GRASS without needing a copy of the laslib.  For GRASS configuration, the library will be in that lib folder and includes in the laslib/inc folder.
>>> 
>>> On Aug 24, 2015, at 3:47 PM, Michael Barton <michael.barton at asu.edu> wrote:
>>> 
>>>> For LASlib compliing, I managed to get past the GEOTIFF problem with the following:
>>>> 
>>>> cmake -G "Unix Makefiles" -D CMAKE_OSX_ARCHITECTURES="i386;x86_64? \
>>>> -D CMAKE_OSX_SYSROOT="/Developer/SDKs/MacOSX10.7.sdk? \
>>>> -D GDAL_CONFIG=/Library/Frameworks/GDAL.framework/Programs/gdal-config \
>>>> -D GEOTIFF_INCLUDE_DIR=/Library/Frameworks/UnixImageIO.framework/unix/include \
>>>> -D GEOTIFF_LIBRARY=/Library/Frameworks/UnixImageIO.framework/unix/lib/libgeotiff.dylib \
>>>> ../
>>>> 
>>>> But now cmake is complaining about the CMAKE_OSX_ARCHITECTURES flag. I don?t know if this harkens back to the similar problem with boost or if this is new. I?ve tried both i386 and x86_64 individually and it still won?t compile.
>>>> 
>>>> Michael
>>>> ____________________
>>>> C. Michael Barton
>>>> Director, Center for Social Dynamics & Complexity
>>>> Professor of Anthropology, School of Human Evolution & Social Change
>>>> Head, Graduate Faculty in Complex Adaptive Systems Science
>>>> Arizona State University
>>>> 
>>>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
>>>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
>>>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> On Aug 24, 2015, at 1:30 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
>>>>> 
>>>>> I?ve started trying to recompile liblas using the notes from last time (I think William provided considerable help on this). So far it is not working.
>>>>> 
>>>>> 1 Recompiling boost 1.5.4
>>>>> 
>>>>> cd /Users/Shared/grass_dev/boost_1_54_0 ##note that I did not do anything to clean up my original compilation. Should I? How with C++?
>>>>> 
>>>>> edit /Users/Shared/grass_dev/boost_1_54_0/tools/build/v2/tools/darwin.jam to delete -gdwarf-2  ## already done
>>>>> 
>>>>> export CXXFLAGS=-stdlib=libstdc++
>>>>> ./bootstrap.sh --prefix=/Users/cmbarton/Dropbox/GRASS_dropbox/compiling/boost-snow --without-libraries=python
>>>>> 
>>>>> ## this worked several years ago but now fails. I DO have the OS X 10.7 SDK FWIW
>>>>> ./bjam variant=release link=static --without-mpi -j4 macosx-version=10.7 macosx-version-min=10.7 architecture=x86 address-model=32_64 install
>>>>> 
>>>>> ## So I tried without specifying the minimum OS and address model. This compiled but could be incorrect
>>>>> ./bjam variant=release link=static --without-mpi -j4 install
>>>>> 
>>>>> ## This was in my notes but does not seem needed
>>>>> Need to manually delete the comma at the end of the list on line 117 of /boost-snow/include/boost/interprocess/errors.hpp
>>>>> 
>>>>> 3. Then follow instructions at: http://www.liblas.org/compilation.html#using-xcode-on-os-x for standard install (not xcode)
>>>>> from libLAS folder...
>>>>> 
>>>>> cd to liblas source folder
>>>>> mkdir makefiles
>>>>> cd makefiles
>>>>> 
>>>>> export BOOST_ROOT="/Users/cmbarton/Dropbox/GRASS_dropbox/compiling/boost-snow"
>>>>> 
>>>>> cmake -G "Unix Makefiles" -D CMAKE_OSX_ARCHITECTURES="i386;x86_64" -D CMAKE_OSX_SYSROOT="/Developer/SDKs/MacOSX10.7.sdk" ../
>>>>> 
>>>>> ## fails because it can?t find geotiff libraries. But it does find geotiff libraries. So that?s weird. Also cannot find laszip. I can?t tell if this is required or optional. I didn?t need it before.
>>>>> ## here is the error?
>>>>> 
>>>>> Searching for LASzip 2.0.1+ library
>>>>> -- Could NOT find LASzip (missing:  LASZIP_LIBRARY LASZIP_INCLUDE_DIR) (Required is at least version "2.0.1")
>>>>> -- Searching for GDAL 1.7.0+ library
>>>>> -- Found acceptable GDAL version 1.11.2
>>>>> -- Searching for GeoTIFF 1.2.5+ library
>>>>> -- Found GeoTIFF version: 1.4.0
>>>>> -- Could NOT find GeoTIFF (missing:  GEOTIFF_LIBRARY) (Required is at least version "1.2.5")
>>>>> CMake Error at CMakeLists.txt:262 (message):
>>>>> GDAL support requires GeoTIFF library which was not found
>>>>> 
>>>>> 
>>>>> 
>>>>> So this is where I?m stuck currently. Any suggestions would be appreciated.
>>>>> 
>>>>> Michael
>>>>> 
>>>>> 
>>>>> ____________________
>>>>> C. Michael Barton
>>>>> Director, Center for Social Dynamics & Complexity
>>>>> Professor of Anthropology, School of Human Evolution & Social Change
>>>>> Head, Graduate Faculty in Complex Adaptive Systems Science
>>>>> Arizona State University
>>>>> 
>>>>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
>>>>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
>>>>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>>> On Aug 24, 2015, at 10:50 AM, Vaclav Petras <wenzeslaus at gmail.com> wrote:
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> On Mon, Aug 24, 2015 at 1:40 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
>>>>>> If I am understanding the compiling instructions correctly, it installs binaries of the open source LAStools and Liblas too. But I may misunderstand. The GRASS LAS tool set needs both I believe.
>>>>>> 
>>>>>> GRASS GIS is fine just with the library. The expected library libLAS (http://www.liblas.org/) as far as I know.
>>>>>> 
>>>>>> I'm not sure what "open source LAStools" would be, some of the LAStools are perhaps open source but some are definitively not. In any case, GRASS GIS does not depend on any tools -- the ones related to libLAS nor the ones related LASlib.
>>>>>> 
>>>>>> Vaclav
>>>>>> 
>>>>>> 
>>>>>> Michael
>>>>>> ____________________
>>>>>> C. Michael Barton
>>>>>> Director, Center for Social Dynamics & Complexity
>>>>>> Professor of Anthropology, School of Human Evolution & Social Change
>>>>>> Head, Graduate Faculty in Complex Adaptive Systems Science
>>>>>> Arizona State University
>>>>>> 
>>>>>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
>>>>>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
>>>>>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> On Aug 24, 2015, at 10:29 AM, Newcomb, Doug <doug_newcomb at fws.gov> wrote:
>>>>>>> 
>>>>>>> Liblas or LASTools?
>>>>>>> 
>>>>>>> Doug
>>>>>>> 
>>>>>>> On Mon, Aug 24, 2015 at 1:08 PM, Michael Barton <Michael.Barton at asu.edu> wrote:
>>>>>>> Yes. The LAS tools are compiled for GDAL 1.10. They were a royal pain to compile. The instructions to the newest LAStools source code makes it sound like it is much easier now. Does anyone have any experience with the current version? I was going to try it but wanted to make sure I had a GRASS version out with at least a clunky working version before risking it.
>>>>>>> 
>>>>>>> Michael
>>>>>>> ____________________
>>>>>>> C. Michael Barton
>>>>>>> Director, Center for Social Dynamics & Complexity
>>>>>>> Professor of Anthropology, School of Human Evolution & Social Change
>>>>>>> Head, Graduate Faculty in Complex Adaptive Systems Science
>>>>>>> Arizona State University
>>>>>>> 
>>>>>>> voice:  480-965-6262 (SHESC), 480-965-8130/727-9746 (CSDC)
>>>>>>> fax: 480-965-7671 (SHESC),  480-727-0709 (CSDC)
>>>>>>> www: http://www.public.asu.edu/~cmbarton, http://csdc.asu.edu
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>> On Aug 24, 2015, at 9:56 AM, William Kyngesburye <woklist at kyngchaos.com> wrote:
>>>>>>>> 
>>>>>>>> Michael, you may need to recompile your las tools to use the current GDAL, this is separate from GRASS compilation.
>>>>>>>> 
>>>>>>>> On Aug 24, 2015, at 10:31 AM, Michael Barton <Michael.Barton at asu.edu> wrote:
>>>>>>>> 
>>>>>>>>> Anna,
>>>>>>>>> 
>>>>>>>>> These work for me and at least some of my students here. So we need to find out why they don't work for you. I'm teaching spatial tech this fall and want to make sure others don't run into trouble. 7.0.1 was a completely fresh checkout and 7.1 was compiled after a make distclean.
>>>>>>>>> 
>>>>>>>>> Do you have any idea what causes this error? Did you install a new gdal? I compiled with William's most current version. I am still using stock Mac Python and wx version 2.8.12. Have you installed anything newer in the testing I saw on the list?
>>>>>>>>> 
>>>>>>>>> Michael Barton
>>>>>>>>> School of Human Evolution &Social Change
>>>>>>>>> Center for Social Dynamics & Complexity
>>>>>>>>> Arizona State University
>>>>>>>>> 
>>>>>>>>> ...Sent from my iPad
>>>>>>>>> 
>>>>>>>>> On Aug 24, 2015, at 7:43 AM, Anna Petr??ov? <kratochanna at gmail.com> wrote:
>>>>>>>>> 
>>>>>>>>>> Hi Michael,
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> sorry to report but the new binaries (70 and 71) don't work, the gui doesn't open with this error. I already saw this error multiple times and it might be enough just to make distclean and recompile or fresh svn checkout.
>>>>>>>>>> GRASS 7.1.svn (loc_ncarolina_spm_base0.3.1):~ > Traceback (most recent call last):
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 140, in <module>
>>>>>>>>>> 
>>>>>>>>>>  sys.exit(main())
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 132, in main
>>>>>>>>>> 
>>>>>>>>>>  app = GMApp(workspaceFile)
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 46, in __init__
>>>>>>>>>> 
>>>>>>>>>>  wx.App.__init__(self, False)
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/etc/python/wx/_core.py", line 7981, in __init__
>>>>>>>>>> 
>>>>>>>>>>  self._BootstrapApp()
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/etc/python/wx/_core.py", line 7555, in _BootstrapApp
>>>>>>>>>> 
>>>>>>>>>>  return _core_.PyApp__BootstrapApp(*args, **kwargs)
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/wxgui.py", line 79, in OnInit
>>>>>>>>>> 
>>>>>>>>>>  from lmgr.frame import GMFrame
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/lmgr/frame.py", line 50, in <module>
>>>>>>>>>> 
>>>>>>>>>>  from lmgr.layertree        import LayerTree, LMIcons
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/lmgr/layertree.py", line 37, in <module>
>>>>>>>>>> 
>>>>>>>>>>  from mapdisp.frame        import MapFrame
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/mapdisp/frame.py", line 34, in <module>
>>>>>>>>>> 
>>>>>>>>>>  from vdigit.toolbars    import VDigitToolbar
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/vdigit/toolbars.py", line 30, in <module>
>>>>>>>>>> 
>>>>>>>>>>  from iclass.digit       import IClassVDigit
>>>>>>>>>> 
>>>>>>>>>> File "/Applications/GRASS-7.1.app/Contents/MacOS/gui/wxpython/iclass/digit.py", line 23, in <module>
>>>>>>>>>> 
>>>>>>>>>>  from vdigit.wxdisplay import DisplayDriver, TYPE_AREA
>>>>>>>>>> 
>>>>>>>>>> ImportError: cannot import name TYPE_AREA
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Also, v.in.lidar or las2las (anything using liblas) doesn't work. I don't have GDAL 1.10, but 1.11.
>>>>>>>>>> 
>>>>>>>>>> dyld: Library not loaded: /Library/Frameworks/GDAL.framework/Versions/1.10/GDAL
>>>>>>>>>> 
>>>>>>>>>> Referenced from: /Applications/GRASS-7.1.app/Contents/MacOS/lib/liblas.2.2.0.dylib
>>>>>>>>>> 
>>>>>>>>>> Reason: image not found
>>>>>>>>>> 
>>>>>>>>>> Trace/BPT trap: 5
>>>>>>>>>> 
>>>>>>>>>> If you don't have time to look at it now, could you please post the GRASS 7.0.0 binary which I believe worked.
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Thank you,
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Anna
>>>>>>>>>> 
>>>>>>>> 
>>>>>>>> -----
>>>>>>>> William Kyngesburye <kyngchaos*at*kyngchaos*dot*com>
>>>>>>>> http://www.kyngchaos.com/
>>>>>>>> 
>>>>>>>> First Pogril: Why is life like sticking your head in a bucket filled with hyena offal?
>>>>>>>> Second Pogril: I don't know.  Why IS life like sticking your head in a bucket filled with hyena offal?
>>>>>>>> First Pogril: I don't know either.  Wretched, isn't it?
>>>>>>>> 
>>>>>>>> -HitchHiker's Guide to the Galaxy
>>>>>>> 
>>>>>>> _______________________________________________
>>>>>>> grass-dev mailing list
>>>>>>> grass-dev at lists.osgeo.org
>>>>>>> http://lists.osgeo.org/mailman/listinfo/grass-dev
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> --
>>>>>>> Doug Newcomb
>>>>>>> USFWS
>>>>>>> Raleigh, NC
>>>>>>> 919-856-4520 ext. 14 doug_newcomb at fws.gov
>>>>>>> ---------------------------------------------------------------------------------------------------------
>>>>>>> The opinions I express are my own and are not representative of the official policy of the U.S.Fish and Wildlife Service or Dept. of the Interior.   Life is too short for undocumented, proprietary data formats.
>>>>>> 
>>>>>> 
>>>>>> _______________________________________________
>>>>>> grass-dev mailing list
>>>>>> grass-dev at lists.osgeo.org
>>>>>> http://lists.osgeo.org/mailman/listinfo/grass-dev
>>>>> 
>>>> 
>>>> _______________________________________________
>>>> grass-dev mailing list
>>>> grass-dev at lists.osgeo.org
>>>> http://lists.osgeo.org/mailman/listinfo/grass-dev
>>> 
>>> -----
>>> William Kyngesburye <kyngchaos*at*kyngchaos*dot*com>
>>> http://www.kyngchaos.com/
>>> 
>>> "Time is an illusion - lunchtime doubly so."
>>> 
>>> - Ford Prefect
>>> 
>>> 
>> 
>> _______________________________________________
>> grass-dev mailing list
>> grass-dev at lists.osgeo.org
>> http://lists.osgeo.org/mailman/listinfo/grass-dev
>> 
>> 
>> 
>> -- 
>> Doug Newcomb
>> USFWS
>> Raleigh, NC
>> 919-856-4520 ext. 14 doug_newcomb at fws.gov
>> ---------------------------------------------------------------------------------------------------------
>> The opinions I express are my own and are not representative of the official policy of the U.S.Fish and Wildlife Service or Dept. of the Interior.   Life is too short for undocumented, proprietary data formats.
> 


From andrew.bell.ia at gmail.com  Mon Aug 31 13:28:53 2015
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 31 Aug 2015 15:28:53 -0500
Subject: [pdal] LAS Header Forwarding
Message-ID: <CACJ51z0awhckw3oMMx7osWaJWYzgC4pEp-PnEmqPKRaZAGT2iw@mail.gmail.com>

For those who might be interested, I recently pushed a change that allows
relatively easy forwarding of header values when reading from and writing
to LAS files.  See the --forward option in the documentation of the LAS
writer.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150831/4f77bb55/attachment.html>

From wenzeslaus at gmail.com  Mon Aug 31 19:28:52 2015
From: wenzeslaus at gmail.com (Vaclav Petras)
Date: Mon, 31 Aug 2015 22:28:52 -0400
Subject: [pdal] GRASS GIS and PDAL: C API?
Message-ID: <CABo5uVtmMgHB6wakFedmUPucPk60TNvdp_WkNGYRaZzrvfNnoA@mail.gmail.com>

Dear all,

first, thanks Howard for detailed answer in the original thread "New Mac
binaries uploaded". The listed points are really encouraging. (I'm creating
a new thread to keep it organized; cross posting grass-dev and pdal.)

Removing the Boost dependency and an actual release with packages sounds
great, however I realized that there is no C API. Is that right? GRASS GIS
now actually somehow lives with Boost dependency of libLAS but it is using
its C API. I don't have much experience in that matter but I know that many
people consider C API much better since it better holds ABI (AFAIU). Is
there any ongoing or planned work on C API for PDAL?

Thanks,
Vaclav

On Thu, Aug 27, 2015 at 3:25 PM, Michael Barton <Michael.Barton at asu.edu>
wrote:

> This looks like a very good direction for GRASS in the future from a
> practical and conceptual standpoint. It will probably take some rewriting
> of the existing LiDAR tools of course. This will be much easier if we can
> compile it more simply (without Boost). I took a look at the tools on the
> website. Having a good ?ground? module will be very important, since that
> is one of the proprietary LAS tools now. But I didn?t see the equivalent of
> las2las. Are these capabilities included in other tools that I didn?t see?
>
> Michael
>
> > On Aug 25, 2015, at 6:50 AM, Howard Butler <howard at hobu.co> wrote:
> >
> > Doug,
> >
> > Thanks for the bump. Here's the case for using PDAL in GRASS:
> >
> > 1) It has full LAS 1.4 support (libLAS stops at 1.2) (LASlib has full
> 1.4 support too)
> > 2) It is entirely open source without LAStools'/LASlib's somewhat
> confusing licensing. It is also BSD if that matters to you.
> > 3) It is developed by a group of developers, and it is developed on
> github with pull requests and typical open source methodology. If you have
> changes to make, you can start having impact right away.
> > 4) It's GDAL for point clouds and supports reading at least 16 different
> point cloud formats and writing at least 14
> > 5) It is composeable. Using its VRT-like Pipeline syntax, you can stack
> together reader, filter, and writer operations into a data flow that can be
> executed via simple command line tools or embedded into applications
> > 6) It supports extension with Python. Using the predicate [1] and
> programmable [2] filters, you can write software that interacts with the
> points without having to develop C/C++. This is very useful for rapid
> prototyping of algorithms (you have the full expressiveness of numpy
> available to you).
> > 7) It supports PCL integration. Advanced exploitive techniques [3]
> developed in that environment are available to utilize in processing
> pipelines via simple JSON configuration.
> > 8) It has full coordinate system support through GeoTIFF/GDAL/proj.4.
> This is a big missing feature of LASlib.
> >
> > With regard to PDAL's boost dependency, we are working to remove that.
> It's not gone at the moment, but it is really close. We recognize that
> Boost is a pain for many folks, and the C++11 standard added most of the
> features from boost PDAL was depending upon anyway. The most significant
> boost reliance at the moment is PDAL's use of program_options, but we are
> working around it.
> >
> > PDAL will be having its 1.0.0 release before FOSS4G 2015 in September.
> If you will be attending FOSS4G 2015, make sure to attend Michael Smith's
> presentation at 14:40 on Thursday where he will give examples and
> background on how to use PDAL for point cloud data processing and
> management.
> >
> > We have PDAL packages for OSGeo4W64 and OSGeo4Mac. These are maintained
> by the developers of the software. We recognize that without packages, many
> folks cannot use the code, and we will be maintaining these packages as
> best we can going forward. We will leave the Linux packaging to the
> experts, however, and the official release will be the signal to those
> folks to bring it off the lab bench.
> >
> > Hope this helps,
> >
> > Howard
> >
> >
> > [1] http://www.pdal.io/stages/filters.predicate.html
> > [2] http://www.pdal.io/stages/filters.programmable.html
> > [3] http://www.pdal.io/stages/filters.pclblock.html#implemented-filters
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20150831/f3a21290/attachment.html>

