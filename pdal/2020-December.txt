From andrew.bell.ia at gmail.com  Tue Dec  1 04:25:56 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 1 Dec 2020 07:25:56 -0500
Subject: [pdal] Several Overlapping Patches When Writing to pgpointcloud
 through filters.chipper
In-Reply-To: <5fc5b1d5.1c69fb81.2c408.6ce9SMTPIN_ADDED_BROKEN@mx.google.com>
References: <5fc5b1d5.1c69fb81.2c408.6ce9SMTPIN_ADDED_BROKEN@mx.google.com>
Message-ID: <CACJ51z2Ke8mCvg+5JAhtz6bc0f4fQR1AT7ND7n+OmzV=iy9Q+A@mail.gmail.com>

I don't think this should be happening, but I'm not very familiar with
pgpointcloud. Do you get the same overlapping tile behavior if you write to
LAS, for example?

On Mon, Nov 30, 2020 at 10:00 PM Peter Lim <peter.lim at gpslands.com> wrote:

> Hi,
>
>
>
> I?m reading some las files, using filters.chipper and write to PostgreSQ
> database using the following pipeline:
>
>
>
> [
>
>     {
>
> "type":"readers.las",
>
>                 "filename":"X:/tem/*.las"
>
>    },
>
>   {
>
>                 "type":"filters.reprojection",
>
>                 "in_srs":"EPSG:32648",
>
>                 "out_srs":"EPSG:3414"
>
>     },
>
>     {
>
>                  "type":"filters.chipper",
>
>                 "capacity":600
>
>     },
>
>     {
>
> "type":"writers.pgpointcloud",
>
> "connection":"host='localhost' dbname='lidar' user='anyuser'  ",
>
> "table":"example",
>
> "schema":"pc",
>
>                 "overwrite":"true",
>
> "compression":"dimensional",
>
> "srid":"3414",
>
> "scale_x":"0.001",
>
>                 "scale_y":"0.001",
>
>                 "scale_z":"0.001",
>
>                 "offset_x":"2000",
>
>
> "offset_y":"20000",
>
>
>                 "output_dims":"Intensity, X, Y,
> Z"
>
>     }
>
> ]
>
>
>
> However, the table has many overlapping patches as shown below:
>
>
>
> I had tried using filters.mortonorder but still the same results.
>
>
>
> May I know is there anyway to avoid or reduce overlapping patches.
>
>
>
> Please advise.
>
>
>
> Thank you.
>
>
>
> Best Regards,
>
>
>
> Peter Lim
>
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
> <#m_6653623188670215846_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>


-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201201/9f0025ff/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.jpg
Type: image/jpeg
Size: 15284 bytes
Desc: not available
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201201/9f0025ff/attachment-0001.jpg>

From RPhillips at linz.govt.nz  Tue Dec  1 19:06:33 2020
From: RPhillips at linz.govt.nz (Rose Phillips)
Date: Wed, 2 Dec 2020 03:06:33 +0000
Subject: [pdal] Extracting specific GpsTime Count from LAS file
Message-ID: <SYXPR01MB22065D9A17D1AA9125F7338C9CF30@SYXPR01MB2206.ausprd01.prod.outlook.com>

Hi guys

I'm struggling to extract the count for a specific GPS time (0.0) in one of my LAS files e.g.

(pdal) C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime --filters.stats.where=(GpsTime == 0)
PDAL: filters.stats: Invalid value '(GpsTime' for argument 'where'.

(pdal) C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime --filters.stats.where=(GpsTime == 000000000.000000)
PDAL: filters.stats: Invalid value '(GpsTime' for argument 'where'.

(pdal) C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime --filters.stats.where=(GpsTime == False)
PDAL: filters.stats: Invalid value '(GpsTime' for argument 'where'.

(pdal) C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.stats.dimensions=GpsTime --filters.range.limits="GpsTime[0:0]" --filters.stats.count=GpsTime
PDAL: Argument references invalid/unused stage: 'filters.range'.

C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.range.limits="GpsTime[0:0]" --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
PDAL: Argument references invalid/unused stage: 'filters.range'.

(pdal) C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.range.limits="GpsTime[0.0:0.0]" --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
PDAL: Argument references invalid/unused stage: 'filters.range'.

Any chance you could give me pointer where I've gone wrong? I know this time exists as it shows up in the earliest GPS Time in the Point Data Record metadata header.

I was able to extract all the GPS times using this correct for the same file using this command :-

(pdal) C:\Users\rphillips>pdal info --stats F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime

Many thanks and kind regards Rose

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201202/05bc53d6/attachment.html>

From andrew.bell.ia at gmail.com  Tue Dec  1 19:16:20 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 1 Dec 2020 22:16:20 -0500
Subject: [pdal] Extracting specific GpsTime Count from LAS file
In-Reply-To: <SYXPR01MB22065D9A17D1AA9125F7338C9CF30@SYXPR01MB2206.ausprd01.prod.outlook.com>
References: <SYXPR01MB22065D9A17D1AA9125F7338C9CF30@SYXPR01MB2206.ausprd01.prod.outlook.com>
Message-ID: <CACJ51z1u45YKq2bpnnsGXHj1OX-aKJHisDZb-ut-Mb0sQ8qbbQ@mail.gmail.com>

You need to place the "where" clause in quotes.

On Tue, Dec 1, 2020, 10:12 PM Rose Phillips <RPhillips at linz.govt.nz> wrote:

> Hi guys
>
>
>
> I?m struggling to extract the count for a specific GPS time (0.0) in one
> of my LAS files e.g.
>
>
>
> (pdal) C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
> --filters.stats.where=(GpsTime == 0)
>
> PDAL: filters.stats: Invalid value '(GpsTime' for argument 'where'.
>
>
>
> (pdal) C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
> --filters.stats.where=(GpsTime == 000000000.000000)
>
> PDAL: filters.stats: Invalid value '(GpsTime' for argument 'where'.
>
>
>
> (pdal) C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
> --filters.stats.where=(GpsTime == False)
>
> PDAL: filters.stats: Invalid value '(GpsTime' for argument 'where'.
>
>
>
> (pdal) C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.stats.dimensions=GpsTime --filters.range.limits="GpsTime[0:0]"
> --filters.stats.count=GpsTime
>
> PDAL: Argument references invalid/unused stage: 'filters.range'.
>
>
>
> C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.range.limits="GpsTime[0:0]" --filters.stats.dimensions=GpsTime
> --filters.stats.count=GpsTime
>
> PDAL: Argument references invalid/unused stage: 'filters.range'.
>
>
>
> (pdal) C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.range.limits="GpsTime[0.0:0.0]"
> --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
>
> PDAL: Argument references invalid/unused stage: 'filters.range'.
>
>
>
> Any chance you could give me pointer where I?ve gone wrong? I know this
> time exists as it shows up in the earliest GPS Time in the Point Data
> Record metadata header.
>
>
>
> I was able to extract all the GPS times using this correct for the same
> file using this command :-
>
>
>
> (pdal) C:\Users\rphillips>pdal info --stats
> F:\Raw\NZVD2016\LAS_Tiled\CL2_AT24_2018_1000_1426.las
> --filters.stats.dimensions=GpsTime --filters.stats.count=GpsTime
>
>
>
> Many thanks and kind regards Rose
>
> ------------------------------
>
> This message contains information, which may be in confidence and may be
> subject to legal privilege. If you are not the intended recipient, you must
> not peruse, use, disseminate, distribute or copy this message. If you have
> received this message in error, please notify us immediately (Phone 0800
> 665 463 or info at linz.govt.nz) and destroy the original message. LINZ
> accepts no responsibility for changes to this email, or for any
> attachments, after its transmission from LINZ. Thank You.
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201201/4680669d/attachment.html>

From rapposelli at 3dtarget.it  Wed Dec  2 00:20:06 2020
From: rapposelli at 3dtarget.it (3D TARGET-Simone Rapposelli)
Date: Wed, 2 Dec 2020 08:20:06 +0000
Subject: [pdal] entwine dlls to distribute in windows desktop application
Message-ID: <851a64cd1c9642d080f9481b5e091f35@3dtarget.it>

Hi all,

we would like to integrate entwine.exe in our Windows desktop application to launch it in batch mode, but we have seen that it has dependencies with hundreds of dlls. Do you know if and in case which are the essential dlls to use?
Kind regards,

Simone Rapposelli

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201202/a235afb6/attachment-0001.html>

From Peder.Axensten at slu.se  Wed Dec  2 04:51:39 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Wed, 2 Dec 2020 12:51:39 +0000
Subject: [pdal] Simple filter aborts.
Message-ID: <5DD877DF-5681-46FE-AE55-D18A9B06C915@slu.se>

I?m trying to implement a filter. The principle is fairly simple (see below). First I access all points in ?view_" to set up local variables and then I copy points that fulfil certain criteria to ?points". Could it be easier? ?

Both variants runs well on OS X, but not in Ubuntu 20.10 under Docker.
I use pdal 2.1.0 on both platforms.

Both variant aborts with:
malloc(): mismatching next->prev_size (unsorted)
But at different places.


Is there a better (correct) principle of doing this?
Am I constructing ?points? in the correct way?
What pdal filter do you recommend I take a good look at to better understand the principles?
Why do the variants abort at different locations?

Any hints are welcome!


=========

// Variant 1.
PointViewPtr Remove_overlap::run( PointViewPtr view_ ) {

for( PointId idx = 0; idx < view_->size(); ++idx ) {
// Set up stuff, read-accessing all points in view_
}

PointViewPtr points{ view_->makeNew() }; // Aborts here.
for( PointId idx = 0; idx < view_->size(); ++idx ) {
if( is_ok( view_, idx ) )
points->appendPoint( *view_, idx );
}

return points;
}


// Variant 2.
PointViewPtr Remove_overlap::run( PointViewPtr view_ ) {
PointViewPtr points{ view_->makeNew() };

for( PointId idx = 0; idx < view_->size(); ++idx ) {
// Set up stuff, read-accessing all points in view_
}

for( PointId idx = 0; idx < view_->size(); ++idx ) {
if( is_ok( view_, idx ) )
points->appendPoint( *view_, idx ); // Aborts here after a few hundred iterations (out of a few millions)
}

return points;
}

Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Ume?
Visiting address: Skogsmarksgr?nd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From andrew.bell.ia at gmail.com  Wed Dec  2 05:13:58 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 2 Dec 2020 08:13:58 -0500
Subject: [pdal] Simple filter aborts.
In-Reply-To: <5DD877DF-5681-46FE-AE55-D18A9B06C915@slu.se>
References: <5DD877DF-5681-46FE-AE55-D18A9B06C915@slu.se>
Message-ID: <CACJ51z3hafJAxGL5n+w-wCG3uEVJYcmLe901_fwCyBZGjy55yQ@mail.gmail.com>

No idea without seeing more of your code. You're corrupting memory
somewhere.

On Wed, Dec 2, 2020 at 7:52 AM Peder Axensten <Peder.Axensten at slu.se> wrote:

> I?m trying to implement a filter. The principle is fairly simple (see
> below). First I access all points in ?view_" to set up local variables and
> then I copy points that fulfil certain criteria to ?points". Could it be
> easier? ?
>
> Both variants runs well on OS X, but not in Ubuntu 20.10 under Docker.
> I use pdal 2.1.0 on both platforms.
>
> Both variant aborts with:
> malloc(): mismatching next->prev_size (unsorted)
> But at different places.
>
>
> Is there a better (correct) principle of doing this?
> Am I constructing ?points? in the correct way?
> What pdal filter do you recommend I take a good look at to better
> understand the principles?
> Why do the variants abort at different locations?
>
> Any hints are welcome!
>
>
> =========
>
> // Variant 1.
> PointViewPtr Remove_overlap::run( PointViewPtr view_ ) {
>
> for( PointId idx = 0; idx < view_->size(); ++idx ) {
> // Set up stuff, read-accessing all points in view_
> }
>
> PointViewPtr points{ view_->makeNew() }; // Aborts here.
> for( PointId idx = 0; idx < view_->size(); ++idx ) {
> if( is_ok( view_, idx ) )
> points->appendPoint( *view_, idx );
> }
>
> return points;
> }
>
>
> // Variant 2.
> PointViewPtr Remove_overlap::run( PointViewPtr view_ ) {
> PointViewPtr points{ view_->makeNew() };
>
> for( PointId idx = 0; idx < view_->size(); ++idx ) {
> // Set up stuff, read-accessing all points in view_
> }
>
> for( PointId idx = 0; idx < view_->size(); ++idx ) {
> if( is_ok( view_, idx ) )
> points->appendPoint( *view_, idx ); // Aborts here after a few hundred
> iterations (out of a few millions)
> }
>
> return points;
> }
>
> Best regards,
>
> Peder Axensten
> Research engineer
>
> Remote Sensing
> Department of Forest Resource Management
> Swedish University of Agricultural Sciences
> SE-901 83 Ume?
> Visiting address: Skogsmarksgr?nd
> Phone: +46 90 786 85 00
> peder.axensten at slu.se, www.slu.se/srh
>
> The Department of Forest Resource Management is environmentally certified
> in accordance with ISO 14001.
>
> ---
> N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina
> personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <
> https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
> E-mailing SLU will result in SLU processing your personal data. For more
> information on how this is done, click here <
> https://www.slu.se/en/about-slu/contact-slu/personal-data/>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>


-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201202/389bea5d/attachment.html>

From howard at hobu.co  Wed Dec  2 07:30:56 2020
From: howard at hobu.co (Howard Butler)
Date: Wed, 2 Dec 2020 09:30:56 -0600
Subject: [pdal] entwine dlls to distribute in windows desktop application
In-Reply-To: <851a64cd1c9642d080f9481b5e091f35@3dtarget.it>
References: <851a64cd1c9642d080f9481b5e091f35@3dtarget.it>
Message-ID: <9CAB69D5-A823-484B-890E-D4399D33C73C@hobu.co>



> On Dec 2, 2020, at 2:20 AM, 3D TARGET-Simone Rapposelli <rapposelli at 3dtarget.it> wrote:
> 
> Hi all,
>  
> we would like to integrate entwine.exe in our Windows desktop application to launch it in batch mode, but we have seen that it has dependencies with hundreds of dlls. Do you know if and in case which are the essential dlls to use?
> Kind regards,
>  
> Simone Rapposelli


Simone,

You will have to work through these issues yourself and build a custom build to limit the DLL footprint of the Entwine/PDAL combo. Presumably you are using the conda packages which do indeed link many things to provide the widest capability.

Do note that the Entwine licensing is LGPL. You will need to maintain dynamic linking of Entwine to not trigger any consequences of the LGPL in your commercial product. There is no static linking exception for Entwine. Contact me privately for commercial options on this topic.

Hope this helps,

Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201202/59fe07af/attachment.html>

From rapposelli at 3dtarget.it  Fri Dec  4 04:42:16 2020
From: rapposelli at 3dtarget.it (3D TARGET-Simone Rapposelli)
Date: Fri, 4 Dec 2020 12:42:16 +0000
Subject: [pdal] R: entwine dlls to distribute in windows desktop application
In-Reply-To: <9CAB69D5-A823-484B-890E-D4399D33C73C@hobu.co>
References: <851a64cd1c9642d080f9481b5e091f35@3dtarget.it>
 <9CAB69D5-A823-484B-890E-D4399D33C73C@hobu.co>
Message-ID: <726a743a34344d95a18df3fd8c6930c0@3dtarget.it>

Hi Howard,

thank you for your reply and yes, I used conda packages: I will try to follow your suggestions to solve these issues.
Kind regards,

Simone

Da: Howard Butler [mailto:howard at hobu.co]
Inviato: mercoled? 2 dicembre 2020 16:31
A: 3D TARGET-Simone Rapposelli <rapposelli at 3dtarget.it>
Cc: pdal at lists.osgeo.org
Oggetto: Re: [pdal] entwine dlls to distribute in windows desktop application




On Dec 2, 2020, at 2:20 AM, 3D TARGET-Simone Rapposelli <rapposelli at 3dtarget.it<mailto:rapposelli at 3dtarget.it>> wrote:

Hi all,

we would like to integrate entwine.exe in our Windows desktop application to launch it in batch mode, but we have seen that it has dependencies with hundreds of dlls. Do you know if and in case which are the essential dlls to use?
Kind regards,

Simone Rapposelli


Simone,

You will have to work through these issues yourself and build a custom build to limit the DLL footprint of the Entwine/PDAL combo. Presumably you are using the conda packages which do indeed link many things to provide the widest capability.

Do note that the Entwine licensing is LGPL. You will need to maintain dynamic linking of Entwine to not trigger any consequences of the LGPL in your commercial product. There is no static linking exception for Entwine. Contact me privately for commercial options on this topic.

Hope this helps,

Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201204/9ef12410/attachment.html>

From Peder.Axensten at slu.se  Thu Dec 10 04:40:32 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Thu, 10 Dec 2020 12:40:32 +0000
Subject: [pdal] Corrupt file for empty PointView?
Message-ID: <11F78DE3-39FC-43AD-8853-3B4A6C110052@slu.se>

Hej,

I am rewriting my filtering tools into pdal filters. On the whole it works ok, but if I have files where all points are ?removed? by the filter, the resulting [empty] file is corrupt. All other cases seem to work as expected. Is this a known issue? Do I need to handle empty files in a specific way in pdal?

In my original filtering tools I used liblas for reading/writing the files and I did have to save empty point clouds in a specific way or they would be corrupt. It was not difficult, mainly I had to specify the header information ? setting all bounding box coordinates to zero, for example.

A real life case would be a scan of water and a filter that do not let points classified as water pass. When processing very large areas divided into tens of thousands of files, such cases occur and it is not feasible to handle them all by hand.

Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Ume?
Visiting address: Skogsmarksgr?nd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

---
N?r du skickar e-post till SLU s? inneb?r detta att SLU behandlar dina personuppgifter. F?r att l?sa mer om hur detta g?r till, klicka h?r <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From andrew.bell.ia at gmail.com  Thu Dec 10 05:58:04 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Thu, 10 Dec 2020 08:58:04 -0500
Subject: [pdal] Corrupt file for empty PointView?
In-Reply-To: <11F78DE3-39FC-43AD-8853-3B4A6C110052@slu.se>
References: <11F78DE3-39FC-43AD-8853-3B4A6C110052@slu.se>
Message-ID: <CACJ51z3gR=Q1wQAOSOSGPa7HnqHNEAT7P4J=_xhVzUA=EMyUtw@mail.gmail.com>

On Thu, Dec 10, 2020 at 7:40 AM Peder Axensten <Peder.Axensten at slu.se>
wrote:

> Hej,
>
> I am rewriting my filtering tools into pdal filters. On the whole it works
> ok, but if I have files where all points are ?removed? by the filter, the
> resulting [empty] file is corrupt. All other cases seem to work as
> expected. Is this a known issue? Do I need to handle empty files in a
> specific way in pdal?
>

Without knowing the details of your pipeline/process, it's impossible to
know the issue, but there is nothing structural that creates corrupt files
when there are no points. Creating files with no points is a pretty common
case, though there may be a bug in a specific writer.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201210/b03bb389/attachment.html>

From beckley at unavco.org  Tue Dec 15 10:03:33 2020
From: beckley at unavco.org (Matt Beckley)
Date: Tue, 15 Dec 2020 11:03:33 -0700
Subject: [pdal] EPT:// prefix issue with PDAL 2.2
Message-ID: <CACrek76caKMjfS=CmPjpyAuAAw3_MA4qoZUfZAaK11tVPd5pqg@mail.gmail.com>

Hello,

It seems like when reading the ept data from the AWS 3DEP entwine bucket
the reader will not work unless I add the prefix, "ept://" to the URL (see
examples below).  This applies only to PDAL v2.2, and it is not clear if
this is a dataset-specific issue.  PDAL 2.1 will run with or without the
ept:// prefix, but it has the odd result that the filesizes will differ
slightly if using ept:// in the prefix or not.  Point counts are the same
whether or not you use ept:// with PDAL 2.1, but the "filesource_id"
parameter differs, so the filesize differences are probably due to slight
header differences.  In regards to the PDAL2.2 EPT issue, so far this seems
to happen on the following AWS 3DEP Entwine datasets:

USGS LPC CA Central Valley 2017 LAS 2019
CO_Southwest_NRCS_B2_2018
TX WestTexas B1 2018
NM SouthCentral B8 2018

*My question:*  For PDAL v2.2, should I always use the EPT:// prefix when
using readers.ept?  (seems related to:
https://github.com/PDAL/PDAL/pull/3174).  Also, as an aside, is streaming
available for readers.ept?  Documentation doesn't indicate it is, but this
issue: https://github.com/PDAL/PDAL/issues/2439 makes it seem that maybe it
is?  I'm uncertain how to test this.

Any info you could provide would be most appreciated.

Test1:  PDAL 2.2 WITHOUT EPT:// Prefix (PDAL installed via isolated conda
environment):

{


    "pipeline": [{


        "type": "readers.ept",


        "filename": "
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",

        "bounds": "([-13484500, -13484200], [4653000,4654200])"


    },


       "points_CA_noept.laz"]}

pdal pipeline pipeline.json gives error:

PDAL: readers.ept: Could not read from
s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019

Test2:  PDAL 2.2 WITH EPT:// Prefix (PDAL installed via isolated conda
environment):
{


    "pipeline": [{


        "type": "readers.ept",


        "filename": "ept://
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",

        "bounds": "([-13484500, -13484200], [4653000,4654200])"


    },


       "points_CA_wept.laz"]}

pdal pipeline pipeline.json runs successfully


Test3:  PDAL 2.1 WITHOUT EPT:// Prefix (PDAL installed via isolated conda
environment):
{
    "pipeline": [{
        "type": "readers.ept",
        "filename": "ept://
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
",
        "bounds": "([-13484500, -13484200], [4653000,4654200])"
    },
       "points_CA_wept_v21.laz"]}

pdal pipeline pipeline.json runs successfully, filesize is: 3453289 bytes.
 "count": 956938


Test4:  PDAL 2.1 WITH EPT:// Prefix (PDAL installed via isolated conda
environment):
{


    "pipeline": [{


        "type": "readers.ept",


        "filename": "
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",

        "bounds": "([-13484500, -13484200], [4653000,4654200])"


    },


       "points_CA_NOept_v21.laz"]}

pdal pipeline pipeline.json runs successfully, but filesize is different:
 3479637 bytes. "count": 956938


Point counts for results from PDAL 2.1 run match.  Only difference is
"filesource_id".  Version without EPT:// prefix has filesource_id=0, while
with EPT:// prefix "filesource_id": 26982.
---------------------------
Matthew Beckley
Data Engineer
UNAVCO/OpenTopography
beckley at unavco.org
cell: 301-982-9819
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201215/bc9ff3b2/attachment.html>

From connor at hobu.co  Tue Dec 15 10:21:24 2020
From: connor at hobu.co (Connor Manning)
Date: Tue, 15 Dec 2020 12:21:24 -0600
Subject: [pdal] EPT:// prefix issue with PDAL 2.2
In-Reply-To: <CACrek76caKMjfS=CmPjpyAuAAw3_MA4qoZUfZAaK11tVPd5pqg@mail.gmail.com>
References: <CACrek76caKMjfS=CmPjpyAuAAw3_MA4qoZUfZAaK11tVPd5pqg@mail.gmail.com>
Message-ID: <CAO=FyjJuEGK7eSjcv=s2sm897RU56gSwD_+RmAZDZSG+ysncBA@mail.gmail.com>

In one of the last few releases (not sure which) we tried to move away from
the "ept://" pseudo-protocol and instead use the presence of "ept.json" at
the end to signify the EPT reader.  So please try using a filename of
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019/ept.json
instead - this is the recommended format from now on.  I think we kept
support for both formats for at least one release.

This change was for a few reasons: when accessing over a network, the
double protocol (ept://http://...) is strange, and also that using the root
directory rather than the ept.json filename means that your "filename"
option is not a real file, e.g.
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
is a 404, but
https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019/ept.json
is an actual file.

I wouldn't worry much about the file size difference here since your point
counts match: since the EPT reader runs in a multi-threaded fashion, the
order of points may vary between runs, which leads to slight differences in
the compression.  You could add a "filters.sort" after the EPT reader to
counteract this (for LAZ data I'd recommend sorting by GpsTime and maybe
secondarily by ReturnNumber).

I'm not sure why your filesource_id would be changing, so maybe open a
Github issue on that one.

- Connor

On Tue, Dec 15, 2020 at 12:04 PM Matt Beckley <beckley at unavco.org> wrote:

> Hello,
>
> It seems like when reading the ept data from the AWS 3DEP entwine bucket
> the reader will not work unless I add the prefix, "ept://" to the URL (see
> examples below).  This applies only to PDAL v2.2, and it is not clear if
> this is a dataset-specific issue.  PDAL 2.1 will run with or without the
> ept:// prefix, but it has the odd result that the filesizes will differ
> slightly if using ept:// in the prefix or not.  Point counts are the same
> whether or not you use ept:// with PDAL 2.1, but the "filesource_id"
> parameter differs, so the filesize differences are probably due to slight
> header differences.  In regards to the PDAL2.2 EPT issue, so far this seems
> to happen on the following AWS 3DEP Entwine datasets:
>
> USGS LPC CA Central Valley 2017 LAS 2019
> CO_Southwest_NRCS_B2_2018
> TX WestTexas B1 2018
> NM SouthCentral B8 2018
>
> *My question:*  For PDAL v2.2, should I always use the EPT:// prefix when
> using readers.ept?  (seems related to:
> https://github.com/PDAL/PDAL/pull/3174).  Also, as an aside, is streaming
> available for readers.ept?  Documentation doesn't indicate it is, but this
> issue: https://github.com/PDAL/PDAL/issues/2439 makes it seem that maybe
> it is?  I'm uncertain how to test this.
>
> Any info you could provide would be most appreciated.
>
> Test1:  PDAL 2.2 WITHOUT EPT:// Prefix (PDAL installed via isolated conda
> environment):
>
> {
>
>
>     "pipeline": [{
>
>
>         "type": "readers.ept",
>
>
>         "filename": "
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>
>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>
>
>     },
>
>
>        "points_CA_noept.laz"]}
>
> pdal pipeline pipeline.json gives error:
>
> PDAL: readers.ept: Could not read from
> s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
>
> Test2:  PDAL 2.2 WITH EPT:// Prefix (PDAL installed via isolated conda
> environment):
> {
>
>
>     "pipeline": [{
>
>
>         "type": "readers.ept",
>
>
>         "filename": "ept://
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>
>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>
>
>     },
>
>
>        "points_CA_wept.laz"]}
>
> pdal pipeline pipeline.json runs successfully
>
>
> Test3:  PDAL 2.1 WITHOUT EPT:// Prefix (PDAL installed via isolated conda
> environment):
> {
>     "pipeline": [{
>         "type": "readers.ept",
>         "filename": "ept://
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
> ",
>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>     },
>        "points_CA_wept_v21.laz"]}
>
> pdal pipeline pipeline.json runs successfully, filesize is: 3453289 bytes.
>  "count": 956938
>
>
> Test4:  PDAL 2.1 WITH EPT:// Prefix (PDAL installed via isolated conda
> environment):
> {
>
>
>     "pipeline": [{
>
>
>         "type": "readers.ept",
>
>
>         "filename": "
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>
>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>
>
>     },
>
>
>        "points_CA_NOept_v21.laz"]}
>
> pdal pipeline pipeline.json runs successfully, but filesize is different:
>  3479637 bytes. "count": 956938
>
>
> Point counts for results from PDAL 2.1 run match.  Only difference is
> "filesource_id".  Version without EPT:// prefix has filesource_id=0, while
> with EPT:// prefix "filesource_id": 26982.
> ---------------------------
> Matthew Beckley
> Data Engineer
> UNAVCO/OpenTopography
> beckley at unavco.org
> cell: 301-982-9819
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201215/5d845640/attachment-0001.html>

From beckley at unavco.org  Tue Dec 15 10:25:11 2020
From: beckley at unavco.org (Matt Beckley)
Date: Tue, 15 Dec 2020 11:25:11 -0700
Subject: [pdal] EPT:// prefix issue with PDAL 2.2
In-Reply-To: <CAO=FyjJuEGK7eSjcv=s2sm897RU56gSwD_+RmAZDZSG+ysncBA@mail.gmail.com>
References: <CACrek76caKMjfS=CmPjpyAuAAw3_MA4qoZUfZAaK11tVPd5pqg@mail.gmail.com>
 <CAO=FyjJuEGK7eSjcv=s2sm897RU56gSwD_+RmAZDZSG+ysncBA@mail.gmail.com>
Message-ID: <CACrek75PcYviykdkTy74P_vJHXXArv9=6j3hks3roUc9yoqOUA@mail.gmail.com>

Hi Connor,

Thanks for the quick and informative reply.  I will implement the filename
as you suggested.  A quick follow-up:  Is streaming enabled on readers.ept?

---------------------------
Matthew Beckley
Data Engineer
UNAVCO/OpenTopography
beckley at unavco.org
cell: 301-982-9819


On Tue, Dec 15, 2020 at 11:21 AM Connor Manning <connor at hobu.co> wrote:

> In one of the last few releases (not sure which) we tried to move away
> from the "ept://" pseudo-protocol and instead use the presence of
> "ept.json" at the end to signify the EPT reader.  So please try using a
> filename of
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019/ept.json
> instead - this is the recommended format from now on.  I think we kept
> support for both formats for at least one release.
>
> This change was for a few reasons: when accessing over a network, the
> double protocol (ept://http://...) is strange, and also that using the
> root directory rather than the ept.json filename means that your "filename"
> option is not a real file, e.g.
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
> is a 404, but
> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019/ept.json
> is an actual file.
>
> I wouldn't worry much about the file size difference here since your point
> counts match: since the EPT reader runs in a multi-threaded fashion, the
> order of points may vary between runs, which leads to slight differences in
> the compression.  You could add a "filters.sort" after the EPT reader to
> counteract this (for LAZ data I'd recommend sorting by GpsTime and maybe
> secondarily by ReturnNumber).
>
> I'm not sure why your filesource_id would be changing, so maybe open a
> Github issue on that one.
>
> - Connor
>
> On Tue, Dec 15, 2020 at 12:04 PM Matt Beckley <beckley at unavco.org> wrote:
>
>> Hello,
>>
>> It seems like when reading the ept data from the AWS 3DEP entwine bucket
>> the reader will not work unless I add the prefix, "ept://" to the URL (see
>> examples below).  This applies only to PDAL v2.2, and it is not clear if
>> this is a dataset-specific issue.  PDAL 2.1 will run with or without the
>> ept:// prefix, but it has the odd result that the filesizes will differ
>> slightly if using ept:// in the prefix or not.  Point counts are the same
>> whether or not you use ept:// with PDAL 2.1, but the "filesource_id"
>> parameter differs, so the filesize differences are probably due to slight
>> header differences.  In regards to the PDAL2.2 EPT issue, so far this seems
>> to happen on the following AWS 3DEP Entwine datasets:
>>
>> USGS LPC CA Central Valley 2017 LAS 2019
>> CO_Southwest_NRCS_B2_2018
>> TX WestTexas B1 2018
>> NM SouthCentral B8 2018
>>
>> *My question:*  For PDAL v2.2, should I always use the EPT:// prefix
>> when using readers.ept?  (seems related to:
>> https://github.com/PDAL/PDAL/pull/3174).  Also, as an aside, is
>> streaming available for readers.ept?  Documentation doesn't indicate it is,
>> but this issue: https://github.com/PDAL/PDAL/issues/2439 makes it seem
>> that maybe it is?  I'm uncertain how to test this.
>>
>> Any info you could provide would be most appreciated.
>>
>> Test1:  PDAL 2.2 WITHOUT EPT:// Prefix (PDAL installed via isolated conda
>> environment):
>>
>> {
>>
>>
>>     "pipeline": [{
>>
>>
>>         "type": "readers.ept",
>>
>>
>>         "filename": "
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>>
>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>
>>
>>     },
>>
>>
>>        "points_CA_noept.laz"]}
>>
>> pdal pipeline pipeline.json gives error:
>>
>> PDAL: readers.ept: Could not read from
>> s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
>>
>> Test2:  PDAL 2.2 WITH EPT:// Prefix (PDAL installed via isolated conda
>> environment):
>> {
>>
>>
>>     "pipeline": [{
>>
>>
>>         "type": "readers.ept",
>>
>>
>>         "filename": "ept://
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>>
>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>
>>
>>     },
>>
>>
>>        "points_CA_wept.laz"]}
>>
>> pdal pipeline pipeline.json runs successfully
>>
>>
>> Test3:  PDAL 2.1 WITHOUT EPT:// Prefix (PDAL installed via isolated conda
>> environment):
>> {
>>     "pipeline": [{
>>         "type": "readers.ept",
>>         "filename": "ept://
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
>> ",
>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>     },
>>        "points_CA_wept_v21.laz"]}
>>
>> pdal pipeline pipeline.json runs successfully, filesize is: 3453289
>> bytes.  "count": 956938
>>
>>
>> Test4:  PDAL 2.1 WITH EPT:// Prefix (PDAL installed via isolated conda
>> environment):
>> {
>>
>>
>>     "pipeline": [{
>>
>>
>>         "type": "readers.ept",
>>
>>
>>         "filename": "
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>>
>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>
>>
>>     },
>>
>>
>>        "points_CA_NOept_v21.laz"]}
>>
>> pdal pipeline pipeline.json runs successfully, but filesize is different:
>>  3479637 bytes. "count": 956938
>>
>>
>> Point counts for results from PDAL 2.1 run match.  Only difference is
>> "filesource_id".  Version without EPT:// prefix has filesource_id=0, while
>> with EPT:// prefix "filesource_id": 26982.
>> ---------------------------
>> Matthew Beckley
>> Data Engineer
>> UNAVCO/OpenTopography
>> beckley at unavco.org
>> cell: 301-982-9819
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201215/6c11dc51/attachment.html>

From connor at hobu.co  Tue Dec 15 10:30:54 2020
From: connor at hobu.co (Connor Manning)
Date: Tue, 15 Dec 2020 12:30:54 -0600
Subject: [pdal] EPT:// prefix issue with PDAL 2.2
In-Reply-To: <CACrek75PcYviykdkTy74P_vJHXXArv9=6j3hks3roUc9yoqOUA@mail.gmail.com>
References: <CACrek76caKMjfS=CmPjpyAuAAw3_MA4qoZUfZAaK11tVPd5pqg@mail.gmail.com>
 <CAO=FyjJuEGK7eSjcv=s2sm897RU56gSwD_+RmAZDZSG+ysncBA@mail.gmail.com>
 <CACrek75PcYviykdkTy74P_vJHXXArv9=6j3hks3roUc9yoqOUA@mail.gmail.com>
Message-ID: <CAO=FyjJ=AO3SgaRuG-qGiSX06AbTAvaRTsPRqV5Huryt31c=4A@mail.gmail.com>

Yes it is, I see that the "streamable" tag was missing from the
documentation for the EPT reader and I've just now added it, so that should
be displayed the next time the docs are generated.

On Tue, Dec 15, 2020 at 12:25 PM Matt Beckley <beckley at unavco.org> wrote:

> Hi Connor,
>
> Thanks for the quick and informative reply.  I will implement the filename
> as you suggested.  A quick follow-up:  Is streaming enabled on readers.ept?
>
> ---------------------------
> Matthew Beckley
> Data Engineer
> UNAVCO/OpenTopography
> beckley at unavco.org
> cell: 301-982-9819
>
>
> On Tue, Dec 15, 2020 at 11:21 AM Connor Manning <connor at hobu.co> wrote:
>
>> In one of the last few releases (not sure which) we tried to move away
>> from the "ept://" pseudo-protocol and instead use the presence of
>> "ept.json" at the end to signify the EPT reader.  So please try using a
>> filename of
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019/ept.json
>> instead - this is the recommended format from now on.  I think we kept
>> support for both formats for at least one release.
>>
>> This change was for a few reasons: when accessing over a network, the
>> double protocol (ept://http://...) is strange, and also that using the
>> root directory rather than the ept.json filename means that your "filename"
>> option is not a real file, e.g.
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
>> is a 404, but
>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019/ept.json
>> is an actual file.
>>
>> I wouldn't worry much about the file size difference here since your
>> point counts match: since the EPT reader runs in a multi-threaded fashion,
>> the order of points may vary between runs, which leads to slight
>> differences in the compression.  You could add a "filters.sort" after the
>> EPT reader to counteract this (for LAZ data I'd recommend sorting by
>> GpsTime and maybe secondarily by ReturnNumber).
>>
>> I'm not sure why your filesource_id would be changing, so maybe open a
>> Github issue on that one.
>>
>> - Connor
>>
>> On Tue, Dec 15, 2020 at 12:04 PM Matt Beckley <beckley at unavco.org> wrote:
>>
>>> Hello,
>>>
>>> It seems like when reading the ept data from the AWS 3DEP entwine bucket
>>> the reader will not work unless I add the prefix, "ept://" to the URL (see
>>> examples below).  This applies only to PDAL v2.2, and it is not clear if
>>> this is a dataset-specific issue.  PDAL 2.1 will run with or without the
>>> ept:// prefix, but it has the odd result that the filesizes will differ
>>> slightly if using ept:// in the prefix or not.  Point counts are the same
>>> whether or not you use ept:// with PDAL 2.1, but the "filesource_id"
>>> parameter differs, so the filesize differences are probably due to slight
>>> header differences.  In regards to the PDAL2.2 EPT issue, so far this seems
>>> to happen on the following AWS 3DEP Entwine datasets:
>>>
>>> USGS LPC CA Central Valley 2017 LAS 2019
>>> CO_Southwest_NRCS_B2_2018
>>> TX WestTexas B1 2018
>>> NM SouthCentral B8 2018
>>>
>>> *My question:*  For PDAL v2.2, should I always use the EPT:// prefix
>>> when using readers.ept?  (seems related to:
>>> https://github.com/PDAL/PDAL/pull/3174).  Also, as an aside, is
>>> streaming available for readers.ept?  Documentation doesn't indicate it is,
>>> but this issue: https://github.com/PDAL/PDAL/issues/2439 makes it seem
>>> that maybe it is?  I'm uncertain how to test this.
>>>
>>> Any info you could provide would be most appreciated.
>>>
>>> Test1:  PDAL 2.2 WITHOUT EPT:// Prefix (PDAL installed via isolated
>>> conda environment):
>>>
>>> {
>>>
>>>
>>>     "pipeline": [{
>>>
>>>
>>>         "type": "readers.ept",
>>>
>>>
>>>         "filename": "
>>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>>>
>>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>>
>>>
>>>     },
>>>
>>>
>>>        "points_CA_noept.laz"]}
>>>
>>> pdal pipeline pipeline.json gives error:
>>>
>>> PDAL: readers.ept: Could not read from
>>> s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
>>>
>>> Test2:  PDAL 2.2 WITH EPT:// Prefix (PDAL installed via isolated conda
>>> environment):
>>> {
>>>
>>>
>>>     "pipeline": [{
>>>
>>>
>>>         "type": "readers.ept",
>>>
>>>
>>>         "filename": "ept://
>>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>>>
>>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>>
>>>
>>>     },
>>>
>>>
>>>        "points_CA_wept.laz"]}
>>>
>>> pdal pipeline pipeline.json runs successfully
>>>
>>>
>>> Test3:  PDAL 2.1 WITHOUT EPT:// Prefix (PDAL installed via isolated
>>> conda environment):
>>> {
>>>     "pipeline": [{
>>>         "type": "readers.ept",
>>>         "filename": "ept://
>>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019
>>> ",
>>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>>     },
>>>        "points_CA_wept_v21.laz"]}
>>>
>>> pdal pipeline pipeline.json runs successfully, filesize is: 3453289
>>> bytes.  "count": 956938
>>>
>>>
>>> Test4:  PDAL 2.1 WITH EPT:// Prefix (PDAL installed via isolated conda
>>> environment):
>>> {
>>>
>>>
>>>     "pipeline": [{
>>>
>>>
>>>         "type": "readers.ept",
>>>
>>>
>>>         "filename": "
>>> https://s3-us-west-2.amazonaws.com/usgs-lidar-public/USGS_LPC_CA_Central_Valley_2017_LAS_2019",
>>>
>>>         "bounds": "([-13484500, -13484200], [4653000,4654200])"
>>>
>>>
>>>     },
>>>
>>>
>>>        "points_CA_NOept_v21.laz"]}
>>>
>>> pdal pipeline pipeline.json runs successfully, but filesize is
>>> different:  3479637 bytes. "count": 956938
>>>
>>>
>>> Point counts for results from PDAL 2.1 run match.  Only difference is
>>> "filesource_id".  Version without EPT:// prefix has filesource_id=0, while
>>> with EPT:// prefix "filesource_id": 26982.
>>> ---------------------------
>>> Matthew Beckley
>>> Data Engineer
>>> UNAVCO/OpenTopography
>>> beckley at unavco.org
>>> cell: 301-982-9819
>>> _______________________________________________
>>> pdal mailing list
>>> pdal at lists.osgeo.org
>>> https://lists.osgeo.org/mailman/listinfo/pdal
>>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201215/4be75892/attachment-0001.html>

From david.greenberg at usda.gov  Tue Dec 22 14:40:40 2020
From: david.greenberg at usda.gov (Greenberg, David - FS, Vallejo, CA)
Date: Tue, 22 Dec 2020 22:40:40 +0000
Subject: [pdal] filtering noise in EPT data from the USGS public AWS bucket
Message-ID: <MN2PR09MB574000DF57C19C586C9BEFA890DF0@MN2PR09MB5740.namprd09.prod.outlook.com>

Hi everyone,

I'm interested in filtering noise from point clouds stored in EPT within the USGS public AWS bucket. I see that the points already have classifications. Does anyone know what method was used to classify the noise in these datasets?

I ask because my inclination is to use filters.outlier with the statistical option, and I'd like to evaluate this option against the method that has already been used. When I remove the original classifications and use filter.outlier with that option and the default parameters, I get a very different set of noise-classified points than the one that comes with the point clouds.

Thanks in advance

David




This electronic message contains information generated by the USDA solely for the intended recipients. Any unauthorized interception of this message or the use or disclosure of the information it contains may violate the law and subject the violator to civil or criminal penalties. If you believe you have received this message in error, please notify the sender and delete the email immediately.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201222/96f074e8/attachment.html>

From peter.lim at gpslands.com  Tue Dec 29 20:15:00 2020
From: peter.lim at gpslands.com (Peter Lim)
Date: Wed, 30 Dec 2020 12:15:00 +0800
Subject: [pdal] Took long time to generate Geo-tiff file after Update to
 Pdal 2.1.0
Message-ID: <000f01d6de62$573c9e00$05b5da00$@lim@gpslands.com>

Hi,

 

I've recently updated the Pdal version to 2.1.0 (git_version: Release).  

 

It took about 40 hours to generate a geo-tiff file from a laz file with 23
million points 

using 64GB Ram and the following json commands:

[

    {

        "type":"readers.las",

        "filename":"somefile.laz"

    },

 

                                {

                                                "type":"writers.gdal",

                                                "resolution": 0.03,

                                                "data_type":"uint16",

                                                "output_type":"mean",

                                                "dimension":"Intensity",

 
"gdalopts":"COMPRESS=DEFLATE,ZLEVEL=9,NUM_THREADS=ALL_CPUS",            

                                                "filename":"somefile.tif"


                                                

                                }                              

]

 

Before the Pdal update, it used to take about 3 - 5 hours only

 

Any idea why was it taken such long time.

 

 

Thank you.

 

Best Regards,

 

Peter Lim

 



-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201230/6de9542c/attachment.html>

From andrew.bell.ia at gmail.com  Wed Dec 30 07:03:19 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 30 Dec 2020 10:03:19 -0500
Subject: [pdal] Took long time to generate Geo-tiff file after Update to
 Pdal 2.1.0
In-Reply-To: <5febfed1.1c69fb81.e5614.6ee9SMTPIN_ADDED_BROKEN@mx.google.com>
References: <5febfed1.1c69fb81.e5614.6ee9SMTPIN_ADDED_BROKEN@mx.google.com>
Message-ID: <CACJ51z2d7z-NC8VzwUzpp69aUKmqkVoskmMDK2Q+67LFaJe1Cg@mail.gmail.com>

I don't see any changes of note between 2.0 and 2.1. You should run some
sort of a profiler or debugger in order to determine the root cause of the
change.  Note that you may get better performance by providing the bounds
of the output raster.

On Tue, Dec 29, 2020 at 11:15 PM Peter Lim <peter.lim at gpslands.com> wrote:

> Hi,
>
>
>
> I?ve recently updated the Pdal version to 2.1.0 (git_version: Release).
>
>
>
> It took about 40 hours to generate a geo-tiff file from a laz file with 23
> million points
>
> using 64GB Ram and the following json commands:
>
> [
>
>     {
>
>         "type":"readers.las",
>
>         "filename":"somefile.laz"
>
>     },
>
>
>
>                                 {
>
>                                                 "type":"writers.gdal",
>
>                                                 "resolution": 0.03,
>
>                                                 "data_type":"uint16",
>
>                                                 "output_type":"mean",
>
>                                                 "dimension":"Intensity",
>
>
> "gdalopts":"COMPRESS=DEFLATE,ZLEVEL=9,NUM_THREADS=ALL_CPUS",
>
>
> "filename":"somefile.tif"
>
>
>
>                                 }
>
> ]
>
>
>
> Before the Pdal update, it used to take about 3 ? 5 hours only
>
>
>
> Any idea why was it taken such long time.
>
>
>
>
>
> Thank you.
>
>
>
> Best Regards,
>
>
>
> Peter Lim
>
>
>
>
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient>
> <#m_8160687524060090510_DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
>


-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201230/0bae2ad0/attachment.html>

From peter.lim at gpslands.com  Wed Dec 30 23:18:26 2020
From: peter.lim at gpslands.com (Peter Lim)
Date: Thu, 31 Dec 2020 15:18:26 +0800
Subject: [pdal] Took long time to generate Geo-tiff file after Update to
 Pdal 2.1.0
In-Reply-To: <CACJ51z2d7z-NC8VzwUzpp69aUKmqkVoskmMDK2Q+67LFaJe1Cg@mail.gmail.com>
References: <5febfed1.1c69fb81.e5614.6ee9SMTPIN_ADDED_BROKEN@mx.google.com>
 <CACJ51z2d7z-NC8VzwUzpp69aUKmqkVoskmMDK2Q+67LFaJe1Cg@mail.gmail.com>
Message-ID: <001401d6df45$2293b010$67bb1030$@lim@gpslands.com>

Thanks Andrew for your advice!

 

When I run on another laz file, I have the following message:

 

proj_create_from_database: datum not found

proj_create_from_database: ellipsoid not found

proj_create_from_database: prime meridian not found

proj_create_from_database: datum not found

proj_create_from_database: ellipsoid not found

proj_create_from_database: prime meridian not found

PDAL: readers.las: reading point 50000 of 176406445 total points 

 

and Pdal stops.

 

No tif file is generated.  May I know what is the issue?

 

Thank you.

 

Best Regards,

 

Peter Lim

GPS Lands (S) Pte Ltd

 

From: Andrew Bell [mailto:andrew.bell.ia at gmail.com] 
Sent: Wednesday, 30 December 2020 11:03 pm
To: Peter Lim
Cc: pdal
Subject: Re: [pdal] Took long time to generate Geo-tiff file after Update to Pdal 2.1.0

 

I don't see any changes of note between 2.0 and 2.1. You should run some sort of a profiler or debugger in order to determine the root cause of the change.  Note that you may get better performance by providing the bounds of the output raster.

 

On Tue, Dec 29, 2020 at 11:15 PM Peter Lim <peter.lim at gpslands.com> wrote:

Hi,

 

I?ve recently updated the Pdal version to 2.1.0 (git_version: Release).  

 

It took about 40 hours to generate a geo-tiff file from a laz file with 23 million points 

using 64GB Ram and the following json commands:

[

    {

        "type":"readers.las",

        "filename":"somefile.laz"

    },

 

                                {

                                                "type":"writers.gdal",

                                                "resolution": 0.03,

                                                "data_type":"uint16",

                                                "output_type":"mean",

                                                "dimension":"Intensity",

                                                "gdalopts":"COMPRESS=DEFLATE,ZLEVEL=9,NUM_THREADS=ALL_CPUS",            

                                                "filename":"somefile.tif"             

                                                

                                }                              

]

 

Before the Pdal update, it used to take about 3 ? 5 hours only

 

Any idea why was it taken such long time.

 

 

Thank you.

 

Best Regards,

 

Peter Lim

 

 


 <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 

Virus-free.  <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> www.avast.com 

_______________________________________________
pdal mailing list
pdal at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/pdal




 

-- 

Andrew Bell
andrew.bell.ia at gmail.com



-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20201231/485641dd/attachment.html>

