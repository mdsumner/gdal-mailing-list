From andrew.bell.ia at gmail.com  Tue Sep  1 13:00:33 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 1 Sep 2020 16:00:33 -0400
Subject: [pdal] PDAL 2.2RC2
Message-ID: <CACJ51z0k3a+11nZWJdsWbsWDHOy9Zv8RXeUzmYb72YMV-i29VQ@mail.gmail.com>

All,

I've made release candidate 2 for PDAL 2.2 available. It adds a forgotten
stage, writers.raster. Also note that OCI support will be removed in a
future release.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200901/4b233a97/attachment.html>

From howard at hobu.co  Wed Sep  2 06:16:00 2020
From: howard at hobu.co (Howard Butler)
Date: Wed, 2 Sep 2020 08:16:00 -0500
Subject: [pdal] PDAL 2.2RC2
In-Reply-To: <CACJ51z0k3a+11nZWJdsWbsWDHOy9Zv8RXeUzmYb72YMV-i29VQ@mail.gmail.com>
References: <CACJ51z0k3a+11nZWJdsWbsWDHOy9Zv8RXeUzmYb72YMV-i29VQ@mail.gmail.com>
Message-ID: <CBBC7433-5C6D-4E15-BD3F-BE9352E50173@hobu.co>



> On Sep 1, 2020, at 3:00 PM, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> 
> All,
> 
> I've made release candidate 2 for PDAL 2.2 available. It adds a forgotten stage, writers.raster. Also note that OCI support will be removed in a future release.

Release notes and tarballs for 2.2.0RC2 are available from Github at 

https://github.com/PDAL/PDAL/releases/tag/2.2.0rc2 <https://github.com/PDAL/PDAL/releases/tag/2.2.0rc2>

Howard

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200902/999425f5/attachment.html>

From adam.d.steer at gmail.com  Wed Sep  2 06:47:09 2020
From: adam.d.steer at gmail.com (Adam Steer)
Date: Wed, 2 Sep 2020 15:47:09 +0200
Subject: [pdal] PDAL 2.2RC2
In-Reply-To: <CBBC7433-5C6D-4E15-BD3F-BE9352E50173@hobu.co>
References: <CACJ51z0k3a+11nZWJdsWbsWDHOy9Zv8RXeUzmYb72YMV-i29VQ@mail.gmail.com>
 <CBBC7433-5C6D-4E15-BD3F-BE9352E50173@hobu.co>
Message-ID: <CAFORoyg9SjLp2CEjQ=NO+0A1WQKhizZ0o3t3qyRWqxubZ7tZTQ@mail.gmail.com>

Thanks Andrew, Howard, and all of the contributors - there is a lot of
useful-looking capability in there...





On Wed, 2 Sep 2020 at 15:16, Howard Butler <howard at hobu.co> wrote:

>
>
> On Sep 1, 2020, at 3:00 PM, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
>
> All,
>
> I've made release candidate 2 for PDAL 2.2 available. It adds a forgotten
> stage, writers.raster. Also note that OCI support will be removed in a
> future release.
>
>
> Release notes and tarballs for 2.2.0RC2 are available from Github at
>
> https://github.com/PDAL/PDAL/releases/tag/2.2.0rc2
>
> Howard
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200902/f68329be/attachment.html>

From ben.southall at sri.com  Wed Sep  2 09:46:57 2020
From: ben.southall at sri.com (Ben Southall)
Date: Wed, 2 Sep 2020 16:46:57 +0000
Subject: [pdal] Allowing selection of PDAL shared readers by file extension?
Message-ID: <BLAPR09MB7044CD6FCBFB6A9517015CB98E2F0@BLAPR09MB7044.namprd09.prod.outlook.com>

Hello,

I'm writing a PDAL Reader plugin for a custom file type. If I write it as a static plugin, I know I can specify file extensions in StaticPluginInfo to allow PDAL to figure out when to use the reader. But then I have to rebuild all of PDAL to use the reader. Is there some runtime option (or other configuration step, aside from recompilation) that would allow me to tell PDAL to use a custom reader for certain file types? I know that for a single-input application, one can use -r readers.my_custom_reader, if I'd like to be able to load my custom data to a pipeline with mixed input types, or into a kernel (such as pdal delta) that takes two inputs.

Let's say I've got a .custom_ext dataset and .las dataset I'd like to run through pdal delta. It would appear that  I'm out of luck - if I use -r readers.my_custom_reader, then I think that my_custom_reader will be used for both inputs, so the .las dataset won't load. If I allow for automatic selection of reader type, then clearly it fails for my .custom_ext file, since the code that infers reader from file extension doesn't know about my dynamic reader.

To get pdal delta working, I'm currently writing a version that overloads the dataset loading code so that I can check for .custom_ext before attempting the usual driver inference process. But it would be nice to be able to tell PDAL about my fancy custom reader without having to do this (or without having to recompile PDAL to include my reader statically).

Best,

Ben
SRI email will be unavailable starting at 6 PM PDT, September 4, 2020. Email messages will be queued until email resumes on September 6, 2020.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200902/004daa4d/attachment.html>

From runette at gmail.com  Wed Sep  2 10:05:54 2020
From: runette at gmail.com (Paul Harwood)
Date: Wed, 2 Sep 2020 18:05:54 +0100
Subject: [pdal] PDAL 2.2RC2
In-Reply-To: <CAFORoyg9SjLp2CEjQ=NO+0A1WQKhizZ0o3t3qyRWqxubZ7tZTQ@mail.gmail.com>
References: <CACJ51z0k3a+11nZWJdsWbsWDHOy9Zv8RXeUzmYb72YMV-i29VQ@mail.gmail.com>
 <CBBC7433-5C6D-4E15-BD3F-BE9352E50173@hobu.co>
 <CAFORoyg9SjLp2CEjQ=NO+0A1WQKhizZ0o3t3qyRWqxubZ7tZTQ@mail.gmail.com>
Message-ID: <CAE8nN5MntksEubSW2L579pqrxTwJQwMsePeB2o3M82fQgJ7RMA@mail.gmail.com>

+1

On Wed, 2 Sep 2020 at 14:47, Adam Steer <adam.d.steer at gmail.com> wrote:

> Thanks Andrew, Howard, and all of the contributors - there is a lot of
> useful-looking capability in there...
>
>
>
>
>
> On Wed, 2 Sep 2020 at 15:16, Howard Butler <howard at hobu.co> wrote:
>
>>
>>
>> On Sep 1, 2020, at 3:00 PM, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
>>
>> All,
>>
>> I've made release candidate 2 for PDAL 2.2 available. It adds a forgotten
>> stage, writers.raster. Also note that OCI support will be removed in a
>> future release.
>>
>>
>> Release notes and tarballs for 2.2.0RC2 are available from Github at
>>
>> https://github.com/PDAL/PDAL/releases/tag/2.2.0rc2
>>
>> Howard
>>
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200902/72863bf3/attachment-0001.html>

From andrew.bell.ia at gmail.com  Thu Sep  3 16:14:19 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Thu, 3 Sep 2020 19:14:19 -0400
Subject: [pdal] Allowing selection of PDAL shared readers by file
	extension?
In-Reply-To: <BLAPR09MB7044CD6FCBFB6A9517015CB98E2F0@BLAPR09MB7044.namprd09.prod.outlook.com>
References: <BLAPR09MB7044CD6FCBFB6A9517015CB98E2F0@BLAPR09MB7044.namprd09.prod.outlook.com>
Message-ID: <CACJ51z1x9K4yTamQZdYxFGLYNBPE_NhXdYu4_ehdwGfiW-49Xg@mail.gmail.com>

After some discussion, I've reopened this issue:
https://github.com/PDAL/PDAL/issues/2714

If you have comments, please add them to the issue so they're all in one
place.

Thanks,

On Wed, Sep 2, 2020 at 12:47 PM Ben Southall <ben.southall at sri.com> wrote:

> Hello,
>
>
>
> I’m writing a PDAL Reader plugin for a custom file type. If I write it as
> a static plugin, I know I can specify file extensions in StaticPluginInfo
> to allow PDAL to figure out when to use the reader. But then I have to
> rebuild all of PDAL to use the reader. Is there some runtime option (or
> other configuration step, aside from recompilation) that would allow me to
> tell PDAL to use a custom reader for certain file types? I know that for a
> single-input application, one can use -r readers.my_custom_reader, if I’d
> like to be able to load my custom data to a pipeline with mixed input
> types, or into a kernel (such as pdal delta) that takes two inputs.
>
>
>
> Let’s say I’ve got a .custom_ext dataset and .las dataset I’d like to run
> through pdal delta. It would appear that  I’m out of luck – if I use -r
> readers.my_custom_reader, then I think that my_custom_reader will be used
> for both inputs, so the .las dataset won’t load. If I allow for automatic
> selection of reader type, then clearly it fails for my .custom_ext file,
> since the code that infers reader from file extension doesn’t know about my
> dynamic reader.
>
>
>
> To get pdal delta working, I’m currently writing a version that overloads
> the dataset loading code so that I can check for .custom_ext before
> attempting the usual driver inference process. But it would be nice to be
> able to tell PDAL about my fancy custom reader without having to do this
> (or without having to recompile PDAL to include my reader statically).
>
>
>
> Best,
>
>
>
> Ben
> SRI email will be unavailable starting at 6 PM PDT, September 4, 2020.
> Email messages will be queued until email resumes on September 6, 2020.
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200903/9e54084e/attachment.html>

From alexandre.poirot at pix4d.com  Fri Sep  4 02:32:50 2020
From: alexandre.poirot at pix4d.com (Alexandre Poirot)
Date: Fri, 4 Sep 2020 11:32:50 +0200
Subject: [pdal] "Unknown" values in WKT string
Message-ID: <CAD-6rM7uc1oYHWrCZ3kyr=Q6f5PUOd_JYqHe3BJ7SqVD-T=mAg@mail.gmail.com>

Hello all,

I am trying to understand a behaviour of PDAL 2.1.0 regarding LAS file reading.

I have a LAS 1.4 file which have the following content as its WKT string:

----------
COMPD_CS["NAD83(2011) / Alabama West + Ellipsoid
(Meters)",PROJCS["NAD83(2011) / Alabama
West",GEOGCS["NAD83(2011)",DATUM["NAD83_National_Spatial_Reference_System_2011",SPHEROID["GRS
1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],AUTHORITY["EPSG","1116"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","6318"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",30],PARAMETER["central_meridian",-87.5],PARAMETER["scale_factor",0.999933333],PARAMETER["false_easting",600000],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["X",EAST],AXIS["Y",NORTH],AUTHORITY["EPSG","6356"]],VERT_CS["Ellipsoid
(Meters)",VERT_DATUM["Ellipsoid",2002],UNIT["metre",1.0,AUTHORITY["EPSG","9001"]],AXIS["Up",UP]]]
-----------

I got this file from a colleague.

When I run the command (configuration: Archlinux with Linux 5.8 kernel):

----------
pdal info --metadata <myfile>
----------

I obtain the following result for the spatial reference:

----------
"spatialreference": "COMPD_CS[\"unknown\",PROJCS[\"NAD83(2011) /
Alabama West\",GEOGCS[\"NAD83(2011)\",DATUM[\"NAD83_National_Spatial_Reference_System_2011\",SPHEROID[\"GRS
1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"1116\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"6318\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",30],PARAMETER[\"central_meridian\",-87.5],PARAMETER[\"scale_factor\",0.999933333],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"6356\"]],VERT_CS[\"unknown\",VERT_DATUM[\"unknown\",2005],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Up\",UP]]]"
----------

I don't understand why and where the COMPD_CS, VERT_CS and VERT_DATUM
are filled with "unknown" while it is defined in the LAS file.
There is also some messages displayed in the console (6 to be thorough):
"proj_uom_get_info_from_database: unit of measure not found"

So my first question is do you know why this behavior is happening?
A second question is can I trust the point positions that PDAL read
from the LAS file with the "unknown" being present in the srs?

Could "Ellipsoid" be a user defined coordinate system that my proj
installation doesn't know?

Should I open an issue on the Github repository?

By the way, congratulations for the great work you've achieved so far
on this library!

Best regards,
Alexandre Poirot | Software Engineer
Route de Renens 24 | 1008 Prilly, Switzerland
alexandre.poirot at pix4d.com
https://www.pix4d.com/

From howard at hobu.co  Fri Sep  4 06:52:52 2020
From: howard at hobu.co (Howard Butler)
Date: Fri, 4 Sep 2020 08:52:52 -0500
Subject: [pdal] "Unknown" values in WKT string
In-Reply-To: <CAD-6rM7uc1oYHWrCZ3kyr=Q6f5PUOd_JYqHe3BJ7SqVD-T=mAg@mail.gmail.com>
References: <CAD-6rM7uc1oYHWrCZ3kyr=Q6f5PUOd_JYqHe3BJ7SqVD-T=mAg@mail.gmail.com>
Message-ID: <B5A6E94E-88E3-4F1B-992A-7452C62BC790@hobu.co>

Alexandre,

Would it be possible to (privately) inspect the file? PDAL transits the WKT through GDAL/PROJ, and it hands off all production and consumption to that. The entity names on the WKT are unknown because they don't match entries in the database that PROJ is using. It would be helpful to know what PROJ version you are using, but anything current is likely to have this behavior.

Also, which software produced this file?

Howard

> On Sep 4, 2020, at 4:32 AM, Alexandre Poirot <alexandre.poirot at pix4d.com> wrote:
> 
> Hello all,
> 
> I am trying to understand a behaviour of PDAL 2.1.0 regarding LAS file reading.
> 
> I have a LAS 1.4 file which have the following content as its WKT string:
> 
> ----------
> COMPD_CS["NAD83(2011) / Alabama West + Ellipsoid
> (Meters)",PROJCS["NAD83(2011) / Alabama
> West",GEOGCS["NAD83(2011)",DATUM["NAD83_National_Spatial_Reference_System_2011",SPHEROID["GRS
> 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],AUTHORITY["EPSG","1116"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","6318"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",30],PARAMETER["central_meridian",-87.5],PARAMETER["scale_factor",0.999933333],PARAMETER["false_easting",600000],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["X",EAST],AXIS["Y",NORTH],AUTHORITY["EPSG","6356"]],VERT_CS["Ellipsoid
> (Meters)",VERT_DATUM["Ellipsoid",2002],UNIT["metre",1.0,AUTHORITY["EPSG","9001"]],AXIS["Up",UP]]]
> -----------
> 
> I got this file from a colleague.
> 
> When I run the command (configuration: Archlinux with Linux 5.8 kernel):
> 
> ----------
> pdal info --metadata <myfile>
> ----------
> 
> I obtain the following result for the spatial reference:
> 
> ----------
> "spatialreference": "COMPD_CS[\"unknown\",PROJCS[\"NAD83(2011) /
> Alabama West\",GEOGCS[\"NAD83(2011)\",DATUM[\"NAD83_National_Spatial_Reference_System_2011\",SPHEROID[\"GRS
> 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"1116\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"6318\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",30],PARAMETER[\"central_meridian\",-87.5],PARAMETER[\"scale_factor\",0.999933333],PARAMETER[\"false_easting\",600000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"6356\"]],VERT_CS[\"unknown\",VERT_DATUM[\"unknown\",2005],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Up\",UP]]]"
> ----------
> 
> I don't understand why and where the COMPD_CS, VERT_CS and VERT_DATUM
> are filled with "unknown" while it is defined in the LAS file.
> There is also some messages displayed in the console (6 to be thorough):
> "proj_uom_get_info_from_database: unit of measure not found"
> 
> So my first question is do you know why this behavior is happening?
> A second question is can I trust the point positions that PDAL read
> from the LAS file with the "unknown" being present in the srs?
> 
> Could "Ellipsoid" be a user defined coordinate system that my proj
> installation doesn't know?
> 
> Should I open an issue on the Github repository?
> 
> By the way, congratulations for the great work you've achieved so far
> on this library!
> 
> Best regards,
> Alexandre Poirot | Software Engineer
> Route de Renens 24 | 1008 Prilly, Switzerland
> alexandre.poirot at pix4d.com
> https://www.pix4d.com/
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal


From howard at hobu.co  Fri Sep  4 07:21:51 2020
From: howard at hobu.co (Howard Butler)
Date: Fri, 4 Sep 2020 09:21:51 -0500
Subject: [pdal] Metrics calculation
In-Reply-To: <CACJ51z1nE6678_XmATBacPuitfnJMYG7mVUe-J7+wExd8E8UzQ@mail.gmail.com>
References: <9B4DCEC2-B8F5-4169-A2C6-555E363E2793@slu.se>
 <CACJ51z1nE6678_XmATBacPuitfnJMYG7mVUe-J7+wExd8E8UzQ@mail.gmail.com>
Message-ID: <A26AD013-A67B-4CAF-82F7-A996B1DE119A@hobu.co>



> On Aug 31, 2020, at 1:40 PM, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> 
> 
> On Mon, Aug 31, 2020 at 9:07 AM Peder Axensten <Peder.Axensten at slu.se <mailto:Peder.Axensten at slu.se>> wrote:
> 
> I’ve started with the tool to produce raster metrics. I copied the files for writers.gdal and renamed [what I think is] relevant parts.
> Q1: Is this a good way to start, do you think? Or should I use something else to start from?
> 
> Does writers.gdal not already do what you want? What capability is missing, exactly? Specific statistics?

One of the issues with writers.gdal is its statistics aren't for the cell, but rather for the neighborhood region. This ticket documents the issue, which we can hopefully enhance in a future release. https://github.com/PDAL/PDAL/issues/3215 <https://github.com/PDAL/PDAL/issues/3215>


> 
> Q3: Do you think this is a good way to do the transition to pdal or would you suggest a better way?
> 
> I don't understand what you're trying to do, exactly, so I can't answer.
> 
> We have one tool to produce raster metrics from laz files and another to calculate plot metrics from a set of laz files and a csv file containing coordinates and radius of plots. They are coded in C++17 and structured as a library where the actual tools are rather short files that handles command line options and then make a call into the library. You specify what metrics you need in the command line options (see the —help output below). The library structure makes it pretty straightforward to add yet more metrics. We use a tool implemented in R for the actual modelling/prediction. These tools are executed from a make script to process tens of thousands of files in a paralleled manner.
> 
> PDAL targets C++11. If you're making code for the public, it must build under C++11 for now.

Which C++17 constructs are you using? Just filesystem stuff? PDAL has some utilities to handle filesystem activity to keep the bar at C++11.

>  
> Q4: Would there be a general interest for such drivers (writers.gdal.metrics and writers.text.metrics)? We’d be happy to eventually make the code open source.


There is definitely interest for FUSION-like forestry metrics from a number of PDAL using sub-communities. I think it has been an outstanding question about how those statistics are delivered. For example, what formats are suitable, convenient, and sufficient for per-point or per-cell moments to be passed on to the next consumer in the processing chain. FUSION, for example, generates a blizzard of ascii files of which most do not need to be used. PDAL's metadata system doesn't seem like a good fit for such a thing.

Howard


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200904/048dcbdc/attachment-0001.html>

From Peder.Axensten at slu.se  Mon Sep  7 08:33:46 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Mon, 7 Sep 2020 15:33:46 +0000
Subject: [pdal] Metrics calculation
In-Reply-To: <A26AD013-A67B-4CAF-82F7-A996B1DE119A@hobu.co>
References: <9B4DCEC2-B8F5-4169-A2C6-555E363E2793@slu.se>
 <CACJ51z1nE6678_XmATBacPuitfnJMYG7mVUe-J7+wExd8E8UzQ@mail.gmail.com>
 <A26AD013-A67B-4CAF-82F7-A996B1DE119A@hobu.co>
Message-ID: <AADDE1F8-C1BC-4F7E-A77A-98C0B941A0AA@slu.se>


> On 4 Sep 2020, at 16:21, Howard Butler <howard at hobu.co> wrote:
>
>> On Mon, Aug 31, 2020 at 9:07 AM Peder Axensten <Peder.Axensten at slu.se> wrote:
>>
>> I’ve started with the tool to produce raster metrics. I copied the files for writers.gdal and renamed [what I think is] relevant parts.
>> Q1: Is this a good way to start, do you think? Or should I use something else to start from?
>>
>> Does writers.gdal not already do what you want? What capability is missing, exactly? Specific statistics?
>
> One of the issues with writers.gdal is its statistics aren't for the cell, but rather for the neighborhood region. This ticket documents the issue, which we can hopefully enhance in a future release. https://github.com/PDAL/PDAL/issues/3215

I thought that writers.gdal might be a good starting point for a writers.raster_metrics as they both “convert” a point cloud to a raster. So far I basically just renamed things and it seems to work – the next step would be to replace code to change the actual functionality. Would you suggest a different class as a starting point? What would you suggest as a starting point for a writers.text_metrics? The tool we have today takes a directory with las files and a csv file as input and produces a copy of the original csv file with additional columns containing metric values. Would that fit with the pdal way of doing things, if we read the points from a pdal pipe?



>> Q3: Do you think this is a good way to do the transition to pdal or would you suggest a better way?
>>
>> I don't understand what you're trying to do, exactly, so I can't answer.
>>
>> We have one tool to produce raster metrics from laz files and another to calculate plot metrics from a set of laz files and a csv file containing coordinates and radius of plots. They are coded in C++17 and structured as a library where the actual tools are rather short files that handles command line options and then make a call into the library. You specify what metrics you need in the command line options (see the —help output below). The library structure makes it pretty straightforward to add yet more metrics. We use a tool implemented in R for the actual modelling/prediction. These tools are executed from a make script to process tens of thousands of files in a paralleled manner.
>>
>> PDAL targets C++11. If you're making code for the public, it must build under C++11 for now.
>
> Which C++17 constructs are you using? Just filesystem stuff? PDAL has some utilities to handle filesystem activity to keep the bar at C++11.

Yes, using pdal would mean that I could loose a lot of the present support code, such as [raster] file handling. I don’t think my code for the actual metrics handling would be difficult to make C++11 compliant. And as it seems that pdal could handle most of the supporting stuff, I think raster_metrics would be ok.

I don’t yet know yet how much support pdal has for [text] tables, as needed by text_metrics. Obviously, I would need to read and write csv files, and access and add columns. The code I have for that today uses string_view liberally, charconv, fold-expressions (e.g. for efficient string concatenation), and probably other things such as if constexpr. I also use some external libraries (boost and fmt).

I guess that I would first rewrite the code to take advantage of the pdal ecosystem and then see what happens when I restrict the compiler to C++11 and take it from there. But I dread the moment…



>>  Q4: Would there be a general interest for such drivers (writers.gdal.metrics and writers.text.metrics)? We’d be happy to eventually make the code open source.
>
> There is definitely interest for FUSION-like forestry metrics from a number of PDAL using sub-communities. I think it has been an outstanding question about how those statistics are delivered. For example, what formats are suitable, convenient, and sufficient for per-point or per-cell moments to be passed on to the next consumer in the processing chain. FUSION, for example, generates a blizzard of ascii files of which most do not need to be used. PDAL's metadata system doesn't seem like a good fit for such a thing.

I think that for raster_metrics using gdal for raster export is pretty natural? We opted for producing one-band files rather than one multi-band file, as it makes it simpler to see what is what through file name extensions. Separate files for separate things is also important when using make scripts to process many files, as we do.

For text_metrics we felt that using csv-like files fitted the rest of our processing environment best. (Actually we use semicolon delimited files as comma is used as the fractional delimiter of numbers in Swedish typography, sometimes causing unpredictable results with localised software…) As all our field data are circular plots, we look for east, north, and radius in the header line. It would not be difficult to use square or rectangular plots using different tags, but that would be rather hands on? To really generalise, I guess that an area concept would be needed along the lines of the point concept. Then different readers/writers (csv, hdf, json, etc.) and pipes could be implemented in a general way, using dimensions for auxiliary data?


Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Umeå
Visiting address: Skogsmarksgränd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

---
När du skickar e-post till SLU så innebär detta att SLU behandlar dina personuppgifter. För att läsa mer om hur detta går till, klicka här <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From howard at hobu.co  Mon Sep  7 08:56:53 2020
From: howard at hobu.co (Howard Butler)
Date: Mon, 7 Sep 2020 10:56:53 -0500
Subject: [pdal] Metrics calculation
In-Reply-To: <AADDE1F8-C1BC-4F7E-A77A-98C0B941A0AA@slu.se>
References: <9B4DCEC2-B8F5-4169-A2C6-555E363E2793@slu.se>
 <CACJ51z1nE6678_XmATBacPuitfnJMYG7mVUe-J7+wExd8E8UzQ@mail.gmail.com>
 <A26AD013-A67B-4CAF-82F7-A996B1DE119A@hobu.co>
 <AADDE1F8-C1BC-4F7E-A77A-98C0B941A0AA@slu.se>
Message-ID: <CAB5BAB1-0A8A-403E-9FED-286205C6AC07@hobu.co>



> On Sep 7, 2020, at 10:33 AM, Peder Axensten <Peder.Axensten at slu.se> wrote:
> 
> I guess that I would first rewrite the code to take advantage of the pdal ecosystem and then see what happens when I restrict the compiler to C++11 and take it from there. But I dread the moment…

We are very close to going to c++17, and we have tried to do it last release and failed. It was OSX/clang that was the challenge at the time. Maybe it is no longer the case. In my opinion the threshold to open up to C++17 is OSX, Linux, and Windows successful compilation and tests across the compilers available to the Conda CI that PDAL uses. PDAL also uses the same Conda Forge setup for its binary builds.

> I think that for raster_metrics using gdal for raster export is pretty natural? We opted for producing one-band files rather than one multi-band file, as it makes it simpler to see what is what through file name extensions. Separate files for separate things is also important when using make scripts to process many files, as we do.

Seems reasonable. Something like TileDB would also seem to be a good fit, but use what people can consume.

> 
> For text_metrics we felt that using csv-like files fitted the rest of our processing environment best. (Actually we use semicolon delimited files as comma is used as the fractional delimiter of numbers in Swedish typography, sometimes causing unpredictable results with localised software…) As all our field data are circular plots, we look for east, north, and radius in the header line. It would not be difficult to use square or rectangular plots using different tags, but that would be rather hands on? To really generalise, I guess that an area concept would be needed along the lines of the point concept. Then different readers/writers (csv, hdf, json, etc.) and pipes could be implemented in a general way, using dimensions for auxiliary data?

Understood. I am (maybe vainly) hoping for some convenience for other groups such as FUSION and its users who might be looking to leverage PDAL to have the opportunity to get output in formats they can consume.


From Peder.Axensten at slu.se  Mon Sep  7 11:27:57 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Mon, 7 Sep 2020 18:27:57 +0000
Subject: [pdal] Metrics calculation
In-Reply-To: <CAB5BAB1-0A8A-403E-9FED-286205C6AC07@hobu.co>
References: <9B4DCEC2-B8F5-4169-A2C6-555E363E2793@slu.se>
 <CACJ51z1nE6678_XmATBacPuitfnJMYG7mVUe-J7+wExd8E8UzQ@mail.gmail.com>
 <A26AD013-A67B-4CAF-82F7-A996B1DE119A@hobu.co>
 <AADDE1F8-C1BC-4F7E-A77A-98C0B941A0AA@slu.se>
 <CAB5BAB1-0A8A-403E-9FED-286205C6AC07@hobu.co>
Message-ID: <E9E5A1B1-CEBD-4652-9348-30D98E6B681C@slu.se>

> On 7 Sep 2020, at 17:56, Howard Butler <howard at hobu.co> wrote:
>
>> On Sep 7, 2020, at 10:33 AM, Peder Axensten <Peder.Axensten at slu.se> wrote:
>>
>> I guess that I would first rewrite the code to take advantage of the pdal ecosystem and then see what happens when I restrict the compiler to C++11 and take it from there. But I dread the moment…
>
> We are very close to going to c++17, and we have tried to do it last release and failed. It was OSX/clang that was the challenge at the time. Maybe it is no longer the case. In my opinion the threshold to open up to C++17 is OSX, Linux, and Windows successful compilation and tests across the compilers available to the Conda CI that PDAL uses. PDAL also uses the same Conda Forge setup for its binary builds.

I am on OSX and use clang, but not Apple’s. I stoped using it a few years ago as it wasn’t ever updated… There are alternatives. I use MacPorts to install a recent clang and libraries (including boost, gdal, and pdal) and keep them updated.


>> I think that for raster_metrics using gdal for raster export is pretty natural? We opted for producing one-band files rather than one multi-band file, as it makes it simpler to see what is what through file name extensions. Separate files for separate things is also important when using make scripts to process many files, as we do.
>
> Seems reasonable. Something like TileDB would also seem to be a good fit, but use what people can consume.
>
>> For text_metrics we felt that using csv-like files fitted the rest of our processing environment best. (Actually we use semicolon delimited files as comma is used as the fractional delimiter of numbers in Swedish typography, sometimes causing unpredictable results with localised software…) As all our field data are circular plots, we look for east, north, and radius in the header line. It would not be difficult to use square or rectangular plots using different tags, but that would be rather hands on? To really generalise, I guess that an area concept would be needed along the lines of the point concept. Then different readers/writers (csv, hdf, json, etc.) and pipes could be implemented in a general way, using dimensions for auxiliary data?
>
> Understood. I am (maybe vainly) hoping for some convenience for other groups such as FUSION and its users who might be looking to leverage PDAL to have the opportunity to get output in formats they can consume.

I can only give my view of our experience. FUSION is not always straightforward to use. Its raster metrics calculation produces output that requires further processing and to calculate metrics for plots you must first prepare individual las files of each plot’s points, if I remember correctly. If there had been metrics calculation in pdal we would not have developed our own tools. Pdal tools that produces metrics in say tif and csv formats would be very straightforward to use in our process chain and having them in the pdal ecosystem would offer greater flexibility.

We use the following stages that are managed by a make script:
1 Normalisation and filtering (las->las, tool in C++).
2 Raster metrics (las->tif, tool in C++).
3 Plot metrics (las+csv->csv, tool in C++).
4 Modelling and variable calculation (tif+csv->tif, tool in R).
5 Merging tif files for each variable (many tif->one tif, in gdal).
6 Evaluation (tool in R).

Using make ensures that all is up to date and also enables parallel processing.

Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Umeå
Visiting address: Skogsmarksgränd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

---
När du skickar e-post till SLU så innebär detta att SLU behandlar dina personuppgifter. För att läsa mer om hur detta går till, klicka här <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From andrew.bell.ia at gmail.com  Wed Sep  9 08:34:05 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Wed, 9 Sep 2020 11:34:05 -0400
Subject: [pdal] PDAL 2.2.0 Released
Message-ID: <CACJ51z2YLYAcQo111T==miKbxXuRMDT+C8rhdTMzinx2BNZRQA@mail.gmail.com>

All,

PDAL version 2.2 is now available. You can download the source code and see
the release notes here: https://github.com/PDAL/PDAL/releases/tag/2.2.0
A Conda version should be available shortly.

In addition to new filters and many bug fixes, this version features a
"where" option for filters to allow points to bypass a filter stage. The
assign filter also has added simple math functionality.

For API users, note that the default storage of data in PDAL 2.2 has
changed to column-major from row-major order (data comprising a single
point is no longer stored contiguously). You can access the behavior in
PDAL 2.1 by using the class RowPointTable instead of ColumnPointTable,
which is the default data storage structure in PDAL 2.2.

Please let me know if you have any questions,

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200909/c1e9e780/attachment.html>

From Peder.Axensten at slu.se  Thu Sep 10 06:43:30 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Thu, 10 Sep 2020 13:43:30 +0000
Subject: [pdal] How to get the metadata of a file?
Message-ID: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>

I want to implement a writer that takes a point cloud file and rasterises it (percentiles and other statistics):
class Raster_metrics : public pdal::Writer;

My understanding from the documentation is that I should setup things in
void Raster_metrics::ready( pdal::PointTableRef table );
Correct?
To do that I need to access the header data of the input file, specifically its bounding box.
How do I get the input file’s bounding box from table?
And other file metadata?

Further I should process the actual points in
void Raster_metrics::write( pdal::PointViewPtr view ) — for chunks of points.
Correct?
I want to be able to process points also in a serialised manner – in what member function should I do that?

And finally I should calculate the statistics and output the these as rasters [using gdal] in
void Raster_metrics::done( pdal::PointTableRef table )
Correct?

I’ve been reading through the documentation on pdal.io, but I find it a bit scant – is there more detailed documentation somewhere?
(I.e. https://pdal.io/api/cpp/metadata.html is just a list of member functions.)

Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Umeå
Visiting address: Skogsmarksgränd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

---
När du skickar e-post till SLU så innebär detta att SLU behandlar dina personuppgifter. För att läsa mer om hur detta går till, klicka här <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From andrew.bell.ia at gmail.com  Thu Sep 10 07:27:17 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Thu, 10 Sep 2020 10:27:17 -0400
Subject: [pdal] How to get the metadata of a file?
In-Reply-To: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
References: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
Message-ID: <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>

On Thu, Sep 10, 2020 at 9:43 AM Peder Axensten <Peder.Axensten at slu.se>
wrote:

> I want to implement a writer that takes a point cloud file and rasterises
> it (percentiles and other statistics):
> class Raster_metrics : public pdal::Writer;
>
> My understanding from the documentation is that I should setup things in
> void Raster_metrics::ready( pdal::PointTableRef table );
> Correct?
> To do that I need to access the header data of the input file,
> specifically its bounding box.
>

PDAL typically works on PointView objects rather than PointTable objects.
Normally one would calculate the bounds based on PointView in either
filter() or run(). Search for calculateBounds(). It would not be
unreasonable to create a separate raster for each input PointView.

How do I get the input file’s bounding box from table?
>

You don't.


> And other file metadata?
>

Metadata is generally stored with each stage. If you want the metadata that
was read, you have to walk stages back until you find the one you're
looking for, call getMetadata(), and then extract any information you're
looking for. We don't usually use file metadata during processing, with the
exception of spatial reference, which is stored separately. We don't use
metadata-provided bounding boxes because 1) they have been known to be
wrong 2) PDAL may aggregate and drop points in between the time that data
is read and the time that a filter is run.

Further I should process the actual points in
> void Raster_metrics::write( pdal::PointViewPtr view ) — for chunks of
> points.
> Correct?
> I want to be able to process points also in a serialised manner – in what
> member function should I do that?
>

I don't know what you mean. You can simply loop through all the points in
the view and process them one at a time. If you don't need all the points
prior to beginning processing, you can implement a stream mode filter by
inheriting from Streamable and implement processOne().  That said, if you
need bounds, you need all the points, which means that your filter won't
work in stream mode.

And finally I should calculate the statistics and output the these as
> rasters [using gdal] in
> void Raster_metrics::done( pdal::PointTableRef table )
> Correct?
>

This is up to you. Using the new functionality in 2.2, you can call
view.createRaster(). It will return a raster to which you can write data. I
would do this in filter() or run().

I’ve been reading through the documentation on pdal.io, but I find it a bit
> scant – is there more detailed documentation somewhere?
> (I.e. https://pdal.io/api/cpp/metadata.html is just a list of member
> functions.)
>

What is available on the PDAL website is what exists. We don't have much
documentation of individual functions. Sorry. Please make use of the
existing code and tests.  Feel free to write with specific questions.

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200910/d4160eca/attachment.html>

From runette at gmail.com  Thu Sep 10 08:32:57 2020
From: runette at gmail.com (Paul Harwood)
Date: Thu, 10 Sep 2020 16:32:57 +0100
Subject: [pdal] PDAL 2.2.0 - missing Red Dimension
Message-ID: <CAE8nN5Moo-0+Bn9AXMV=HYKOoSSY6NJjDE50b5ihfT3ysHpL9g@mail.gmail.com>

Hi

I just tried to upgrade my application to PDAL 2.2.0 and got an
unexpected result. I got the PDAL binaries for Windows form Conda-Forge.

The upgrade worked.

However ...

My application uses the API to load the PointView, looks in the Layout for
DimTypes of X, Y, Z and Red, Green, Blue and uses them.

Under 2.2.0 - I get X, Y & Z and the values are as expected. BUT I don't
get a Red Dimension - just Green, Blue and GpsTime!

If have looked at some other data and the Dimension Names (apart from X, Y
and Z) are all shifted by one in the Dimension.json file.

Is this something that I have done wrong?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200910/f967e419/attachment.html>

From andrew.bell.ia at gmail.com  Thu Sep 10 08:46:11 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Thu, 10 Sep 2020 11:46:11 -0400
Subject: [pdal] PDAL 2.2.0 - missing Red Dimension
In-Reply-To: <CAE8nN5Moo-0+Bn9AXMV=HYKOoSSY6NJjDE50b5ihfT3ysHpL9g@mail.gmail.com>
References: <CAE8nN5Moo-0+Bn9AXMV=HYKOoSSY6NJjDE50b5ihfT3ysHpL9g@mail.gmail.com>
Message-ID: <CACJ51z04QhSjiOmH08VboTxs2HTNhHjw4DGaqNqYi3FzsxAm2w@mail.gmail.com>

Are you sure that you've rebuilt all your code against the new version?

On Thu, Sep 10, 2020 at 11:33 AM Paul Harwood <runette at gmail.com> wrote:

> Hi
>
> I just tried to upgrade my application to PDAL 2.2.0 and got an
> unexpected result. I got the PDAL binaries for Windows form Conda-Forge.
>
> The upgrade worked.
>
> However ...
>
> My application uses the API to load the PointView, looks in the Layout for
> DimTypes of X, Y, Z and Red, Green, Blue and uses them.
>
> Under 2.2.0 - I get X, Y & Z and the values are as expected. BUT I don't
> get a Red Dimension - just Green, Blue and GpsTime!
>
> If have looked at some other data and the Dimension Names (apart from X, Y
> and Z) are all shifted by one in the Dimension.json file.
>
> Is this something that I have done wrong?
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200910/886ea56f/attachment.html>

From runette at gmail.com  Thu Sep 10 13:39:10 2020
From: runette at gmail.com (Paul Harwood)
Date: Thu, 10 Sep 2020 21:39:10 +0100
Subject: [pdal] PDAL 2.2.0 - missing Red Dimension
In-Reply-To: <CACJ51z04QhSjiOmH08VboTxs2HTNhHjw4DGaqNqYi3FzsxAm2w@mail.gmail.com>
References: <CAE8nN5Moo-0+Bn9AXMV=HYKOoSSY6NJjDE50b5ihfT3ysHpL9g@mail.gmail.com>
 <CACJ51z04QhSjiOmH08VboTxs2HTNhHjw4DGaqNqYi3FzsxAm2w@mail.gmail.com>
Message-ID: <CAE8nN5NH+WSRG5hSbKExB8-itXZbzq_407XD1kF8Lx9zQC-qdw@mail.gmail.com>

You were right thanks - I had forgotten about the CAPI layer in the middle.

On Thu, 10 Sep 2020 at 16:46, Andrew Bell <andrew.bell.ia at gmail.com> wrote:

> Are you sure that you've rebuilt all your code against the new version?
>
> On Thu, Sep 10, 2020 at 11:33 AM Paul Harwood <runette at gmail.com> wrote:
>
>> Hi
>>
>> I just tried to upgrade my application to PDAL 2.2.0 and got an
>> unexpected result. I got the PDAL binaries for Windows form Conda-Forge.
>>
>> The upgrade worked.
>>
>> However ...
>>
>> My application uses the API to load the PointView, looks in the Layout
>> for DimTypes of X, Y, Z and Red, Green, Blue and uses them.
>>
>> Under 2.2.0 - I get X, Y & Z and the values are as expected. BUT I don't
>> get a Red Dimension - just Green, Blue and GpsTime!
>>
>> If have looked at some other data and the Dimension Names (apart from X,
>> Y and Z) are all shifted by one in the Dimension.json file.
>>
>> Is this something that I have done wrong?
>> _______________________________________________
>> pdal mailing list
>> pdal at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/pdal
>
>
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200910/2b583d2d/attachment.html>

From Peder.Axensten at slu.se  Fri Sep 11 04:17:24 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Fri, 11 Sep 2020 11:17:24 +0000
Subject: [pdal] How to get the metadata of a file?
In-Reply-To: <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>
References: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
 <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>
Message-ID: <6B77A4E7-421E-4475-A76F-08B02B7B1F3A@slu.se>

(Sorry for the double mail, Andrew. I forgot to cc the pdal list…)

> On 10 Sep 2020, at 16:27, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
>
> On Thu, Sep 10, 2020 at 9:43 AM Peder Axensten <Peder.Axensten at slu.se> wrote:
> I want to implement a writer that takes a point cloud file and rasterises it (percentiles and other statistics):
> class Raster_metrics : public pdal::Writer;
>
> My understanding from the documentation is that I should setup things in
> void Raster_metrics::ready( pdal::PointTableRef table );
> Correct?
> To do that I need to access the header data of the input file, specifically its bounding box.
>
> PDAL typically works on PointView objects rather than PointTable objects. Normally one would calculate the bounds based on PointView in either filter() or run(). Search for calculateBounds(). It would not be unreasonable to create a separate raster for each input PointView.
>
> How do I get the input file’s bounding box from table?
>
> You don't.
>
> And other file metadata?
>
> Metadata is generally stored with each stage. If you want the metadata that was read, you have to walk stages back until you find the one you're looking for, call getMetadata(), and then extract any information you're looking for. We don't usually use file metadata during processing, with the exception of spatial reference, which is stored separately. We don't use metadata-provided bounding boxes because 1) they have been known to be wrong 2) PDAL may aggregate and drop points in between the time that data is read and the time that a filter is run.

That is a serious bummer… Our processing chain is based on the fact that the input files (there are tens of thousands of them that we process one by one) are aligned to each other in a regular grid. This ensures that we produce rasters that will align and have neither gaps nor overlaps. Points that are outside their file’s bbox are outliers (!) and ignored. To us, the file’s bbox as given by the header info is at least as important as the spatial reference. Such an access function could simply return an empty bbox for file formats with no such header info:
table.headerBounds( bbox );
if( bbox.empty() || argDontTrustHeaderBbox )table.calculateBounds( bbox );

I would rather not use time to scan through all points for min/max values when the file header already supplies that info. In a previous processing stage we make sure that the header info is correct. Recalculating the bbox at every step (scanning through all points an extra time) translates to a rather longer processing time as there are many Tbytes of point files…

It seems that pdal info somehow gets the header info – but I don’t see/understand how this is implemented in code?

I’m trying really hard to present strong arguments for the usefulness of a pdal::PointViewPtr::headerBounds() member function – am I making progress? :-)

> Further I should process the actual points in
> void Raster_metrics::write( pdal::PointViewPtr view ) — for chunks of points.
> Correct?
> I want to be able to process points also in a serialised manner – in what member function should I do that?
>
> I don't know what you mean. You can simply loop through all the points in the view and process them one at a time. If you don't need all the points prior to beginning processing, you can implement a stream mode filter by inheriting from Streamable and implement processOne().  That said, if you need bounds, you need all the points, which means that your filter won't work in stream mode.

Another argument for a pdal::PointViewPtr::headerBounds() member function?
I imagine there are more tools than mine that could be made Streamable using this info?

> And finally I should calculate the statistics and output the these as rasters [using gdal] in
> void Raster_metrics::done( pdal::PointTableRef table )
> Correct?
>
> This is up to you. Using the new functionality in 2.2, you can call view.createRaster(). It will return a raster to which you can write data. I would do this in filter() or run().

That sounds very useful! I will check it out when I get to implement this part.

To summarise, your suggestion is that I should do everything (setup, consuming the points, and saving the rasters to file) in one member function, either in filter() or run()? This would certainly simplify things. What are the principle differences between the two? What would be the more natural fit for my Stage?

Would it be more natural to implement my tool as a Filter, rather than a Writer?
Being new to pdal I don’t really understand how the principle differences between the two applies to a tool such as mine.

Are filter()/run() called once for each input file?
In my case I would probably throw an exception at the second call, as merging files does not really make sense here...

> I’ve been reading through the documentation on pdal.io, but I find it a bit scant – is there more detailed documentation somewhere?
> (I.e. https://pdal.io/api/cpp/metadata.html is just a list of member functions.)
>
> What is available on the PDAL website is what exists. We don't have much documentation of individual functions. Sorry. Please make use of the existing code and tests.  Feel free to write with specific questions.
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com

Thanks for taking the time to reply to my questions, Andrew.
I do try to read what documentation there is and study other stages that I think might be applicable to mine, but many things are unclear to me even so.

Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Umeå
Visiting address: Skogsmarksgränd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.
---
När du skickar e-post till SLU så innebär detta att SLU behandlar dina personuppgifter. För att läsa mer om hur detta går till, klicka här <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From andrew.bell.ia at gmail.com  Fri Sep 11 05:44:57 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Fri, 11 Sep 2020 08:44:57 -0400
Subject: [pdal] How to get the metadata of a file?
In-Reply-To: <B276360A-75A1-4CD9-B5F6-81F01857B448@slu.se>
References: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
 <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>
 <B276360A-75A1-4CD9-B5F6-81F01857B448@slu.se>
Message-ID: <CACJ51z3FLQTVO7bzO-HXUUAtyo6CGKXuFaOHYhLnMYPbu1fvVw@mail.gmail.com>

On Fri, Sep 11, 2020 at 7:10 AM Peder Axensten <Peder.Axensten at slu.se>
wrote:

> > On 10 Sep 2020, at 16:27, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> >
> > On Thu, Sep 10, 2020 at 9:43 AM Peder Axensten <Peder.Axensten at slu.se>
> wrote:
> > I want to implement a writer that takes a point cloud file and
> rasterises it (percentiles and other statistics):
> > class Raster_metrics : public pdal::Writer;
> >
> > Metadata is generally stored with each stage. If you want the metadata
> that was read, you have to walk stages back until you find the one you're
> looking for, call getMetadata(), and then extract any information you're
> looking for. We don't usually use file metadata during processing, with the
> exception of spatial reference, which is stored separately. We don't use
> metadata-provided bounding boxes because 1) they have been known to be
> wrong 2) PDAL may aggregate and drop points in between the time that data
> is read and the time that a filter is run.
>
> That is a serious bummer… Our processing chain is based on the fact that
> the input files (there are tens of thousands of them that we process one by
> one) are aligned to each other in a regular grid. This ensures that we
> produce rasters that will align and have neither gaps nor overlaps.


If you were to use writers.gdal, you can pass whatever bounds you like to
the stage as an option and they will be respected, regardless of the data.
You can run pdal info to extract the metadata and pass that as bounds to
the writer if you wish. I believe some users do this.


> Points that are outside their file’s bbox are outliers (!) and ignored. To
> us, the file’s bbox as given by the header info is at least as important as
> the spatial reference. Such an access function could simply return an empty
> bbox for file formats with no such header info:
> table.headerBounds( bbox );
> if( bbox.empty() || argDontTrustHeaderBbox )table.calculateBounds( bbox );
>

PDAL just doesn't work like this. The input may be many files with many
processing steps before writing a raster. Your processing model of a single
file without data modification before calculating a raster is a
specialization.

I would rather not use time to scan through all points for min/max values
> when the file header already supplies that info.


It's generally trivial compared to other processing.


> In a previous processing stage we make sure that the header info is
> correct. Recalculating the bbox at every step (scanning through all points
> an extra time) translates to a rather longer processing time as there are
> many Tbytes of point files…


> It seems that pdal info somehow gets the header info – but I don’t
> see/understand how this is implemented in code?
>

pdal info operates on a single file. It emits data from the file header as
stored in metadata.


> I’m trying really hard to present strong arguments for the usefulness of a
> pdal::PointViewPtr::headerBounds() member function – am I making progress?
> :-)
>

You're looking at a PointView as a representation of a LAS file, and it may
be that, but it may well NOT be that. Furthermore, many (most?) file
formats don't provide such information. PDAL supports 20+ formats.

If you're wanting to do special processing using the PDAL code, go for it.
It's open-source and you're free to modify it for your own purposes. You
could modify the LAS reader to put the bounds from the header in the
PointView and then use that in your raster creation code, but that's not
something that's going to be generally applicable.


> > Further I should process the actual points in
> > void Raster_metrics::write( pdal::PointViewPtr view ) — for chunks of
> points.
> > Correct?
> > I want to be able to process points also in a serialised manner – in
> what member function should I do that?
> >
> > I don't know what you mean. You can simply loop through all the points
> in the view and process them one at a time. If you don't need all the
> points prior to beginning processing, you can implement a stream mode
> filter by inheriting from Streamable and implement processOne().  That
> said, if you need bounds, you need all the points, which means that your
> filter won't work in stream mode.
>
> Another argument for a pdal::PointViewPtr::headerBounds() member function?
> I imagine there are more tools than mine that could be made Streamable
> using this info?
>

See above. Also, this information wouldn't be sufficient to permit most of
the non-streamable filters to become streaming.


> > And finally I should calculate the statistics and output the these as
> rasters [using gdal] in
> > void Raster_metrics::done( pdal::PointTableRef table )
> > Correct?
> >
> > This is up to you. Using the new functionality in 2.2, you can call
> view.createRaster(). It will return a raster to which you can write data. I
> would do this in filter() or run().
>
> That sounds very useful! I will check it out when I get to implement this
> part.
>
> To summarise, your suggestion is that I should do everything (setup,
> consuming the points, and saving the rasters to file) in one member
> function, either in filter() or run()? This would certainly simplify
> things. What are the principle differences between the two? What would be
> the more natural fit for my Stage?
>

If you're creating a raster as final output, you should create a Writer and
implement the write() function.


> Would it be more natural to implement my tool as a Filter, rather than a
> Writer?
> Being new to pdal I don’t really understand how the principle differences
> between the two applies to a tool such as mine.
>

For all practical purposes, a filter and writer are the same, but writers
can be created/inferred from the output filenames in pipelines.


> Are filter()/run() called once for each input file?
>

They are called once for each PointView. Each input file is initially
placed in its own PointView. Perhaps this is helpful:
https://pdal.io/development/overview.html


> In my case I would probably throw an exception at the second call, as
> merging files does not really make sense here...
>

The PDAL "engine" makes these calls as appropriate. You don't need to call
them (and in fact can't without modifying the code, as they're private).
Your code should call prepare() and execute().

--
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200911/a9810b9a/attachment-0001.html>

From Peder.Axensten at slu.se  Mon Sep 14 02:02:51 2020
From: Peder.Axensten at slu.se (Peder Axensten)
Date: Mon, 14 Sep 2020 09:02:51 +0000
Subject: [pdal] How to get the metadata of a file?
In-Reply-To: <CACJ51z3FLQTVO7bzO-HXUUAtyo6CGKXuFaOHYhLnMYPbu1fvVw@mail.gmail.com>
References: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
 <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>
 <B276360A-75A1-4CD9-B5F6-81F01857B448@slu.se>
 <CACJ51z3FLQTVO7bzO-HXUUAtyo6CGKXuFaOHYhLnMYPbu1fvVw@mail.gmail.com>
Message-ID: <5F323F88-F483-4131-9CB7-918350E9EDCE@slu.se>

Pity.

I see that the present users’ domain doesn’t seem to have a need for bounding box header information. I believe that users in other domains do – possibly few and small domains, but who knows? To me it still seems an arbitrary limitation and your arguments have not convinced me.

But it’s your prerogative. I’ll ponder what the most viable option is for us: status quo with liblas, use pdal for reading only, or make a pdal filter/writer and use some workaround in our process chain. I will probably come back for more advice... :-)

Pdal needs statistics/metrics calculation to attract the forest remote sensing domain mentioned by Howard.

Best regards,

Peder Axensten
Research engineer

Remote Sensing
Department of Forest Resource Management
Swedish University of Agricultural Sciences
SE-901 83 Umeå
Visiting address: Skogsmarksgränd
Phone: +46 90 786 85 00
peder.axensten at slu.se, www.slu.se/srh

The Department of Forest Resource Management is environmentally certified in accordance with ISO 14001.

> On 11 Sep 2020, at 14:44, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
>
> On Fri, Sep 11, 2020 at 7:10 AM Peder Axensten <Peder.Axensten at slu.se> wrote:
> > On 10 Sep 2020, at 16:27, Andrew Bell <andrew.bell.ia at gmail.com> wrote:
> >
> > On Thu, Sep 10, 2020 at 9:43 AM Peder Axensten <Peder.Axensten at slu.se> wrote:
> > I want to implement a writer that takes a point cloud file and rasterises it (percentiles and other statistics):
> > class Raster_metrics : public pdal::Writer;
> >
> > Metadata is generally stored with each stage. If you want the metadata that was read, you have to walk stages back until you find the one you're looking for, call getMetadata(), and then extract any information you're looking for. We don't usually use file metadata during processing, with the exception of spatial reference, which is stored separately. We don't use metadata-provided bounding boxes because 1) they have been known to be wrong 2) PDAL may aggregate and drop points in between the time that data is read and the time that a filter is run.
>
> That is a serious bummer… Our processing chain is based on the fact that the input files (there are tens of thousands of them that we process one by one) are aligned to each other in a regular grid. This ensures that we produce rasters that will align and have neither gaps nor overlaps.
>
> If you were to use writers.gdal, you can pass whatever bounds you like to the stage as an option and they will be respected, regardless of the data. You can run pdal info to extract the metadata and pass that as bounds to the writer if you wish. I believe some users do this.
>
> Points that are outside their file’s bbox are outliers (!) and ignored. To us, the file’s bbox as given by the header info is at least as important as the spatial reference. Such an access function could simply return an empty bbox for file formats with no such header info:
> table.headerBounds( bbox );
> if( bbox.empty() || argDontTrustHeaderBbox )table.calculateBounds( bbox );
>
> PDAL just doesn't work like this. The input may be many files with many processing steps before writing a raster. Your processing model of a single file without data modification before calculating a raster is a specialization.
>
> I would rather not use time to scan through all points for min/max values when the file header already supplies that info.
>
> It's generally trivial compared to other processing.
>
> In a previous processing stage we make sure that the header info is correct. Recalculating the bbox at every step (scanning through all points an extra time) translates to a rather longer processing time as there are many Tbytes of point files…
>
> It seems that pdal info somehow gets the header info – but I don’t see/understand how this is implemented in code?
>
> pdal info operates on a single file. It emits data from the file header as stored in metadata.
>
> I’m trying really hard to present strong arguments for the usefulness of a pdal::PointViewPtr::headerBounds() member function – am I making progress? :-)
>
> You're looking at a PointView as a representation of a LAS file, and it may be that, but it may well NOT be that. Furthermore, many (most?) file formats don't provide such information. PDAL supports 20+ formats.
>
> If you're wanting to do special processing using the PDAL code, go for it. It's open-source and you're free to modify it for your own purposes. You could modify the LAS reader to put the bounds from the header in the PointView and then use that in your raster creation code, but that's not something that's going to be generally applicable.
>
> > Further I should process the actual points in
> > void Raster_metrics::write( pdal::PointViewPtr view ) — for chunks of points.
> > Correct?
> > I want to be able to process points also in a serialised manner – in what member function should I do that?
> >
> > I don't know what you mean. You can simply loop through all the points in the view and process them one at a time. If you don't need all the points prior to beginning processing, you can implement a stream mode filter by inheriting from Streamable and implement processOne().  That said, if you need bounds, you need all the points, which means that your filter won't work in stream mode.
>
> Another argument for a pdal::PointViewPtr::headerBounds() member function?
> I imagine there are more tools than mine that could be made Streamable using this info?
>
> See above. Also, this information wouldn't be sufficient to permit most of the non-streamable filters to become streaming.
>
> > And finally I should calculate the statistics and output the these as rasters [using gdal] in
> > void Raster_metrics::done( pdal::PointTableRef table )
> > Correct?
> >
> > This is up to you. Using the new functionality in 2.2, you can call view.createRaster(). It will return a raster to which you can write data. I would do this in filter() or run().
>
> That sounds very useful! I will check it out when I get to implement this part.
>
> To summarise, your suggestion is that I should do everything (setup, consuming the points, and saving the rasters to file) in one member function, either in filter() or run()? This would certainly simplify things. What are the principle differences between the two? What would be the more natural fit for my Stage?
>
> If you're creating a raster as final output, you should create a Writer and implement the write() function.
>
> Would it be more natural to implement my tool as a Filter, rather than a Writer?
> Being new to pdal I don’t really understand how the principle differences between the two applies to a tool such as mine.
>
> For all practical purposes, a filter and writer are the same, but writers can be created/inferred from the output filenames in pipelines.
>
> Are filter()/run() called once for each input file?
>
> They are called once for each PointView. Each input file is initially placed in its own PointView. Perhaps this is helpful: https://pdal.io/development/overview.html
>
> In my case I would probably throw an exception at the second call, as merging files does not really make sense here...
>
> The PDAL "engine" makes these calls as appropriate. You don't need to call them (and in fact can't without modifying the code, as they're private). Your code should call prepare() and execute().
>
> --
> Andrew Bell
> andrew.bell.ia at gmail.com

---
När du skickar e-post till SLU så innebär detta att SLU behandlar dina personuppgifter. För att läsa mer om hur detta går till, klicka här <https://www.slu.se/om-slu/kontakta-slu/personuppgifter/>
E-mailing SLU will result in SLU processing your personal data. For more information on how this is done, click here <https://www.slu.se/en/about-slu/contact-slu/personal-data/>

From andrew.bell.ia at gmail.com  Mon Sep 14 04:39:20 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Mon, 14 Sep 2020 07:39:20 -0400
Subject: [pdal] How to get the metadata of a file?
In-Reply-To: <5F323F88-F483-4131-9CB7-918350E9EDCE@slu.se>
References: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
 <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>
 <B276360A-75A1-4CD9-B5F6-81F01857B448@slu.se>
 <CACJ51z3FLQTVO7bzO-HXUUAtyo6CGKXuFaOHYhLnMYPbu1fvVw@mail.gmail.com>
 <5F323F88-F483-4131-9CB7-918350E9EDCE@slu.se>
Message-ID: <CACJ51z2SFxROetpXuV8iYw6reUSV3QFd0b3HjvE2nMAq7moEsQ@mail.gmail.com>

On Mon, Sep 14, 2020 at 5:02 AM Peder Axensten <Peder.Axensten at slu.se>
wrote:

> Pity.
>
> I see that the present users’ domain doesn’t seem to have a need for
> bounding box header information. I believe that users in other domains do –
> possibly few and small domains, but who knows? To me it still seems an
> arbitrary limitation and your arguments have not convinced me.


PDAL has been around for about six years and this hasn't come up, so I
think this is a pretty unique ask. We calculate the bounding area all the
time with the existing code and it works fine. The time it takes is dwarfed
by the time it takes to read the file itself, with no other processing in
place.


> But it’s your prerogative.


Actually, no. The code is there for you to do as you wish. The data you
want is there, you just have to write a bit of code to fetch it.

I’ll ponder what the most viable option is for us: status quo with liblas,
> use pdal for reading only, or make a pdal filter/writer and use some
> workaround in our process chain. I will probably come back for more
> advice... :-)
>

If what you want is just to read a LAS file into memory, then there's no
reason not to use liblas if it meets your requirements.

Best,

-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200914/04fac299/attachment.html>

From g.miguel.guerrero.m at gmail.com  Mon Sep 14 11:49:39 2020
From: g.miguel.guerrero.m at gmail.com (Miguel Guerrero)
Date: Mon, 14 Sep 2020 11:49:39 -0700
Subject: [pdal] New filters.lloydkmeans
Message-ID: <CAJUPYVWGdh4dP5PvJWn5DFxjSc6UD+hO=w05Qh1CUJbPSMPF6g@mail.gmail.com>

Hello,
Thanks for the new release of PDAL.
I used the new segmentation filter *filters.lloydkmeans* but it does not
seem to work, for me at least. The command starts processing a LiDAR file
(LAS) but it takes a while until it throws an error message (memory)
Question, is this filter available in Python-PDAL?
What would be the best practice to use this segmentation filter?

My best regards,

Miguel


  "pipeline":[
    {
        "type":"filters.lloydkmeans",
        "k":10,
        "maxiters":20,
        "dimensions":"X,Y,Z"
    },
    {
        "type":"filters.ferry",
        "dimensions":"ClusterID => PointSourceId"
    },
    {
        "type":"writers.las",
        "filename":"%s"
    }
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200914/32ee2e15/attachment-0001.html>

From brad.chambers at gmail.com  Mon Sep 14 12:35:48 2020
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Mon, 14 Sep 2020 14:35:48 -0500
Subject: [pdal] New filters.lloydkmeans
In-Reply-To: <CAJUPYVWGdh4dP5PvJWn5DFxjSc6UD+hO=w05Qh1CUJbPSMPF6g@mail.gmail.com>
References: <CAJUPYVWGdh4dP5PvJWn5DFxjSc6UD+hO=w05Qh1CUJbPSMPF6g@mail.gmail.com>
Message-ID: <CAJyqqPwJBJjUtpb3k6fOq7mWV8soWEtvHHDu6h4_t1tWAXfFgA@mail.gmail.com>

Miguel,

On Mon, Sep 14, 2020 at 1:49 PM Miguel Guerrero <
g.miguel.guerrero.m at gmail.com> wrote:

> Question, is this filter available in Python-PDAL?
>

It should be, but if you find otherwise, you can create an issue on GitHub.


> What would be the best practice to use this segmentation filter?
>

It is going to depend on the nature of your data and what you are trying to
accomplish. The defaults/examples are not necessarily indicative of "good"
values as you have found.

Brad
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200914/43c9fc20/attachment.html>

From brad.chambers at gmail.com  Mon Sep 14 13:12:33 2020
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Mon, 14 Sep 2020 15:12:33 -0500
Subject: [pdal] New filters.lloydkmeans
In-Reply-To: <CAJyqqPwJBJjUtpb3k6fOq7mWV8soWEtvHHDu6h4_t1tWAXfFgA@mail.gmail.com>
References: <CAJUPYVWGdh4dP5PvJWn5DFxjSc6UD+hO=w05Qh1CUJbPSMPF6g@mail.gmail.com>
 <CAJyqqPwJBJjUtpb3k6fOq7mWV8soWEtvHHDu6h4_t1tWAXfFgA@mail.gmail.com>
Message-ID: <CAJyqqPx4iN7-hn5UXbPf+rOn=wW3TX2xhw4A-wbhEaGd+Vz3UA@mail.gmail.com>

Actually, after taking a closer look, I think you've uncovered a recently
introduced bug. I've created a ticket if you'd like to track (
https://github.com/PDAL/PDAL/issues/3240).

Brad

On Mon, Sep 14, 2020 at 2:35 PM Bradley Chambers <brad.chambers at gmail.com>
wrote:

> Miguel,
>
> On Mon, Sep 14, 2020 at 1:49 PM Miguel Guerrero <
> g.miguel.guerrero.m at gmail.com> wrote:
>
>> Question, is this filter available in Python-PDAL?
>>
>
> It should be, but if you find otherwise, you can create an issue on GitHub.
>
>
>> What would be the best practice to use this segmentation filter?
>>
>
> It is going to depend on the nature of your data and what you are trying
> to accomplish. The defaults/examples are not necessarily indicative of
> "good" values as you have found.
>
> Brad
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200914/0d4ee94f/attachment.html>

From g.miguel.guerrero.m at gmail.com  Mon Sep 14 13:15:33 2020
From: g.miguel.guerrero.m at gmail.com (Miguel Guerrero)
Date: Mon, 14 Sep 2020 13:15:33 -0700
Subject: [pdal] New filters.lloydkmeans
In-Reply-To: <CAJyqqPx4iN7-hn5UXbPf+rOn=wW3TX2xhw4A-wbhEaGd+Vz3UA@mail.gmail.com>
References: <CAJUPYVWGdh4dP5PvJWn5DFxjSc6UD+hO=w05Qh1CUJbPSMPF6g@mail.gmail.com>
 <CAJyqqPwJBJjUtpb3k6fOq7mWV8soWEtvHHDu6h4_t1tWAXfFgA@mail.gmail.com>
 <CAJyqqPx4iN7-hn5UXbPf+rOn=wW3TX2xhw4A-wbhEaGd+Vz3UA@mail.gmail.com>
Message-ID: <CAJUPYVWXLF_0V8Nnb485VCnM=0tEg+fB2qJxcPx03UNkJs=-TQ@mail.gmail.com>

Thanks, I'll check it out.

On Mon, Sep 14, 2020 at 1:12 PM Bradley Chambers <brad.chambers at gmail.com>
wrote:

> Actually, after taking a closer look, I think you've uncovered a recently
> introduced bug. I've created a ticket if you'd like to track (
> https://github.com/PDAL/PDAL/issues/3240).
>
> Brad
>
> On Mon, Sep 14, 2020 at 2:35 PM Bradley Chambers <brad.chambers at gmail.com>
> wrote:
>
>> Miguel,
>>
>> On Mon, Sep 14, 2020 at 1:49 PM Miguel Guerrero <
>> g.miguel.guerrero.m at gmail.com> wrote:
>>
>>> Question, is this filter available in Python-PDAL?
>>>
>>
>> It should be, but if you find otherwise, you can create an issue on
>> GitHub.
>>
>>
>>> What would be the best practice to use this segmentation filter?
>>>
>>
>> It is going to depend on the nature of your data and what you are trying
>> to accomplish. The defaults/examples are not necessarily indicative of
>> "good" values as you have found.
>>
>> Brad
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200914/7f1db57d/attachment.html>

From alexandre.poirot at pix4d.com  Tue Sep 15 08:16:23 2020
From: alexandre.poirot at pix4d.com (Alexandre Poirot)
Date: Tue, 15 Sep 2020 17:16:23 +0200
Subject: [pdal] "Unknown" values in WKT string
In-Reply-To: <B5A6E94E-88E3-4F1B-992A-7452C62BC790@hobu.co>
References: <CAD-6rM7uc1oYHWrCZ3kyr=Q6f5PUOd_JYqHe3BJ7SqVD-T=mAg@mail.gmail.com>
 <B5A6E94E-88E3-4F1B-992A-7452C62BC790@hobu.co>
Message-ID: <CAD-6rM7jieGUFAuAuSh9UR_LsucTaBp-XhBtkcv_PJuruG=oSA@mail.gmail.com>

 Hello Howard,

Thanks for your reply and sorry to be so late to answer.

In terms of libraries, I use :
- libgeotiff 1.6.0
- proj 7.0.1
- gdal 3.1.0
- LASzip 3.4.3
- laz-perf 1.4.0
- PDAL 2.1.0

I use a specific build environment that builds all these libraries for each
OS I'm using (MacOS, Linux, Windows).

The software that produced this file is "LP360 from GeoCue Group Inc.", so
probably issued by this: https://geocue.com/products/lp-360/

After investigation, I realized that the file I was trying to read have 2
VLRs:
- An "OGC Well Known Text" which is the WKT string I expected PDAL to read
- A "GeoTiff Projection Keys" which is what is actually read (in
https://github.com/PDAL/PDAL/blob/2.1.0/io/GeotiffSupport.cpp#L148)

So I guess the "Unknown" in the WKT string I get from PDAL comes from the
process of reading the GeoTiff Projection Keys.

In this file the point data format is 7, and the global encoding field
value is 17 (0b00010001).

Now I went a bit in the PDAL code to understand why the GeoTiff Projection
Keys were chosen over the OGC Well Known Text and I found this block
https://github.com/PDAL/PDAL/blob/2.1.0/io/LasHeader.cpp#L198-L212.

Then I investigated a bit more by reading the LAS 1.4 format specification (
http://www.asprs.org/wp-content/uploads/2019/03/LAS_1_4_r14.pdf).
About the global encoding field value, in means that:
- The GPS Time Type is "Adjusted Standard GPS Time"/
- The WKT bit is set, meaning the CRS is WKT and not GeoTIFF.

In the specification, it is also said that:
-----
The CRS is represented by either GeoTIFF or Well Known Text (WKT) as
indicated by the WKT Global Encoding bit. Point Record Formats 0-5 can use
either GeoTIFF or WKT, but not both simultaneously. Point Data Record
Formats 6-10 must use WKT.
-----

Since my LAS 1.4 file has a point format of 7 and its WKT bit set, this
means we should use the WKT record here and not the GeoTIFF one. The
GeoTiff record is actually superfluous as it would never be used, but it
doesn't make the whole file invalid.

I guess the logic in
https://github.com/PDAL/PDAL/blob/2.1.0/io/LasHeader.cpp#L198-L212 needs to
be updated to be specification compliant.

What is the best option here to adjust this behavior of PDAL?

Best regards,
Alexandre Poirot | Software Engineer
Route de Renens 24 | 1008 Prilly, Switzerland
alexandre.poirot at pix4d.com
https://www.pix4d.com/


PS: I don't know yet if I can share the file with you, but here is a dump
of lasinfo of this file:
reporting all LAS header entries:
  file signature:             'LASF'
  file source ID:             0
  global_encoding:            17
  project ID GUID data 1-4:   00000000-0000-0000-0000-000000000000
  version major.minor:        1.4
  system identifier:          'OTHER'
  generating software:        'LP360 from GeoCue Group Inc.   '
  file creation day/year:     133/2020
  header size:                375
  offset to point data:       4608
  number var. length records: 2
  point data format:          7
  point data record length:   54
  number of point records:    0
  number of points by return: 0 0 0 0 0
  scale factor x y z:         0.001 0.001 0.001
  offset x y z:               1000000 1000000 0
  min x y z:                  663911.055 524463.042 179.282
  max x y z:                  664455.787 524605.649 251.952
  start of waveform data packet record: 0
  start of first extended variable length record: 0
  number of extended_variable length records: 0
  extended number of point records: 8286875
  extended number of points by return: 8279964 6911 0 0 0 0 0 0 0 0 0 0 0 0
0
variable length header record 1 of 2:
  reserved             0
  user ID              'LASF_Projection'
  record ID            2112
  length after header  816
  description          'OGC Well Known Text'
    WKT OGC COORDINATE SYSTEM:
    COMPD_CS["NAD83(2011) / Alabama West + Ellipsoid
(Meters)",PROJCS["NAD83(2011) / Alabama
West",GEOGCS["NAD83(2011)",DATUM["NAD83_National_Spatial_Reference_System_2011",SPHEROID["GRS
1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],AUTHORITY["EPSG","1116"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","6318"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",30],PARAMETER["central_meridian",-87.5],PARAMETER["scale_factor",0.999933333],PARAMETER["false_easting",600000],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["X",EAST],AXIS["Y",NORTH],AUTHORITY["EPSG","6356"]],VERT_CS["Ellipsoid
(Meters)",VERT_DATUM["Ellipsoid",2002],UNIT["metre",1.0,AUTHORITY["EPSG","9001"]],AXIS["Up",UP]]]
variable length header record 2 of 2:
  reserved             0
  user ID              'LASF_Projection'
  record ID            34735
  length after header  64
  description          'GeoTiff Projection Keys'
    GeoKeyDirectoryTag version 1.1.0 number of keys 7
      key 1024 tiff_tag_location 0 count 1 value_offset 1 -
GTModelTypeGeoKey: ModelTypeProjected
      key 1025 tiff_tag_location 0 count 1 value_offset 1 -
GTRasterTypeGeoKey: RasterPixelIsArea
      key 3072 tiff_tag_location 0 count 1 value_offset 6356 -
ProjectedCSTypeGeoKey: NAD83(2011) / Alabama West
      key 3076 tiff_tag_location 0 count 1 value_offset 0 -
ProjLinearUnitsGeoKey: look-up for 0 not implemented
      key 4096 tiff_tag_location 0 count 1 value_offset 32767 - EPSG code
32767 not found in 'vertcs.csv' file
set_VerticalCSTypeGeoKey: look-up for 32767 not implemented
VerticalCSTypeGeoKey: look-up for 32767 not implemented
      key 4098 tiff_tag_location 0 count 1 value_offset 0 -
VerticalDatumGeoKey: Vertical Datum Codes 0
      key 4099 tiff_tag_location 0 count 1 value_offset 9001 -
VerticalUnitsGeoKey: Linear_Meter
the header is followed by 3245 user-defined bytes
reporting minimum and maximum for all LAS point record entries ...
  X          -336088945 -335544213
  Y          -475536958 -475394351
  Z              179282     251952
  intensity         512      14080
  return_number       1          2
  number_of_returns   1          2
  edge_of_flight_line 0          1
  scan_direction_flag 1          1
  classification      0          2
  scan_angle_rank   -45         40
  user_data           0          7
  point_source_ID     2          2
  gps_time 271441788.061201 271441882.931595
  Color R 0 65280
        G 0 65280
        B 0 65280
  extended_return_number          1      2
  extended_number_of_returns      1      2
  extended_classification         0      2
  extended_scan_angle         -7474   6636
  extended_scanner_channel        0      0
number of first returns:        8279964
number of intermediate returns: 0
number of last returns:         8279964
number of single returns:       8273053
overview over extended number of returns of given pulse: 8273053 13822 0 0
0 0 0 0 0 0 0 0 0 0 0
histogram of classification of points:
         1530388  never classified (0)
          110209  unclassified (1)
         6646278  ground (2)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200915/762240fe/attachment-0001.html>

From klassen.js at gmail.com  Tue Sep 15 08:48:45 2020
From: klassen.js at gmail.com (Jim Klassen)
Date: Tue, 15 Sep 2020 10:48:45 -0500
Subject: [pdal] How to get the metadata of a file?
In-Reply-To: <CACJ51z2SFxROetpXuV8iYw6reUSV3QFd0b3HjvE2nMAq7moEsQ@mail.gmail.com>
References: <31D4A744-FCAD-4851-9FCB-D40651A279C1@slu.se>
 <CACJ51z1++DhxOi5HcDw2QWY=6Wkh+syz9eevbtWv_8LywXtHRw@mail.gmail.com>
 <B276360A-75A1-4CD9-B5F6-81F01857B448@slu.se>
 <CACJ51z3FLQTVO7bzO-HXUUAtyo6CGKXuFaOHYhLnMYPbu1fvVw@mail.gmail.com>
 <5F323F88-F483-4131-9CB7-918350E9EDCE@slu.se>
 <CACJ51z2SFxROetpXuV8iYw6reUSV3QFd0b3HjvE2nMAq7moEsQ@mail.gmail.com>
Message-ID: <384ed473-4371-df2e-9332-b2619d58a114@gmail.com>

On 9/14/20 6:39 AM, Andrew Bell wrote:
>
> On Mon, Sep 14, 2020 at 5:02 AM Peder Axensten <Peder.Axensten at slu.se <mailto:Peder.Axensten at slu.se>> wrote:
>
>     Pity.
>
>     I see that the present users’ domain doesn’t seem to have a need for bounding box header information. I believe that users in other domains do – possibly few and small domains, but who knows? To me it still seems an arbitrary limitation and your arguments have not convinced me.
>
>
> PDAL has been around for about six years and this hasn't come up, so I think this is a pretty unique ask. We calculate the bounding area all the time with the existing code and it works fine. The time it takes is dwarfed by the time it takes to read the file itself, with no other processing in place.
>
>     But it’s your prerogative.
>
>
> Actually, no. The code is there for you to do as you wish. The data you want is there, you just have to write a bit of code to fetch it.
>
>     I’ll ponder what the most viable option is for us: status quo with liblas, use pdal for reading only, or make a pdal filter/writer and use some workaround in our process chain. I will probably come back for more advice... :-)
>
>
> If what you want is just to read a LAS file into memory, then there's no reason not to use liblas if it meets your requirements.
>
> Best,
>
> -- 
> Andrew Bell
> andrew.bell.ia at gmail.com <mailto:andrew.bell.ia at gmail.com>
>

In my work we regularly work from a "tileindex" (which in this case is an index of the the desired output tiles rather than calculated from existing files).  We then use OGR within python to iterate over the features in the tile index and use that to override parameters in the pipeline like "readers.tindex.bounds" (or "readers.ept.bounds"), "writers.gdal.bounds", "writers.gdal.filename", etc.  Then each tile is submitted to a job queue which lets us process the tiles in parallel.

In our case the source is generally LAZ tiles, but relying on the LAZ header for the bounding box would still present issues for us. First, we generally set "readers.tindex.bounds" to be slightly larger than "writers.gdal.bounds" to avoid edge artifacts in the output tiles.  Second, in our case the LAZ tiles are more-or-less but not exactly grid aligned so using a tile bounding box would produce no-data areas in the output tiles.  (And this is after we had PDAL re-write all the LAZ tiles which along with doing other pre-processing and data cleanup, had the effect of correcting the bounding box information in the header which was all over the place as delivered).

So for us, we've found it more useful to move the tile bounding box identification a level above PDAL in our workflow.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200915/2a5432ce/attachment.html>

From andrew.bell.ia at gmail.com  Tue Sep 15 08:51:41 2020
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 15 Sep 2020 11:51:41 -0400
Subject: [pdal] "Unknown" values in WKT string
In-Reply-To: <CAD-6rM7jieGUFAuAuSh9UR_LsucTaBp-XhBtkcv_PJuruG=oSA@mail.gmail.com>
References: <CAD-6rM7uc1oYHWrCZ3kyr=Q6f5PUOd_JYqHe3BJ7SqVD-T=mAg@mail.gmail.com>
 <B5A6E94E-88E3-4F1B-992A-7452C62BC790@hobu.co>
 <CAD-6rM7jieGUFAuAuSh9UR_LsucTaBp-XhBtkcv_PJuruG=oSA@mail.gmail.com>
Message-ID: <CACJ51z24N3hdgFDqOSuEKROJV8wtyt2+x2zpC8MSUjMBP7TFLQ@mail.gmail.com>

If your data is point format 7, then it is necessarily version 1.4.  The
last line of the code that you referenced checks for this case, and PDAL
should be using the WKT specification that is in the file. Geotiff can't be
used with point format 7 and if it exists, you should get an error.

That said, you make have uncovered a bug in that we expect WKT for any file
with version 1.4, even if it's point format 0-5. I'll have to look back at
the code history to verify that there's not some reason that this is done.

On Tue, Sep 15, 2020 at 11:16 AM Alexandre Poirot <
alexandre.poirot at pix4d.com> wrote:

> Hello Howard,
>
> Thanks for your reply and sorry to be so late to answer.
>
> In terms of libraries, I use :
> - libgeotiff 1.6.0
> - proj 7.0.1
> - gdal 3.1.0
> - LASzip 3.4.3
> - laz-perf 1.4.0
> - PDAL 2.1.0
>
> I use a specific build environment that builds all these libraries for
> each OS I'm using (MacOS, Linux, Windows).
>
> The software that produced this file is "LP360 from GeoCue Group Inc.", so
> probably issued by this: https://geocue.com/products/lp-360/
>
> After investigation, I realized that the file I was trying to read have 2
> VLRs:
> - An "OGC Well Known Text" which is the WKT string I expected PDAL to read
> - A "GeoTiff Projection Keys" which is what is actually read (in
> https://github.com/PDAL/PDAL/blob/2.1.0/io/GeotiffSupport.cpp#L148)
>
> So I guess the "Unknown" in the WKT string I get from PDAL comes from the
> process of reading the GeoTiff Projection Keys.
>
> In this file the point data format is 7, and the global encoding field
> value is 17 (0b00010001).
>
> Now I went a bit in the PDAL code to understand why the GeoTiff Projection
> Keys were chosen over the OGC Well Known Text and I found this block
> https://github.com/PDAL/PDAL/blob/2.1.0/io/LasHeader.cpp#L198-L212.
>
> Then I investigated a bit more by reading the LAS 1.4 format specification
> (http://www.asprs.org/wp-content/uploads/2019/03/LAS_1_4_r14.pdf).
> About the global encoding field value, in means that:
> - The GPS Time Type is "Adjusted Standard GPS Time"/
> - The WKT bit is set, meaning the CRS is WKT and not GeoTIFF.
>
> In the specification, it is also said that:
> -----
> The CRS is represented by either GeoTIFF or Well Known Text (WKT) as
> indicated by the WKT Global Encoding bit. Point Record Formats 0-5 can use
> either GeoTIFF or WKT, but not both simultaneously. Point Data Record
> Formats 6-10 must use WKT.
> -----
>
> Since my LAS 1.4 file has a point format of 7 and its WKT bit set, this
> means we should use the WKT record here and not the GeoTIFF one. The
> GeoTiff record is actually superfluous as it would never be used, but it
> doesn't make the whole file invalid.
>
> I guess the logic in
> https://github.com/PDAL/PDAL/blob/2.1.0/io/LasHeader.cpp#L198-L212 needs
> to be updated to be specification compliant.
>
> What is the best option here to adjust this behavior of PDAL?
>
> Best regards,
> Alexandre Poirot | Software Engineer
> Route de Renens 24 | 1008 Prilly, Switzerland
> alexandre.poirot at pix4d.com
> https://www.pix4d.com/
>
>
> PS: I don't know yet if I can share the file with you, but here is a dump
> of lasinfo of this file:
> reporting all LAS header entries:
>   file signature:             'LASF'
>   file source ID:             0
>   global_encoding:            17
>   project ID GUID data 1-4:   00000000-0000-0000-0000-000000000000
>   version major.minor:        1.4
>   system identifier:          'OTHER'
>   generating software:        'LP360 from GeoCue Group Inc.   '
>   file creation day/year:     133/2020
>   header size:                375
>   offset to point data:       4608
>   number var. length records: 2
>   point data format:          7
>   point data record length:   54
>   number of point records:    0
>   number of points by return: 0 0 0 0 0
>   scale factor x y z:         0.001 0.001 0.001
>   offset x y z:               1000000 1000000 0
>   min x y z:                  663911.055 524463.042 179.282
>   max x y z:                  664455.787 524605.649 251.952
>   start of waveform data packet record: 0
>   start of first extended variable length record: 0
>   number of extended_variable length records: 0
>   extended number of point records: 8286875
>   extended number of points by return: 8279964 6911 0 0 0 0 0 0 0 0 0 0 0
> 0 0
> variable length header record 1 of 2:
>   reserved             0
>   user ID              'LASF_Projection'
>   record ID            2112
>   length after header  816
>   description          'OGC Well Known Text'
>     WKT OGC COORDINATE SYSTEM:
>     COMPD_CS["NAD83(2011) / Alabama West + Ellipsoid
> (Meters)",PROJCS["NAD83(2011) / Alabama
> West",GEOGCS["NAD83(2011)",DATUM["NAD83_National_Spatial_Reference_System_2011",SPHEROID["GRS
> 1980",6378137,298.257222101,AUTHORITY["EPSG","7019"]],AUTHORITY["EPSG","1116"]],PRIMEM["Greenwich",0,AUTHORITY["EPSG","8901"]],UNIT["degree",0.0174532925199433,AUTHORITY["EPSG","9122"]],AUTHORITY["EPSG","6318"]],PROJECTION["Transverse_Mercator"],PARAMETER["latitude_of_origin",30],PARAMETER["central_meridian",-87.5],PARAMETER["scale_factor",0.999933333],PARAMETER["false_easting",600000],PARAMETER["false_northing",0],UNIT["metre",1,AUTHORITY["EPSG","9001"]],AXIS["X",EAST],AXIS["Y",NORTH],AUTHORITY["EPSG","6356"]],VERT_CS["Ellipsoid
> (Meters)",VERT_DATUM["Ellipsoid",2002],UNIT["metre",1.0,AUTHORITY["EPSG","9001"]],AXIS["Up",UP]]]
> variable length header record 2 of 2:
>   reserved             0
>   user ID              'LASF_Projection'
>   record ID            34735
>   length after header  64
>   description          'GeoTiff Projection Keys'
>     GeoKeyDirectoryTag version 1.1.0 number of keys 7
>       key 1024 tiff_tag_location 0 count 1 value_offset 1 -
> GTModelTypeGeoKey: ModelTypeProjected
>       key 1025 tiff_tag_location 0 count 1 value_offset 1 -
> GTRasterTypeGeoKey: RasterPixelIsArea
>       key 3072 tiff_tag_location 0 count 1 value_offset 6356 -
> ProjectedCSTypeGeoKey: NAD83(2011) / Alabama West
>       key 3076 tiff_tag_location 0 count 1 value_offset 0 -
> ProjLinearUnitsGeoKey: look-up for 0 not implemented
>       key 4096 tiff_tag_location 0 count 1 value_offset 32767 - EPSG code
> 32767 not found in 'vertcs.csv' file
> set_VerticalCSTypeGeoKey: look-up for 32767 not implemented
> VerticalCSTypeGeoKey: look-up for 32767 not implemented
>       key 4098 tiff_tag_location 0 count 1 value_offset 0 -
> VerticalDatumGeoKey: Vertical Datum Codes 0
>       key 4099 tiff_tag_location 0 count 1 value_offset 9001 -
> VerticalUnitsGeoKey: Linear_Meter
> the header is followed by 3245 user-defined bytes
> reporting minimum and maximum for all LAS point record entries ...
>   X          -336088945 -335544213
>   Y          -475536958 -475394351
>   Z              179282     251952
>   intensity         512      14080
>   return_number       1          2
>   number_of_returns   1          2
>   edge_of_flight_line 0          1
>   scan_direction_flag 1          1
>   classification      0          2
>   scan_angle_rank   -45         40
>   user_data           0          7
>   point_source_ID     2          2
>   gps_time 271441788.061201 271441882.931595
>   Color R 0 65280
>         G 0 65280
>         B 0 65280
>   extended_return_number          1      2
>   extended_number_of_returns      1      2
>   extended_classification         0      2
>   extended_scan_angle         -7474   6636
>   extended_scanner_channel        0      0
> number of first returns:        8279964
> number of intermediate returns: 0
> number of last returns:         8279964
> number of single returns:       8273053
> overview over extended number of returns of given pulse: 8273053 13822 0 0
> 0 0 0 0 0 0 0 0 0 0 0
> histogram of classification of points:
>          1530388  never classified (0)
>           110209  unclassified (1)
>          6646278  ground (2)
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal



-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200915/2380b4e4/attachment-0001.html>

From klassen.js at gmail.com  Tue Sep 15 09:02:42 2020
From: klassen.js at gmail.com (Jim Klassen)
Date: Tue, 15 Sep 2020 11:02:42 -0500
Subject: [pdal] readers.tindex.bounds
Message-ID: <09c4ff5a-d263-bae1-3703-0d2beca543a4@gmail.com>

I think I may have found a bug where readers.tindex.bounds creates an empty polygon, likely introduced around c5735c3be8 Remove pdal::gdal::Geometry  (#3104).

I made an issue for it at:

     https://github.com/PDAL/PDAL/issues/3234

I included a simple patch in the issue that fixes it for me, but I'm not sure if it is the right way to go or not.

From antonio.molina at nmgroup.com  Fri Sep 18 00:56:46 2020
From: antonio.molina at nmgroup.com (Antonio Molina)
Date: Fri, 18 Sep 2020 08:56:46 +0100
Subject: [pdal] Distance Vector2PointCloud or PointCloud2PointCloud
Message-ID: <CAAJ=AAQHSOdubc36SHMSzbbgjYv9EAp-zBqzfnkO2v8CifSpUg@mail.gmail.com>

Hi,

Is there any way to measure distances between a vector and a point cloud or
between two point clouds in pdal? I am looking for something similar to
CloudCompare cloud2cloud distance algorithm, where a new scalar field is
generated for each return with the min distance between 2 point clouds.

I have been trying with haudorff:
https://pdal.io/apps/hausdorff.html?highlight=distance

But it returns the maximum distance between two point clouds, which is not
exactly what I am looking for.

Thank you :)


Kind regards

Antonio Javier Soto Molina

*Geospatial Specialist*


Network Mapping Limited

Unit 8 Whitfield Business Park,

Manse Lane,

Knaresborough,

North Yorkshire,

HG5 8BS

United Kingdom



*Tel:       * +44 (0)1276 857800

*Fax:       *+44 (0)1276 856367

*Mob:*      +44 (0)751 735 6212

*Email:*   antonio.molina at trimble.com <dimitrios.karapilafis at trimble.com>

*Web:     *www.nmgroup.com

Registered in England No. 634 7879

*Follow us on social media!*

<https://www.linkedin.com/company/nmgroup/>
<https://www.youtube.com/channel/UCS5b4XE4ERCn0S0WsF379FA>
<https://twitter.com/nmgroupinnovate?lang=en>

‘

<https://www.linkedin.com/company/nmgroup/>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200918/be3472e1/attachment.html>

From brad.chambers at gmail.com  Fri Sep 18 07:17:31 2020
From: brad.chambers at gmail.com (Bradley Chambers)
Date: Fri, 18 Sep 2020 09:17:31 -0500
Subject: [pdal] Distance Vector2PointCloud or PointCloud2PointCloud
In-Reply-To: <CAAJ=AAQHSOdubc36SHMSzbbgjYv9EAp-zBqzfnkO2v8CifSpUg@mail.gmail.com>
References: <CAAJ=AAQHSOdubc36SHMSzbbgjYv9EAp-zBqzfnkO2v8CifSpUg@mail.gmail.com>
Message-ID: <CAJyqqPy7jH=QLAcfWWji-QYRcWe47uMZFbpbcuJEkDosMiSg9w@mail.gmail.com>

I don't believe that we have what you are looking for currently. It
wouldn't be difficult to develop, and in fact we do something very similar
in the Delta kernel. It only reports the delta per point per common
dimension between the two input files though, and does not compute the
distance or store the result in either of the files.

On Fri, Sep 18, 2020 at 2:57 AM Antonio Molina <antonio.molina at nmgroup.com>
wrote:

> Hi,
>
> Is there any way to measure distances between a vector and a point cloud
> or between two point clouds in pdal? I am looking for something similar to
> CloudCompare cloud2cloud distance algorithm, where a new scalar field is
> generated for each return with the min distance between 2 point clouds.
>
> I have been trying with haudorff:
> https://pdal.io/apps/hausdorff.html?highlight=distance
>
> But it returns the maximum distance between two point clouds, which is not
> exactly what I am looking for.
>
> Thank you :)
>
>
> Kind regards
>
> Antonio Javier Soto Molina
>
> *Geospatial Specialist*
>
>
> Network Mapping Limited
>
> Unit 8 Whitfield Business Park,
>
> Manse Lane,
>
> Knaresborough,
>
> North Yorkshire,
>
> HG5 8BS
>
> United Kingdom
>
>
>
> *Tel:       * +44 (0)1276 857800
>
> *Fax:       *+44 (0)1276 856367
>
> *Mob:*      +44 (0)751 735 6212
>
> *Email:*   antonio.molina at trimble.com <dimitrios.karapilafis at trimble.com>
>
> *Web:     *www.nmgroup.com
>
> Registered in England No. 634 7879
>
> *Follow us on social media!*
>
> <https://www.linkedin.com/company/nmgroup/>
> <https://www.youtube.com/channel/UCS5b4XE4ERCn0S0WsF379FA>
> <https://twitter.com/nmgroupinnovate?lang=en>
>
> ‘
>
> <https://www.linkedin.com/company/nmgroup/>
> _______________________________________________
> pdal mailing list
> pdal at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/pdal
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/pdal/attachments/20200918/0da06b65/attachment.html>

