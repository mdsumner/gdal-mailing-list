From kreve at sdfe.dk  Fri Nov  1 11:47:40 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Fri, 1 Nov 2019 18:47:40 +0000
Subject: [PROJ] Motion: Promote PROJ 6.2.1RC1 to final release
In-Reply-To: <B944B545-D052-4F08-9500-28C24B3E0775@hobu.co>
References: <4345413.QIzuDGggrG@even-i700>
 <B944B545-D052-4F08-9500-28C24B3E0775@hobu.co>
Message-ID: <F9D55262-FDE1-4CEF-9749-D03BDD335D1C@sdfe.dk>

With +1’s from Hard, Even and Myself I declare this motion passed.

Release announcement will follow shortly.

/Kristian

> On 30 Oct 2019, at 13:14, Howard Butler <howard at hobu.co> wrote:
> 
> 
> 
>> On Oct 30, 2019, at 3:36 AM, Even Rouault <even.rouault at spatialys.com> wrote:
>> 
>> ﻿On mercredi 30 octobre 2019 07:20:04 CET Kristian Evers wrote:
>>> PSC Members,
>>> 
>>> No problems with PROJ 6.2.1RC1 has been reported, so I hereby
>>> motion that the release candidate be promoted to final release.
>>> 
>>> I'll start with my +1
>> 
>> +1
> 
> +1
> 
> 
> Howard
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


From kreve at sdfe.dk  Fri Nov  1 11:50:24 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Fri, 1 Nov 2019 18:50:24 +0000
Subject: [PROJ] Announcing PROJ 6.2.1
Message-ID: <3EC30FAC-617E-4A59-AC4B-0DF2A2FCBF64@sdfe.dk>

On behalf of the PROJ development team I am happy to announce the
release of PROJ 6.2.1.  See release notes below for details. 

Download the source distribution here:

https://download.osgeo.org/proj/proj-6.2.1.tar.gz (https://download.osgeo.org/proj/proj-6.2.1.tar.gz.md5)

https://download.osgeo.org/proj/proj-6.2.1.zip (https://download.osgeo.org/proj/proj-6.2.1.zip.md5)



—————————————————————————————————————————————

6.2.1 Release Notes
-------------------

 Updates
 -------

 o Update the EPSG database to version 9.8.2

 Bug fixes
 -------

 o Fixed erroneous spelling of "Potsdam" (#1573)

 o Calculate y-coordinate correctly in bertin1953 in all cases (#1579)

 o proj_create_crs_to_crs_from_pj(): make the PJ* arguments const PJ* (#1583)

 o PROJStringParser::createFromPROJString(): avoid potential infinite
   recursion (#1574)

 o Avoid core dump when setting ctx==NULL in functions
   proj_coordoperation_is_instantiable and
   proj_coordoperation_has_ballpark_transformation (#1590)

 o createOperations(): fix conversion from/to PROJ.4 CRS strings with
   non-ISO-kosher options and +towgs84/+nadgrids (#1602)

 o proj_trans_generic(): properly set coordinate time to HUGE_VAL when no
   value is passed to the function (#1604)

 o Fix support for +proj=ob_tran +o_proj=lonlat/latlong/latlon instead of only
   only allowing +o_proj=longlat (#1601)

 o Improve backwards compatibility of vertical transforms (#1613)

 o Improve emulation of deprecated +init style initialization (#1614)

 o cs2cs: autopromote CRS to 3D when there's a mix of 2D and 3D (#1563)

 o Avoid divisions by zero in odd situations (#1620)

 o Avoid compile error on Solaris (#1639)

 o proj_create_crs_to_crs(): fix when there are only transformations with
   ballpark steps (#1643)

 o PROJ string CRS ingester: recognize more unit-less parameters, and general
   handling of +key=string_value parameters (#1645)

 o Only call pkg-config in configure when necessary (#1652)

 o aeqd: for spherical forward path, go to higher precision ellipsoidal
   case when the point coordinates are super close to the origin (#1654)

 o proj_create_crs_to_crs(): remove elimination of Ballpark operations
   that caused transformation failures in some cases (#1665)

 o createOperations(): allow transforming from a compoundCRS of a bound
   verticalCRS to a 2D CRS (#1667)

 o Avoid segfaults in case of out-of-memory situations (#1679)

 o createOperations(): fix double vertical unit conversion from CompoundCRS
   to other CRS when the horizontal part of the projected CRS uses non-metre
   unit (#1683)

 o importFromWkt(): fix axis orientation for non-standard ESRI WKT (#1690)



From gdt at lexort.com  Fri Nov  1 11:53:35 2019
From: gdt at lexort.com (Greg Troxel)
Date: Fri, 01 Nov 2019 14:53:35 -0400
Subject: [PROJ] Future maintainance releases
In-Reply-To: <94846156-EAEE-4082-B2E0-321791630C8A@sdfe.dk> (Kristian Evers's
 message of "Thu, 31 Oct 2019 07:20:58 +0000")
References: <13568718.XafZnbjQPh@even-i700>
 <3787220d-fdaf-69b3-4cc5-b38ee371206e@xs4all.nl>
 <4f3c66f428d74fa8915451f062cb0a04@sdfe.dk>
 <2058429.pZbsZHp53L@even-i700>
 <c4921a928b1c2d1b3f38c6dda663e224@xs4all.nl>
 <rmisgnauz1m.fsf@s1.lexort.com>
 <4625A259-37DB-47F0-BA1B-B7D417884DBC@sdfe.dk>
 <rmi36f9spcp.fsf@s1.lexort.com>
 <5C951202-F58F-4001-B4B4-905E8EA829B2@cleverelephant.ca>
 <94846156-EAEE-4082-B2E0-321791630C8A@sdfe.dk>
Message-ID: <rmik18jjumo.fsf@s1.lexort.com>

Kristian Evers <kreve at sdfe.dk> writes:

> Greg, I am well aware of the intricacies of packaging systems. It is not simple
> and you and Bas have difficult task of making it all fit together. Please don’t
> think that I don’t understand or respect the job you do.

> I am also aware that PROJ has made a lot of changes over a somewhat short
> time. I would love to live in a world where that wasn’t necessary but unfortunately
> PROJ was in an less than ideal state for far too long. It is no ones fault, it is just
> the way things turned out. Now we are catching up and that means moving quickly
> for a bit. I think most agrees that this is the right thing to do. I also know that it is
> a difficult task to migrate from one API to the other. I believe the benefits of the
> new features in PROJ is worth it. I also think that PROJ 6 is a good bridge between
> the new and the old. I fully expect PROJ 6 to be around in packaging systems
> for quite some time still. But I also fear that most projects will be stuck using the
> old API forever if we keep hanging on to proj_api.h. Were that to happen I would
> be extremely discouraged from working on PROJ - my motivation is to bring
> better use of geodesy to the masses. We can’t do that properly through the old
> API.

Certainly I realize this is all very complicated with no 100% wonderful
approaches.

> I think what we have now is a good compromise: Those that can use PROJ 
> when it comes out and get the benefit of regular updates to the EPSG database
> etc. And those who can’t use PROJ 7 just yet can still use the 6.x branch which
> is already rather good. Should it prove necessary we will release maintenance
> releases of the 6.x branch, at least for the first year of it being superseded by
> PROJ 7.

I still am missing something.   When 7 comes out, with a packaging
system that has a single proj version, what version do you think that
should be?

Do you mean that by having 7 released, then there can be a year of
packaging sytems having 6, during which time upstreams of proj-using
packages can be pressured to make a formal release which is compatible
with proj 7?   In all seriousness, this might be the best that can be
realistically hoped for.



From kreve at sdfe.dk  Fri Nov  1 12:24:21 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Fri, 1 Nov 2019 19:24:21 +0000
Subject: [PROJ] Future maintainance releases
In-Reply-To: <rmik18jjumo.fsf@s1.lexort.com>
References: <13568718.XafZnbjQPh@even-i700>
 <3787220d-fdaf-69b3-4cc5-b38ee371206e@xs4all.nl>
 <4f3c66f428d74fa8915451f062cb0a04@sdfe.dk> <2058429.pZbsZHp53L@even-i700>
 <c4921a928b1c2d1b3f38c6dda663e224@xs4all.nl> <rmisgnauz1m.fsf@s1.lexort.com>
 <4625A259-37DB-47F0-BA1B-B7D417884DBC@sdfe.dk>
 <rmi36f9spcp.fsf@s1.lexort.com>
 <5C951202-F58F-4001-B4B4-905E8EA829B2@cleverelephant.ca>
 <94846156-EAEE-4082-B2E0-321791630C8A@sdfe.dk>
 <rmik18jjumo.fsf@s1.lexort.com>
Message-ID: <EEA3B56B-E56D-4BE6-A057-A8FD4919A342@sdfe.dk>



> On 1 Nov 2019, at 19:53, Greg Troxel <gdt at lexort.com> wrote:
> 
> Kristian Evers <kreve at sdfe.dk> writes:
> 
>> Greg, I am well aware of the intricacies of packaging systems. It is not simple
>> and you and Bas have difficult task of making it all fit together. Please don’t
>> think that I don’t understand or respect the job you do.
> 
>> I am also aware that PROJ has made a lot of changes over a somewhat short
>> time. I would love to live in a world where that wasn’t necessary but unfortunately
>> PROJ was in an less than ideal state for far too long. It is no ones fault, it is just
>> the way things turned out. Now we are catching up and that means moving quickly
>> for a bit. I think most agrees that this is the right thing to do. I also know that it is
>> a difficult task to migrate from one API to the other. I believe the benefits of the
>> new features in PROJ is worth it. I also think that PROJ 6 is a good bridge between
>> the new and the old. I fully expect PROJ 6 to be around in packaging systems
>> for quite some time still. But I also fear that most projects will be stuck using the
>> old API forever if we keep hanging on to proj_api.h. Were that to happen I would
>> be extremely discouraged from working on PROJ - my motivation is to bring
>> better use of geodesy to the masses. We can’t do that properly through the old
>> API.
> 
> Certainly I realize this is all very complicated with no 100% wonderful
> approaches.
> 
>> I think what we have now is a good compromise: Those that can use PROJ 
>> when it comes out and get the benefit of regular updates to the EPSG database
>> etc. And those who can’t use PROJ 7 just yet can still use the 6.x branch which
>> is already rather good. Should it prove necessary we will release maintenance
>> releases of the 6.x branch, at least for the first year of it being superseded by
>> PROJ 7.
> 
> I still am missing something.   When 7 comes out, with a packaging
> system that has a single proj version, what version do you think that
> should be?

With many applications still relying on proj_api.h I would think that a
version from the 6.x branch should be in the packaging system. 

> 
> Do you mean that by having 7 released, then there can be a year of
> packaging sytems having 6, during which time upstreams of proj-using
> packages can be pressured to make a formal release which is compatible
> with proj 7?   In all seriousness, this might be the best that can be
> realistically hoped for.
> 

Yes, something like that. A preliminary release schedule after the 7.0.0
release look something like:

March 1st 2020:	7.0.0 + 6.3.1
June 1st 2020:	7.0.1 + 6.3.2
September 2020:	7.1.0 (+ 6.3.3)
December 2020:	7.1.1
March 1s 2021:	7.2.0

I won’t commit to too many maintenance release of 6.3 branch since it may
diverge from master rather quickly. I don’t know exactly what the shelf-life of
a PROJ release is, but let’s say that it is a year. Then you’d have a soft
end-of-life of PROJ 6.x either in the middle or end of 2021. That leaves roughly
two years from now to coerce the lagging projects to adopt the new API. If a
project still hasn’t made the transition in that time I fear they never will.

I hope the above is manageable. Otherwise I am not sure what to do, apart from
keeping 6.x alive indefinitely, which to no surprise is not going to happen :-)

/Kristian

> 
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


From julien.schroder at gmail.com  Fri Nov  1 13:12:11 2019
From: julien.schroder at gmail.com (YK_climate)
Date: Fri, 1 Nov 2019 13:12:11 -0700 (MST)
Subject: [PROJ] Needs a sanity check on Vertical Transformation
Message-ID: <1572639131647-0.post@n6.nabble.com>

Hello,
I have been trying to perform vertical transformation with Proj for a few
days now, I think I am done but I am in some help to be sure I didn't make
some stupid mistakes!
I am looking at getting coordinates in WGS84-Ellipsoid to WG84-EGM96,WG84-
EGM2008 and to NAD83(2011)GEOID12B.

Here is what I have working so far : 
WGS84-EGM2008 : cs2cs EPSG:4979 EPSG:4326+3855
WGS84-EGM96    : cs2cs EPSG:4979 EPSG:4326+5773
Is this correct?

So naturally I thought that GEOID12B would be as easy : 
NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:6319+5703 <= no vertical
change
NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:5498         <= no vertical
change

After reading about geoidgrids I tried this and it works but I need to be
sure I am using the right parameters
cs2cs EPSG:4979 "+proj=longlat +datum=NAD83 +geoidgrids=g2012bu0.gtx"

Thank you for your time!




--
Sent from: http://osgeo-org.1560.x6.nabble.com/PROJ-4-f3840930.html

From cjmce at lsu.edu  Fri Nov  1 13:14:48 2019
From: cjmce at lsu.edu (Clifford J Mugnier)
Date: Fri, 1 Nov 2019 20:14:48 +0000
Subject: [PROJ] Needs a sanity check on Vertical Transformation
In-Reply-To: <1572639131647-0.post@n6.nabble.com>
References: <1572639131647-0.post@n6.nabble.com>
Message-ID: <SN6PR06MB4701801F8839FC99DD362EF2A8620@SN6PR06MB4701.namprd06.prod.outlook.com>

GEOID12B has been superceded


Clifford J. Mugnier, c.p., c.m.s.

Chief of Geodesy

LSU Center for GeoInformatics (ERAD 266)

Dept. of Civil Engineering (P.F. Taylor 3531)

LOUISIANA STATE UNIVERSITY

Baton Rouge, LA  70803

Academic: (225) 578-8536

Research: (225) 578-4578

Cell:             (225) 328-8975

honorary lifetime member, lsps

fellow emeritus, asprs

member, apsg

________________________________
From: PROJ <proj-bounces at lists.osgeo.org> on behalf of YK_climate <julien.schroder at gmail.com>
Sent: Friday, November 1, 2019 3:12 PM
To: proj at lists.osgeo.org <proj at lists.osgeo.org>
Subject: [PROJ] Needs a sanity check on Vertical Transformation

Hello,
I have been trying to perform vertical transformation with Proj for a few
days now, I think I am done but I am in some help to be sure I didn't make
some stupid mistakes!
I am looking at getting coordinates in WGS84-Ellipsoid to WG84-EGM96,WG84-
EGM2008 and to NAD83(2011)GEOID12B.

Here is what I have working so far :
WGS84-EGM2008 : cs2cs EPSG:4979 EPSG:4326+3855
WGS84-EGM96    : cs2cs EPSG:4979 EPSG:4326+5773
Is this correct?

So naturally I thought that GEOID12B would be as easy :
NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:6319+5703 <= no vertical
change
NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:5498         <= no vertical
change

After reading about geoidgrids I tried this and it works but I need to be
sure I am using the right parameters
cs2cs EPSG:4979 "+proj=longlat +datum=NAD83 +geoidgrids=g2012bu0.gtx"

Thank you for your time!




--
Sent from: https://nam04.safelinks.protection.outlook.com/?url=http%3A%2F%2Fosgeo-org.1560.x6.nabble.com%2FPROJ-4-f3840930.html&amp;data=02%7C01%7Ccjmce%40lsu.edu%7Cafe36ce1aea14cae713b08d75f07c9fb%7C2d4dad3f50ae47d983a09ae2b1f466f8%7C0%7C1%7C637082359369233259&amp;sdata=QIuy0Tjq6YxORR76mA0%2BlzqWoHc3ee9bBtZVdUaB9Cw%3D&amp;reserved=0
_______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Flists.osgeo.org%2Fmailman%2Flistinfo%2Fproj&amp;data=02%7C01%7Ccjmce%40lsu.edu%7Cafe36ce1aea14cae713b08d75f07c9fb%7C2d4dad3f50ae47d983a09ae2b1f466f8%7C0%7C1%7C637082359369233259&amp;sdata=iEajlneP1WEN%2FLEI9kIJPfa1BYXkbNqu1frYdjy3Z94%3D&amp;reserved=0
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191101/a23a740a/attachment.html>

From even.rouault at spatialys.com  Fri Nov  1 13:33:35 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Fri, 01 Nov 2019 21:33:35 +0100
Subject: [PROJ] Needs a sanity check on Vertical Transformation
In-Reply-To: <1572639131647-0.post@n6.nabble.com>
References: <1572639131647-0.post@n6.nabble.com>
Message-ID: <5925847.I67IV3XJ70@even-i700>

On vendredi 1 novembre 2019 13:12:11 CET YK_climate wrote:
> Hello,
> I have been trying to perform vertical transformation with Proj for a few
> days now, I think I am done but I am in some help to be sure I didn't make
> some stupid mistakes!
> I am looking at getting coordinates in WGS84-Ellipsoid to WG84-EGM96,WG84-
> EGM2008 and to NAD83(2011)GEOID12B.
> 
> Here is what I have working so far :
> WGS84-EGM2008 : cs2cs EPSG:4979 EPSG:4326+3855
> WGS84-EGM96    : cs2cs EPSG:4979 EPSG:4326+5773
> Is this correct?

Yes

> 
> So naturally I thought that GEOID12B would be as easy :
> NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:6319+5703 <= no vertical
> change
> NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:5498         <= no vertical
> change

As the target SRS here use the NAVD88 height vertical CRS, but in EPSG, there 
is no transformation from NAVD88 to WGS84, then PROJ < 6.2.1 didn't do any 
vertical change.

Starting with PROJ 6.2.1, it will use the NAVD88->NAD83/NAD83(2011) grids, so 
GEOID12B if that's what you've available, as a fallback.

$ ~/proj/install-proj-6.2.1/bin/projinfo -s EPSG:4979 -t EPSG:5498  --spatial-
test intersects

Candidate operations found: 294
-------------------------------------
Operation n°1:

unknown id, NAD83(2011) to NAVD88 height (1) + Inverse of NAD83 to WGS 84 (1), 
4.02 m, USA - CONUS - onshore, at least one grid missing

PROJ string:
+proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert 
+xy_in=deg +xy_out=rad +step +inv +proj=vgridshift +grids=g2012bu0.gtx 
+multiplier=1 +step +proj=unitconvert +xy_in=rad +xy_out=deg +step 
+proj=axisswap +order=2,1



Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From gdt at lexort.com  Fri Nov  1 18:54:31 2019
From: gdt at lexort.com (Greg Troxel)
Date: Fri, 01 Nov 2019 21:54:31 -0400
Subject: [PROJ] Future maintainance releases
In-Reply-To: <EEA3B56B-E56D-4BE6-A057-A8FD4919A342@sdfe.dk> (Kristian Evers's
 message of "Fri, 1 Nov 2019 19:24:21 +0000")
References: <13568718.XafZnbjQPh@even-i700>
 <3787220d-fdaf-69b3-4cc5-b38ee371206e@xs4all.nl>
 <4f3c66f428d74fa8915451f062cb0a04@sdfe.dk>
 <2058429.pZbsZHp53L@even-i700>
 <c4921a928b1c2d1b3f38c6dda663e224@xs4all.nl>
 <rmisgnauz1m.fsf@s1.lexort.com>
 <4625A259-37DB-47F0-BA1B-B7D417884DBC@sdfe.dk>
 <rmi36f9spcp.fsf@s1.lexort.com>
 <5C951202-F58F-4001-B4B4-905E8EA829B2@cleverelephant.ca>
 <94846156-EAEE-4082-B2E0-321791630C8A@sdfe.dk>
 <rmik18jjumo.fsf@s1.lexort.com>
 <EEA3B56B-E56D-4BE6-A057-A8FD4919A342@sdfe.dk>
Message-ID: <rmik18jhwko.fsf@s1.lexort.com>

Kristian Evers <kreve at sdfe.dk> writes:

>> I still am missing something.   When 7 comes out, with a packaging
>> system that has a single proj version, what version do you think that
>> should be?
>
> With many applications still relying on proj_api.h I would think that a
> version from the 6.x branch should be in the packaging system. 

Yes, but I am saying that means *only 6.x* in the packaging system.

To have both requires us to be able to simultaneously install 6.x and
7.x; it's not reasonable to prohibit simultaneously installing two
things that depend on different proj versions.  That requires some
namespacing scheme, and given how -L/-R library searching works, it more
or less means having different names for the libraries, which means
something like proj6.so and proj7.so, and then pkgconfig/etc. support to
find that, and support in all the depending packages to find the right
ones.  So far, I haven't seen any discussion of upstream proj starting
to do this, and it feels like tilting at windmills to start to patch
this in as a packager.

>> Do you mean that by having 7 released, then there can be a year of
>> packaging sytems having 6, during which time upstreams of proj-using
>> packages can be pressured to make a formal release which is compatible
>> with proj 7?   In all seriousness, this might be the best that can be
>> realistically hoped for.

(I meant "having only 6", just like they now have only 5, and not yet 6.)

> Yes, something like that. A preliminary release schedule after the 7.0.0
> release look something like:
>
> March 1st 2020:	7.0.0 + 6.3.1
> June 1st 2020:	7.0.1 + 6.3.2
> September 2020:	7.1.0 (+ 6.3.3)
> December 2020:	7.1.1
> March 1s 2021:	7.2.0
>
> I won’t commit to too many maintenance release of 6.3 branch since it may
> diverge from master rather quickly. I don’t know exactly what the shelf-life of
> a PROJ release is, but let’s say that it is a year. Then you’d have a soft
> end-of-life of PROJ 6.x either in the middle or end of 2021. That leaves roughly
> two years from now to coerce the lagging projects to adopt the new API. If a
> project still hasn’t made the transition in that time I fear they never will.
>
> I hope the above is manageable. Otherwise I am not sure what to do, apart from
> keeping 6.x alive indefinitely, which to no surprise is not going to happen :-)

I epxect packaging systems to just have 6 -- perhaps starting around the
time 6.3.1 is releaesd in March, and then to move to just 7 perhaps in
March of 2021, dropping things that don't have support for 7.   I don't
expect pkgsrc to try to have two at once, especially without explicit
upstream support for parallel installs.  I'll let Bas comment on guesses
for what Debian might do, and of course anybody else who deals with any
other system.


But I think we are asympotically close to understanding each other, and
we'll muddle through :-)

From markus.metz.giswork at gmail.com  Sun Nov  3 12:20:56 2019
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Sun, 3 Nov 2019 21:20:56 +0100
Subject: [PROJ] GDAL 2 + PROJ 6 does not work
Message-ID: <CAG+h=FGLAwuhpT_hq_NDMuZ4HeQH3LAvTcuk-LBFJx0uy6dyOg@mail.gmail.com>

Hopefully some package maintainers are listening.

A CRS constructed from a proj string (deprecated in GDAL 3 + PROJ 6, I
know), works either in PROJ 6 or in GDAL 2, but not in both. The reason is
that for PROJ 6, "+type=crs" is needed, but unfortunately GDAL 2 does not
recognize this parameter and subsequently can not create a CRS from a proj
string containing "+type=crs".

Therefore I recommend to not package GDAL 2 with PROJ 6.

Markus M
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191103/8d225fee/attachment.html>

From even.rouault at spatialys.com  Sun Nov  3 13:42:54 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sun, 03 Nov 2019 22:42:54 +0100
Subject: [PROJ] [gdal-dev] GDAL 2 + PROJ 6 does not work
In-Reply-To: <CAG+h=FGLAwuhpT_hq_NDMuZ4HeQH3LAvTcuk-LBFJx0uy6dyOg@mail.gmail.com>
References: <CAG+h=FGLAwuhpT_hq_NDMuZ4HeQH3LAvTcuk-LBFJx0uy6dyOg@mail.gmail.com>
Message-ID: <6459637.nHUpXZE4MP@even-i700>

On dimanche 3 novembre 2019 21:20:56 CET Markus Metz wrote:
> Hopefully some package maintainers are listening.
> 
> A CRS constructed from a proj string (deprecated in GDAL 3 + PROJ 6, I
> know), works either in PROJ 6 or in GDAL 2, but not in both. The reason is
> that for PROJ 6, "+type=crs" is needed, but unfortunately GDAL 2 does not
> recognize this parameter and subsequently can not create a CRS from a proj
> string containing "+type=crs".

For the sake of my curiousity, can you explain exactly how you go into 
problems ?
The only quirk I found on quick tests with GDAL 2.4 + PROJ 6 is when using the 
now deprecated "+init=epsg:XXXX" syntax

$ gdalsrsinfo "+init=epsg:4326"

proj_create: init=epsg:/init=IGNF: syntax not supported in non-PROJ4 emulation 
mode

And autotest/osr pass, except one corner test.

> Therefore I recommend to not package GDAL 2 with PROJ 6.

Indeed, GDAL 2 is best used with PROJ 5.2.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From cameron.shorter at gmail.com  Sun Nov  3 13:45:37 2019
From: cameron.shorter at gmail.com (Cameron Shorter)
Date: Mon, 4 Nov 2019 08:45:37 +1100
Subject: [PROJ] Catalog of problems related to time dependent datums,
 misalign webmapping and Australia's problems
Message-ID: <b88fc0b0-db69-bb5a-0479-45f16d423631@gmail.com>

Hi proj folks, in wrapping up a bunch of things as I my contract at NSW 
Spatial Services (as a Geospatial BA), I've copied a bunch of the 
problems we have catalogued into my public blog so they can be accessed 
later.

These include:

Summary of the problems: https://www.opengeospatial.org/blog/3045

Very technical description: 
http://cameronshorter.blogspot.com/2019/08/time-dependent-datum-problems.html

Presentation from Joel Haasdyk and Roger Lott at the OGC: 
https://drive.google.com/file/d/1gxu2Ug0I7axDnmOuHhnwJkFi5WBCqY6y/view?usp=sharing 


Generic post about "Scrappy Collaboration": 
http://cameronshorter.blogspot.com/2019/11/scrappy-collaboration.html

Enjoy, ...

-- 
Cameron Shorter
Technology Demystifier
Open Technologies and Geospatial Consultant

M +61 (0) 419 142 254


From kreve at sdfe.dk  Mon Nov  4 04:55:51 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Mon, 4 Nov 2019 12:55:51 +0000
Subject: [PROJ] Future maintainance releases
In-Reply-To: <rmik18jhwko.fsf@s1.lexort.com>
References: <13568718.XafZnbjQPh@even-i700>
 <3787220d-fdaf-69b3-4cc5-b38ee371206e@xs4all.nl>
 <4f3c66f428d74fa8915451f062cb0a04@sdfe.dk>	<2058429.pZbsZHp53L@even-i700>
 <c4921a928b1c2d1b3f38c6dda663e224@xs4all.nl>	<rmisgnauz1m.fsf@s1.lexort.com>
 <4625A259-37DB-47F0-BA1B-B7D417884DBC@sdfe.dk>
 <rmi36f9spcp.fsf@s1.lexort.com>
 <5C951202-F58F-4001-B4B4-905E8EA829B2@cleverelephant.ca>
 <94846156-EAEE-4082-B2E0-321791630C8A@sdfe.dk>
 <rmik18jjumo.fsf@s1.lexort.com>
 <EEA3B56B-E56D-4BE6-A057-A8FD4919A342@sdfe.dk>
 <rmik18jhwko.fsf@s1.lexort.com>
Message-ID: <d8022e53589643c38aa85ce759f61a55@sdfe.dk>

> Yes, but I am saying that means *only 6.x* in the packaging system.

I know. Apparently my communication skills are rubbish. This is the
situation I've been talking about all along. Packaging systems will
more or less always be lagging behind. In this case it will be lagging
more. Fully expected. 

> But I think we are asympotically close to understanding each other, and
we'll muddle through :-)

I think so too. Hopefully everything works out in the end :-)

/Kristian

-----Original Message-----
From: Greg Troxel <gdt at lexort.com> 
Sent: 2. november 2019 02:55
To: Kristian Evers <kreve at sdfe.dk>
Cc: proj at lists.osgeo.org
Subject: Re: [PROJ] Future maintainance releases

Kristian Evers <kreve at sdfe.dk> writes:

>> I still am missing something.   When 7 comes out, with a packaging
>> system that has a single proj version, what version do you think that
>> should be?
>
> With many applications still relying on proj_api.h I would think that a
> version from the 6.x branch should be in the packaging system. 

Yes, but I am saying that means *only 6.x* in the packaging system.

To have both requires us to be able to simultaneously install 6.x and
7.x; it's not reasonable to prohibit simultaneously installing two
things that depend on different proj versions.  That requires some
namespacing scheme, and given how -L/-R library searching works, it more
or less means having different names for the libraries, which means
something like proj6.so and proj7.so, and then pkgconfig/etc. support to
find that, and support in all the depending packages to find the right
ones.  So far, I haven't seen any discussion of upstream proj starting
to do this, and it feels like tilting at windmills to start to patch
this in as a packager.

>> Do you mean that by having 7 released, then there can be a year of
>> packaging sytems having 6, during which time upstreams of proj-using
>> packages can be pressured to make a formal release which is compatible
>> with proj 7?   In all seriousness, this might be the best that can be
>> realistically hoped for.

(I meant "having only 6", just like they now have only 5, and not yet 6.)

> Yes, something like that. A preliminary release schedule after the 7.0.0
> release look something like:
>
> March 1st 2020:	7.0.0 + 6.3.1
> June 1st 2020:	7.0.1 + 6.3.2
> September 2020:	7.1.0 (+ 6.3.3)
> December 2020:	7.1.1
> March 1s 2021:	7.2.0
>
> I won’t commit to too many maintenance release of 6.3 branch since it may
> diverge from master rather quickly. I don’t know exactly what the shelf-life of
> a PROJ release is, but let’s say that it is a year. Then you’d have a soft
> end-of-life of PROJ 6.x either in the middle or end of 2021. That leaves roughly
> two years from now to coerce the lagging projects to adopt the new API. If a
> project still hasn’t made the transition in that time I fear they never will.
>
> I hope the above is manageable. Otherwise I am not sure what to do, apart from
> keeping 6.x alive indefinitely, which to no surprise is not going to happen :-)

I epxect packaging systems to just have 6 -- perhaps starting around the
time 6.3.1 is releaesd in March, and then to move to just 7 perhaps in
March of 2021, dropping things that don't have support for 7.   I don't
expect pkgsrc to try to have two at once, especially without explicit
upstream support for parallel installs.  I'll let Bas comment on guesses
for what Debian might do, and of course anybody else who deals with any
other system.


But I think we are asympotically close to understanding each other, and
we'll muddle through :-)

From brian.shaw at noaa.gov  Mon Nov  4 06:26:02 2019
From: brian.shaw at noaa.gov (Brian Shaw)
Date: Mon, 4 Nov 2019 09:26:02 -0500
Subject: [PROJ] Needs a sanity check on Vertical Transformation
In-Reply-To: <5925847.I67IV3XJ70@even-i700>
References: <1572639131647-0.post@n6.nabble.com> <5925847.I67IV3XJ70@even-i700>
Message-ID: <2d05ea2e-6da0-ef8b-b921-2d3193621597@noaa.gov>

Not sure if this helps but here are a few notes.

GEOID18 supersedes GEOID12B in CONUS and Puerto Rico.  GEOID12B should 
be used in Alaska, Hawaii, Guam, and the Commonwealth of the Northern 
Mariana Islands.  American Samoa should not be used for anything as 
ASVD02 is no longer valid after earthquakes.

A note on Geoids, Horizontal (Geometric) Datums and Vertical Datums.  To 
get an orthometric height (aka elevation) in a particular vertical datum 
you should use coordinates in a particular geometric datum with lat,lon, 
and ellipsoid height along with a geoid model to get an orthometric 
height.  For the US here are the appropriate datums and geoid models.  
Note that the corresponding geoid models should be used based on the 
datum of your coordinates. Also note the the original NAD 83 (1986) was 
a 2D datum while all other realizations were 3D, aka geometric.

Also note that if you are concerned about accuracy, WGS84 should be 
avoided if at all possible.   WGS84 has a 3-5 meter uncertainty so any 
time you use coordinates or use it as a pivot in transformations you 
introduce this uncertainty into your coordinates.

Table on geoids and NAD 83 realizations

NAD 83 (realization) 	Geoid Model 	Regions
NAD 83 (1986) 	N/A 	
NAD 83 (HARN) 	GEOID96/GEOID99 	
NAD 83 (FBN) 	GEOID03 	
NAD 83 (CORS96) 	GEOID03 	
NAD 83 (NSRS2007) 	GEOID09 	
NAD 83 (2011) 	GEOID12B 	HI, AK, Guam, CNMI
NAD 83 (2011) 	GEOID18 	CONUS, PRVI


Cheers
Brian


On 11/1/2019 4:33 PM, Even Rouault wrote:
> On vendredi 1 novembre 2019 13:12:11 CET YK_climate wrote:
>> Hello,
>> I have been trying to perform vertical transformation with Proj for a few
>> days now, I think I am done but I am in some help to be sure I didn't make
>> some stupid mistakes!
>> I am looking at getting coordinates in WGS84-Ellipsoid to WG84-EGM96,WG84-
>> EGM2008 and to NAD83(2011)GEOID12B.
>>
>> Here is what I have working so far :
>> WGS84-EGM2008 : cs2cs EPSG:4979 EPSG:4326+3855
>> WGS84-EGM96    : cs2cs EPSG:4979 EPSG:4326+5773
>> Is this correct?
> Yes
>
>> So naturally I thought that GEOID12B would be as easy :
>> NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:6319+5703 <= no vertical
>> change
>> NAD83(2011)-GEOID12B    : cs2cs EPSG:4979 EPSG:5498         <= no vertical
>> change
> As the target SRS here use the NAVD88 height vertical CRS, but in EPSG, there
> is no transformation from NAVD88 to WGS84, then PROJ < 6.2.1 didn't do any
> vertical change.
>
> Starting with PROJ 6.2.1, it will use the NAVD88->NAD83/NAD83(2011) grids, so
> GEOID12B if that's what you've available, as a fallback.
>
> $ ~/proj/install-proj-6.2.1/bin/projinfo -s EPSG:4979 -t EPSG:5498  --spatial-
> test intersects
>
> Candidate operations found: 294
> -------------------------------------
> Operation n°1:
>
> unknown id, NAD83(2011) to NAVD88 height (1) + Inverse of NAD83 to WGS 84 (1),
> 4.02 m, USA - CONUS - onshore, at least one grid missing
>
> PROJ string:
> +proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert
> +xy_in=deg +xy_out=rad +step +inv +proj=vgridshift +grids=g2012bu0.gtx
> +multiplier=1 +step +proj=unitconvert +xy_in=rad +xy_out=deg +step
> +proj=axisswap +order=2,1
>
>
>
> Even
>

-- 
*************************************
Brian Shaw
Geodesist
NOAA/NOS/National Geodetic Survey
Phone # 240-533-9522

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191104/aa0ad4df/attachment-0001.html>

From even.rouault at spatialys.com  Mon Nov  4 06:36:04 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 04 Nov 2019 15:36:04 +0100
Subject: [PROJ] Needs a sanity check on Vertical Transformation
In-Reply-To: <2d05ea2e-6da0-ef8b-b921-2d3193621597@noaa.gov>
References: <1572639131647-0.post@n6.nabble.com> <5925847.I67IV3XJ70@even-i700>
 <2d05ea2e-6da0-ef8b-b921-2d3193621597@noaa.gov>
Message-ID: <2237272.s5PTrbxPFN@even-i700>

Brian,

I've been working on that very subject those last days. Pending work is in
https://github.com/OSGeo/PROJ/pull/1710
and
https://github.com/OSGeo/proj-datumgrid/pull/60

to add support for GEOID18 (as well as older GEOID versions for specialized 
purposes)
For getting a value in the grids, PROJ will use the Datum of the GeographicCRS 
indicated in the EPSG database for the transformation record between NAVD88 
and the NAD83 realizations you mention below, possibly doing a horizontal 
adjustment to go back and forth between the initial and final CRS and this 
interpolation CRS. It will not go through WGS84.

So for example (with the 2 above pull requests in place), transforming between 
NAD83(2011) + NAVD88 height and NA83(2011) (3D) shows that no horizontal 
adjustment is attempted:

projinfo -s EPSG:6318+5703 -t EPSG:6319 --spatial-test intersects -o PROJ
Candidate operations found: 2
-------------------------------------
Operation n°1:

unknown id, Inverse of NAD83(2011) to NAVD88 height (3), 0.015 m, USA - CONUS 
- onshore

PROJ string:
+proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert 
+xy_in=deg +xy_out=rad +step +proj=vgridshift +grids=g2018u0.gtx +multiplier=1 
+step +proj=unitconvert +xy_in=rad +xy_out=deg +step +proj=axisswap +order=2,1

-------------------------------------
Operation n°2:

unknown id, Inverse of NAD83(2011) to NAVD88 height (2), 0.02 m, USA - Alaska

PROJ string:
+proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert 
+xy_in=deg +xy_out=rad +step +proj=vgridshift +grids=g2012ba0.gtx 
+multiplier=1 +step +proj=unitconvert +xy_in=rad +xy_out=deg +step 
+proj=axisswap +order=2,1

Even

> GEOID18 supersedes GEOID12B in CONUS and Puerto Rico.  GEOID12B should
> be used in Alaska, Hawaii, Guam, and the Commonwealth of the Northern
> Mariana Islands.  American Samoa should not be used for anything as
> ASVD02 is no longer valid after earthquakes.
> 
> A note on Geoids, Horizontal (Geometric) Datums and Vertical Datums.  To
> get an orthometric height (aka elevation) in a particular vertical datum
> you should use coordinates in a particular geometric datum with lat,lon,
> and ellipsoid height along with a geoid model to get an orthometric
> height.  For the US here are the appropriate datums and geoid models. 
> Note that the corresponding geoid models should be used based on the
> datum of your coordinates. Also note the the original NAD 83 (1986) was
> a 2D datum while all other realizations were 3D, aka geometric.
> 
> Also note that if you are concerned about accuracy, WGS84 should be
> avoided if at all possible.   WGS84 has a 3-5 meter uncertainty so any
> time you use coordinates or use it as a pivot in transformations you
> introduce this uncertainty into your coordinates.
> 
> Table on geoids and NAD 83 realizations
> 
> NAD 83 (realization) 	Geoid Model 	Regions
> NAD 83 (1986) 	N/A
> NAD 83 (HARN) 	GEOID96/GEOID99
> NAD 83 (FBN) 	GEOID03
> NAD 83 (CORS96) 	GEOID03
> NAD 83 (NSRS2007) 	GEOID09
> NAD 83 (2011) 	GEOID12B 	HI, AK, Guam, CNMI
> NAD 83 (2011) 	GEOID18 	CONUS, PRVI
> 

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From markus.metz.giswork at gmail.com  Mon Nov  4 12:21:28 2019
From: markus.metz.giswork at gmail.com (Markus Metz)
Date: Mon, 4 Nov 2019 21:21:28 +0100
Subject: [PROJ] [gdal-dev] GDAL 2 + PROJ 6 does not work
In-Reply-To: <6459637.nHUpXZE4MP@even-i700>
References: <CAG+h=FGLAwuhpT_hq_NDMuZ4HeQH3LAvTcuk-LBFJx0uy6dyOg@mail.gmail.com>
 <6459637.nHUpXZE4MP@even-i700>
Message-ID: <CAG+h=FHg_TuYQh9mQhgLGNkhVPQTPEgovjwW4X_QBS7e=4ROCg@mail.gmail.com>

On Sun, Nov 3, 2019 at 10:42 PM Even Rouault <even.rouault at spatialys.com>
wrote:
>
> On dimanche 3 novembre 2019 21:20:56 CET Markus Metz wrote:
> > Hopefully some package maintainers are listening.
> >
> > A CRS constructed from a proj string (deprecated in GDAL 3 + PROJ 6, I
> > know), works either in PROJ 6 or in GDAL 2, but not in both. The reason
is
> > that for PROJ 6, "+type=crs" is needed, but unfortunately GDAL 2 does
not
> > recognize this parameter and subsequently can not create a CRS from a
proj
> > string containing "+type=crs".
>
> For the sake of my curiousity, can you explain exactly how you go into
> problems ?
> The only quirk I found on quick tests with GDAL 2.4 + PROJ 6 is when
using the
> now deprecated "+init=epsg:XXXX" syntax

I tried gdalinfo (GDAL 2.4.2 + PROJ 6.2.1) on a raster with a CRS that does
not contain an authority code, and it failed to find any CRS. Recompiling
with configure --with-proj5-api=no solved the problem for me. That makes
sense to me because the new PROJ API produces quite different results when
used on PROJ5 or PROJ6.

I have seen the combination of GDAL 2 + PROJ 6 on Debian and it might occur
also on EPEL for RHEL 8.

> Indeed, GDAL 2 is best used with PROJ 5.2.

And if I want to use PROJ 6 + GDAL, I should use GDAL 3, right?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191104/23514b25/attachment.html>

From julien.schroder at gmail.com  Mon Nov  4 12:41:18 2019
From: julien.schroder at gmail.com (Julien Schroder)
Date: Mon, 4 Nov 2019 13:41:18 -0700
Subject: [PROJ] Needs a sanity check on Vertical Transformation
In-Reply-To: <2237272.s5PTrbxPFN@even-i700>
References: <1572639131647-0.post@n6.nabble.com> <5925847.I67IV3XJ70@even-i700>
 <2d05ea2e-6da0-ef8b-b921-2d3193621597@noaa.gov> <2237272.s5PTrbxPFN@even-i700>
Message-ID: <CANhNitpk=RnqA4_rWrk7-_iv_n_L8k9geTy-37nLcdhLwtrycQ@mail.gmail.com>

Thank you so much for your help it is much clearer now and a perfect timing
with the new release.
That is good to know about WGS84 and the resulting uncertainty, it is
slightly worrying, I will investigate that further.
Thank again

*Julien Schroder | Spatial Analyst | Photographer*
julien.schroder at gmail.com | +1 514 797 1464

Website <http://arctic-mood.com/> | Instagram
<https://www.instagram.com/arctic.mood/?hl=en> | Linkedin
<https://www.linkedin.com/in/julien-schroder-2225a578> | Facebook
<https://www.facebook.com/julien.schroder.1/> | Twitter
<http://twitter.com/Julienschroder>


Le lun. 4 nov. 2019 à 07:36, Even Rouault <even.rouault at spatialys.com> a
écrit :

> Brian,
>
> I've been working on that very subject those last days. Pending work is in
> https://github.com/OSGeo/PROJ/pull/1710
> and
> https://github.com/OSGeo/proj-datumgrid/pull/60
>
> to add support for GEOID18 (as well as older GEOID versions for
> specialized
> purposes)
> For getting a value in the grids, PROJ will use the Datum of the
> GeographicCRS
> indicated in the EPSG database for the transformation record between
> NAVD88
> and the NAD83 realizations you mention below, possibly doing a horizontal
> adjustment to go back and forth between the initial and final CRS and this
> interpolation CRS. It will not go through WGS84.
>
> So for example (with the 2 above pull requests in place), transforming
> between
> NAD83(2011) + NAVD88 height and NA83(2011) (3D) shows that no horizontal
> adjustment is attempted:
>
> projinfo -s EPSG:6318+5703 -t EPSG:6319 --spatial-test intersects -o PROJ
> Candidate operations found: 2
> -------------------------------------
> Operation n°1:
>
> unknown id, Inverse of NAD83(2011) to NAVD88 height (3), 0.015 m, USA -
> CONUS
> - onshore
>
> PROJ string:
> +proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert
> +xy_in=deg +xy_out=rad +step +proj=vgridshift +grids=g2018u0.gtx
> +multiplier=1
> +step +proj=unitconvert +xy_in=rad +xy_out=deg +step +proj=axisswap
> +order=2,1
>
> -------------------------------------
> Operation n°2:
>
> unknown id, Inverse of NAD83(2011) to NAVD88 height (2), 0.02 m, USA -
> Alaska
>
> PROJ string:
> +proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert
> +xy_in=deg +xy_out=rad +step +proj=vgridshift +grids=g2012ba0.gtx
> +multiplier=1 +step +proj=unitconvert +xy_in=rad +xy_out=deg +step
> +proj=axisswap +order=2,1
>
> Even
>
> > GEOID18 supersedes GEOID12B in CONUS and Puerto Rico.  GEOID12B should
> > be used in Alaska, Hawaii, Guam, and the Commonwealth of the Northern
> > Mariana Islands.  American Samoa should not be used for anything as
> > ASVD02 is no longer valid after earthquakes.
> >
> > A note on Geoids, Horizontal (Geometric) Datums and Vertical Datums.  To
> > get an orthometric height (aka elevation) in a particular vertical datum
> > you should use coordinates in a particular geometric datum with lat,lon,
> > and ellipsoid height along with a geoid model to get an orthometric
> > height.  For the US here are the appropriate datums and geoid models.
> > Note that the corresponding geoid models should be used based on the
> > datum of your coordinates. Also note the the original NAD 83 (1986) was
> > a 2D datum while all other realizations were 3D, aka geometric.
> >
> > Also note that if you are concerned about accuracy, WGS84 should be
> > avoided if at all possible.   WGS84 has a 3-5 meter uncertainty so any
> > time you use coordinates or use it as a pivot in transformations you
> > introduce this uncertainty into your coordinates.
> >
> > Table on geoids and NAD 83 realizations
> >
> > NAD 83 (realization)  Geoid Model     Regions
> > NAD 83 (1986)         N/A
> > NAD 83 (HARN)         GEOID96/GEOID99
> > NAD 83 (FBN)  GEOID03
> > NAD 83 (CORS96)       GEOID03
> > NAD 83 (NSRS2007)     GEOID09
> > NAD 83 (2011)         GEOID12B        HI, AK, Guam, CNMI
> > NAD 83 (2011)         GEOID18         CONUS, PRVI
> >
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191104/bf411c4b/attachment.html>

From even.rouault at spatialys.com  Mon Nov  4 12:44:02 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 04 Nov 2019 21:44:02 +0100
Subject: [PROJ] [gdal-dev] GDAL 2 + PROJ 6 does not work
In-Reply-To: <CAG+h=FHg_TuYQh9mQhgLGNkhVPQTPEgovjwW4X_QBS7e=4ROCg@mail.gmail.com>
References: <CAG+h=FGLAwuhpT_hq_NDMuZ4HeQH3LAvTcuk-LBFJx0uy6dyOg@mail.gmail.com>
 <6459637.nHUpXZE4MP@even-i700>
 <CAG+h=FHg_TuYQh9mQhgLGNkhVPQTPEgovjwW4X_QBS7e=4ROCg@mail.gmail.com>
Message-ID: <2143852.YdCvKdnHoM@even-i700>

> I tried gdalinfo (GDAL 2.4.2 + PROJ 6.2.1) on a raster with a CRS that does
> not contain an authority code, and it failed to find any CRS. Recompiling
> with configure --with-proj5-api=no solved the problem for me. That makes
> sense to me because the new PROJ API produces quite different results when
> used on PROJ5 or PROJ6.

ok, a bit weird still but I trust you. GDAL 2 hardly uses PROJ for CRS 
building as it has self-contained logic to deal with EPSG, WKT and import/
export PROJ strings.

> I have seen the combination of GDAL 2 + PROJ 6 on Debian and it might occur
> also on EPEL for RHEL 8.

For Debian, I believe this combination is just a transitional state to deploy 
first PROJ 6 and then GDAL 3.

> 
> > Indeed, GDAL 2 is best used with PROJ 5.2.
> 
> And if I want to use PROJ 6 + GDAL, I should use GDAL 3, right?

yes, the recommended combinations are :
- GDAL 2.x with PROJ 5.2
- GDAL 3.x requires PROJ >= 6


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Thu Nov  7 06:15:24 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 07 Nov 2019 15:15:24 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
Message-ID: <2050292.DNJDU9U1K9@even-i700>

Hi,

It has been reported that PROJ 6.2.1 (also applies to master) runs super slow 
if used with a too old SQLite version (https://github.com/OSGeo/PROJ/issues/
1718). It works fine with SQLite 3.11 (as found on Ubuntu 16.04 for example). 
SQLite 3.11 was released on 2016-02-15, so meets our "older than 2 years" 
rule.

Hence the following motion
~~
Require SQLite 3.11 for PROJ master
~~

+1 Even

PR implementing this ready in https://github.com/OSGeo/PROJ/pull/1721
Will apply for PROJ 6.3

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From howard at hobu.co  Thu Nov  7 06:50:30 2019
From: howard at hobu.co (Howard Butler)
Date: Thu, 7 Nov 2019 08:50:30 -0600
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <2050292.DNJDU9U1K9@even-i700>
References: <2050292.DNJDU9U1K9@even-i700>
Message-ID: <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>



> On Nov 7, 2019, at 8:15 AM, Even Rouault <even.rouault at spatialys.com> wrote:
> 
> Hi,
> 
> It has been reported that PROJ 6.2.1 (also applies to master) runs super slow 
> if used with a too old SQLite version (https://github.com/OSGeo/PROJ/issues/
> 1718). It works fine with SQLite 3.11 (as found on Ubuntu 16.04 for example). 
> SQLite 3.11 was released on 2016-02-15, so meets our "older than 2 years" 
> rule.
> 
> Hence the following motion
> ~~
> Require SQLite 3.11 for PROJ master
> ~~
> 
> +1 Even
> 
> PR implementing this ready in https://github.com/OSGeo/PROJ/pull/1721
> Will apply for PROJ 6.3
> 
> -- 
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


From howard at hobu.co  Thu Nov  7 06:52:48 2019
From: howard at hobu.co (Howard Butler)
Date: Thu, 7 Nov 2019 08:52:48 -0600
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
References: <2050292.DNJDU9U1K9@even-i700>
 <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
Message-ID: <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>

+0. I'd like to hear from the packagers on this. We're already making life complicated for them, and SQLite is a frequently referenced dependency. Does 3.11 pick up common RHEL/Centos installations? Android/iOS? 

Howard 

> On Nov 7, 2019, at 8:50 AM, Howard Butler <howard at hobu.co> wrote:
> 
> 
> 
>> On Nov 7, 2019, at 8:15 AM, Even Rouault <even.rouault at spatialys.com> wrote:
>> 
>> Hi,
>> 
>> It has been reported that PROJ 6.2.1 (also applies to master) runs super slow 
>> if used with a too old SQLite version (https://github.com/OSGeo/PROJ/issues/
>> 1718). It works fine with SQLite 3.11 (as found on Ubuntu 16.04 for example). 
>> SQLite 3.11 was released on 2016-02-15, so meets our "older than 2 years" 
>> rule.
>> 
>> Hence the following motion
>> ~~
>> Require SQLite 3.11 for PROJ master
>> ~~
>> 
>> +1 Even
>> 
>> PR implementing this ready in https://github.com/OSGeo/PROJ/pull/1721
>> Will apply for PROJ 6.3
>> 
>> -- 
>> Spatialys - Geospatial professional services
>> http://www.spatialys.com
>> _______________________________________________
>> PROJ mailing list
>> PROJ at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/proj
> 


From even.rouault at spatialys.com  Thu Nov  7 07:06:46 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 07 Nov 2019 16:06:46 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
References: <2050292.DNJDU9U1K9@even-i700>
 <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
 <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
Message-ID: <1961918.9Koyq8LJcu@even-i700>

On jeudi 7 novembre 2019 08:52:48 CET Howard Butler wrote:
> +0. I'd like to hear from the packagers on this. We're already making life
> complicated for them, and SQLite is a frequently referenced dependency.
> Does 3.11 pick up common RHEL/Centos installations? Android/iOS?

This was triggered by someone trying on RHEL 7 that offers SQLite 3.7.17. So 
the solution for them would also to have a backport of a more recent SQLite 
version. As SQLite is quite backward compatible, I don't think this shouldn't 
be an issue.

The alternative to this would be to modify our implementation to work decently 
with older SQLite versions. But on a quick look, this doesn't seem to be 
doable without writing horrible SQL requests in the code. I'm not even sure 
this is doable for all requests. Or perhaps it would require creating extra 
materialized table(s) instead of requesting a view which is a union of several 
tables. I'm not super enthusiastic about that.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From sebastic at xs4all.nl  Thu Nov  7 07:10:34 2019
From: sebastic at xs4all.nl (Sebastiaan Couwenberg)
Date: Thu, 7 Nov 2019 16:10:34 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
References: <2050292.DNJDU9U1K9@even-i700>
 <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
 <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
Message-ID: <b99c007d-b932-ba89-3837-590ff1a9fcab@xs4all.nl>

On 11/7/19 3:52 PM, Howard Butler wrote:
> +0. I'd like to hear from the packagers on this. We're already making life complicated for them, and SQLite is a frequently referenced dependency. Does 3.11 pick up common RHEL/Centos installations? Android/iOS? 

Debian has 3.16.2 in oldstable.

Ubuntu has 3.11.0 in xenial.

CentOS 7 has 3.7.17.
CentOS 8 has 3.26.0.

Kind Regards,

Bas

-- 
 GPG Key ID: 4096R/6750F10AE88D4AF1
Fingerprint: 8182 DE41 7056 408D 6146  50D1 6750 F10A E88D 4AF1

From jmckenna at gatewaygeomatics.com  Thu Nov  7 07:43:02 2019
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Thu, 7 Nov 2019 11:43:02 -0400
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <2050292.DNJDU9U1K9@even-i700>
References: <2050292.DNJDU9U1K9@even-i700>
Message-ID: <1f5262f6-ac9b-f2bc-07d9-51357d7f95bc@gatewaygeomatics.com>

+1

As a Windows packager (6,000+ downloads per month for the MapServer 
community) we upgraded to minimum SQLite 3.17.0 for MS4W releases, as 
that SQLite release has reported 25% performance boost through R-tree 
indexing improvements.

-jeff



On 2019-11-07 10:15 AM, Even Rouault wrote:
> Hi,
> 
> It has been reported that PROJ 6.2.1 (also applies to master) runs super slow
> if used with a too old SQLite version (https://github.com/OSGeo/PROJ/issues/
> 1718). It works fine with SQLite 3.11 (as found on Ubuntu 16.04 for example).
> SQLite 3.11 was released on 2016-02-15, so meets our "older than 2 years"
> rule.
> 
> Hence the following motion
> ~~
> Require SQLite 3.11 for PROJ master
> ~~
> 
> +1 Even
> 
> PR implementing this ready in https://github.com/OSGeo/PROJ/pull/1721
> Will apply for PROJ 6.3
> 

From pramsey at cleverelephant.ca  Thu Nov  7 07:46:32 2019
From: pramsey at cleverelephant.ca (Paul Ramsey)
Date: Thu, 7 Nov 2019 07:46:32 -0800
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
References: <2050292.DNJDU9U1K9@even-i700>
 <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
 <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
Message-ID: <D3FA992A-52F6-47C8-BA3F-34AB41CCDA34@cleverelephant.ca>

Some packagers may now feel punished for getting on the Proj6 train. They’d have been better off just continuing with Proj4 and waiting out the transition for a couple more years.
This isn’t an optional requirement for Proj6, basically it’s an unusably bad performance regression, so using Proj6 requires a newer SQLite given current state. The Motion is sort of beside the point, it’s just a technical fact.

P.

> On Nov 7, 2019, at 6:52 AM, Howard Butler <howard at hobu.co> wrote:
> 
> +0. I'd like to hear from the packagers on this. We're already making life complicated for them, and SQLite is a frequently referenced dependency. Does 3.11 pick up common RHEL/Centos installations? Android/iOS? 
> 
> Howard 
> 
>> On Nov 7, 2019, at 8:50 AM, Howard Butler <howard at hobu.co> wrote:
>> 
>> 
>> 
>>> On Nov 7, 2019, at 8:15 AM, Even Rouault <even.rouault at spatialys.com> wrote:
>>> 
>>> Hi,
>>> 
>>> It has been reported that PROJ 6.2.1 (also applies to master) runs super slow 
>>> if used with a too old SQLite version (https://github.com/OSGeo/PROJ/issues/
>>> 1718). It works fine with SQLite 3.11 (as found on Ubuntu 16.04 for example). 
>>> SQLite 3.11 was released on 2016-02-15, so meets our "older than 2 years" 
>>> rule.
>>> 
>>> Hence the following motion
>>> ~~
>>> Require SQLite 3.11 for PROJ master
>>> ~~
>>> 
>>> +1 Even
>>> 
>>> PR implementing this ready in https://github.com/OSGeo/PROJ/pull/1721
>>> Will apply for PROJ 6.3
>>> 
>>> -- 
>>> Spatialys - Geospatial professional services
>>> http://www.spatialys.com
>>> _______________________________________________
>>> PROJ mailing list
>>> PROJ at lists.osgeo.org
>>> https://lists.osgeo.org/mailman/listinfo/proj
>> 
> 
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


From even.rouault at spatialys.com  Thu Nov  7 07:57:10 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 07 Nov 2019 16:57:10 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <D3FA992A-52F6-47C8-BA3F-34AB41CCDA34@cleverelephant.ca>
References: <2050292.DNJDU9U1K9@even-i700>
 <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
 <D3FA992A-52F6-47C8-BA3F-34AB41CCDA34@cleverelephant.ca>
Message-ID: <8163547.8fvSUZ30rA@even-i700>

> This isn’t an optional requirement for
> Proj6, basically it’s an unusably bad performance regression, so using
> Proj6 requires a newer SQLite given current state.

Agreed. This probably mostly affects RHEL 7 which, while not being antiquated 
from the point of view of RedHat's release policies, still ships with outdated 
components by todays' standards. So RHEL 7 users have two options: use PROJ 
5.x or PROJ 6 + backported SQLite.

> The Motion is sort of
> beside the point, it’s just a technical fact.

This motion is mostly purely procedural to be in compliance with
"Changing the version requirements for a dependency needs to be approved by 
the PSC."
of https://proj.org/community/rfc/rfc-3.html as Kristian reminded me.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From gdt at lexort.com  Thu Nov  7 08:37:12 2019
From: gdt at lexort.com (Greg Troxel)
Date: Thu, 07 Nov 2019 11:37:12 -0500
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <8163547.8fvSUZ30rA@even-i700> (Even Rouault's message of "Thu,
 07 Nov 2019 16:57:10 +0100")
References: <2050292.DNJDU9U1K9@even-i700>
 <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
 <D3FA992A-52F6-47C8-BA3F-34AB41CCDA34@cleverelephant.ca>
 <8163547.8fvSUZ30rA@even-i700>
Message-ID: <rmizhh7iqx3.fsf@s1.lexort.com>

Even Rouault <even.rouault at spatialys.com> writes:

>> This isn’t an optional requirement for
>> Proj6, basically it’s an unusably bad performance regression, so using
>> Proj6 requires a newer SQLite given current state.
>
> Agreed. This probably mostly affects RHEL 7 which, while not being antiquated 
> from the point of view of RedHat's release policies, still ships with outdated 
> components by todays' standards. So RHEL 7 users have two options: use PROJ 
> 5.x or PROJ 6 + backported SQLite.

This is a fundamental issue with LTS releases.  The idea of building
current versions of software using dependencies from the LTS release
basically does not work.  Taken to the extreme, supporting that means
that every package has to work with all versions of dependencies -- and
compilers -- that were released over 5 years ago.

As for RHEL 7, it sounds like the question is "build modern proj with
old sqlite3", and it seems reasonable to just say that isn't supported;
presumably somebody choosing an LTS release also wants old proj, old
qgis, etc.  And if they want new, they probably should build an entire
tree of modern versions that are intercompatible.

All that said,

  NetBSD 8 base system: 	3.17.0
  pkgsrc 2019Q3:		3.29.0
  pkgsrc curent:		3.30.1

I don't have a NetBSD 7 system handy, or 9 (not released), but since
proj is in pkgsrc and not in base, it's trivial to make it depend on
pkgsrc sqlite3.

So I see no issue with requiring 3.11.

I geuss the question is

  If someone builds proj with sqlite3 so old that it will be slow, is it
  better to let it work and be slow or fail the build?

and I can see your point that it's better to fail.

From knudsen.thomas at gmail.com  Thu Nov  7 08:49:26 2019
From: knudsen.thomas at gmail.com (Thomas Knudsen)
Date: Thu, 7 Nov 2019 17:49:26 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <rmizhh7iqx3.fsf@s1.lexort.com>
References: <2050292.DNJDU9U1K9@even-i700>
 <1372C615-9DC5-4A95-A8E9-2ADDD631B7B0@hobu.co>
 <D3FA992A-52F6-47C8-BA3F-34AB41CCDA34@cleverelephant.ca>
 <8163547.8fvSUZ30rA@even-i700> <rmizhh7iqx3.fsf@s1.lexort.com>
Message-ID: <CAH0YoEOpsmLwHqkZ7dDTjHk12riBuQMfMRhLK5OH77baih0B6Q@mail.gmail.com>

+1
(convinced by the evidence and reasoning provided by Greg and Bas, although
it would be nice if we in any practical way could "suggest", rather than
"require" >=3.11)

Den tor. 7. nov. 2019 kl. 17.37 skrev Greg Troxel <gdt at lexort.com>:

> Even Rouault <even.rouault at spatialys.com> writes:
>
> >> This isn’t an optional requirement for
> >> Proj6, basically it’s an unusably bad performance regression, so using
> >> Proj6 requires a newer SQLite given current state.
> >
> > Agreed. This probably mostly affects RHEL 7 which, while not being
> antiquated
> > from the point of view of RedHat's release policies, still ships with
> outdated
> > components by todays' standards. So RHEL 7 users have two options: use
> PROJ
> > 5.x or PROJ 6 + backported SQLite.
>
> This is a fundamental issue with LTS releases.  The idea of building
> current versions of software using dependencies from the LTS release
> basically does not work.  Taken to the extreme, supporting that means
> that every package has to work with all versions of dependencies -- and
> compilers -- that were released over 5 years ago.
>
> As for RHEL 7, it sounds like the question is "build modern proj with
> old sqlite3", and it seems reasonable to just say that isn't supported;
> presumably somebody choosing an LTS release also wants old proj, old
> qgis, etc.  And if they want new, they probably should build an entire
> tree of modern versions that are intercompatible.
>
> All that said,
>
>   NetBSD 8 base system:         3.17.0
>   pkgsrc 2019Q3:                3.29.0
>   pkgsrc curent:                3.30.1
>
> I don't have a NetBSD 7 system handy, or 9 (not released), but since
> proj is in pkgsrc and not in base, it's trivial to make it depend on
> pkgsrc sqlite3.
>
> So I see no issue with requiring 3.11.
>
> I geuss the question is
>
>   If someone builds proj with sqlite3 so old that it will be slow, is it
>   better to let it work and be slow or fail the build?
>
> and I can see your point that it's better to fail.
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191107/5f5a6bcc/attachment.html>

From even.rouault at spatialys.com  Thu Nov  7 09:14:49 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 07 Nov 2019 18:14:49 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <CAH0YoEOpsmLwHqkZ7dDTjHk12riBuQMfMRhLK5OH77baih0B6Q@mail.gmail.com>
References: <2050292.DNJDU9U1K9@even-i700> <rmizhh7iqx3.fsf@s1.lexort.com>
 <CAH0YoEOpsmLwHqkZ7dDTjHk12riBuQMfMRhLK5OH77baih0B6Q@mail.gmail.com>
Message-ID: <2436506.o3IJx8z8PO@even-i700>

On jeudi 7 novembre 2019 17:49:26 CET Thomas Knudsen wrote:
> +1
> (convinced by the evidence and reasoning provided by Greg and Bas, although
> it would be nice if we in any practical way could "suggest", rather than
> "require" >=3.11)

No, this is really a functional requirement to get nominal behaviour of the 
library. Otherwise runtime experience will be terrible (it is not like running 
with older sqlite is 10% slower. It is 1 to 2 order of magnitude slower. see 
the ticket) and people will complain. If people really want to run against 
older versions, they can easily change configure.ac/CMakeLists.txt to remove 
the check, but at least they will know that they're doing risky games and 
hopefully they won't complain to community forums that it is slow.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From kreve at sdfe.dk  Thu Nov  7 10:27:59 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Thu, 7 Nov 2019 18:27:59 +0000
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <2436506.o3IJx8z8PO@even-i700>
References: <2050292.DNJDU9U1K9@even-i700> <rmizhh7iqx3.fsf@s1.lexort.com>
 <CAH0YoEOpsmLwHqkZ7dDTjHk12riBuQMfMRhLK5OH77baih0B6Q@mail.gmail.com>
 <2436506.o3IJx8z8PO@even-i700>
Message-ID: <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk>

I am also +1 on this. I am just wondering if 3.11 is the lowest possible
version that is feasible to use with PROJ. From the linked issue I understand
that SQLite 3.8.x is too slow and that it works with 3.11. I take it that 3.11 was
chosen because it was readily available for Even. Would 3.9 or 3.10 work
as well? Or was there a specific change in 3.11 that we know is the one that
makes the difference?

/Kristian

> On 7 Nov 2019, at 18:14, Even Rouault <even.rouault at spatialys.com> wrote:
> 
> On jeudi 7 novembre 2019 17:49:26 CET Thomas Knudsen wrote:
>> +1
>> (convinced by the evidence and reasoning provided by Greg and Bas, although
>> it would be nice if we in any practical way could "suggest", rather than
>> "require" >=3.11)
> 
> No, this is really a functional requirement to get nominal behaviour of the 
> library. Otherwise runtime experience will be terrible (it is not like running 
> with older sqlite is 10% slower. It is 1 to 2 order of magnitude slower. see 
> the ticket) and people will complain. If people really want to run against 
> older versions, they can easily change configure.ac/CMakeLists.txt to remove 
> the check, but at least they will know that they're doing risky games and 
> hopefully they won't complain to community forums that it is slow.
> 
> -- 
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


From even.rouault at spatialys.com  Thu Nov  7 10:51:08 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 07 Nov 2019 19:51:08 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk>
References: <2050292.DNJDU9U1K9@even-i700> <2436506.o3IJx8z8PO@even-i700>
 <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk>
Message-ID: <2021685.NZW87uO35g@even-i700>

On jeudi 7 novembre 2019 18:27:59 CET Kristian Evers wrote:
> I am also +1 on this. I am just wondering if 3.11 is the lowest possible
> version that is feasible to use with PROJ. From the linked issue I
> understand that SQLite 3.8.x is too slow and that it works with 3.11. I
> take it that 3.11 was chosen because it was readily available for Even.
> Would 3.9 or 3.10 work as well? Or was there a specific change in 3.11 that
> we know is the one that makes the difference?

3.11 is likely not the minimum version. I tried to look at the SQLite release 
notes to find the right version, but nothing obvious struck me, so this would 
require doing bisection to find out the minimum version. I don't think it 
really matters to spot the exact version. From the feedback we got up to now, 
the practical concern is with RHEL 7 that ships something too old. Other 
environments have at least 3.11. And anyway, even if it did work for now with 
something older than 3.11, I wouldn't test routinely against it, and our CI 
doens't test that anymore (it is on Xenial on master, so using 3.11), so it 
might break in the future.

On thinking, what has intriguied me is that on Travis, the 6.2 branch runs 
with Ubuntu Trusty / SQLite 3.8.2. Looking at logs, I can indeed see that the 
runtime of test_cpp_api reported there is abnormaly long (45s) but we didn't 
notice. Locally, with a same -O2 build of the 6.2 branch, I get 5.2s with 
sqlite 3.11 vs 32s with 3.8.2. So there might be some amortizing of the 
penalty for runs in the same process / reusing the same database connection.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From schwehr at gmail.com  Thu Nov  7 10:53:50 2019
From: schwehr at gmail.com (Kurt Schwehr)
Date: Thu, 7 Nov 2019 10:53:50 -0800
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk>
References: <2050292.DNJDU9U1K9@even-i700> <rmizhh7iqx3.fsf@s1.lexort.com>
 <CAH0YoEOpsmLwHqkZ7dDTjHk12riBuQMfMRhLK5OH77baih0B6Q@mail.gmail.com>
 <2436506.o3IJx8z8PO@even-i700> <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk>
Message-ID: <CACmBxysmBHocWy0GYFpKG6o4did9i89trGi54QYoJU3VCd7Zpw@mail.gmail.com>

+1 Kurt

If sqlite 3.11.0 is a blocker for a distribution, should they really be
talking about proj 6?

Nothing is jumping out at me looking at https://sqlite.org/changes.html as
to the version, but 3.11.0 seems safe.

On Thu, Nov 7, 2019 at 10:28 AM Kristian Evers <kreve at sdfe.dk> wrote:

> I am also +1 on this. I am just wondering if 3.11 is the lowest possible
> version that is feasible to use with PROJ. From the linked issue I
> understand
> that SQLite 3.8.x is too slow and that it works with 3.11. I take it that
> 3.11 was
> chosen because it was readily available for Even. Would 3.9 or 3.10 work
> as well? Or was there a specific change in 3.11 that we know is the one
> that
> makes the difference?
>
> /Kristian
>
> > On 7 Nov 2019, at 18:14, Even Rouault <even.rouault at spatialys.com>
> wrote:
> >
> > On jeudi 7 novembre 2019 17:49:26 CET Thomas Knudsen wrote:
> >> +1
> >> (convinced by the evidence and reasoning provided by Greg and Bas,
> although
> >> it would be nice if we in any practical way could "suggest", rather than
> >> "require" >=3.11)
> >
> > No, this is really a functional requirement to get nominal behaviour of
> the
> > library. Otherwise runtime experience will be terrible (it is not like
> running
> > with older sqlite is 10% slower. It is 1 to 2 order of magnitude slower.
> see
> > the ticket) and people will complain. If people really want to run
> against
> > older versions, they can easily change configure.ac/CMakeLists.txt to
> remove
> > the check, but at least they will know that they're doing risky games
> and
> > hopefully they won't complain to community forums that it is slow.
> >
> > --
> > Spatialys - Geospatial professional services
> > http://www.spatialys.com
> > _______________________________________________
> > PROJ mailing list
> > PROJ at lists.osgeo.org
> > https://lists.osgeo.org/mailman/listinfo/proj
>
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191107/90058c51/attachment-0001.html>

From gdt at lexort.com  Thu Nov  7 12:19:31 2019
From: gdt at lexort.com (Greg Troxel)
Date: Thu, 07 Nov 2019 15:19:31 -0500
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <CACmBxysmBHocWy0GYFpKG6o4did9i89trGi54QYoJU3VCd7Zpw@mail.gmail.com>
 (Kurt Schwehr's message of "Thu, 7 Nov 2019 10:53:50 -0800")
References: <2050292.DNJDU9U1K9@even-i700> <rmizhh7iqx3.fsf@s1.lexort.com>
 <CAH0YoEOpsmLwHqkZ7dDTjHk12riBuQMfMRhLK5OH77baih0B6Q@mail.gmail.com>
 <2436506.o3IJx8z8PO@even-i700>
 <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk>
 <CACmBxysmBHocWy0GYFpKG6o4did9i89trGi54QYoJU3VCd7Zpw@mail.gmail.com>
Message-ID: <rmi8sorigmk.fsf@s1.lexort.com>

Kurt Schwehr <schwehr at gmail.com> writes:

> +1 Kurt
>
> If sqlite 3.11.0 is a blocker for a distribution, should they really be
> talking about proj 6?

Of course not.  I think this is 100% about people wanting to run LTS and
then build new proj.

From mwtoews at gmail.com  Thu Nov  7 17:25:38 2019
From: mwtoews at gmail.com (Mike Taves)
Date: Fri, 8 Nov 2019 14:25:38 +1300
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <2021685.NZW87uO35g@even-i700>
References: <2050292.DNJDU9U1K9@even-i700> <2436506.o3IJx8z8PO@even-i700>
 <FB25E0DA-A961-4CB6-99D5-58A215BBB098@sdfe.dk> <2021685.NZW87uO35g@even-i700>
Message-ID: <CAM2FmMqs5X1ycJJhpDepCrQtKkHp=4KWaW=BoRrjPuUtKovZLA@mail.gmail.com>

On Fri, 8 Nov 2019 at 07:51, Even Rouault <even.rouault at spatialys.com> wrote:
> 3.11 is likely not the minimum version. I tried to look at the SQLite release
> notes to find the right version, but nothing obvious struck me, so this would
> require doing bisection to find out the minimum version. I don't think it
> really matters to spot the exact version.

I found a bit of time to do a few bisection experiments, and I found
the exact version:

version-3.8.0    # 1.82user
version-3.8.10.2 # 0.78user
version-3.8.11   # 0.06user
version-3.8.11.1 # 0.07user
version-3.9.0    # 0.06user
version-3.9.2    # 0.07user
version-3.30.1   # 0.05user

SQLite version 3.8.11 released on 2015-07-27 should be the minimum version.

The closest item that I can see in the release notes [1] is
"Miscellaneous micro-optimizations"

[1] https://www.sqlite.org/changes.html#version_3_8_11

From even.rouault at spatialys.com  Sat Nov  9 02:33:54 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 09 Nov 2019 11:33:54 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
References: <2050292.DNJDU9U1K9@even-i700>
 <D719934A-E287-44FF-B83E-D9846476936A@hobu.co>
Message-ID: <2088138.fzqQLaNncC@even-i700>

> > Hence the following motion
> > ~~
> > Require SQLite 3.11 for PROJ master
> > ~~
> > 

I declare this motion passed with +1 from PSC members Thomas, Kristian, Kurt 
and myself and +0 from Howard.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From howard at hobu.co  Tue Nov 12 12:38:26 2019
From: howard at hobu.co (Howard Butler)
Date: Tue, 12 Nov 2019 14:38:26 -0600
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
Message-ID: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>

All,

Even has written a crowdfunding page on the CDN and grid files topic at https://www.spatialys.com/en/crowdfunding/ <https://www.spatialys.com/en/crowdfunding/> that I had discussed this earlier at https://lists.osgeo.org/pipermail/proj/2019-September/008858.html <https://lists.osgeo.org/pipermail/proj/2019-September/008858.html> and its subsequent email thread. The page also provides a detailed proposal (though not in final RFC form) that outlines the technical development activities to achieve the effort. Sponsors have pledged half of the resources to complete this topic, but we still need more resources to bring it over the finish line (or starting line, depending on your perspective). If your organization is interested in helping, please contact me or Even directly.

Howard






-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191112/6e1c1cc3/attachment.html>

From even.rouault at spatialys.com  Wed Nov 13 09:57:06 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 13 Nov 2019 18:57:06 +0100
Subject: [PROJ] PSC Motion: require SQLite 3.11 as minimum version
In-Reply-To: <2088138.fzqQLaNncC@even-i700>
References: <2050292.DNJDU9U1K9@even-i700>
 <D719934A-E287-44FF-B83E-D9846476936A@hobu.co> <2088138.fzqQLaNncC@even-i700>
Message-ID: <47713449.cRB4ApYMgn@even-i700>

On samedi 9 novembre 2019 11:33:54 CET Even Rouault wrote:
> > > Hence the following motion
> > > ~~
> > > Require SQLite 3.11 for PROJ master
> > > ~~
> 
> I declare this motion passed with +1 from PSC members Thomas, Kristian, Kurt
> and myself and +0 from Howard.

For RHEL 7 users, Howard just pointed me to this backport package of sqlite 3.30.1
that Devrim Gündüz has just done:
https://git.postgresql.org/gitweb/?p=pgrpms.git;a=commit;h=6955796a5a02a794b483551f3336b6af05b3d6b8

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ccrook at linz.govt.nz  Wed Nov 13 11:00:29 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Wed, 13 Nov 2019 19:00:29 +0000
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
Message-ID: <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>

Hi

Sorry I missed the original email thread...

I'm very interested in the possibilities hinted at for GeoTIFF for grid files - but not very clear what capability that would provide.   It sounds like it could provide a way of encoding some aspects of the deformation model we use in NZ.

The specific capability I am hoping for is:

- multiple levels of nested grid
- 1,2, or 3 (more ?) dimensions of data at each grid node (eg de, dn, du,  + possibly uncertainties of each, NTv2 only provides dx/dy and uncertainties of them IIRC)
- values to be floating point or possibly I4 with a defined offset and scale factor for each dimension

Presumably this would also define an interpolation technique (bilinear in each dimension).  NTv2 places what appear to me to be unnecessarily tight constraints on relationships of subgrids with parent grids.  How do you envisage the selection of grid to use at a specific grid cell would be implemented?

I'm also wondering if this could encode more deformation related metadata, such as simple time function parameters (eg step function applying at a certain time, linear ramp between start and end time, or possibly even piecewise linear time function to provide an encoding for post earthquake deformation.

At first sight this looks to provide some very exciting capabilities for time dependent transformations that are going to be needed more and more.

Cheers
Chris

From: PROJ [mailto:proj-bounces at lists.osgeo.org] On Behalf Of Howard Butler
Sent: Wednesday, 13 November 2019 9:39 a.m.
To: PROJ
Subject: [PROJ] Grid CDN Update and Crowdfunding Request

All,

Even has written a crowdfunding page on the CDN and grid files topic at https://www.spatialys.com/en/crowdfunding/ that I had discussed this earlier at https://lists.osgeo.org/pipermail/proj/2019-September/008858.html and its subsequent email thread. The page also provides a detailed proposal (though not in final RFC form) that outlines the technical development activities to achieve the effort. Sponsors have pledged half of the resources to complete this topic, but we still need more resources to bring it over the finish line (or starting line, depending on your perspective). If your organization is interested in helping, please contact me or Even directly.

Howard







________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191113/2cd335bf/attachment.html>

From even.rouault at spatialys.com  Wed Nov 13 11:27:17 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 13 Nov 2019 20:27:17 +0100
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
 <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>
Message-ID: <5102911.KMM7vXTL4R@even-i700>

Chris,

> I'm very interested in the possibilities hinted at for GeoTIFF for grid
> files - but not very clear what capability that would provide.   It sounds
> like it could provide a way of encoding some aspects of the deformation
> model we use in NZ.

The scope of this campaign was directly dedicated to 'classic' horizontal and 
vertical shift grids. I know we had a discussion a few months ago about 
deformation models.

> The specific capability I am hoping for is:
> 
> - multiple levels of nested grid
> - 1,2, or 3 (more ?) dimensions of data at each grid node (eg de, dn, du,  +
> possibly uncertainties of each, NTv2 only provides dx/dy and uncertainties
> of them IIRC) - values to be floating point or possibly I4 with a defined
> offset and scale factor for each dimension

GDAL can encode offset and scale factors in a TIFF tag (as XML metadata), but 
I'm not sure of the value of that for the need we want to address, rather than 
use Float32 directly
Regarding uncertainties, we don't make currently use of them, so I'd imagine 
that we would not include them in the TIFFs to make them more compact.

> Presumably this would also define an interpolation technique (bilinear in
> each dimension).  NTv2 places what appear to me to be unnecessarily tight
> constraints on relationships of subgrids with parent grids.  How do you
> envisage the selection of grid to use at a specific grid cell would be
> implemented?

I was only thinking to a single-level of subgrids, like the Canadian 
ntv2_0.gsb, which is the most complex grid we have in the proj-datumgrid 
repository. The algorithm is simple: select the (first) subgrid whose extent 
intersects the point to transform.

TIFF files have a concept of SubIFDs that could potentiall be used to 
implement multiple levels but there's no support for this in GDAL and I'm not 
completely sure about the state of this in libtiff itself.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ccrook at linz.govt.nz  Wed Nov 13 12:46:07 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Wed, 13 Nov 2019 20:46:07 +0000
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <5102911.KMM7vXTL4R@even-i700>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
 <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>
 <5102911.KMM7vXTL4R@even-i700>
Message-ID: <A87E66F06E86F14B857F2EB047CDF93231436073@prdassexch01.ad.linz.govt.nz>

Thanks Even

I'm afraid I've dropped the ball for a while on the deformation models - was more than a few months ago!  But I'm still looking for opportunities.

If PROJ is adding a grid format it makes sense to me to allow it to server for deformation grids (just a horizontal/vertical/3d shift with a time function) as well the classic case and geoid models.  It seems that we could use TIFF tags to handle them with very little extra effort - not that I'm familiar with TIFF.  LINZ would be very interested in supporting that as an extra feature as we don't have a binary format for publishing our deformation grids.  I'm just being a bit opportunistic :-)

On  level of subgrids if the algorithm is to simple pick the first grid that includes the point, then that provides all the generality we want (far more than simply nested grids), as that doesn't enforce any sort of parent child relationship.  On the other hand it could be less efficient for implementation as it would require searching through all the lowest level child grids for points only on the parent.

On using ints rather than float32 the only reason is that there might be opportunities for compression.  In many case int2 with scale and offset could equally server the purpose, and then you've halved the size of the file (and grid memory possibly).  But certainly not essential.

On uncertainties of components that is certainly not a requirement at the moment - we don't provide them at the moment.  It is a feature of NTv2, and I can certainly imagine it becoming more desirable as accuracy requirements of transformations become more demanding and uncertainty of transformations becomes more critical.

The main thing I would be hoping for is that the grid can support 1/2/3 dimensional displacements (ideally without requiring all grids to define 3 dimensional displacements).

At the risk of pushing the barrow too far, a nice to have would be a grid set id in the grid headers so that we could have more than displacement field.   Each grid set would include one or more grids.    The search algorithm would select and sum the first grid of each set including the calculation point.  This could include an optional simple time function for each grid to support deformation models.  With that simple addition we could completely encode almost any deformation model.

Cheers
Chris

-----Original Message-----
From: Even Rouault [mailto:even.rouault at spatialys.com]
Sent: Thursday, 14 November 2019 8:27 a.m.
To: proj at lists.osgeo.org
Cc: Chris Crook; 'Howard Butler'
Subject: Re: [PROJ] Grid CDN Update and Crowdfunding Request

Chris,

> I'm very interested in the possibilities hinted at for GeoTIFF for grid
> files - but not very clear what capability that would provide.   It sounds
> like it could provide a way of encoding some aspects of the
> deformation model we use in NZ.

The scope of this campaign was directly dedicated to 'classic' horizontal and vertical shift grids. I know we had a discussion a few months ago about deformation models.

> The specific capability I am hoping for is:
>
> - multiple levels of nested grid
> - 1,2, or 3 (more ?) dimensions of data at each grid node (eg de, dn,
> du,  + possibly uncertainties of each, NTv2 only provides dx/dy and
> uncertainties of them IIRC) - values to be floating point or possibly
> I4 with a defined offset and scale factor for each dimension

GDAL can encode offset and scale factors in a TIFF tag (as XML metadata), but I'm not sure of the value of that for the need we want to address, rather than use Float32 directly Regarding uncertainties, we don't make currently use of them, so I'd imagine that we would not include them in the TIFFs to make them more compact.

> Presumably this would also define an interpolation technique (bilinear
> in each dimension).  NTv2 places what appear to me to be unnecessarily
> tight constraints on relationships of subgrids with parent grids.  How
> do you envisage the selection of grid to use at a specific grid cell
> would be implemented?

I was only thinking to a single-level of subgrids, like the Canadian ntv2_0.gsb, which is the most complex grid we have in the proj-datumgrid repository. The algorithm is simple: select the (first) subgrid whose extent intersects the point to transform.

TIFF files have a concept of SubIFDs that could potentiall be used to implement multiple levels but there's no support for this in GDAL and I'm not completely sure about the state of this in libtiff itself.

Even

--
Spatialys - Geospatial professional services http://www.spatialys.com

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From even.rouault at spatialys.com  Wed Nov 13 13:18:30 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 13 Nov 2019 22:18:30 +0100
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF93231436073@prdassexch01.ad.linz.govt.nz>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
 <5102911.KMM7vXTL4R@even-i700>
 <A87E66F06E86F14B857F2EB047CDF93231436073@prdassexch01.ad.linz.govt.nz>
Message-ID: <2777734.uEDfq6OiKp@even-i700>

Chris,

> If PROJ is adding a grid format it makes sense to me to allow it to server
> for deformation grids (just a horizontal/vertical/3d shift with a time
> function) as well the classic case and geoid models.  It seems that we
> could use TIFF tags to handle them with very little extra effort - not that
> I'm familiar with TIFF.  LINZ would be very interested in supporting that
> as an extra feature as we don't have a binary format for publishing our
> deformation grids.  I'm just being a bit opportunistic :-)

TIFF is rather versatile, so it is likely you can make a deformation model fit 
into it.

> On  level of subgrids if the algorithm is to simple pick the first grid that
> includes the point, then that provides all the generality we want (far more
> than simply nested grids), as that doesn't enforce any sort of parent child
> relationship.

Do we need an explicit concept of a parent grid at all ? If we keep the logic 
"first match, first used", then parent grids should be put at the end of the 
chain of the grids
(or at the beginning if we choose for the equivalent "last matched, used", 
where the search would start by the end of the sequence)

> On the other hand it could be less efficient for
> implementation as it would require searching through all the lowest level
> child grids for points only on the parent.

If the number of grids in the file is reasonable, then bbox testing should be 
quite fast. We don't need to load the grid data at all. If it would be larger 
than a few tens of thousands, then we might have to build a in-memory index of 
grid envelopes, but I don't think that would really be needed.
For the network based approach, the idea would be to use the same tricks as 
used for cloud optimized geotiffs for pyramids, that is all TIFF IFD headers 
are put at the beginning of the file, so in a initial GET, we can get all the 
descriptors.

> 
> On using ints rather than float32 the only reason is that there might be
> opportunities for compression.  In many case int2 with scale and offset
> could equally server the purpose, and then you've halved the size of the
> file (and grid memory possibly).  But certainly not essential.

The DEFLATE and LZW algorithm of TIFF can use a mode of the differencial 
predictor designed specifically for IEEE floating point data.
See http://chriscox.org/TIFFTN3d1.pdf , page 3
This is handled by GDAL & libtiff.
That said, the integer-based differencial predictor with scale & offset might 
perhaps perform better. I guess some experimentations should be done to see 
the effects.

> On uncertainties of components that is certainly not a requirement at the
> moment - we don't provide them at the moment.  It is a feature of NTv2, and
> I can certainly imagine it becoming more desirable as accuracy requirements
> of transformations become more demanding and uncertainty of transformations
> becomes more critical.

In TIFF, you can put has many bands as you like, either with pixels of all 
bands packed together (pixel interleaving), or in separate blocks (band 
interleaving). The only constraint is that for a given grid, all bands must 
have the same data type.

> The main thing I would be hoping for is that the grid can support 1/2/3
> dimensional displacements (ideally without requiring all grids to define 3
> dimensional displacements).

Would potentially be possible given my above remark.

> At the risk of pushing the barrow too far, a nice to have would be a grid
> set id in the grid headers so that we could have more than displacement
> field.   Each grid set would include one or more grids.    The search
> algorithm would select and sum the first grid of each set including the
> calculation point.  This could include an optional simple time function for
> each grid to support deformation models.  With that simple addition we
> could completely encode almost any deformation model.

The GDAL_METADATA TIFF tag can hold any arbitrary KEY=VALUE pair:
https://www.awaresystems.be/imaging/tiff/tifftags/gdal_metadata.html 

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From martin.desruisseaux at geomatys.com  Wed Nov 13 13:48:53 2019
From: martin.desruisseaux at geomatys.com (Martin Desruisseaux)
Date: Wed, 13 Nov 2019 22:48:53 +0100
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <5102911.KMM7vXTL4R@even-i700>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
 <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>
 <5102911.KMM7vXTL4R@even-i700>
Message-ID: <9d2680dd-153a-8f69-550a-2597f89b9f11@geomatys.com>

Since part of the discussion seems to be about a file format for grids: 
OGC has a meeting next week in Toulouse with the CRS working group 
meeting on Monday at 16:30 local time [1].  I do not know if this is 
coincidence, but a proposed agenda item is "Proposal for a standard 
geodetic grid file". As far as I know this is just about starting the 
discussion at OGC; I don't think there is a draft yet.

     Martin

[1] http://ogcmeet.org/events/1911tc/#agenda

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191113/47a4caf5/attachment.html>

From ccrook at linz.govt.nz  Wed Nov 13 14:13:56 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Wed, 13 Nov 2019 22:13:56 +0000
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <9d2680dd-153a-8f69-550a-2597f89b9f11@geomatys.com>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
 <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>
 <5102911.KMM7vXTL4R@even-i700>
 <9d2680dd-153a-8f69-550a-2597f89b9f11@geomatys.com>
Message-ID: <A87E66F06E86F14B857F2EB047CDF932314362E7@prdassexch01.ad.linz.govt.nz>

Looks like a happy alignment of the stars :-)

I believe discussions in the past have been along the lines of proposing an entirely new geodetic grid format.  It seems to me if GeoTIFF can serve our requirements it could get us a huge step up in terms of existing infrastructure, particularly with the potential for online selection of subsets, grid creation and management.  (Apart from the constraints from the circular proj  <-> geotiff dependency that is, but libtiff is presumably fair game).

Cheers
Chris

From: PROJ [mailto:proj-bounces at lists.osgeo.org] On Behalf Of Martin Desruisseaux
Sent: Thursday, 14 November 2019 10:49 a.m.
To: proj at lists.osgeo.org
Subject: Re: [PROJ] Grid CDN Update and Crowdfunding Request


Since part of the discussion seems to be about a file format for grids: OGC has a meeting next week in Toulouse with the CRS working group meeting on Monday at 16:30 local time [1].  I do not know if this is coincidence, but a proposed agenda item is "Proposal for a standard geodetic grid file". As far as I know this is just about starting the discussion at OGC; I don't think there is a draft yet.

    Martin

[1] http://ogcmeet.org/events/1911tc/#agenda



________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191113/57ec44af/attachment-0001.html>

From Jochem.Lesparre at kadaster.nl  Thu Nov 14 00:22:05 2019
From: Jochem.Lesparre at kadaster.nl (Lesparre, Jochem)
Date: Thu, 14 Nov 2019 08:22:05 +0000
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <9d2680dd-153a-8f69-550a-2597f89b9f11@geomatys.com>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
 <A87E66F06E86F14B857F2EB047CDF93231435F05@prdassexch01.ad.linz.govt.nz>
 <5102911.KMM7vXTL4R@even-i700>
 <9d2680dd-153a-8f69-550a-2597f89b9f11@geomatys.com>
Message-ID: <DB6P192MB0152F527E9BE703849D155EBEF710@DB6P192MB0152.EURP192.PROD.OUTLOOK.COM>

Hi,

A repository would be nice and a new grid format is welcome too. I do not like NTv2 due to its peculiarities:

Correction values, metadata on spacing and even grid bounds are given in arcseconds instead of decimal degrees. Longitude values have inverted sign, thus east of the Greenwich meridian is negative. This affects the correction values and the metadata values for the grid bounds. Also the order in which the correction values are given in the NTv2 correction grid file, is from southeast to northwest and starts with the east-west direction. While the order in which the correction values are listed in the VDatum grid file is better: from southwest to northeast and starts with the west-east direction.

Kind regards, Jochem



Disclaimer:
De inhoud van dit bericht is uitsluitend bestemd voor geadresseerde.
Gebruik van de inhoud van dit bericht door anderen zonder toestemming van het Kadaster 
is onrechtmatig. Mocht dit bericht ten onrechte bij u terecht komen, dan verzoeken wij u 
dit direct te melden aan de verzender en het bericht te vernietigen. 
Aan de inhoud van dit bericht kunnen geen rechten worden ontleend.

Disclaimer:
The content of this message is meant to be received by the addressee only.
Use of the content of this message by anyone other than the addressee without the consent 
of the Kadaster is unlawful. If you have received this message, but are not the addressee, 
please contact the sender immediately and destroy the message.
No rights can be derived from the content of this message
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191114/d81d4ace/attachment.html>

From even.rouault at spatialys.com  Mon Nov 18 03:58:27 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 18 Nov 2019 12:58:27 +0100
Subject: [PROJ] Grid CDN Update and Crowdfunding Request
In-Reply-To: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
References: <A07658ED-1DBC-435D-8544-65D22F6EF3B2@hobu.co>
Message-ID: <1619941.ARNm1oElk5@even-i700>

Hi,

> Even has written a crowdfunding page on the CDN and grid files topic at
> https://www.spatialys.com/en/crowdfunding/
> <https://www.spatialys.com/en/crowdfunding/>

The good news is that the funding targets for this project have now been 
reached. I'll work now with Howard to prepare a proper RFC.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From xavier.collilieux at ensg.eu  Mon Nov 18 12:18:52 2019
From: xavier.collilieux at ensg.eu (Xavier Collilieux)
Date: Mon, 18 Nov 2019 20:18:52 +0000
Subject: [PROJ] Anomalous characters in the file data/ITRF2014 in version
	6.2.0
Message-ID: <3005F0FD58AE03439837685371FBCB71FDEF5E85@mailex1.ign.fr>

Dear all,

Sorry to annoy you if this error is already known. 

I found that a few tranformations making use of ITRF2014 tectonic plate rotation poles were wrong whereas the file  data/ITRF2014 looks correct (for example the transformation +proj=helmert +init=ITRF2014:EURA). 
After investigation, I finally found that some "minus" characters in the file data/ITRF2014 are incorrect.
For example, in the following line:
+proj=helmert +drx=−0.000085 +dry=−0.000531 +drz=0.000770  +convention=position_vector 

Once I have replaced the character above with the appropriate "minus" sign and recompiled, the transformation provides the right result (only checked for this one).

Best regards,

- Xavier 

PS: I use version 6.2.0 with Ubuntu 18 in command line mode. 


From even.rouault at spatialys.com  Mon Nov 18 12:57:30 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 18 Nov 2019 21:57:30 +0100
Subject: [PROJ] Anomalous characters in the file data/ITRF2014 in
	version 6.2.0
In-Reply-To: <3005F0FD58AE03439837685371FBCB71FDEF5E85@mailex1.ign.fr>
References: <3005F0FD58AE03439837685371FBCB71FDEF5E85@mailex1.ign.fr>
Message-ID: <1874389.jHLkReLrje@even-i700>

Xavier,

> Sorry to annoy you if this error is already known.

Not at all. Thanks for identifying and raising this ! I've just pushed a fix 
in master and 6.2 branches.
(I checked that the ITRF2000 and ITRF2008 files didn't have that issue)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From matt.wilkie at gov.yk.ca  Fri Nov 22 14:41:01 2019
From: matt.wilkie at gov.yk.ca (mhw-at-yg)
Date: Fri, 22 Nov 2019 15:41:01 -0700 (MST)
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
Message-ID: <1574462461793-0.post@n6.nabble.com>

Hello,

Within the Yukon and NWT (Canada), how do you convert spatial data
horizontal datum from NAD83-Original (circa 1994) to NAD83-CSRS (2002+)?

I’ve been up and down NRCAN’s geodetic reference site[0] and a bunch of
other ones and am more confused than when I started. The consensus on the
net seems to be to use NTv2 to migrate from Original to CSRS, but there are
no grid shift files for the territories [1],[2].

Esri (ArcGIS Desktop) and Safe (FME) use transforms which are a null
operation, all that happens is a change in the name, the coordinates are
left unaltered. However looking at the v7 velocity grid[3] it looks like
there have been significant shifts since the 1990s.

Most of our new data acquisitions from survey and LiDAR are coming in as
CSRS. When combining with our old data and project-on-the-fly I’ve observed
different coordinates for the same points depending on how the locations are
reported. So we need to bring our holdings into a common coordinate system
to be assured our analyses are the most correct they can be, but how?

[0]:
https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems/18766
[1]: https://webapp.geod.nrcan.gc.ca/geod/tools-outils/grids.php (List)
[2]: https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php
(Download, sign in but free account)
[3]: https://webapp.geod.nrcan.gc.ca/geod/tools-outils/nad83-docs.php

Thanks in advance for your advice,

Matt Wilkie
Geomatics Analyst
Environment | Information Management & Technology
T 867-667-8133 | Yukon.ca




-----
-Matt
--
Sent from: http://osgeo-org.1560.x6.nabble.com/PROJ-4-f3840930.html

From even.rouault at spatialys.com  Fri Nov 22 15:08:09 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 23 Nov 2019 00:08:09 +0100
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <1574462461793-0.post@n6.nabble.com>
References: <1574462461793-0.post@n6.nabble.com>
Message-ID: <6362384.HoVnLkAt2k@even-i700>

Matt,

> 
> Within the Yukon and NWT (Canada), how do you convert spatial data
> horizontal datum from NAD83-Original (circa 1994) to NAD83-CSRS (2002+)?

I suppose this is the same topic as what you've revived recently in
https://github.com/OSGeo/PROJ/issues/202#issuecomment-556545661 ?

> 
> I’ve been up and down NRCAN’s geodetic reference site[0] and a bunch of
> other ones and am more confused than when I started. The consensus on the
> net seems to be to use NTv2 to migrate from Original to CSRS, but there are
> no grid shift files for the territories [1],[2].
> 
> Esri (ArcGIS Desktop) and Safe (FME) use transforms which are a null
> operation, all that happens is a change in the name, the coordinates are
> left unaltered. However looking at the v7 velocity grid[3] it looks like
> there have been significant shifts since the 1990s.
> 
> Most of our new data acquisitions from survey and LiDAR are coming in as
> CSRS. When combining with our old data and project-on-the-fly I’ve observed
> different coordinates for the same points depending on how the locations are
> reported. So we need to bring our holdings into a common coordinate system
> to be assured our analyses are the most correct they can be, but how?

With PROJ 6.2.1, this should be mostly require to find the grids mentionned in the ESPG transformation records I listed at
https://github.com/OSGeo/PROJ/issues/202#issuecomment-556792769
and putting them in the PROJ_LIB resource directory

For example, if I try

$ projinfo -s NAD83 -t "NAD83(CSRS)v4" --spatial-test intersects -o PROJ

I get:

Candidate operations found: 2
-------------------------------------
Operation n°1:

EPSG:9119, NAD83 to NAD83(CSRS)v4 (9), 0.1 m, Canada - British Columbia - mainland, at least one grid missing

PROJ string:
+proj=pipeline +step +proj=axisswap +order=2,1 +step +proj=unitconvert +xy_in=deg +xy_out=rad +step +proj=hgridshift +grids=BC_93_05.GSB +step +proj=unitconvert +xy_in=rad +xy_out=deg +step +proj=axisswap +order=2,1

Grid BC_93_05.GSB needed but not found on the system.

-------------------------------------
Operation n°2:

unknown id, Ballpark geographic offset from NAD83 to NAD83(CSRS)v4, unknown accuracy, World, has ballpark transformation

PROJ string:
+proj=noop


OK, so after logging, I could download
https://webapp.geod.nrcan.gc.ca/geod/process/download-helper.php?file_id=BC_93_05

Unzip BC_93_05.zip and place the BC_93_05.GSB file in PROJ_LIB directory, and then


echo "50 -120" | cs2cs -d 9 NAD83  "NAD83(CSRS)v4"
50.000000083	-120.000000806 0.000000000

It works !

Ultimately if those grids meet the open source licensing mentioned at

https://github.com/osgeo/proj-datumgrid#about-the-datum-grid-package 

they could be included in the proj-datumgrid-northamerica package.

And apparently, from
https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php?locale=en
they are subject to Open Government Licence - Canada
https://open.canada.ca/en/open-government-licence-canada

https://opendefinition.org/licenses/ lists it under the "Other conformant licenses" category.
Roughly a Creative-Commons By style.
So could probably be candidate for inclusion in proj-datumgrid.


Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From Matt.Wilkie at gov.yk.ca  Fri Nov 22 15:59:50 2019
From: Matt.Wilkie at gov.yk.ca (Matt.Wilkie at gov.yk.ca)
Date: Fri, 22 Nov 2019 23:59:50 +0000
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <6362384.HoVnLkAt2k@even-i700>
References: <1574462461793-0.post@n6.nabble.com> <6362384.HoVnLkAt2k@even-i700>
Message-ID: <7c4f940a1f244ef9855c1eb5a7250117@app-exch1.gov.yk.ca>

Hi Even,

Yeah, it's the same quest that had me wake up the Github issue.

It would be great to resolve the licensing question for the provincial grids, and help if I can. It won't help my particular situation of: no grids available at all. I was hoping (grasping at straws) that someone here would have an alternate idea.

The BC grid files are here ftp://ftp.gdbc.gov.bc.ca/sections/outgoing/gsr/NTv2.0/ but the license is definitely closed (Disclaimer.txt). It should be okay to have a script that displayed the disclaimer, downloaded, and stuffed the files in the right directory though as the restriction is on redistribution:

> No further distribution of NTv2 SOFTWARE, GRID SHIFT FILES and PROCEDURES, 
> in any form, either in whole or in part, is permitted.

I've also queried NRCAN Geodetic Services, a local survey and engineering company, and a few other people who've been publicly noisy about aspects of CSRS that seem to intersect my scenario. I'll report back on those conversations too.

Cheers,

Matt
Geomatics Analyst | Environment | T 867-667-8133 | Yukon.ca

From even.rouault at spatialys.com  Fri Nov 22 16:51:51 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 23 Nov 2019 01:51:51 +0100
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <7c4f940a1f244ef9855c1eb5a7250117@app-exch1.gov.yk.ca>
References: <1574462461793-0.post@n6.nabble.com> <6362384.HoVnLkAt2k@even-i700>
 <7c4f940a1f244ef9855c1eb5a7250117@app-exch1.gov.yk.ca>
Message-ID: <62992551.7xUAaxFYcE@even-i700>

On vendredi 22 novembre 2019 23:59:50 CET Matt.Wilkie at gov.yk.ca wrote:
> Hi Even,
> 
> Yeah, it's the same quest that had me wake up the Github issue.
> 
> It would be great to resolve the licensing question for the provincial
> grids, and help if I can. 

You mean the ones on
https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php ?
Well, I think the Open Government Licence - Canada should be good enough given 
it is endorsed by https://opendefinition.org/licenses/

> It won't help my particular situation of: no
> grids available at all. 

Ah ok, now after reading
https://en.wikipedia.org/wiki/Provinces_and_territories_of_Canada explains the 
difference between a province and territory, I better understand your issue 
with the Yukkon *territory*, to be opposed to the transformations available 
for the *provinces*

Well, yes if there is no data published, we can't do much :-) Your local 
contacts within the related agencies are certainly the best approach.

> It should be okay to have a script that displayed the disclaimer, 
downloaded, and stuffed the files in the right directory though as the 
restriction is on redistribution:

I can't log on that ftp server. It times out.
How are those datasets different from the ones on
https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php , like 
the BC_93_05.GSB ?

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nicolas.cadieux at archeotec.ca  Sat Nov 23 07:40:02 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Sat, 23 Nov 2019 10:40:02 -0500
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
Message-ID: <69549AB1-5225-4693-AF09-3EE50F9E823A@archeotec.ca>

﻿
﻿
Hi,
You probably found this but I am posting anyways in case you did not

http://www.naref.org/transf/nad83_hydroscan2006.pdf

https://webapp.geod.nrcan.gc.ca/geod/tools-outils/ntv2.php?locale=en

https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems-tools/tools-applications/10925#Epochs

Look for Trx and NTv2 tools.

Nicolas



>> Le 22 nov. 2019 à 17:41, mhw-at-yg <matt.wilkie at gov.yk.ca> a écrit :
> ﻿Hello,
> 
> Within the Yukon and NWT (Canada), how do you convert spatial data
> horizontal datum from NAD83-Original (circa 1994) to NAD83-CSRS (2002+)?
> 
> I’ve been up and down NRCAN’s geodetic reference site[0] and a bunch of
> other ones and am more confused than when I started. The consensus on the
> net seems to be to use NTv2 to migrate from Original to CSRS, but there are
> no grid shift files for the territories [1],[2].
> 
> Esri (ArcGIS Desktop) and Safe (FME) use transforms which are a null
> operation, all that happens is a change in the name, the coordinates are
> left unaltered. However looking at the v7 velocity grid[3] it looks like
> there have been significant shifts since the 1990s.
> 
> Most of our new data acquisitions from survey and LiDAR are coming in as
> CSRS. When combining with our old data and project-on-the-fly I’ve observed
> different coordinates for the same points depending on how the locations are
> reported. So we need to bring our holdings into a common coordinate system
> to be assured our analyses are the most correct they can be, but how?
> 
> [0]:
> https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems/18766
> [1]: https://webapp.geod.nrcan.gc.ca/geod/tools-outils/grids.php (List)
> [2]: https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php
> (Download, sign in but free account)
> [3]: https://webapp.geod.nrcan.gc.ca/geod/tools-outils/nad83-docs.php
> 
> Thanks in advance for your advice,
> 
> Matt Wilkie
> Geomatics Analyst
> Environment | Information Management & Technology
> T 867-667-8133 | Yukon.ca
> 
> 
> 
> 
> -----
> -Matt
> --
> Sent from: http://osgeo-org.1560.x6.nabble.com/PROJ-4-f3840930.html
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191123/6b29c5ac/attachment.html>

From even.rouault at spatialys.com  Sat Nov 23 09:53:06 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Sat, 23 Nov 2019 18:53:06 +0100
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <62992551.7xUAaxFYcE@even-i700>
References: <1574462461793-0.post@n6.nabble.com>
 <7c4f940a1f244ef9855c1eb5a7250117@app-exch1.gov.yk.ca>
 <62992551.7xUAaxFYcE@even-i700>
Message-ID: <1806956.uVZmG2kfRV@even-i700>

> You mean the ones on
> https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php ?
> Well, I think the Open Government Licence - Canada should be good enough
> given it is endorsed by https://opendefinition.org/licenses/
> 

I went ahead and submitted the provincial grids for inclusion:
https://github.com/OSGeo/PROJ/pull/1739
https://github.com/OSGeo/proj-datumgrid/pull/61

> Look for Trx and NTv2 tools.

PROJ doesn't support yet the epoch transformation method that
Trx / NAD83(CSRS) v7.0 velocity grid can do

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From bugs at gnu.support  Mon Nov 25 04:15:24 2019
From: bugs at gnu.support (Jean Louis)
Date: Mon, 25 Nov 2019 13:15:24 +0100
Subject: [PROJ] How to construct proper cs2cs command line arguments
Message-ID: <20191125121524.GK22503@protected.rcdrun.com>

Hello,

I have been using this: https://mygeodata.cloud/cs2cs/

and I used input:

+proj=longlat +datum=WGS84 +no_defs

or EPSG:4326

and output to be:

+proj=utm +zone=36 +ellps=clrk80 +towgs84=-160,-6,-302,0,0,0,0 +units=m +no_defs

or Arc 1960 / UTM zone 36N (EPSG:21096)

then with coordinates:

-1.122159, 29.714413

I could get 134183.400916;-123935.185151

which looks proper to me.

But how exactly do I construct the cs2cs command line?

Jean

From kreve at sdfe.dk  Mon Nov 25 04:22:59 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Mon, 25 Nov 2019 12:22:59 +0000
Subject: [PROJ] How to construct proper cs2cs command line arguments
In-Reply-To: <20191125121524.GK22503@protected.rcdrun.com>
References: <20191125121524.GK22503@protected.rcdrun.com>
Message-ID: <c9005030594e46969318c0ef3b15febe@sdfe.dk>

Jean Louis,

Take a look at the documentation for cs2cs. I believe it should answer all your questions regarding cs2cs.
Here it is: https://proj.org/apps/cs2cs.html

/Kristian

-----Original Message-----
From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Jean Louis
Sent: 25. november 2019 13:15
To: proj at lists.osgeo.org
Subject: [PROJ] How to construct proper cs2cs command line arguments

Hello,

I have been using this: https://mygeodata.cloud/cs2cs/

and I used input:

+proj=longlat +datum=WGS84 +no_defs

or EPSG:4326

and output to be:

+proj=utm +zone=36 +ellps=clrk80 +towgs84=-160,-6,-302,0,0,0,0 +units=m +no_defs

or Arc 1960 / UTM zone 36N (EPSG:21096)

then with coordinates:

-1.122159, 29.714413

I could get 134183.400916;-123935.185151

which looks proper to me.

But how exactly do I construct the cs2cs command line?

Jean
_______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/proj

From even.rouault at spatialys.com  Mon Nov 25 04:46:37 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 25 Nov 2019 13:46:37 +0100
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids and
	GeoTIFF grids
Message-ID: <12415641.pOODJWFWK1@even-i700>

Hi,

As announced last week, you'll find a RFC describing two new capabilities,
remote access to grids and a GeoTIFF-based format for grids, in
https://github.com/OSGeo/PROJ/pull/1747

You can get an (almost correct) preview of it by going through
https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst
(some links will not work in this preview: expected given that this rendering doesn't go through Sphinx)

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From Matt.Wilkie at gov.yk.ca  Mon Nov 25 11:03:25 2019
From: Matt.Wilkie at gov.yk.ca (Matt.Wilkie at gov.yk.ca)
Date: Mon, 25 Nov 2019 19:03:25 +0000
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <69549AB1-5225-4693-AF09-3EE50F9E823A@archeotec.ca>
References: <69549AB1-5225-4693-AF09-3EE50F9E823A@archeotec.ca>
Message-ID: <8cbca59cf7a34ede90a778b41deca1d3@app-exch1.gov.yk.ca>

Hi Nicolas,

> You probably found this but I am posting anyways in case you did not
> http://www.naref.org/transf/nad83_hydroscan2006.pdf
> https://webapp.geod.nrcan.gc.ca/geod/tools-outils/ntv2.php?locale=en
> https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems-tools/tools-applications/10925#Epochs
> Look for Trx and NTv2 tools.

Yes I found those. It’s good that you posted them so now the list has a record for whomever chances on this thread next. It was Mike Craymer’s 2006 hydro scan presentation in particular that convinced me it’s necessary to account for the shift even up here north of 60.

NRCAN’s TRX tool will let me transform coordinates from one CSRS epoch to another but not from Original to CSRS. (It’s also only designed for point CSV-style records and can’t be used (efficiently) for bulk lines, polygons, etc.) I’m not familiar with the tool so there could be a way to use TRX and/or it’s data files/algorithms in a way that isn’t exposed in the GUI. Or I’m just using it wrong!

NTv2 tools can only operate with grid shift files, and since there are none here can’t do anything.

I have contacted Geodetic Survey of Canada and asked for advice; no word back yet.

Thanks for your help,

Matt
Geomatics Analyst | Environment | T 867-667-8133 | Yukon.ca

From: Nicolas Cadieux <nicolas.cadieux at archeotec.ca>
Sent: November 23, 2019 7:40 AM
To: Matt.Wilkie <Matt.Wilkie at gov.yk.ca>
Cc: proj at lists.osgeo.org
Subject: Re: [PROJ] WGS84/NAD83 Original to {current} transforms

﻿
﻿
Hi,
You probably found this but I am posting anyways in case you did not

http://www.naref.org/transf/nad83_hydroscan2006.pdf<https://imsva91-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=http%3a%2f%2fwww.naref.org%2ftransf%2fnad83%5fhydroscan2006.pdf&umid=F647DBDA-9805-5805-B5E8-D43BFBE0BEFB&auth=c132af8ee7c9d1278d61a701569070a095ce962e-2d7bd192d2f6e453799af10038f86f69fe2fa332>

https://webapp.geod.nrcan.gc.ca/geod/tools-outils/ntv2.php?locale=en

https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems-tools/tools-applications/10925#Epochs

Look for Trx and NTv2 tools.

Nicolas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191125/51e655af/attachment.html>

From matt.wilkie at gov.yk.ca  Mon Nov 25 11:12:25 2019
From: matt.wilkie at gov.yk.ca (mhw-at-yg)
Date: Mon, 25 Nov 2019 12:12:25 -0700 (MST)
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <1806956.uVZmG2kfRV@even-i700>
References: <1574462461793-0.post@n6.nabble.com> <6362384.HoVnLkAt2k@even-i700>
 <7c4f940a1f244ef9855c1eb5a7250117@app-exch1.gov.yk.ca>
 <62992551.7xUAaxFYcE@even-i700> <1806956.uVZmG2kfRV@even-i700>
Message-ID: <1574709145432-0.post@n6.nabble.com>

> I can't log on that ftp server. It times out.
> How are those datasets different from the ones on
> https://webapp.geod.nrcan.gc.ca/geod/data-donnees/transformations.php ,
> like the BC_93_05.GSB ?

I'm pretty sure the GSB files are identical. The ftp site has different
packaging, more than just the files.

>> Look for Trx and NTv2 tools.
>
> PROJ doesn't support yet the epoch transformation method that
> Trx / NAD83(CSRS) v7.0 velocity grid can do

Ahh, good to know. Thanks.

Matt



-----
-Matt
--
Sent from: http://osgeo-org.1560.x6.nabble.com/PROJ-4-f3840930.html

From brian.shaw at noaa.gov  Mon Nov 25 12:51:16 2019
From: brian.shaw at noaa.gov (Brian Shaw)
Date: Mon, 25 Nov 2019 15:51:16 -0500
Subject: [PROJ] Preferred grid format for transformations?
Message-ID: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>

Hi there

The National Geodetic Survey is considering changes to the grids we 
output for transformations, geoids and more and I was wondering if there 
are currently any preferred or ideal grid formats in the PROJ 
community?  I have been doing a little research as well as seen a few 
threads recently that mentioned GeoTiff, NetCDF and HDF5 but wanted to 
see if you guys had any preferences?

A few things that will be coming in 2022 include grids for 3D 
velocities, uncertainties for grids (geoids, transformations) and more 
so some of the things discussed like having multidimensional information 
at each node would be nice.

Thanks for your time
Brian

-- 
*************************************
Brian Shaw
Geodesist
NOAA/NOS/National Geodetic Survey
Phone # 240-533-9522


From even.rouault at spatialys.com  Mon Nov 25 13:09:17 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 25 Nov 2019 22:09:17 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
Message-ID: <1824479.mY7Kx9EFK2@even-i700>

Brian,

> The National Geodetic Survey is considering changes to the grids we
> output for transformations, geoids and more and I was wondering if there
> are currently any preferred or ideal grid formats in the PROJ
> community?  I have been doing a little research as well as seen a few
> threads recently that mentioned GeoTiff, NetCDF and HDF5 but wanted to
> see if you guys had any preferences?

This is indeed a "hot" topic. I've submitted today a Request for Comments
to the PROJ (and larger) community, whose one of the main topics is a discussion about
adopting a GeoTIFF format:
https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst#grids-in-geotiff-format

> A few things that will be coming in 2022 include grids for 3D
> velocities, uncertainties for grids (geoids, transformations) and more
> so some of the things discussed like having multidimensional information
> at each node would be nice.

I assume here that by "multidimensional" you mean storing several samples per grid node,
where the grid is still 2D indexed (referenced to a geographic longitude, latitude CRS
typically) ?
The above GeoTIFF proposal should be able to allow this.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ccrook at linz.govt.nz  Mon Nov 25 13:22:29 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Mon, 25 Nov 2019 21:22:29 +0000
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <1824479.mY7Kx9EFK2@even-i700>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <1824479.mY7Kx9EFK2@even-i700>
Message-ID: <A87E66F06E86F14B857F2EB047CDF9323144DC8D@prdassexch01.ad.linz.govt.nz>

Hi Brian

Also picking up on this  - for a while Land Information New Zealand (LINZ) has been looking for a suitable format for publishing our deformation model - essentially a 3d time dependent transformation model.  This includes both a secular velocity model as well as 3d deformation grids for significant earthquakes.

I am writing a  proposal for extending the GeoTIFF format to fully encode this transformation - I hope to submit this proposal as a document for comment to this list by the end of this week.  The functional model LINZ uses for deformation is relatively simple and generalised - what I am hoping is that the format will be useful beyond LINZ usage.  This proposal essentially adds some metadata to the GeoTIFF format that defines how the component grids are used to determine the point displacements at any time.

Cheers
Chris


> -----Original Message-----
> From: PROJ [mailto:proj-bounces at lists.osgeo.org] On Behalf Of Even
> Rouault
> Sent: Tuesday, 26 November 2019 10:10 a.m.
> To: proj at lists.osgeo.org
> Subject: Re: [PROJ] Preferred grid format for transformations?
>
> Brian,
>
> > The National Geodetic Survey is considering changes to the grids we
> > output for transformations, geoids and more and I was wondering if
> > there are currently any preferred or ideal grid formats in the PROJ
> > community?  I have been doing a little research as well as seen a few
> > threads recently that mentioned GeoTiff, NetCDF and HDF5 but wanted to
> > see if you guys had any preferences?
>
> This is indeed a "hot" topic. I've submitted today a Request for Comments to
> the PROJ (and larger) community, whose one of the main topics is a
> discussion about adopting a GeoTIFF format:
> https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs
> /source/community/rfc/rfc-4.rst#grids-in-geotiff-format
>
> > A few things that will be coming in 2022 include grids for 3D
> > velocities, uncertainties for grids (geoids, transformations) and more
> > so some of the things discussed like having multidimensional
> > information at each node would be nice.
>
> I assume here that by "multidimensional" you mean storing several samples
> per grid node, where the grid is still 2D indexed (referenced to a geographic
> longitude, latitude CRS
> typically) ?
> The above GeoTIFF proposal should be able to allow this.
>
> Even
>
> --
> Spatialys - Geospatial professional services http://www.spatialys.com
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From martin.desruisseaux at geomatys.com  Mon Nov 25 13:46:46 2019
From: martin.desruisseaux at geomatys.com (Martin Desruisseaux)
Date: Mon, 25 Nov 2019 22:46:46 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <1824479.mY7Kx9EFK2@even-i700>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <1824479.mY7Kx9EFK2@even-i700>
Message-ID: <ba09e206-548b-4e99-a02b-5bac6e9b7324@geomatys.com>

Le 25/11/2019 à 22:09, Even Rouault a écrit :

>> A few things that will be coming in 2022 include grids for 3D
>> velocities, uncertainties for grids (geoids, transformations) and more
>> so some of the things discussed like having multidimensional information
>> at each node would be nice.
> I assume here that by "multidimensional" you mean storing several samples per grid node,
> where the grid is still 2D indexed (referenced to a geographic longitude, latitude CRS
> typically) ? The above GeoTIFF proposal should be able to allow this.

I do not have an answer about the 2022 grids, but even if they are 2D 
indexed, a future grid could be 3D for example with time as the third 
dimension (e.g. a same file could contain many grids at different 
epochs). The NetCDF format may be more future proof in this regard.

GeoTIFF has better established tags for defining the CRS, but in the 
case of datum shift grid we are defining a transformation between 2 CRS. 
Some extension may be needed for defining the second CRS (or at least 
its datum). I do not know if anyone is free to invent new GeoTIFF tags, 
or if a coordination is needed with some standard (e.g. for avoiding 
keys collision). By comparison defining new NetCDF attributes is 
relatively "natural" in that format.

While GeoTIFF has better defined conventions regarding CRS definition, 
NetCDF has better defined conventions regarding uncertainties definition 
and other scientific information (e.g. units of measurements, standard 
names for a wide range of physical phenomenons, etc).

Regarding the binary format complexity, it is possible to leave some 
choice to data producers. NetCDF 3 is simpler than GeoTIFF while NetCDF 
4 is more complex (I think). But a convention for storing datum shift 
grids in a NetCDF file does not need to choose between NetCDF 3 or 4; 
the same convention can work for both. A NetCDF 3 file would not support 
tiles, compression and sub-grids, but that may be sufficient for small 
grids. A data producer could use the NetCDF 4 format only for larger 
grids. For a user of UCAR NetCDF library it should be transparent (at 
least in Java; I presume it is the case in C/C++ too). PROJ could have a 
very lightweight NetCDF 3 reader embedded with just enough capabilities 
for those datum shift grids (so it would not even require a libtiff 
dependency), and requires the real NetCDF library only for more complex 
grids.

     Martin



From even.rouault at spatialys.com  Mon Nov 25 14:04:46 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 25 Nov 2019 23:04:46 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <ba09e206-548b-4e99-a02b-5bac6e9b7324@geomatys.com>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <1824479.mY7Kx9EFK2@even-i700>
 <ba09e206-548b-4e99-a02b-5bac6e9b7324@geomatys.com>
Message-ID: <4003170.UCBvYNt6YA@even-i700>

Martin,

> I do not have an answer about the 2022 grids, but even if they are 2D
> indexed, a future grid could be 3D for example with time as the third
> dimension (e.g. a same file could contain many grids at different
> epochs). The NetCDF format may be more future proof in this regard.

RFC 4 indeed discusses the pros & cons of a few formats: netCDF v3, netCDF 4 / 
HDF5, GeoTIFF, GeoPackage.

> GeoTIFF has better established tags for defining the CRS, but in the
> case of datum shift grid we are defining a transformation between 2 CRS.
> Some extension may be needed for defining the second CRS (or at least
> its datum). I do not know if anyone is free to invent new GeoTIFF tags,
> or if a coordination is needed with some standard (e.g. for avoiding
> keys collision). By comparison defining new NetCDF attributes is
> relatively "natural" in that format.

RFC 4 goes into the details how I envision dealing with 2 CRS (actually 3). 
Basically. Adding new TIFF tags is complicated. My proposal is to feed the 
extra metadata information we need in the already well established 
GDAL_METADATA tag that contains a XML payload with arbitrary KEY=VALUE pairs 
(with a few refinements explained in the RFC)

> 
> While GeoTIFF has better defined conventions regarding CRS definition,
> NetCDF has better defined conventions regarding uncertainties definition
> and other scientific information (e.g. units of measurements, standard
> names for a wide range of physical phenomenons, etc).
> 
> Regarding the binary format complexity, it is possible to leave some
> choice to data producers. NetCDF 3 is simpler than GeoTIFF while NetCDF
> 4 is more complex (I think). But a convention for storing datum shift
> grids in a NetCDF file does not need to choose between NetCDF 3 or 4;
> the same convention can work for both. A NetCDF 3 file would not support
> tiles, compression and sub-grids, but that may be sufficient for small
> grids. A data producer could use the NetCDF 4 format only for larger
> grids. For a user of UCAR NetCDF library it should be transparent (at
> least in Java; I presume it is the case in C/C++ too). PROJ could have a
> very lightweight NetCDF 3 reader embedded with just enough capabilities
> for those datum shift grids (so it would not even require a libtiff
> dependency), and requires the real NetCDF library only for more complex
> grids.

I initially considered having a "hand-written" TIFF/GeoTIFF reader (that is 
without libtiff dependency), with a very strict subset of TIFF supports, but 
my feeling was that people would want the "full thing" with all the bells and 
whistles supported by GeoTIFF, and they wouldn't understand why this ".tif" 
file works, and not that other one. With netCDF that would be the same, a 
".nc" being netCDF 3 would work with a hand written netCDF v3 reader, but 
suddenly people would want to ue another ".nc" that happens to be netCDF v4/
HDF5 and that wouldn't work.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From martin.desruisseaux at geomatys.com  Mon Nov 25 14:16:14 2019
From: martin.desruisseaux at geomatys.com (Martin Desruisseaux)
Date: Mon, 25 Nov 2019 23:16:14 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <4003170.UCBvYNt6YA@even-i700>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <1824479.mY7Kx9EFK2@even-i700>
 <ba09e206-548b-4e99-a02b-5bac6e9b7324@geomatys.com>
 <4003170.UCBvYNt6YA@even-i700>
Message-ID: <32507219-394a-2e08-1c2b-c9b27b8b497d@geomatys.com>

Le 25/11/2019 à 23:04, Even Rouault a écrit :

> (...snip...), a ".nc" being netCDF 3 would work with a hand written 
> netCDF v3 reader, but suddenly people would want to use another ".nc" 
> that happens to be netCDF v4/ HDF5 and that wouldn't work.
>
But could this problem be mitigated by an explicit error message of the 
kind "The use of this datum shift grid file require PROJ to be compiled 
with option +NetCDF4"? (the NetCDF version can be identified by magic 
numbers).

     Martin



From ccrook at linz.govt.nz  Mon Nov 25 14:41:07 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Mon, 25 Nov 2019 22:41:07 +0000
Subject: [PROJ] Management of datum grid files.
Message-ID: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>

Hi All



I am looking at installing 16 grids for New Zealand vertical datums into proj-datumgrid, and it has raised some questions on the structure and maintenance of this in the future.



Given the current level of interest in grids, and the increasing importance and acquistion of geoid grids, plus (hopefully) extension to include deformation models comprising multiple grids, I am thinking that the number of grids in use may start to grow rapidly.



Following the current convention I would install my grids into proj-datumgrid-oceania, which currently holds a number of grids of relating to Australian datums.  I doubt that many Australian users will be interested in the NZ grids, and vice versa.  (Particularly of course as we do not share a land boundary).



Also for the most part (as far as  I can see) there is not particular packaging around the datumgrid products (other than conda).  So for the most part users will need to download the zip file from the URL on the PROJ pages, and install manually.



So I am wondering if this is a sensible approach.



Initially I thought I wondered about create a directory in proj-datumgrid for NZ grids and a  new product proj-datumgrid-nz.   But since LINZ (NZ geodetic agency) will be publishing these in any case, would it make more sense for LINZ to maintain and host the proj-datumgrid-nz product, and for that simply to be referenced in proj documentation?



The current initiative to deliver grids via a CDN (https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst) will simplify this, but  the current proposal doesn't replace proj-datumgrid so I think this will be an issue for a bit longer.



To make this work well it would be useful to have a command line tool for installing grids that is installed with PROJ.  Say (sudo) install_proj_datumgrid <region>.   This could have a configuration file which defines the URL of the authoritative source for each region so that "install_proj_datumgrid nz" would download and install a file from (say) www.geodesy.linz.govt.nz/download/proj-datumgrid/proj-datumgrid-nz.zip<http://www.geodesy.linz.govt.nz/download/proj-datumgrid/proj-datumgrid-nz.zip>.  This could work well with the existing products too, eg install_proj_datumgrid oceania.   (This could be a trivial shell script for linux - sure for other OS targets)



With this approach the only thing LINZ would need to maintain within the PROJ infrastructure would be the url of the proj-datumgrid-nz zip file.



Comments?



Cheers

Chris Crook

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191125/285da176/attachment-0001.html>

From even.rouault at spatialys.com  Mon Nov 25 14:44:58 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Mon, 25 Nov 2019 23:44:58 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <32507219-394a-2e08-1c2b-c9b27b8b497d@geomatys.com>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <4003170.UCBvYNt6YA@even-i700>
 <32507219-394a-2e08-1c2b-c9b27b8b497d@geomatys.com>
Message-ID: <9014949.cze0rWdGFn@even-i700>

On lundi 25 novembre 2019 23:16:14 CET Martin Desruisseaux wrote:
> Le 25/11/2019 à 23:04, Even Rouault a écrit :
> > (...snip...), a ".nc" being netCDF 3 would work with a hand written
> > netCDF v3 reader, but suddenly people would want to use another ".nc"
> > that happens to be netCDF v4/ HDF5 and that wouldn't work.
> 
> But could this problem be mitigated by an explicit error message of the
> kind "The use of this datum shift grid file require PROJ to be compiled
> with option +NetCDF4"? (the NetCDF version can be identified by magic
> numbers).

That would be indeed an obvious thing to do, but users would still be stuck. 
Anyway, a hand-written reader would probably useless, as I would expect most 
binary packagers to consider building against the netcdf library if PROJ could 
be built against it.

However, let me try to summarize the major cons of a netCDF approach for the 
prespective of PROJ that I can anticipate:

- the C netCDF API, be it v3 or v4, does not have a pluggable I/O layer in 
which we could put our own I/O layer, so it cannot be used to access remote 
grids. The libhdf5 API has such a layer (used by GDAL for example). So that 
would restrict to netCDF v4/HDF5 only files using libhdf5. Or netCDF v3 would 
have to be addressed by a hand-written reader. Not an exciting perspective

- libnetcdf and/or libhdf5 are unsecurity tested, at least as far as I know. 
Personal past experience revealed that this is not just a theoretical problem 
and crashes or worse happen on corrupted/hostile files. Upstream didn't really 
seem interested in adressing them at the time I tried to bring that to their 
attention (which I can understand. Being one of the libtiff co-maintainers, 
this is a unsexy and sometimes challenging job). This is a serious problem 
given than we plan to access grids stored on HTTP. Even if in the default 
configuration, we should control what is accessed too, I don't think it would 
be a great service to put our users to a potential risk.

- HDF5 is indeed much more powerful than GeoTIFF. We would have to restrict 
even more severely a profile than I proposed to do with GeoTIFF to avoid 
having to deal with crazy formulations. Actually with my hat of GDAL developer 
on, this very flexibility of HDF5 is a serious problem because data producers 
tend to follow their own personal inspiration of how to structure the data, 
and in particular interoperability of geoferencing encodings is close to null. 
Try to open a random gridded .hdf5 file with gdalinfo, and in most cases, 
you'll get no SRS or geotransformation matrix.

- the cloud-friendliness of HDF5 is unknown to me. On the contrary, I know 
that COG is a technology used heavily.


For 3D (time,long,lat) indexing, I'd assume the number of values along the 
time axis not to be too large (that would be great to have some feedback for 
Brian, Chris or other potential data producers on that). In that case, one 
TIFF IFD per time slice should be able to address that.


Even


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Mon Nov 25 15:20:43 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 00:20:43 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
Message-ID: <3620026.VIMQX10h4f@even-i700>

Chris,

Interesting points !

>  doubt that many Australian users will be interested in the NZ grids, and 
vice versa.  (Particularly of course as we do not share a land boundary).

We had to try to find some classification, to have a reasonable number of 
packages of a reasonable size. This is not perfect. For example for French 
grids, they are stored in -europe even for the oversea territories in North 
America, Carribeans, Indian ocean...

> So for the
> most part users will need to download the zip file from the URL on the PROJ
> pages, and install manually.

Yes, the "advanced" PROJ API or the projinfo utility also gives a hint 
currently, like
"Grid GDA94_GDA2020_conformal.gsb needed but not found on the system. Can be 
obtained from the proj-datumgrid-oceania package at https://
download.osgeo.org/proj/proj-datumgrid-oceania-latest.zip"
 
> Initially I thought I wondered about create a directory in proj-datumgrid
> for NZ grids and a  new product proj-datumgrid-nz. 

I think our current release manager would probably object that having to 
handle more packages will be overhead for him (as we need to keep track of 
their versionning). We would certainly add a "africa", "south-america" and 
"asia" subpackages if we have datasets for them, but having to create separate 
packages for each agency would be a larger maintainance and distribution 
burden.

> But since LINZ (NZ
> geodetic agency) will be publishing these in any case, would it make more
> sense for LINZ to maintain and host the proj-datumgrid-nz product, and for
> that simply to be referenced in proj documentation?

Several points:
- I suppose that depends on the PROJ community trusts the data producer (I'm 
talking in general here. Nothing specific about LINZ !) to maintain its 
content, and at a stable location. One concern I have is with superseded 
grids. There are some agencies that tend to hide old grids when they release a 
new one. Which can be problematic for reproducibility, or even if you just use 
an old version of PROJ whose database hasn't been updated to point at the new 
grid. By having the grids "physically" in the git repo of proj-datumgrid we as 
as project can decide about their fate.
- Up to now data producers tended to deliver their datasets in "random" 
formats and we had to do a conversion to something PROJ could ingest.
- We need to be really sure about the filename of the grid. What EPSG mentions 
in its database and what data producers actually deliver tend to be different, 
so we have a database table to do that mapping. Even slight changes like 
foo.gsb becoming FOO.GSB could break PROJ good working.
- By having the grids stored in proj-datumgrid, we can also check their 
licensing situation before inclusion.

> The current initiative to deliver grids via a CDN
> (https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/sou
> rce/community/rfc/rfc-4.rst) will simplify this, but  the current proposal
> doesn't replace proj-datumgrid so I think this will be an issue for a bit
> longer.

Yes, in my mind, proj-datumgrid will remain the "master", and we will have a  
script that will resync its content onto the cloud storage we will have access 
to.

> To make this work well it would be useful to have a command line tool for
> installing grids that is installed with PROJ.  Say (sudo)
> install_proj_datumgrid <region>.   This could have a configuration file
> which defines the URL of the authoritative source for each region so that
> "install_proj_datumgrid nz" would download and install a file from (say)
> www.geodesy.linz.govt.nz/download/proj-datumgrid/proj-datumgrid-nz.zip<http
> ://www.geodesy.linz.govt.nz/download/proj-datumgrid/proj-datumgrid-nz.zip>. 
> This could work well with the existing products too, eg
> install_proj_datumgrid oceania.   (This could be a trivial shell script for
> linux - sure for other OS targets)

A python script then :-) It would probably also need the path to the data 
(PROJ_LIB) directory, as this can vary between binary distributions. Or we 
could also have a --user flag (like pip install --user) that would install 
them in the ${XDG_DATA_HOME}/proj directory mentionned in RFC4 to hold the 
network cache, and the default search path of PROJ would also look into that.

All this discussion shows that for use cases where people will be able and 
willing to rely on network access, just telling PROJ "go and fetch the grids 
wherever they are stored" should be a huge usability improvement.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nicolas.cadieux at archeotec.ca  Mon Nov 25 16:15:56 2019
From: nicolas.cadieux at archeotec.ca (Nicolas Cadieux)
Date: Mon, 25 Nov 2019 19:15:56 -0500
Subject: [PROJ] WGS84/NAD83 Original to {current} transforms
In-Reply-To: <8cbca59cf7a34ede90a778b41deca1d3@app-exch1.gov.yk.ca>
References: <8cbca59cf7a34ede90a778b41deca1d3@app-exch1.gov.yk.ca>
Message-ID: <969F324B-5032-4D78-ABA1-05DE25FBD7D4@archeotec.ca>

Hi,

If Trx can do it, then one could write a script to transform the lines or polygone in vertices, and feed that to TRX than reform the polygons after.  This can be done in python using the Wkt format I guess.

Nicolas

> Le 25 nov. 2019 à 14:03, Matt.Wilkie at gov.yk.ca a écrit :
> 
> ﻿
> Hi Nicolas,
>  
> > You probably found this but I am posting anyways in case you did not
> > https://smex-ctp.trendmicro.com:443/wis/clicktime/v1/query?url=http%3a%2f%2fwww.naref.org%2ftransf%2fnad83%5fhydroscan2006.pdf&umid=40305a49-61bb-42d7-951b-bbc5c5904520&auth=bd2babbd5e69184293a183dfbc57b0bdaf82945c-1dcf80ab7e74bf790c09a0deebf87886af363e36
> > https://webapp.geod.nrcan.gc.ca/geod/tools-outils/ntv2.php?locale=en
> > https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems-tools/tools-applications/10925#Epochs
> > Look for Trx and NTv2 tools.
>  
> Yes I found those. It’s good that you posted them so now the list has a record for whomever chances on this thread next. It was Mike Craymer’s 2006 hydro scan presentation in particular that convinced me it’s necessary to account for the shift even up here north of 60.
>  
> NRCAN’s TRX tool will let me transform coordinates from one CSRS epoch to another but not from Original to CSRS. (It’s also only designed for point CSV-style records and can’t be used (efficiently) for bulk lines, polygons, etc.) I’m not familiar with the tool so there could be a way to use TRX and/or it’s data files/algorithms in a way that isn’t exposed in the GUI. Or I’m just using it wrong!
>  
> NTv2 tools can only operate with grid shift files, and since there are none here can’t do anything.
>  
> I have contacted Geodetic Survey of Canada and asked for advice; no word back yet.
>  
> Thanks for your help,
>  
> Matt
> Geomatics Analyst | Environment | T 867-667-8133 | Yukon.ca
>  
> From: Nicolas Cadieux <nicolas.cadieux at archeotec.ca> 
> Sent: November 23, 2019 7:40 AM
> To: Matt.Wilkie <Matt.Wilkie at gov.yk.ca>
> Cc: proj at lists.osgeo.org
> Subject: Re: [PROJ] WGS84/NAD83 Original to {current} transforms
>  
> ﻿
> ﻿
> Hi,
> You probably found this but I am posting anyways in case you did not
>  
> http://www.naref.org/transf/nad83_hydroscan2006.pdf
>  
> https://webapp.geod.nrcan.gc.ca/geod/tools-outils/ntv2.php?locale=en
>  
> https://www.nrcan.gc.ca/maps-tools-and-publications/tools/geodetic-reference-systems-tools/tools-applications/10925#Epochs
>  
> Look for Trx and NTv2 tools.
>  
> Nicolas
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191125/dbe7633d/attachment.html>

From nyall.dawson at gmail.com  Mon Nov 25 16:26:55 2019
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Tue, 26 Nov 2019 10:26:55 +1000
Subject: [PROJ] "Trustworthiness" of vertical transformations
Message-ID: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>

Hi list,

I've seen a lot of activity on the PROJ repo lately relating to
vertical datum transformations. Coming from zero knowledge about the
world of vertical transformations... if I setup a simple
transformation between two proj CRS objects created using auth/id
codes, and transform a 3d point using proj_trans_generic... how
"trustworthy" is the resultant z value?

I've seen some examples (e.g in
https://github.com/OSGeo/PROJ/issues/1743) which use a
"EPSG:26911+5703" type construct, which leads me to believe that the
world of vertical transformations is not so straightforward! Any tips
to give a newbie entering this world to avoid the inevitable pitfalls
which await?

Cheers,
Nyall

From kristianevers at gmail.com  Tue Nov 26 00:26:31 2019
From: kristianevers at gmail.com (Kristian Evers)
Date: Tue, 26 Nov 2019 09:26:31 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <9014949.cze0rWdGFn@even-i700>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <4003170.UCBvYNt6YA@even-i700>
 <32507219-394a-2e08-1c2b-c9b27b8b497d@geomatys.com>
 <9014949.cze0rWdGFn@even-i700>
Message-ID: <7B39DFFE-5285-45CC-AD1B-0661870A42B0@gmail.com>

> 
> For 3D (time,long,lat) indexing, I'd assume the number of values along the 
> time axis not to be too large (that would be great to have some feedback for 
> Brian, Chris or other potential data producers on that). In that case, one 
> TIFF IFD per time slice should be able to address that.
> 

An interesting case here is transformations between ITRFyyyy and the Greenlandic
GR96 reference frame. Due to the mostly melting nature of the ice sheet Greenland
is subject to large amount of elastic deformation. This deformation is not predictable
from year to year, so in one year you may see deformation in the up component of
+5 cm and the next year it may be -1 cm. To capture this fully we need a time-varying
deformation model. Currently we are producing a set of deformation grids (x, y and z
components) per year since 1996. Returning to the question above, that gives us
23 values (and rising) on the time axis. Whether that is too large or not I don’t know.

/Kristian

From martin.desruisseaux at geomatys.com  Tue Nov 26 01:08:48 2019
From: martin.desruisseaux at geomatys.com (Martin Desruisseaux)
Date: Tue, 26 Nov 2019 10:08:48 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <9014949.cze0rWdGFn@even-i700>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <4003170.UCBvYNt6YA@even-i700>
 <32507219-394a-2e08-1c2b-c9b27b8b497d@geomatys.com>
 <9014949.cze0rWdGFn@even-i700>
Message-ID: <2d847d87-fb64-a348-be46-c7667a0a7390@geomatys.com>

I will not insist for NetCDF, but just want to bring some clarifications:

Le 25/11/2019 à 23:44, Even Rouault a écrit :

> - HDF5 is indeed much more powerful than GeoTIFF. We would have to 
> restrict even more severely a profile than I proposed to do with 
> GeoTIFF to avoid having to deal with crazy formulations. Actually with 
> my hat of GDAL developer on, this very flexibility of HDF5 is a 
> serious problem because data producers tend to follow their own 
> personal inspiration of how to structure the data, and in particular 
> interoperability of geoferencing encodings is close to null.
>
HDF5 is only a binary container. How data are organized inside that 
container is defined outside HDF5. In our case, they are defined by 
CF-Conventions. This is the same separation than XML versus schemas: we 
can see HDF5 as a kind of binary XML + arrays, and CF-Conventions as a 
XML schema for NetCDF/HDF. The CF-Convention addresses the 
georeferencing encoding in various ways. One way standardized by 
CF-Conventions is to use WKT [1].


> the cloud-friendliness of HDF5 is unknown to me. On the contrary, I 
> know that COG is a technology used heavily.
>
I did not benchmarked HDF5 myself, but I attended a talk in an Apache 
Conference 2 or 3 years ago were such benchmarking in the cloud had been 
done for various formats (I do not remember if TIFF was among them 
however). HDF5 performances on the cloud were reported good except for 
arrays of character strings (a problem of data chunk size not matching 
the size of data block transferred on network).

Note that HDF5 is in active development (I see 9 commits yesterday, 82 
commits this month), is governed by a Technical Advisory Board since 
2018 [2] and has a massive community-built software ecosystem according 
their web site [3]. HDF was initiated by the National Center for 
Supercomputing Applications (NCSA) and is used heavily too (e.g. at 
NASA). It is the de facto standard in the scientific and research community.

But as said before I do not insist if the preference is still for 
GeoTIFF in PROJ. I just wanted to reply to some of the arguments that 
were advanced in this thread.

     Regards

         Martin

[1] http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html#use-of-the-crs-well-known-text-format
[2] https://confluence.hdfgroup.org/display/HDF5TAB
[3] https://www.hdfgroup.org/community/

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191126/fef8d319/attachment.html>

From kreve at sdfe.dk  Tue Nov 26 02:52:07 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Tue, 26 Nov 2019 10:52:07 +0000
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
Message-ID: <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>

Nyall,

You are indeed correct in assuming that the world of vertical
transformations isn't always straight forward. I think the best
tip I can give you is to consult the accuracy of the transformation
as reported by PROJ. In the example Even has used in the issue
that you link to it is 0.35 m. In other cases it will be "unknown accuracy"
if there is not enough information available about a given transformation.
Ultimately the accuracies are reported by the local geodetic authorities
so in general I would just trust those.

You can get the transformation accuracy using the API function
proj_coordoperation_get_accuracy(). I think it would be cool if 
information about transformation accuracy where readily available in
software like QGIS (nudge, nudge :-))

/Kristian

-----Original Message-----
From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Nyall Dawson
Sent: 26. november 2019 01:27
To: PROJ <proj at lists.osgeo.org>
Subject: [PROJ] "Trustworthiness" of vertical transformations

Hi list,

I've seen a lot of activity on the PROJ repo lately relating to
vertical datum transformations. Coming from zero knowledge about the
world of vertical transformations... if I setup a simple
transformation between two proj CRS objects created using auth/id
codes, and transform a 3d point using proj_trans_generic... how
"trustworthy" is the resultant z value?

I've seen some examples (e.g in
https://github.com/OSGeo/PROJ/issues/1743) which use a
"EPSG:26911+5703" type construct, which leads me to believe that the
world of vertical transformations is not so straightforward! Any tips
to give a newbie entering this world to avoid the inevitable pitfalls
which await?

Cheers,
Nyall
_______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/proj

From even.rouault at spatialys.com  Tue Nov 26 04:17:51 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 13:17:51 +0100
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
Message-ID: <8621843.BXbLCLqfYF@even-i700>

Nyall,

> I've seen a lot of activity on the PROJ repo lately relating to
> vertical datum transformations. Coming from zero knowledge about the
> world of vertical transformations... if I setup a simple
> transformation between two proj CRS objects created using auth/id
> codes, and transform a 3d point using proj_trans_generic... how
> "trustworthy" is the resultant z value?

If those are just projected CRS or geographic 2D CRS, the resultant z value 
will be unchanged. To have some "hope" that you get a change in z value, you 
must work with either a CompoundCRS or a Geographic 3D CRS.

> 
> I've seen some examples (e.g in
> https://github.com/OSGeo/PROJ/issues/1743) which use a
> "EPSG:26911+5703" type construct, 

This is a special syntax inherited from GDAL to build a compound CRS from a 
horizontal CRS (geographic or vertical) + a vertical CRS.
Otherwise the EPSG dataset includes a few coded compound CRS: 	
https://github.com/OSGeo/PROJ/blob/master/data/sql/compound_crs.sql
So you can use EPSG:3901 to get "KKJ / Finland Uniform Coordinate System + N60 
height" directly, instead of EPSG:2393+5717
There's also a more official one coming from a OGC white paper, that you can 
see on https://proj.org/apps/projinfo.html :
urn:ogc:def:crs,crs:EPSG::2393,crs:EPSG::5717

> which leads me to believe that the
> world of vertical transformations is not so straightforward!

Indeed it is not. It is what has required the most tunings the last weeks/
months in PROJ. Computing those transformations is also expensive timewise 
speaking, because there are both horizontal and vertical transformations to 
consider (and as described in https://github.com/OSGeo/PROJ/issues/1743 , if 
there's no registered transformation between the vertical CRS and the source 
or target geographic 3D CRS, then PROJ researches all the vertical CRS to 
whatever_geographic_3D_CRS is registered, and then computes the horizontal 
transformation between those whatever_geographic_3D_CRS and the source and 
target CRS (*)). Timings of several hundred of milliseconds in 
createOperations() are not uncommon, so you need to make sure to keep the 
result cached. Execution of pipelines (coordinate reprojection) then runs as 
decently as possible.

I've especially worked on improving the results of CompoundCRS <--> Geographic 
3D CRS transformations. I'm pretty sure CompoundCRS <--> CompoundCRS would 
also require some additional love.

One of the practical difficulties is that if you work with 'exotic' vertical 
CRS, there will be no registered transformation between them and a (the) 
Geographic 3D CRS, so you'll get a no change in the Z value.

Even

(*) I've a document in the works describing most of the logic behind 
createOperations(), but it takes a loooong time to write, as everytime I try 
to find an example to illustrate my theory, I find something to improve in the 
code :-)

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Tue Nov 26 04:19:57 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 13:19:57 +0100
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <7B39DFFE-5285-45CC-AD1B-0661870A42B0@gmail.com>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <9014949.cze0rWdGFn@even-i700>
 <7B39DFFE-5285-45CC-AD1B-0661870A42B0@gmail.com>
Message-ID: <1656925.fX9CAOFAZg@even-i700>

> Returning to the question above, that
> gives us 23 values (and rising) on the time axis. Whether that is too large
> or not I don’t know.

Yes that would be manageable. libtiff would have issues with more than 65536 
IFDs in a file, but the efficiency limit is probably lower.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From kreve at sdfe.dk  Tue Nov 26 04:39:37 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Tue, 26 Nov 2019 12:39:37 +0000
Subject: [PROJ] Preferred grid format for transformations?
In-Reply-To: <1656925.fX9CAOFAZg@even-i700>
References: <7cc1ee98-a347-2d61-d69a-aa2151a133e8@noaa.gov>
 <9014949.cze0rWdGFn@even-i700>
 <7B39DFFE-5285-45CC-AD1B-0661870A42B0@gmail.com>
 <1656925.fX9CAOFAZg@even-i700>
Message-ID: <364f517658394b1a86c0321979ff385a@sdfe.dk>

At least we can expand the model for a few centuries without hitting that limit :-)

Actually we see that deformation differ on a month to month basis so worst case
we would need 23 * 12 == 276 grids. I would never release a model like that as the
official transformation but it might be useful in research applications. So I think it
would be wise to be somewhat flexible here and not put a cap on the number of
sub-grids (or what we should call them?) in a model. Apart from the tiff limitation
of course.

/Kristian

-----Original Message-----
From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Even Rouault
Sent: 26. november 2019 13:20
To: Kristian Evers <kristianevers at gmail.com>
Cc: proj at lists.osgeo.org
Subject: Re: [PROJ] Preferred grid format for transformations?

> Returning to the question above, that
> gives us 23 values (and rising) on the time axis. Whether that is too large
> or not I don’t know.

Yes that would be manageable. libtiff would have issues with more than 65536 
IFDs in a file, but the efficiency limit is probably lower.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com
_______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/proj

From andrew.bell.ia at gmail.com  Tue Nov 26 05:54:22 2019
From: andrew.bell.ia at gmail.com (Andrew Bell)
Date: Tue, 26 Nov 2019 08:54:22 -0500
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
 and GeoTIFF grids
In-Reply-To: <12415641.pOODJWFWK1@even-i700>
References: <12415641.pOODJWFWK1@even-i700>
Message-ID: <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>

I wouldn't be true to form if I didn't express some skepticism in the value
of this change.

I don't quite understand the environment in which one would care about
700MB of data.  We live in an age where it's difficult to purchase a
storage device as small as 500GB, so minimizing an installation footprint
to avoid 700MB of data strikes me as a bit silly, especially when PROJ has
recently added a requirement for sqlite3.  If the issue is one of
packaging, it seems that there are other alternatives to a "fancy" solution
like this.  Could not the PROJ installation simply download the files from
some known source?  I'm sure there are other options as well.  Dynamic
fetching of data seems natural these days, but it's non-trivial.  Failures
can occur at many levels and these either need handling in the source code
or errors may be transferred to users who may well scratch their heads
about what's *not* working properly.  Personally, I'd much rather have a
failure/problem at installation-time than a run-time failure.  PROJ is, in
my mind, a core library for many users.  It should be as robust as
possible.  To meet that goal requires careful code.  Extra features require
more code, which requires more maintenance, review and necessarily
increases the likelihood of bugs.  Current maintainers may have time and
expertise to add this enhancement, but it's not clear to me that it's in
the long-term best interest of the basic functionality of the library.

On Mon, Nov 25, 2019 at 7:46 AM Even Rouault <even.rouault at spatialys.com>
wrote:

> Hi,
>
> As announced last week, you'll find a RFC describing two new capabilities,
> remote access to grids and a GeoTIFF-based format for grids, in
> https://github.com/OSGeo/PROJ/pull/1747
>
> You can get an (almost correct) preview of it by going through
>
> https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst
> (some links will not work in this preview: expected given that this
> rendering doesn't go through Sphinx)
>
> Even
>
> --
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj
>


-- 
Andrew Bell
andrew.bell.ia at gmail.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191126/0ed447b6/attachment.html>

From even.rouault at spatialys.com  Tue Nov 26 07:40:24 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 16:40:24 +0100
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
	and GeoTIFF grids
In-Reply-To: <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
Message-ID: <2636809.SJeecnA3Xp@even-i700>

Andrew,

> I don't quite understand the environment in which one would care about
> 700MB of data.  We live in an age where it's difficult to purchase a
> storage device as small as 500GB, so minimizing an installation footprint
> to avoid 700MB of data strikes me as a bit silly, especially when PROJ has
> recently added a requirement for sqlite3.  If the issue is one of
> packaging, it seems that there are other alternatives to a "fancy" solution
> like this.  Could not the PROJ installation simply download the files from
> some known source?  I'm sure there are other options as well.

The motivation part of the RFC addresses this. Not sure I have more to add. 
Server-less computing is probably the use case for which this new 
functionality will shine most. For a short term process, you probably don't 
want to start by downloading hundreds of megabytes of grids to reproject a 
handful of points whereas in practice you just needed 4 points in a grid.

I've just had a chat with Jürgen Fischer who has the burden to package QGIS. 
It appears that the Win32 QGIS standalone installer only bundles the main 
proj-datumgrid package, the proj-datumgrid-oceania package and one German 
grid. So no -europe, -north-america or -world. They are concerned by file 
size, because of a 2GB NSIS limit. So while in theory we live in an era of big 
unlimited data, we can still be stuck by old limitations :-)

> Dynamic
> fetching of data seems natural these days, but it's non-trivial.  Failures
> can occur at many levels and these either need handling in the source code
> or errors may be transferred to users who may well scratch their heads
> about what's *not* working properly. 

Some retry strategy in case of temporary network/server failure will probably 
be needed. There is that in GDAL /vsicurl/

> Personally, I'd much rather have a
> failure/problem at installation-time than a run-time failure. 

The option to use "static" grids will remain. The use case with no network 
connectivity is a valid one.

> PROJ is, in
> my mind, a core library for many users.  It should be as robust as
> possible.  To meet that goal requires careful code.  Extra features require
> more code, which requires more maintenance, review and necessarily
> increases the likelihood of bugs.  Current maintainers may have time and
> expertise to add this enhancement, but it's not clear to me that it's in
> the long-term best interest of the basic functionality of the library.

That's very true !
1) if the feature is useless, and its maintainance becomes a problem, it can 
be decided to rip it off. See the proposal for removal of this obscure 
+catalog in the RFC.
2) if the feature is useful and not working properly, people will complain at 
first it is no longer working. But if they are really dependent on it, they 
will end up help maintaining it. If they don't, go back to 1.

PROJ has ~ 150 projection methods. Probably 10% only of them are used for 99% 
of the use cases. I'm pretty sure most of us (well, speaking about me at 
least) have no idea how to fix potential bugs in the exotic 90% ones. If 
people care about them, they'll read the papers, scratch their heads heavily 
and propose a PR.

PROJ was at the origin 100% about projection methods. Now the projection code 
is only one third of the total code base. So focus moves with time. No idea 
what it will be in 10 years.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jmckenna at gatewaygeomatics.com  Tue Nov 26 07:49:16 2019
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Tue, 26 Nov 2019 11:49:16 -0400
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
 and GeoTIFF grids
In-Reply-To: <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
Message-ID: <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>

I do like that it will still default to using local grid files, unless 
the environment variable is set (PROJ_NETWORK=ON).

I would like this RFC to include effort to improve the documentation on 
which grids should be installed (it is very confusing how 
'proj-datumgrid-latest' differs from world, europe, oceania, 
northamerica, I always assume, like many others I bet, that -latest 
includes europe+oceania+northamerica+world).  As a packager for Windows 
users for MS4W, I struggle to verify if I have installed all of the 
proper grids.  I do notice that in March 2018 I "added all datumgrid 
files" for MS4W users (which increased the download size of course, 
which honestly is worth it because most users have no idea that these 
grid files exist and their importance).

Which brings me to the most important point that I believe is missing in 
the RFC, of notifying the user when a grid file is not leveraged. 
Currently there is no warning, no notice, when a grid is not installed. 
I side with Andrew Bell on his point that during installation I'd like 
to see more messages, notices, or something to install all grid files. 
Could there be a build option of "TEST_ALL_DATUMGRID_FILES" during PROJ 
compilation?

I thank Even, Howard, Kristian, all, for pushing PROJ forward.

-jeff



-- 
Jeff McKenna
MapServer Consulting and Training Services
https://gatewaygeomatics.com/



On 2019-11-26 9:54 AM, Andrew Bell wrote:
> I wouldn't be true to form if I didn't express some skepticism in the 
> value of this change.
> 
> I don't quite understand the environment in which one would care about 
> 700MB of data.  We live in an age where it's difficult to purchase a 
> storage device as small as 500GB, so minimizing an installation 
> footprint to avoid 700MB of data strikes me as a bit silly, especially 
> when PROJ has recently added a requirement for sqlite3.  If the issue is 
> one of packaging, it seems that there are other alternatives to a 
> "fancy" solution like this.  Could not the PROJ installation simply 
> download the files from some known source?  I'm sure there are other 
> options as well.  Dynamic fetching of data seems natural these days, but 
> it's non-trivial.  Failures can occur at many levels and these either 
> need handling in the source code or errors may be transferred to users 
> who may well scratch their heads about what's *not* working properly.  
> Personally, I'd much rather have a failure/problem at installation-time 
> than a run-time failure.  PROJ is, in my mind, a core library for many 
> users.  It should be as robust as possible.  To meet that goal requires 
> careful code.  Extra features require more code, which requires more 
> maintenance, review and necessarily increases the likelihood of bugs.  
> Current maintainers may have time and expertise to add this enhancement, 
> but it's not clear to me that it's in the long-term best interest of the 
> basic functionality of the library.
> 
> On Mon, Nov 25, 2019 at 7:46 AM Even Rouault <even.rouault at spatialys.com 
> <mailto:even.rouault at spatialys.com>> wrote:
> 
>     Hi,
> 
>     As announced last week, you'll find a RFC describing two new
>     capabilities,
>     remote access to grids and a GeoTIFF-based format for grids, in
>     https://github.com/OSGeo/PROJ/pull/1747
> 
>     You can get an (almost correct) preview of it by going through
>     https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst
>     (some links will not work in this preview: expected given that this
>     rendering doesn't go through Sphinx)
> 
>     Even
> 
>     -- 
>     Spatialys - Geospatial professional services
>     http://www.spatialys.com
>     _______________________________________________
>     PROJ mailing list
>     PROJ at lists.osgeo.org <mailto:PROJ at lists.osgeo.org>
>     https://lists.osgeo.org/mailman/listinfo/proj
> 
> 
> 
> -- 
> Andrew Bell
> andrew.bell.ia at gmail.com <mailto:andrew.bell.ia at gmail.com>
> 


From even.rouault at spatialys.com  Tue Nov 26 08:15:16 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 17:15:16 +0100
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
	and GeoTIFF grids
In-Reply-To: <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
 <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
Message-ID: <1982562.spGxhyAQv3@even-i700>

Jeff,

> I would like this RFC to include effort to improve the documentation on
> which grids should be installed (it is very confusing how
> 'proj-datumgrid-latest' differs from world, europe, oceania,
> northamerica, I always assume, like many others I bet, that -latest
> includes europe+oceania+northamerica+world). 

Can you point exactly in the documentation where would you want some 
clarification ?

> Which brings me to the most important point that I believe is missing in
> the RFC, of notifying the user when a grid file is not leveraged.
> Currently there is no warning, no notice, when a grid is not installed.
> I side with Andrew Bell on his point that during installation I'd like
> to see more messages, notices, or something to install all grid files.
> Could there be a build option of "TEST_ALL_DATUMGRID_FILES" during PROJ
> compilation?

Installation is a complicated topic. The PROJ project has no control over how 
PROJ is packaged and installed, and doing the "check at installation" means a 
different technical reality for Debian, Fedora, MS4W, OSGeo4W, conda, etc.
That said I took note of Chris Crook's idea about a script to help, as a post-
installation means (could potentially be run automatically by whatever 
installation process is done)
https://github.com/OSGeo/PROJ/issues/1750

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jmckenna at gatewaygeomatics.com  Tue Nov 26 08:47:23 2019
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Tue, 26 Nov 2019 12:47:23 -0400
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
 and GeoTIFF grids
In-Reply-To: <1982562.spGxhyAQv3@even-i700>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
 <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
 <1982562.spGxhyAQv3@even-i700>
Message-ID: <4aeb032d-87b9-e8d2-225d-016e566eaa48@gatewaygeomatics.com>

Hi Even,

On 2019-11-26 12:15 PM, Even Rouault wrote:
> Jeff,
> 
>> I would like this RFC to include effort to improve the documentation on
>> which grids should be installed (it is very confusing how
>> 'proj-datumgrid-latest' differs from world, europe, oceania,
>> northamerica, I always assume, like many others I bet, that -latest
>> includes europe+oceania+northamerica+world).
> 
> Can you point exactly in the documentation where would you want some
> clarification ?

That is difficult because the datumgrid information seems split into 
many pages.

- this page makes no mention of the difference between 
proj-datumgrid-latest, world, etc. 
https://proj.org/resource_files.html#external-resources

- install doc gives a little more info on which grids to install, but 
only for Conda, and doesn't link to the above page or Github 
https://proj.org/install.html

- links exist to the OSGeo download page, but there was no explanation 
of what 'proj-datumgrid-latest' contains anywhere 
(https://download.osgeo.org/proj/)

- I think most users will go directly to Github  and be overwhelmed by 
all of the different regions and world and proj-datumgrid-XX files 
(https://github.com/OSGeo/proj-datumgrid/releases)

Now you might say 'well jeff fix the docs, they are open' but honestly I 
don't know the answers to the above points.  Maybe I'm looking at too 
many pages (that I mentioned above) and should only focus on the 
README.md (https://github.com/OSGeo/proj-datumgrid), but again, that 
page should then be linked from the main PROJ site I believe.

Sorry for my confusion!

-jeff





> 
>> Which brings me to the most important point that I believe is missing in
>> the RFC, of notifying the user when a grid file is not leveraged.
>> Currently there is no warning, no notice, when a grid is not installed.
>> I side with Andrew Bell on his point that during installation I'd like
>> to see more messages, notices, or something to install all grid files.
>> Could there be a build option of "TEST_ALL_DATUMGRID_FILES" during PROJ
>> compilation?
> 
> Installation is a complicated topic. The PROJ project has no control over how
> PROJ is packaged and installed, and doing the "check at installation" means a
> different technical reality for Debian, Fedora, MS4W, OSGeo4W, conda, etc.
> That said I took note of Chris Crook's idea about a script to help, as a post-
> installation means (could potentially be run automatically by whatever
> installation process is done)
> https://github.com/OSGeo/PROJ/issues/1750
> 
> Even
> 


-- 
Jeff McKenna
MapServer Consulting and Training Services
https://gatewaygeomatics.com/

From jmckenna at gatewaygeomatics.com  Tue Nov 26 08:48:52 2019
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Tue, 26 Nov 2019 12:48:52 -0400
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
 and GeoTIFF grids
In-Reply-To: <1982562.spGxhyAQv3@even-i700>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
 <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
 <1982562.spGxhyAQv3@even-i700>
Message-ID: <e4ea7bb7-4339-e392-9ae6-3e25c76e0136@gatewaygeomatics.com>

Forgot to comment below:

On 2019-11-26 12:15 PM, Even Rouault wrote:
> Jeff,
> 
>> I would like this RFC to include effort to improve the documentation on
>> which grids should be installed (it is very confusing how
>> 'proj-datumgrid-latest' differs from world, europe, oceania,
>> northamerica, I always assume, like many others I bet, that -latest
>> includes europe+oceania+northamerica+world).
> 
> Can you point exactly in the documentation where would you want some
> clarification ?
> 
>> Which brings me to the most important point that I believe is missing in
>> the RFC, of notifying the user when a grid file is not leveraged.
>> Currently there is no warning, no notice, when a grid is not installed.
>> I side with Andrew Bell on his point that during installation I'd like
>> to see more messages, notices, or something to install all grid files.
>> Could there be a build option of "TEST_ALL_DATUMGRID_FILES" during PROJ
>> compilation?
> 
> Installation is a complicated topic. The PROJ project has no control over how
> PROJ is packaged and installed, and doing the "check at installation" means a
> different technical reality for Debian, Fedora, MS4W, OSGeo4W, conda, etc.
> That said I took note of Chris Crook's idea about a script to help, as a post-
> installation means (could potentially be run automatically by whatever
> installation process is done)
> https://github.com/OSGeo/PROJ/issues/1750
> 

Chris' idea looks exactly what I was trying to say ha.  Thanks for 
pointing to that for me.

-jeff



From ccrook at linz.govt.nz  Tue Nov 26 09:09:31 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Tue, 26 Nov 2019 17:09:31 +0000
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF9323144DF39@prdassexch01.ad.linz.govt.nz>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <3620026.VIMQX10h4f@even-i700>,
 <A87E66F06E86F14B857F2EB047CDF9323144DF39@prdassexch01.ad.linz.govt.nz>
Message-ID: <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>

Comments inline below

Cheers
Chris


> -----Original Message-----
> From: Even Rouault [mailto:even.rouault at spatialys.com]
> Sent: Tuesday, 26 November 2019 12:21 p.m.
> To: proj at lists.osgeo.org
> Cc: Chris Crook
> Subject: Re: [PROJ] Management of datum grid files.
>
> Chris,
>
> Interesting points !
>
> >  doubt that many Australian users will be interested in the NZ grids,
> > and
> vice versa.  (Particularly of course as we do not share a land boundary).
>
> We had to try to find some classification, to have a reasonable number of
> packages of a reasonable size. This is not perfect. For example for French
> grids, they are stored in -europe even for the oversea territories in North
> America, Carribeans, Indian ocean...
>
> > So for the
> > most part users will need to download the zip file from the URL on the
> > PROJ pages, and install manually.
>
> Yes, the "advanced" PROJ API or the projinfo utility also gives a hint currently,
> like "Grid GDA94_GDA2020_conformal.gsb needed but not found on the
> system. Can be obtained from the proj-datumgrid-oceania package at
> https:// download.osgeo.org/proj/proj-datumgrid-oceania-latest.zip"
>
> > Initially I thought I wondered about create a directory in
> > proj-datumgrid for NZ grids and a  new product proj-datumgrid-nz.
>
> I think our current release manager would probably object that having to
> handle more packages will be overhead for him (as we need to keep track of
> their versionning). We would certainly add a "africa", "south-america" and
> "asia" subpackages if we have datasets for them, but having to create
> separate packages for each agency would be a larger maintainance and
> distribution burden.

Yes .. that was why I was thinking it made more sense for LINZ to manage it!

Versioning is another question.  I was pondering this when I was writing the
original email, but thought it was already long enough.  Maybe the installer downloading
an agency zip file could require a VERSION file or something similar so that the version
can be reported to users.   Certainly as a datum maintainer we would want to
provide version information to be confident of what users were testing.

>
> > But since LINZ (NZ
> > geodetic agency) will be publishing these in any case, would it make
> > more sense for LINZ to maintain and host the proj-datumgrid-nz
> > product, and for that simply to be referenced in proj documentation?
>
> Several points:
> - I suppose that depends on the PROJ community trusts the data producer
> (I'm talking in general here. Nothing specific about LINZ !) to maintain its
> content, and at a stable location. One concern I have is with superseded
> grids. There are some agencies that tend to hide old grids when they release
> a new one. Which can be problematic for reproducibility, or even if you just
> use an old version of PROJ whose database hasn't been updated to point at
> the new grid. By having the grids "physically" in the git repo of proj-
> datumgrid we as as project can decide about their fate.

I think ultimately the users have to trust the authority managing the local datum definition,
LINZ in New Zealand.   However maybe the information installed into proj should not just
be the location of the grid files, but also the contact details for the responsible authority.
That way the install_proj_datumgrid utility could provide the users with relevant information
if the source files are unavailable or do not provide the expected transformation grids.

Users, or agencies, or the proj project itself could certainly monitor the that the requisite
grids are available and readable (eg in the correct format), and notify the appropriate agencies
if not.

> - Up to now data producers tended to deliver their datasets in "random"
> formats and we had to do a conversion to something PROJ could ingest.
> - We need to be really sure about the filename of the grid. What EPSG
> mentions in its database and what data producers actually deliver tend to be
> different, so we have a database table to do that mapping. Even slight
> changes like foo.gsb becoming FOO.GSB could break PROJ good working.

Totally agree - and certainly we haven't sorted out the LINZ grids and names yet.
Our preference is to fix this at source (ie EPSG) rather than adding a mapping
in proj.  Otherwise we end up with two places to maintain.  This is something we
will be addressing very soon!

Also I don't think that the two approaches are mutually exclusive.  An agency such
as LINZ could either choose to install files directly into proj-datumgrid or just to install
the url/contact details for use by an installer.  Or if the agency is not able or willing to
maintain the grids then maybe local users would be able issue pull requests to proj-datumgrid.

Also global data sets (eg EGM geoid models) may be best managed within proj-datumgrid.

Where possible though it makes sense to me that the proj is responsible for the infrastructure
and frameworks, and agencies can provide the data that it uses.

Of course LINZ can in any case publish a proj-datumgrid-nz.zip file for use by the NZ
community and others in any case.  It just feels like it would make sense to have a framework
that directly supports that!

> - By having the grids stored in proj-datumgrid, we can also check their
> licensing situation before inclusion.
>
> > The current initiative to deliver grids via a CDN
> >
> (https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/doc
> > s/sou
> > rce/community/rfc/rfc-4.rst) will simplify this, but  the current
> > proposal doesn't replace proj-datumgrid so I think this will be an
> > issue for a bit longer.
>
> Yes, in my mind, proj-datumgrid will remain the "master", and we will have a
> script that will resync its content onto the cloud storage we will have access
> to.

So possibly the approach for agency hosted data would be for the resync script
to download from the authoritative site, verify the contents, and post to cloud
storage if it passes file name and format tests, maybe version and licence information
 etc.

> > To make this work well it would be useful to have a command line tool
> > for installing grids that is installed with PROJ.  Say (sudo)
> > install_proj_datumgrid <region>.   This could have a configuration file
> > which defines the URL of the authoritative source for each region so
> > that "install_proj_datumgrid nz" would download and install a file
> > from (say)
> > www.geodesy.linz.govt.nz/download/proj-datumgrid/proj-datumgrid-
> nz.zip
> > <http
> > ://www.geodesy.linz.govt.nz/download/proj-datumgrid/proj-datumgrid-
> nz.zip>.
> > This could work well with the existing products too, eg
> > install_proj_datumgrid oceania.   (This could be a trivial shell script for
> > linux - sure for other OS targets)
>
> A python script then :-) It would probably also need the path to the data
> (PROJ_LIB) directory, as this can vary between binary distributions. Or we
> could also have a --user flag (like pip install --user) that would install them in
> the ${XDG_DATA_HOME}/proj directory mentionned in RFC4 to hold the
> network cache, and the default search path PROJ would also look into
> that.

I like python :-)  I'm not sure if it gives sufficient platform independence?
Do any of the proj binaries have a function to report the default value for PROJ_LIB
that a python utility could use if it is not explicitly set?

> All this discussion shows that for use cases where people will be able and
> willing to rely on network access, just telling PROJ "go and fetch the grids
> wherever they are stored" should be a huge usability improvement.
>
> Even
>
> --
> Spatialys - Geospatial professional services http://www.spatialys.com

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From even.rouault at spatialys.com  Tue Nov 26 12:35:22 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 21:35:22 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144DF39@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
Message-ID: <2124705.S4BY28HgJC@even-i700>

Chris,

not going to answer to each specific point. I think you're proposing 
interesting ideas worth considering. The way we manage "static" proj-
datumgrid-XXXX packages is certainly not carved in stone. As RFC 4 already 
embraces quite a few different subjects and I need to limit my focus, I'd 
prefer we try to stick on them.
Discussing about that with Howard, he mentionned that packagers could probably 
have their own logic to fetch files of interest for them from the CDN. There 
are certainly further developments that can be built on top of that.

> I like python :-)  I'm not sure if it gives sufficient platform
> independence? 

Probably not the most convenient for Windows users that would have a naked 
installation, but I'm not sure we want to have a specific script for Windows. 
We can assume probably assume folks having a GIS stack to have Python not so 
far away.

> Do any of the proj binaries have a function to report the
> default value for PROJ_LIB that a python utility could use if it is not
> explicitly set?

No. The PROJ binary has no idea where PROJ_LIB can be pointed too. That's why 
it is needed to be defined. For some builds typically done by Linux 
distributions where the installaton path is known at build time, the default 
search path is hardcoded in the binary, but for Windows, the actual 
installation path is rarely known in advance.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jmckenna at gatewaygeomatics.com  Tue Nov 26 13:24:06 2019
From: jmckenna at gatewaygeomatics.com (Jeff McKenna)
Date: Tue, 26 Nov 2019 17:24:06 -0400
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
 and GeoTIFF grids
In-Reply-To: <e4ea7bb7-4339-e392-9ae6-3e25c76e0136@gatewaygeomatics.com>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
 <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
 <1982562.spGxhyAQv3@even-i700>
 <e4ea7bb7-4339-e392-9ae6-3e25c76e0136@gatewaygeomatics.com>
Message-ID: <12d003c0-39e9-cc20-f82a-c4afcde52171@gatewaygeomatics.com>

Even I'll help improve the docs, as you progress through this RFC.  -jeff



On 2019-11-26 12:48 PM, Jeff McKenna wrote:
> Forgot to comment below:
> 
> On 2019-11-26 12:15 PM, Even Rouault wrote:
>> Jeff,
>>
>>> I would like this RFC to include effort to improve the documentation on
>>> which grids should be installed (it is very confusing how
>>> 'proj-datumgrid-latest' differs from world, europe, oceania,
>>> northamerica, I always assume, like many others I bet, that -latest
>>> includes europe+oceania+northamerica+world).
>>
>> Can you point exactly in the documentation where would you want some
>> clarification ?
>>
>>> Which brings me to the most important point that I believe is missing in
>>> the RFC, of notifying the user when a grid file is not leveraged.
>>> Currently there is no warning, no notice, when a grid is not installed.
>>> I side with Andrew Bell on his point that during installation I'd like
>>> to see more messages, notices, or something to install all grid files.
>>> Could there be a build option of "TEST_ALL_DATUMGRID_FILES" during PROJ
>>> compilation?
>>
>> Installation is a complicated topic. The PROJ project has no control 
>> over how
>> PROJ is packaged and installed, and doing the "check at installation" 
>> means a
>> different technical reality for Debian, Fedora, MS4W, OSGeo4W, conda, 
>> etc.
>> That said I took note of Chris Crook's idea about a script to help, as 
>> a post-
>> installation means (could potentially be run automatically by whatever
>> installation process is done)
>> https://github.com/OSGeo/PROJ/issues/1750
>>
> 
> Chris' idea looks exactly what I was trying to say ha.  Thanks for 
> pointing to that for me.
> 
> -jeff
> 
> 
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


-- 
Jeff McKenna
MapServer Consulting and Training Services
https://gatewaygeomatics.com/

From ccrook at linz.govt.nz  Tue Nov 26 14:00:20 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Tue, 26 Nov 2019 22:00:20 +0000
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <2124705.S4BY28HgJC@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144DF39@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700>
Message-ID: <A87E66F06E86F14B857F2EB047CDF9323144EECE@prdassexch01.ad.linz.govt.nz>

Even

Cheers
Chris

>
> not going to answer to each specific point. I think you're proposing
> interesting ideas worth considering. The way we manage "static" proj-
> datumgrid-XXXX packages is certainly not carved in stone. As RFC 4 already
> embraces quite a few different subjects and I need to limit my focus, I'd
> prefer we try to stick on them.

I wasn't thinking this is necessarily part of RFC 4 (other than potential relationship with CDN).
This more comes from trying to sort out the missing NZ height grids and where  to implement
and maintain them.

> Discussing about that with Howard, he mentionned that packagers could
> probably have their own logic to fetch files of interest for them from the
> CDN. There are certainly further developments that can be built on top of
> that.
>
> > I like python :-)  I'm not sure if it gives sufficient platform
> > independence?
> Probably not the most convenient for Windows users that would have a
> naked installation, but I'm not sure we want to have a specific script for
> Windows.
> We can assume probably assume folks having a GIS stack to have Python not
> so far away.

I agree.   GDAL packages already include python scripts.  It certainly provides
and easy implementation for an initial version, and much better than nothing
even if there are some users who cannot use it.

> > Do any of the proj binaries have a function to report the default
> > value for PROJ_LIB that a python utility could use if it is not
> > explicitly set?
>
> No. The PROJ binary has no idea where PROJ_LIB can be pointed too. That's
> why it is needed to be defined. For some builds typically done by Linux
> distributions where the installaton path is known at build time, the default
> search path is hardcoded in the binary, but for Windows, the actual
> installation path is rarely known in advance.

I was thinking that once installed the proj utilities must know where they will
look for grid files, so I was just wondering what was the easiest way for a python
utility to determine this.   I'd thought maybe one of the utilities could report
status information including the default search path it was using in the installation.
Of  course programs using proj could reset PROJ_LIB so wouldn't necessarily be
using the same location :-(

Cheers
Chris

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From even.rouault at spatialys.com  Tue Nov 26 14:12:20 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Tue, 26 Nov 2019 23:12:20 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <2124705.S4BY28HgJC@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700>
Message-ID: <23877241.Mo6V5nEIhq@even-i700>

> No. The PROJ binary has no idea where PROJ_LIB can be pointed too. That's
> why it is needed to be defined. For some builds typically done by Linux
> distributions where the installaton path is known at build time, the
> default search path is hardcoded in the binary, but for Windows, the actual
> installation path is rarely known in advance.

Yes, that's why I floated around the idea that PROJ default search path could 
also include the  ${XDG_DATA_HOME}/proj directory, where ${XDG_DATA_HOME} 
resolves to ${HOME}/.local/share on Unix builds and ${USERPROFILE}/.local/
share on Windows builds, that RFC4 plans to use to put the local cache of 
downloaded chunks from the CDN. That has also the advantage that it is a user 
writable directory, which can help people not having admin rights.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From nyall.dawson at gmail.com  Tue Nov 26 15:32:53 2019
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Wed, 27 Nov 2019 09:32:53 +1000
Subject: [PROJ] Call for review on RFC 4 text: Remote access to grids
 and GeoTIFF grids
In-Reply-To: <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
References: <12415641.pOODJWFWK1@even-i700>
 <CACJ51z1fCeLOvXxm1h4OJqAzTy3ra2gnWSqfrnwjuNvdbCFZjg@mail.gmail.com>
 <612ead41-83a1-9e92-5381-28d22d7e6935@gatewaygeomatics.com>
Message-ID: <CAB28Asj3-XTE+17QLHXuOrcsybD07hrGj=n0N2mEfL19DV5c4Q@mail.gmail.com>

On Wed, 27 Nov 2019 at 01:49, Jeff McKenna
<jmckenna at gatewaygeomatics.com> wrote:

> Which brings me to the most important point that I believe is missing in
> the RFC, of notifying the user when a grid file is not leveraged.
> Currently there is no warning, no notice, when a grid is not installed.
> I side with Andrew Bell on his point that during installation I'd like
> to see more messages, notices, or something to install all grid files.
> Could there be a build option of "TEST_ALL_DATUMGRID_FILES" during PROJ
> compilation?

Doesn't responsibility for implementing this warning lie with the
client application? Every application will need to handle this
differently, e.g. in QGIS we implemented a giant warning alert when a
more accurate transformation is possible but can't be used due to
missing grid files (along with a gui based approach to allow users to
download and install these files). But obviously for mapserver this
would need to be handled quite differently (with a big warning in a
log file?). And an application like a R library would also need a
different approach to warning users of this situation too....

FWIW, the code in QGIS which handles this starts at
https://github.com/qgis/QGIS/blob/master/src/core/qgscoordinatetransform_p.cpp#L380

Nyall



>
> I thank Even, Howard, Kristian, all, for pushing PROJ forward.
>
> -jeff
>
>
>
> --
> Jeff McKenna
> MapServer Consulting and Training Services
> https://gatewaygeomatics.com/
>
>
>
> On 2019-11-26 9:54 AM, Andrew Bell wrote:
> > I wouldn't be true to form if I didn't express some skepticism in the
> > value of this change.
> >
> > I don't quite understand the environment in which one would care about
> > 700MB of data.  We live in an age where it's difficult to purchase a
> > storage device as small as 500GB, so minimizing an installation
> > footprint to avoid 700MB of data strikes me as a bit silly, especially
> > when PROJ has recently added a requirement for sqlite3.  If the issue is
> > one of packaging, it seems that there are other alternatives to a
> > "fancy" solution like this.  Could not the PROJ installation simply
> > download the files from some known source?  I'm sure there are other
> > options as well.  Dynamic fetching of data seems natural these days, but
> > it's non-trivial.  Failures can occur at many levels and these either
> > need handling in the source code or errors may be transferred to users
> > who may well scratch their heads about what's *not* working properly.
> > Personally, I'd much rather have a failure/problem at installation-time
> > than a run-time failure.  PROJ is, in my mind, a core library for many
> > users.  It should be as robust as possible.  To meet that goal requires
> > careful code.  Extra features require more code, which requires more
> > maintenance, review and necessarily increases the likelihood of bugs.
> > Current maintainers may have time and expertise to add this enhancement,
> > but it's not clear to me that it's in the long-term best interest of the
> > basic functionality of the library.
> >
> > On Mon, Nov 25, 2019 at 7:46 AM Even Rouault <even.rouault at spatialys.com
> > <mailto:even.rouault at spatialys.com>> wrote:
> >
> >     Hi,
> >
> >     As announced last week, you'll find a RFC describing two new
> >     capabilities,
> >     remote access to grids and a GeoTIFF-based format for grids, in
> >     https://github.com/OSGeo/PROJ/pull/1747
> >
> >     You can get an (almost correct) preview of it by going through
> >     https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst
> >     (some links will not work in this preview: expected given that this
> >     rendering doesn't go through Sphinx)
> >
> >     Even
> >
> >     --
> >     Spatialys - Geospatial professional services
> >     http://www.spatialys.com
> >     _______________________________________________
> >     PROJ mailing list
> >     PROJ at lists.osgeo.org <mailto:PROJ at lists.osgeo.org>
> >     https://lists.osgeo.org/mailman/listinfo/proj
> >
> >
> >
> > --
> > Andrew Bell
> > andrew.bell.ia at gmail.com <mailto:andrew.bell.ia at gmail.com>
> >
>
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj

From nyall.dawson at gmail.com  Tue Nov 26 15:34:33 2019
From: nyall.dawson at gmail.com (Nyall Dawson)
Date: Wed, 27 Nov 2019 09:34:33 +1000
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
Message-ID: <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>

On Tue, 26 Nov 2019 at 20:52, Kristian Evers <kreve at sdfe.dk> wrote:

> You can get the transformation accuracy using the API function
> proj_coordoperation_get_accuracy(). I think it would be cool if
> information about transformation accuracy where readily available in
> software like QGIS (nudge, nudge :-))

That's where I'm coming from now... I'm just wondering if and how we
should expose vertical transformation functionality. Do you have any
ideas on what functionality you would expect an end-user application
to expose for vertical transformations?

Nyall

>
> /Kristian
>
> -----Original Message-----
> From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Nyall Dawson
> Sent: 26. november 2019 01:27
> To: PROJ <proj at lists.osgeo.org>
> Subject: [PROJ] "Trustworthiness" of vertical transformations
>
> Hi list,
>
> I've seen a lot of activity on the PROJ repo lately relating to
> vertical datum transformations. Coming from zero knowledge about the
> world of vertical transformations... if I setup a simple
> transformation between two proj CRS objects created using auth/id
> codes, and transform a 3d point using proj_trans_generic... how
> "trustworthy" is the resultant z value?
>
> I've seen some examples (e.g in
> https://github.com/OSGeo/PROJ/issues/1743) which use a
> "EPSG:26911+5703" type construct, which leads me to believe that the
> world of vertical transformations is not so straightforward! Any tips
> to give a newbie entering this world to avoid the inevitable pitfalls
> which await?
>
> Cheers,
> Nyall
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj

From even.rouault at spatialys.com  Tue Nov 26 16:05:35 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 27 Nov 2019 01:05:35 +0100
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
 <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>
Message-ID: <2619535.AF0HQB3J75@even-i700>

On mercredi 27 novembre 2019 09:34:33 CET Nyall Dawson wrote:
> On Tue, 26 Nov 2019 at 20:52, Kristian Evers <kreve at sdfe.dk> wrote:
> > You can get the transformation accuracy using the API function
> > proj_coordoperation_get_accuracy(). I think it would be cool if
> > information about transformation accuracy where readily available in
> > software like QGIS (nudge, nudge :-))

I should mention that the information about accuracy should be taken with a  
grain of salt for several reasons:
- the EPSG guidance note 7-1 [1] underlines that the exact definition of 
accuracy varies according to geodetic agencies
- in a number of situations, PROJ will have to synthetize the resulting 
accuracy when chaining several steps. The algorithm currently is rather 
simple: just add the (in)accuracies of each step. I do have some vague 
remembering from univ that this was not always the "right" thing to do from a 
math point of view. I guess sometimes perhaps taking the max() would be more 
appropriate. But given that we can potentially mix uncomparable things, 
probably not that a big deal...

> That's where I'm coming from now... I'm just wondering if and how we
> should expose vertical transformation functionality. Do you have any
> ideas on what functionality you would expect an end-user application
> to expose for vertical transformations?

Depends on the use cases. If you want to aggregate point cloud datasets that 
are referenced against several vertical CRS into a single dataset, you will 
probably want to convert them into a single Geographic CRS (ITRF2014, WGS84 
G1762) or a single CompoundCRS appropriate for the area of study so that they 
can be stashed together.

Even

[1] http://www.epsg.org/Portals/0/373-07-1.pdf , §6.5.4.1 Coordinate Operation 
accuracy

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From kreve at sdfe.dk  Wed Nov 27 00:14:27 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Wed, 27 Nov 2019 08:14:27 +0000
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <23877241.Mo6V5nEIhq@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
Message-ID: <93d564aa568742178d33bd47738867a9@sdfe.dk>

Perhaps we should look into using %APPDATA%\Local\PROJ as the default path
for %PROJ_LIB% on Windows?

This has been good practice on Windows for quite a while now. I guess the reason
that PROJ doesn't have a default location on Windows is that in earlier versions of
Windows no such place was available.

/Kristian

-----Original Message-----
From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Even Rouault
Sent: 26. november 2019 23:12
To: proj at lists.osgeo.org
Subject: Re: [PROJ] Management of datum grid files.

> No. The PROJ binary has no idea where PROJ_LIB can be pointed too. That's
> why it is needed to be defined. For some builds typically done by Linux
> distributions where the installaton path is known at build time, the
> default search path is hardcoded in the binary, but for Windows, the actual
> installation path is rarely known in advance.

Yes, that's why I floated around the idea that PROJ default search path could 
also include the  ${XDG_DATA_HOME}/proj directory, where ${XDG_DATA_HOME} 
resolves to ${HOME}/.local/share on Unix builds and ${USERPROFILE}/.local/
share on Windows builds, that RFC4 plans to use to put the local cache of 
downloaded chunks from the CDN. That has also the advantage that it is a user 
writable directory, which can help people not having admin rights.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com
_______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/proj

From kreve at sdfe.dk  Wed Nov 27 00:18:48 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Wed, 27 Nov 2019 08:18:48 +0000
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <2619535.AF0HQB3J75@even-i700>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
 <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>
 <2619535.AF0HQB3J75@even-i700>
Message-ID: <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>

> The algorithm currently is rather 
> simple: just add the (in)accuracies of each step. I do have some vague 
> remembering from univ that this was not always the "right" thing to do from a 
> math point of view. I guess sometimes perhaps taking the max() would be more 
> appropriate. But given that we can potentially mix uncomparable things, 
> probably not that a big deal...

Yeah, this can definitely be improved but it's a simple and effective solution that
doesn't promise too much which is always better that saying that accuracy is
better than it really is. I think this could be a fun topic to have a workshop on
at the OSGeo code sprint in the spring. 

/Kristian

-----Original Message-----
From: Even Rouault <even.rouault at spatialys.com> 
Sent: 27. november 2019 01:06
To: proj at lists.osgeo.org
Cc: Nyall Dawson <nyall.dawson at gmail.com>; Kristian Evers <kreve at sdfe.dk>
Subject: Re: [PROJ] "Trustworthiness" of vertical transformations

On mercredi 27 novembre 2019 09:34:33 CET Nyall Dawson wrote:
> On Tue, 26 Nov 2019 at 20:52, Kristian Evers <kreve at sdfe.dk> wrote:
> > You can get the transformation accuracy using the API function
> > proj_coordoperation_get_accuracy(). I think it would be cool if
> > information about transformation accuracy where readily available in
> > software like QGIS (nudge, nudge :-))

I should mention that the information about accuracy should be taken with a  
grain of salt for several reasons:
- the EPSG guidance note 7-1 [1] underlines that the exact definition of 
accuracy varies according to geodetic agencies
- in a number of situations, PROJ will have to synthetize the resulting 
accuracy when chaining several steps. The algorithm currently is rather 
simple: just add the (in)accuracies of each step. I do have some vague 
remembering from univ that this was not always the "right" thing to do from a 
math point of view. I guess sometimes perhaps taking the max() would be more 
appropriate. But given that we can potentially mix uncomparable things, 
probably not that a big deal...

> That's where I'm coming from now... I'm just wondering if and how we
> should expose vertical transformation functionality. Do you have any
> ideas on what functionality you would expect an end-user application
> to expose for vertical transformations?

Depends on the use cases. If you want to aggregate point cloud datasets that 
are referenced against several vertical CRS into a single dataset, you will 
probably want to convert them into a single Geographic CRS (ITRF2014, WGS84 
G1762) or a single CompoundCRS appropriate for the area of study so that they 
can be stashed together.

Even

[1] http://www.epsg.org/Portals/0/373-07-1.pdf , §6.5.4.1 Coordinate Operation 
accuracy

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Wed Nov 27 04:15:11 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 27 Nov 2019 13:15:11 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <93d564aa568742178d33bd47738867a9@sdfe.dk>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <23877241.Mo6V5nEIhq@even-i700> <93d564aa568742178d33bd47738867a9@sdfe.dk>
Message-ID: <2222220.jTYGqXXbEZ@even-i700>

On mercredi 27 novembre 2019 08:14:27 CET Kristian Evers wrote:
> Perhaps we should look into using %APPDATA%\Local\PROJ as the default path
> for %PROJ_LIB% on Windows?
> 
> This has been good practice on Windows for quite a while now. I guess the
> reason
> that PROJ doesn't have a default location on Windows is that in
> earlier versions of Windows no such place was available.

You're right. Probably that %APPDATA%\Local would be a more idiomatic default expansion of ${XDG_DATA_HOME} for Windows. 
Looking at
http://www.binbert.com/blog/2010/09/default-environment-variable-values-of-windows-7-xp/
I see there is a ton of potential candidate environment variables. As an non-native Windows user
it is hard to tell which one would be the most natural for natively-speaking Windows user...
Any preference ?

It seems %APPDATA%  expands to	C:\Users\{username}\AppData\Roaming . The Roaming
naming sounds funny. Or perhaps this is a Win7 only thing ?
%LOCALAPPDATA% expanding to C:\Users\{username}\AppData\Local would seem not so bad

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From kreve at sdfe.dk  Wed Nov 27 04:21:40 2019
From: kreve at sdfe.dk (Kristian Evers)
Date: Wed, 27 Nov 2019 12:21:40 +0000
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <2222220.jTYGqXXbEZ@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <23877241.Mo6V5nEIhq@even-i700> <93d564aa568742178d33bd47738867a9@sdfe.dk>
 <2222220.jTYGqXXbEZ@even-i700>
Message-ID: <11519664fa344871affc4a7f073ccc8a@sdfe.dk>

I should have written %LOCALAPPDATA%, that's the one that is suitable for PROJ.
I too get confused by the various similar-sounding variables.

You are right that %APPDATA% expands to ...\Roaming\. If I understand correctly
it is meant for users that are available on several computers on a domain which need
shared data across all machines. Somehow... This is a rather specific use case that I
don't think we should use for PROJ.


/Kristian

-----Original Message-----
From: Even Rouault <even.rouault at spatialys.com> 
Sent: 27. november 2019 13:15
To: Kristian Evers <kreve at sdfe.dk>
Cc: proj at lists.osgeo.org
Subject: Re: [PROJ] Management of datum grid files.

On mercredi 27 novembre 2019 08:14:27 CET Kristian Evers wrote:
> Perhaps we should look into using %APPDATA%\Local\PROJ as the default path
> for %PROJ_LIB% on Windows?
> 
> This has been good practice on Windows for quite a while now. I guess the
> reason
> that PROJ doesn't have a default location on Windows is that in
> earlier versions of Windows no such place was available.

You're right. Probably that %APPDATA%\Local would be a more idiomatic default expansion of ${XDG_DATA_HOME} for Windows. 
Looking at
http://www.binbert.com/blog/2010/09/default-environment-variable-values-of-windows-7-xp/
I see there is a ton of potential candidate environment variables. As an non-native Windows user
it is hard to tell which one would be the most natural for natively-speaking Windows user...
Any preference ?

It seems %APPDATA%  expands to	C:\Users\{username}\AppData\Roaming . The Roaming
naming sounds funny. Or perhaps this is a Win7 only thing ?
%LOCALAPPDATA% expanding to C:\Users\{username}\AppData\Local would seem not so bad

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From brian.shaw at noaa.gov  Wed Nov 27 08:54:45 2019
From: brian.shaw at noaa.gov (Brian Shaw)
Date: Wed, 27 Nov 2019 11:54:45 -0500
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
 <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>
 <2619535.AF0HQB3J75@even-i700> <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>
Message-ID: <2c8147e2-ca96-50db-8ea5-7636d2d51d4c@noaa.gov>

Just a few things to note from my perspective but certainly not 
"official" from the US National Geodetic Survey (NGS).  Probably more 
information than you want to know but I believe it can be helpful to 
have a general skepticism in transformations and vertical 
transformations in particular.  I also apologize since this email got 
quite lengthy.

Vertical datums in the US have inherent errors that cause uncertainty in 
places due to systematic errors or incorrect assumptions.  Here is a 
little information about the historical US vertical datums and Ill note 
the future datum should be far more accurate since it will be derived 
primarily through terrestrial, aerial and satellite gravity measurements.

NGVD29 used 26 tide gauges across North America as constraints and made 
the assumption that sea level was the same in all places, which we now 
know is not the case.  This caused inherent errors in the middle of the 
country where data was made to "fit" through least squares adjustments 
causing inaccurate heights due to the assumption that all tide gauges 
were a height of 0.

NAVD88 tried to rectify this by only using one tide gauge as a 
constraint.  This caused the systematic errors in the leveling to 
propagate across the country.  Today people get NAVD88 heights by tying 
into bench marks that have NAVD88 heights on them which allows for them 
to get consistent heights in NAVD88 and is precise and provides 
repeatable heights, but precision is not accuracy as we are seeing while 
planning for the new datum in 2022.

Here at NGS we are working on a new datum and you can see the systematic 
errors from NAVD88 in this map 
<ftp://ftp.ngs.noaa.gov/dist/bshaw/Approximate_Vertical_Change_2022_sm.png> 
that shows the estimated change that will occur from NAVD88 to the new 
Geopotential Datum (Vertical Datum).  Its called "Geopotential" since it 
will be developed primarily through gravity and not hundreds of 
thousands of kilometers of leveling like past vertical datums.

A note on transformations in general is you should understand that 
almost all transformations are often termed mapping grade which is fine 
for GIS but not for geodetic coordinates.  You should also understand 
the uncertainties of the datums being used.  For instance if you are 
using WGS84 coordinates you should understand that just by using that 
datum you are introducing 3-5 meters of uncertainty in the horizontal 
coordinates, I'm not sure about vertically. Geodetically the best rule 
of thumb for having the most accurate coordinates is to preserve your 
original observations and process them in the datum of choice.  That is 
not always possible since you may not be the person/group collecting the 
data but it is something to keep in mind.

A closing note on accuracies as mentioned below by Kristian is that not 
all people report accuracies in the same way.  Even here at NGS there 
are different products that report in different measures. Some report at 
the one sigma level (standard deviation, square root of variance) also 
described as having 68% confidence in the value. Others report at the 
two sigma level (variance, std dev squared) which is often termed having 
95% confidence in the value.  So I would encourage you to know what 
sigma is used to report the accuracy and also understand this may just 
be the accuracy estimated in the datum which doesnt necessarily account 
for the uncertainty in the datum itself.

Cheers
Brian

On 11/27/2019 3:18 AM, Kristian Evers wrote:
>> The algorithm currently is rather
>> simple: just add the (in)accuracies of each step. I do have some vague
>> remembering from univ that this was not always the "right" thing to do from a
>> math point of view. I guess sometimes perhaps taking the max() would be more
>> appropriate. But given that we can potentially mix uncomparable things,
>> probably not that a big deal...
> Yeah, this can definitely be improved but it's a simple and effective solution that
> doesn't promise too much which is always better that saying that accuracy is
> better than it really is. I think this could be a fun topic to have a workshop on
> at the OSGeo code sprint in the spring.
>
> /Kristian
>
> -----Original Message-----
> From: Even Rouault <even.rouault at spatialys.com>
> Sent: 27. november 2019 01:06
> To: proj at lists.osgeo.org
> Cc: Nyall Dawson <nyall.dawson at gmail.com>; Kristian Evers <kreve at sdfe.dk>
> Subject: Re: [PROJ] "Trustworthiness" of vertical transformations
>
> On mercredi 27 novembre 2019 09:34:33 CET Nyall Dawson wrote:
>> On Tue, 26 Nov 2019 at 20:52, Kristian Evers <kreve at sdfe.dk> wrote:
>>> You can get the transformation accuracy using the API function
>>> proj_coordoperation_get_accuracy(). I think it would be cool if
>>> information about transformation accuracy where readily available in
>>> software like QGIS (nudge, nudge :-))
> I should mention that the information about accuracy should be taken with a
> grain of salt for several reasons:
> - the EPSG guidance note 7-1 [1] underlines that the exact definition of
> accuracy varies according to geodetic agencies
> - in a number of situations, PROJ will have to synthetize the resulting
> accuracy when chaining several steps. The algorithm currently is rather
> simple: just add the (in)accuracies of each step. I do have some vague
> remembering from univ that this was not always the "right" thing to do from a
> math point of view. I guess sometimes perhaps taking the max() would be more
> appropriate. But given that we can potentially mix uncomparable things,
> probably not that a big deal...
>
>> That's where I'm coming from now... I'm just wondering if and how we
>> should expose vertical transformation functionality. Do you have any
>> ideas on what functionality you would expect an end-user application
>> to expose for vertical transformations?
> Depends on the use cases. If you want to aggregate point cloud datasets that
> are referenced against several vertical CRS into a single dataset, you will
> probably want to convert them into a single Geographic CRS (ITRF2014, WGS84
> G1762) or a single CompoundCRS appropriate for the area of study so that they
> can be stashed together.
>
> Even
>
> [1] http://www.epsg.org/Portals/0/373-07-1.pdf , §6.5.4.1 Coordinate Operation
> accuracy
>

-- 
*************************************
Brian Shaw
Geodesist
NOAA/NOS/National Geodetic Survey
Phone # 240-533-9522

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191127/83c4ead6/attachment-0001.html>

From ccrook at linz.govt.nz  Wed Nov 27 09:25:36 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Wed, 27 Nov 2019 17:25:36 +0000
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <2c8147e2-ca96-50db-8ea5-7636d2d51d4c@noaa.gov>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
 <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>
 <2619535.AF0HQB3J75@even-i700>
 <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>,
 <2c8147e2-ca96-50db-8ea5-7636d2d51d4c@noaa.gov>
Message-ID: <A87E66F06E86F14B857F2EB047CDF93231450892@prdassexch01.ad.linz.govt.nz>


This is a similar situation to that in New Zealand but on a much larger and more complex scale.  The recently established New Zealand Vertical Datum 2016 provides is based on an aerial gravity survey of the country providing a consistent datum and consistent level of accuracy across the entire country.  Prior to that there were 13 principal levelling datums each derived from levelling from a tide gauges.  Once the new datum was established we built a set of correction grids to convert between them - essentially these represent the local offset to the geopotential level surface representing mean sea level at each tide gauge, plus the systematic errors inherent in the levelling network.

The accuracy is much more complex to define - in many applications the local relative accuracy is much more important than the absolute accuracy.  The levelling datums were very accurate between adjacent benchmarks, but much less accurate in terms of absolute height above the geopotential surface.

Similarly when we transform a data set we may introduce an error to the data set as a whole, but the relative accuracy of data within the data set is very little changed.  It can become horribly comlicated very quickly!

Cheers
Chris
________________________________________
From: PROJ [proj-bounces at lists.osgeo.org] on behalf of Brian Shaw [brian.shaw at noaa.gov]
Sent: Thursday, 28 November 2019 5:54 a.m.
To: proj at lists.osgeo.org
Subject: Re: [PROJ] "Trustworthiness" of vertical transformations

Just a few things to note from my perspective but certainly not "official" from the US National Geodetic Survey (NGS).  Probably more information than you want to know but I believe it can be helpful to have a general skepticism in transformations and vertical transformations in particular.  I also apologize since this email got quite lengthy.

Vertical datums in the US have inherent errors that cause uncertainty in places due to systematic errors or incorrect assumptions.  Here is a little information about the historical US vertical datums and Ill note the future datum should be far more accurate since it will be derived primarily through terrestrial, aerial and satellite gravity measurements.

NGVD29 used 26 tide gauges across North America as constraints and made the assumption that sea level was the same in all places, which we now know is not the case.  This caused inherent errors in the middle of the country where data was made to "fit" through least squares adjustments causing inaccurate heights due to the assumption that all tide gauges were a height of 0.

NAVD88 tried to rectify this by only using one tide gauge as a constraint.  This caused the systematic errors in the leveling to propagate across the country.  Today people get NAVD88 heights by tying into bench marks that have NAVD88 heights on them which allows for them to get consistent heights in NAVD88 and is precise and provides repeatable heights, but precision is not accuracy as we are seeing while planning for the new datum in 2022.

Here at NGS we are working on a new datum and you can see the systematic errors from NAVD88 in this map<ftp://ftp.ngs.noaa.gov/dist/bshaw/Approximate_Vertical_Change_2022_sm.png> that shows the estimated change that will occur from NAVD88 to the new Geopotential Datum (Vertical Datum).  Its called "Geopotential" since it will be developed primarily through gravity and not hundreds of thousands of kilometers of leveling like past vertical datums.

A note on transformations in general is you should understand that almost all transformations are often termed mapping grade which is fine for GIS but not for geodetic coordinates.  You should also understand the uncertainties of the datums being used.  For instance if you are using WGS84 coordinates you should understand that just by using that datum you are introducing 3-5 meters of uncertainty in the horizontal coordinates, I'm not sure about vertically. Geodetically the best rule of thumb for having the most accurate coordinates is to preserve your original observations and process them in the datum of choice.  That is not always possible since you may not be the person/group collecting the data but it is something to keep in mind.

A closing note on accuracies as mentioned below by Kristian is that not all people report accuracies in the same way.  Even here at NGS there are different products that report in different measures. Some report at the one sigma level (standard deviation, square root of variance) also described as having 68% confidence in the value. Others report at the two sigma level (variance, std dev squared) which is often termed having 95% confidence in the value.  So I would encourage you to know what sigma is used to report the accuracy and also understand this may just be the accuracy estimated in the datum which doesnt necessarily account for the uncertainty in the datum itself.

Cheers
Brian

On 11/27/2019 3:18 AM, Kristian Evers wrote:

The algorithm currently is rather
simple: just add the (in)accuracies of each step. I do have some vague
remembering from univ that this was not always the "right" thing to do from a
math point of view. I guess sometimes perhaps taking the max() would be more
appropriate. But given that we can potentially mix uncomparable things,
probably not that a big deal...



Yeah, this can definitely be improved but it's a simple and effective solution that
doesn't promise too much which is always better that saying that accuracy is
better than it really is. I think this could be a fun topic to have a workshop on
at the OSGeo code sprint in the spring.

/Kristian

-----Original Message-----
From: Even Rouault <even.rouault at spatialys.com><mailto:even.rouault at spatialys.com>
Sent: 27. november 2019 01:06
To: proj at lists.osgeo.org<mailto:proj at lists.osgeo.org>
Cc: Nyall Dawson <nyall.dawson at gmail.com><mailto:nyall.dawson at gmail.com>; Kristian Evers <kreve at sdfe.dk><mailto:kreve at sdfe.dk>
Subject: Re: [PROJ] "Trustworthiness" of vertical transformations

On mercredi 27 novembre 2019 09:34:33 CET Nyall Dawson wrote:


On Tue, 26 Nov 2019 at 20:52, Kristian Evers <kreve at sdfe.dk><mailto:kreve at sdfe.dk> wrote:


You can get the transformation accuracy using the API function
proj_coordoperation_get_accuracy(). I think it would be cool if
information about transformation accuracy where readily available in
software like QGIS (nudge, nudge :-))



I should mention that the information about accuracy should be taken with a
grain of salt for several reasons:
- the EPSG guidance note 7-1 [1] underlines that the exact definition of
accuracy varies according to geodetic agencies
- in a number of situations, PROJ will have to synthetize the resulting
accuracy when chaining several steps. The algorithm currently is rather
simple: just add the (in)accuracies of each step. I do have some vague
remembering from univ that this was not always the "right" thing to do from a
math point of view. I guess sometimes perhaps taking the max() would be more
appropriate. But given that we can potentially mix uncomparable things,
probably not that a big deal...



That's where I'm coming from now... I'm just wondering if and how we
should expose vertical transformation functionality. Do you have any
ideas on what functionality you would expect an end-user application
to expose for vertical transformations?



Depends on the use cases. If you want to aggregate point cloud datasets that
are referenced against several vertical CRS into a single dataset, you will
probably want to convert them into a single Geographic CRS (ITRF2014, WGS84
G1762) or a single CompoundCRS appropriate for the area of study so that they
can be stashed together.

Even

[1] http://www.epsg.org/Portals/0/373-07-1.pdf , §6.5.4.1 Coordinate Operation
accuracy




--
*************************************
Brian Shaw
Geodesist
NOAA/NOS/National Geodetic Survey
Phone # 240-533-9522


________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From hellik at web.de  Wed Nov 27 09:31:56 2019
From: hellik at web.de (Helmut Kudrnovsky)
Date: Wed, 27 Nov 2019 10:31:56 -0700 (MST)
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <2222220.jTYGqXXbEZ@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <3620026.VIMQX10h4f@even-i700>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
 <93d564aa568742178d33bd47738867a9@sdfe.dk> <2222220.jTYGqXXbEZ@even-i700>
Message-ID: <1574875916818-0.post@n6.nabble.com>

Even Rouault-2 wrote
> On mercredi 27 novembre 2019 08:14:27 CET Kristian Evers wrote:
>> Perhaps we should look into using %APPDATA%\Local\PROJ as the default
>> path
>> for %PROJ_LIB% on Windows?
>> 
>> This has been good practice on Windows for quite a while now. I guess the
>> reason
>> that PROJ doesn't have a default location on Windows is that in
>> earlier versions of Windows no such place was available.
> 
> You're right. Probably that %APPDATA%\Local would be a more idiomatic
> default expansion of ${XDG_DATA_HOME} for Windows. 
> Looking at
> http://www.binbert.com/blog/2010/09/default-environment-variable-values-of-windows-7-xp/
> I see there is a ton of potential candidate environment variables. As an
> non-native Windows user
> it is hard to tell which one would be the most natural for
> natively-speaking Windows user...
> Any preference ?
> 
> It seems %APPDATA%  expands to	C:\Users\{username}\AppData\Roaming . The
> Roaming
> naming sounds funny. Or perhaps this is a Win7 only thing ?
> %LOCALAPPDATA% expanding to C:\Users\{username}\AppData\Local would seem
> not so bad
> 
> -- 
> Spatialys - Geospatial professional services
> http://www.spatialys.com
> _______________________________________________
> PROJ mailing list

> PROJ at .osgeo

> https://lists.osgeo.org/mailman/listinfo/proj

See

https://docs.microsoft.com/en-us/windows/deployment/usmt/usmt-recognized-environment-variables

As a good overview for  variables in the ms operating system context. 

Addtional files needed by programs should go to %APPDATA% which may or may
expand to different folders in win7, win8, win 10 and newer, but the
variable is there in all ms versions. 

E.g. winGRASS stores the addons in %APPDATA%\roaming subfolder to be
available for a defined user, then available on different boxe in a network  

Keep in mind, in the most cases in windows,  proj  is bundled with other
Software.

E.g. OSGeo4W where proj needed files are living in  e.g.
c:\OSGeo4W\share\proj\ or in standalone winGRASS or qgis where  proj needed
files are living in e.g. c:\programs\qgis\share-subfolder  and  %PROJ_LIB%
is set accordingly. 



-----
best regards
Helmut
--
Sent from: http://osgeo-org.1560.x6.nabble.com/PROJ-4-f3840930.html

From even.rouault at spatialys.com  Wed Nov 27 11:24:05 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 27 Nov 2019 20:24:05 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <1574875916818-0.post@n6.nabble.com>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <2222220.jTYGqXXbEZ@even-i700> <1574875916818-0.post@n6.nabble.com>
Message-ID: <2072521.EARWbhcj6n@even-i700>

> See
> 
> https://docs.microsoft.com/en-us/windows/deployment/usmt/usmt-recognized-env
> ironment-variables
> 
> As a good overview for  variables in the ms operating system context.
> 
> Addtional files needed by programs should go to %APPDATA% which may or may
> expand to different folders in win7, win8, win 10 and newer, but the
> variable is there in all ms versions.

Reading at
https://jpsoft.com/forums/threads/difference-between-appdata-and-localappdata.
8893/#post-50282
"""
The essence can be summed in just two phrases.
%AppData% is a roamed persistent user settings.
%LocalAppData% is non-roamed machine-specific settings or other discardable 
kind of data.

And of course you want to backup %AppData% (but not %LocalAppData%, unless a 
braindead developer put persistent user settings in there).
"""

As we aim this directory to store grids and a cache, %LocalAppData% seems more 
appropriate.

> Keep in mind, in the most cases in windows,  proj  is bundled with other
> Software.
> 
> E.g. OSGeo4W where proj needed files are living in  e.g.
> c:\OSGeo4W\share\proj\ or in standalone winGRASS or qgis where  proj needed
> files are living in e.g. c:\programs\qgis\share-subfolder  and  %PROJ_LIB%
> is set accordingly.

That's one of the reason to propose an installation-independent directory. 
That way different installations may be able to use the same grids & cache.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From jmfluis at gmail.com  Wed Nov 27 11:45:26 2019
From: jmfluis at gmail.com (jmfluis at gmail.com)
Date: Wed, 27 Nov 2019 19:45:26 -0000
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <93d564aa568742178d33bd47738867a9@sdfe.dk>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
 <93d564aa568742178d33bd47738867a9@sdfe.dk>
Message-ID: <004f01d5a55b$387757d0$a9660770$@gmail.com>

A previous point. I hate things installed in %APPDATA% and try to fight is much as I can ... but keep losing. The reason is simple, %APPDATA% is a hidden directory and users who have to set Windows to show hidden directories will not see it, and uninstallers tend to leave things there so it slowly becomes a huge trash sink.

But the point I want to bring is different. I saw in the camake scripts that there is an hard-wired default %PROJ_LIB% pointing to  bin/../share/proj but since this is set by cmake that only works when one builds proj and do not move it after.

Because in GMT we ship an full GDAL3+PROJ and I wanted to avoid the need to set ENV variables, I patched proj code to also look for  bin/../share/proj but at runtime. This means that we can install where ever and it still works. The question is, is there interest for such a feature in the PROJ itself? If yes, I can make a PR.

Joaquim


-----Original Message-----
From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Kristian Evers
Sent: Wednesday, November 27, 2019 8:14 AM
To: Even Rouault <even.rouault at spatialys.com>; proj at lists.osgeo.org
Subject: Re: [PROJ] Management of datum grid files.

Perhaps we should look into using %APPDATA%\Local\PROJ as the default path for %PROJ_LIB% on Windows?

This has been good practice on Windows for quite a while now. I guess the reason that PROJ doesn't have a default location on Windows is that in earlier versions of Windows no such place was available.

/Kristian

-----Original Message-----
From: PROJ <proj-bounces at lists.osgeo.org> On Behalf Of Even Rouault
Sent: 26. november 2019 23:12
To: proj at lists.osgeo.org
Subject: Re: [PROJ] Management of datum grid files.

> No. The PROJ binary has no idea where PROJ_LIB can be pointed too. 
> That's why it is needed to be defined. For some builds typically done 
> by Linux distributions where the installaton path is known at build 
> time, the default search path is hardcoded in the binary, but for 
> Windows, the actual installation path is rarely known in advance.

Yes, that's why I floated around the idea that PROJ default search path could also include the  ${XDG_DATA_HOME}/proj directory, where ${XDG_DATA_HOME} resolves to ${HOME}/.local/share on Unix builds and ${USERPROFILE}/.local/ share on Windows builds, that RFC4 plans to use to put the local cache of downloaded chunks from the CDN. That has also the advantage that it is a user writable directory, which can help people not having admin rights.

Even

--
Spatialys - Geospatial professional services http://www.spatialys.com _______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/proj
_______________________________________________
PROJ mailing list
PROJ at lists.osgeo.org
https://lists.osgeo.org/mailman/listinfo/proj


From even.rouault at spatialys.com  Wed Nov 27 11:55:39 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 27 Nov 2019 20:55:39 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <004f01d5a55b$387757d0$a9660770$@gmail.com>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <93d564aa568742178d33bd47738867a9@sdfe.dk>
 <004f01d5a55b$387757d0$a9660770$@gmail.com>
Message-ID: <4621464.LjgsMBbx6X@even-i700>

> Because in GMT we ship an full GDAL3+PROJ and I wanted to avoid the need to
> set ENV variables, I patched proj code to also look for  bin/../share/proj
> but at runtime. This means that we can install where ever and it still
> works. The question is, is there interest for such a feature in the PROJ
> itself? If yes, I can make a PR.

I believe there's interest in having a better out-of-the-box Win user 
experience. We'll have to look at the details, but IMHO definitely worth a PR.

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From mwtoews at gmail.com  Wed Nov 27 12:12:34 2019
From: mwtoews at gmail.com (Mike Taves)
Date: Thu, 28 Nov 2019 09:12:34 +1300
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <2222220.jTYGqXXbEZ@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <23877241.Mo6V5nEIhq@even-i700> <93d564aa568742178d33bd47738867a9@sdfe.dk>
 <2222220.jTYGqXXbEZ@even-i700>
Message-ID: <CAM2FmMqL=NU8VH=+_Hdis14zo=swPoKw=HNR843Zn4+dps0exw@mail.gmail.com>

On Thu, 28 Nov 2019 at 01:15, Even Rouault <even.rouault at spatialys.com> wrote:
> You're right. Probably that %APPDATA%\Local would be a more idiomatic default expansion of ${XDG_DATA_HOME} for Windows.

There is some simple logic to see in appdir.py's `user_data_dir`
function[1]. They also define a `user_cache_dir` function too. Either
of these are simple enough to port to any other language.

[1] https://github.com/ActiveState/appdirs/blob/a54ea98feed0a7593475b94de3a359e9e1fe8fdb/appdirs.py#L45-L97

From hellik at web.de  Wed Nov 27 12:31:03 2019
From: hellik at web.de (Helmut Kudrnovsky)
Date: Wed, 27 Nov 2019 13:31:03 -0700 (MST)
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <2072521.EARWbhcj6n@even-i700>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <3620026.VIMQX10h4f@even-i700>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
 <93d564aa568742178d33bd47738867a9@sdfe.dk> <2222220.jTYGqXXbEZ@even-i700>
 <1574875916818-0.post@n6.nabble.com> <2072521.EARWbhcj6n@even-i700>
Message-ID: <1574886663941-0.post@n6.nabble.com>

>> Keep in mind, in the most cases in windows,  proj  is bundled with other
>> Software.
>>
>> E.g. OSGeo4W where proj needed files are living in  e.g.
>> c:\OSGeo4W\share\proj\ or in standalone winGRASS or qgis where  proj
>> needed
>> files are living in e.g. c:\programs\qgis\share-subfolder  and 
>> %PROJ_LIB%
>> is set accordingly.
>
>That's one of the reason to propose an installation-independent directory.
>That way different installations may be able to use the same grids & cache. 

so the idea is:

that e.g. OSGeo4W puts the proj shared things into %LOCALAPPDATA%, a
standalone GIS software depending on proj looks into %LOCALAPPDATA% if there
is a subfolder called e.g. proj? or the other way around, a standalone GIS
software depending on proj puts needed files into %LOCALAPPDATA%\proj and
OSGeo4W looks while updating/upgrading its proj version into %LOCALAPPDATA%
if there is a proj subfolder with shared folders? what if in
%LOCALAPPDATA%\proj are already files with the same name? should these be
just overwritten? how will be there a track of updated/ugraded/changed
shared proj files if different software are working/updating/upgrading them
at the same time? 

or should be set %PROJ_LIB% windows system wide (for all users? for just one
user in a multiuser network?) and a standalone GIS software depending on
proj/OSGeo4W while updating looks for %PROJ_LIB% instead of
%LOCALAPPDATA%\proj?

will this work in the windows side of the world? ;-)

I'm not against a consolidated way how to deal with proj supporting files
like grids and their big file sizes; with a _co-maintainer of winGRASS_ hat
on, I know, windows can be sometimes a hardly manageable beast ... here just
for well thought solution on the windows side of the world ;-)





-----
best regards
Helmut
--
Sent from: http://osgeo-org.1560.x6.nabble.com/PROJ-4-f3840930.html

From kristianevers at gmail.com  Wed Nov 27 12:39:54 2019
From: kristianevers at gmail.com (Kristian Evers)
Date: Wed, 27 Nov 2019 21:39:54 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <1574886663941-0.post@n6.nabble.com>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <3620026.VIMQX10h4f@even-i700>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
 <93d564aa568742178d33bd47738867a9@sdfe.dk> <2222220.jTYGqXXbEZ@even-i700>
 <1574875916818-0.post@n6.nabble.com> <2072521.EARWbhcj6n@even-i700>
 <1574886663941-0.post@n6.nabble.com>
Message-ID: <FCFA4688-8B57-466B-BF18-0E3961561DBB@gmail.com>



> On 27 Nov 2019, at 21:31, Helmut Kudrnovsky <hellik at web.de> wrote:
> 
>>> Keep in mind, in the most cases in windows,  proj  is bundled with other
>>> Software.
>>> 
>>> E.g. OSGeo4W where proj needed files are living in  e.g.
>>> c:\OSGeo4W\share\proj\ or in standalone winGRASS or qgis where  proj
>>> needed
>>> files are living in e.g. c:\programs\qgis\share-subfolder  and 
>>> %PROJ_LIB%
>>> is set accordingly.
>> 
>> That's one of the reason to propose an installation-independent directory.
>> That way different installations may be able to use the same grids & cache. 
> 
> so the idea is:
> 
> that e.g. OSGeo4W puts the proj shared things into %LOCALAPPDATA%, a
> standalone GIS software depending on proj looks into %LOCALAPPDATA% if there
> is a subfolder called e.g. proj? or the other way around, a standalone GIS
> software depending on proj puts needed files into %LOCALAPPDATA%\proj and
> OSGeo4W looks while updating/upgrading its proj version into %LOCALAPPDATA%
> if there is a proj subfolder with shared folders? what if in
> %LOCALAPPDATA%\proj are already files with the same name? should these be
> just overwritten? how will be there a track of updated/ugraded/changed
> shared proj files if different software are working/updating/upgrading them
> at the same time? 
> 
> or should be set %PROJ_LIB% windows system wide (for all users? for just one
> user in a multiuser network?) and a standalone GIS software depending on
> proj/OSGeo4W while updating looks for %PROJ_LIB% instead of
> %LOCALAPPDATA%\proj?
> 
> will this work in the windows side of the world? ;-)
> 
> I'm not against a consolidated way how to deal with proj supporting files
> like grids and their big file sizes; with a _co-maintainer of winGRASS_ hat
> on, I know, windows can be sometimes a hardly manageable beast ... here just
> for well thought solution on the windows side of the world ;-)
> 

I would think that we would mostly just continue doing what we doing with PROJ_LIB
at the moment with the addition of looking for usable grids in %APPDATA% (on Windows).

This is somewhat equivalent to what is done on unix-based installs already, where the
logic for finding grids is something like:

1. Look in current dir
2. Look in search paths set by API function
3. Look in PROJ_LIB
4. Look in /usr/local/share/proj or whatever was specified with ./configure

On Windows step 4 would look for resources in %APPDATA%\PROJ

Is that a reasonable approach?

/Kristian








From even.rouault at spatialys.com  Wed Nov 27 12:59:30 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Wed, 27 Nov 2019 21:59:30 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <1574886663941-0.post@n6.nabble.com>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <2072521.EARWbhcj6n@even-i700> <1574886663941-0.post@n6.nabble.com>
Message-ID: <2694920.VR7iRM8BGK@even-i700>

> that e.g. OSGeo4W puts the proj shared things into %LOCALAPPDATA%, a
> standalone GIS software depending on proj looks into %LOCALAPPDATA% if there
> is a subfolder called e.g. proj? or the other way around, a standalone GIS
> software depending on proj puts needed files into %LOCALAPPDATA%\proj and
> OSGeo4W looks while updating/upgrading its proj version into %LOCALAPPDATA%
> if there is a proj subfolder with shared folders? what if in
> %LOCALAPPDATA%\proj are already files with the same name? should these be
> just overwritten? how will be there a track of updated/ugraded/changed
> shared proj files if different software are working/updating/upgrading them
> at the same time?
> 
> or should be set %PROJ_LIB% windows system wide (for all users? for just one
> user in a multiuser network?) and a standalone GIS software depending on
> proj/OSGeo4W while updating looks for %PROJ_LIB% instead of
> %LOCALAPPDATA%\proj?
> 
> will this work in the windows side of the world? ;-)

Huh, what a mess ! No wonder I stay away from Windows as much as possible :-)

I'd say that applications shouldn't mess with  %LOCALAPPDATA%\proj at all. 
What will be put there will be managed by PROJ itself (in RFC4 a sqlite 
database with a cache of downloading grid chunks. And if
https://github.com/OSGeo/PROJ/issues/1750 comes true, with what the script 
will install). An implementation detail.
They might go on with the "old way" of installing the grids in the "PROJ_LIB" 
they manage (or ..\bin\share\proj if we adopt Joaquim's strategy).

So an updated logic for the pj_open_lib_ex() function that attempts to locate 
a grid would be in the order they are done:
- user callback provided by user through proj_context_set_file_finder() ? 
(does anybody use that ? Probably not)
- search paths set through proj_context_set_search_paths()
- PROJ_LIB env var
- hardcoded path at build time
- current dir
- ..\bin\share\proj with proposed PR
- %LOCALAPPDATA%\proj /  ${XDG_DATA_HOME}/proj for grids as files (cf https://
github.com/OSGeo/PROJ/issues/1750)
- RFC4 + networking enabled: %LOCALAPPDATA%\proj /  ${XDG_DATA_HOME}/proj for 
the SQLite3 cache.db
- RFC4 + networking enabled: network access to fetch the grid bit

Actually the current behaviour is a bit more subtle than that. For example, if 
the search paths are defined, this stops the following mechanisms to be 
attempted even if the grid is not found. Some tweakings likely needed to 
rationalize that a bit.


-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ccrook at linz.govt.nz  Wed Nov 27 13:02:32 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Wed, 27 Nov 2019 21:02:32 +0000
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <FCFA4688-8B57-466B-BF18-0E3961561DBB@gmail.com>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <3620026.VIMQX10h4f@even-i700>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
 <93d564aa568742178d33bd47738867a9@sdfe.dk> <2222220.jTYGqXXbEZ@even-i700>
 <1574875916818-0.post@n6.nabble.com> <2072521.EARWbhcj6n@even-i700>
 <1574886663941-0.post@n6.nabble.com>
 <FCFA4688-8B57-466B-BF18-0E3961561DBB@gmail.com>
Message-ID: <A87E66F06E86F14B857F2EB047CDF93231450D47@prdassexch01.ad.linz.govt.nz>

I'm not sure it makes sense to look in the current directory by default.  It seems to me this could inadvertently pick up a grid file that was not deliberately installed into the system.  Would it be safer to require that local grids are explicitly requested, eg ./grid_file

Cheers
Chris


> -----Original Message-----
> From: PROJ [mailto:proj-bounces at lists.osgeo.org] On Behalf Of Kristian
> Evers
> Sent: Thursday, 28 November 2019 9:40 a.m.
> To: Helmut Kudrnovsky
> Cc: proj at lists.osgeo.org
> Subject: Re: [PROJ] Management of datum grid files.
>
>
>
> > On 27 Nov 2019, at 21:31, Helmut Kudrnovsky <hellik at web.de> wrote:
> >
> >>> Keep in mind, in the most cases in windows,  proj  is bundled with
> >>> other Software.
> >>>
> >>> E.g. OSGeo4W where proj needed files are living in  e.g.
> >>> c:\OSGeo4W\share\proj\ or in standalone winGRASS or qgis where  proj
> >>> needed files are living in e.g. c:\programs\qgis\share-subfolder
> >>> and %PROJ_LIB% is set accordingly.
> >>
> >> That's one of the reason to propose an installation-independent
> directory.
> >> That way different installations may be able to use the same grids &
> cache.
> >
> > so the idea is:
> >
> > that e.g. OSGeo4W puts the proj shared things into %LOCALAPPDATA%, a
> > standalone GIS software depending on proj looks into %LOCALAPPDATA%
> if
> > there is a subfolder called e.g. proj? or the other way around, a
> > standalone GIS software depending on proj puts needed files into
> > %LOCALAPPDATA%\proj and OSGeo4W looks while updating/upgrading its
> > proj version into %LOCALAPPDATA% if there is a proj subfolder with
> > shared folders? what if in %LOCALAPPDATA%\proj are already files with
> > the same name? should these be just overwritten? how will be there a
> > track of updated/ugraded/changed shared proj files if different
> > software are working/updating/upgrading them at the same time?
> >
> > or should be set %PROJ_LIB% windows system wide (for all users? for
> > just one user in a multiuser network?) and a standalone GIS software
> > depending on proj/OSGeo4W while updating looks for %PROJ_LIB%
> instead
> > of %LOCALAPPDATA%\proj?
> >
> > will this work in the windows side of the world? ;-)
> >
> > I'm not against a consolidated way how to deal with proj supporting
> > files like grids and their big file sizes; with a _co-maintainer of
> > winGRASS_ hat on, I know, windows can be sometimes a hardly
> manageable
> > beast ... here just for well thought solution on the windows side of
> > the world ;-)
> >
>
> I would think that we would mostly just continue doing what we doing with
> PROJ_LIB at the moment with the addition of looking for usable grids in
> %APPDATA% (on Windows).
>
> This is somewhat equivalent to what is done on unix-based installs already,
> where the logic for finding grids is something like:
>
> 1. Look in current dir
> 2. Look in search paths set by API function 3. Look in PROJ_LIB 4. Look in
> /usr/local/share/proj or whatever was specified with ./configure
>
> On Windows step 4 would look for resources in %APPDATA%\PROJ
>
> Is that a reasonable approach?
>
> /Kristian
>
>
>
>
>
>
>
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From kristianevers at gmail.com  Wed Nov 27 13:23:25 2019
From: kristianevers at gmail.com (Kristian Evers)
Date: Wed, 27 Nov 2019 22:23:25 +0100
Subject: [PROJ] Management of datum grid files.
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF93231450D47@prdassexch01.ad.linz.govt.nz>
References: <A87E66F06E86F14B857F2EB047CDF9323144DE2E@prdassexch01.ad.linz.govt.nz>
 <3620026.VIMQX10h4f@even-i700>
 <A87E66F06E86F14B857F2EB047CDF9323144E8E0@prdassexch01.ad.linz.govt.nz>
 <2124705.S4BY28HgJC@even-i700> <23877241.Mo6V5nEIhq@even-i700>
 <93d564aa568742178d33bd47738867a9@sdfe.dk> <2222220.jTYGqXXbEZ@even-i700>
 <1574875916818-0.post@n6.nabble.com> <2072521.EARWbhcj6n@even-i700>
 <1574886663941-0.post@n6.nabble.com>
 <FCFA4688-8B57-466B-BF18-0E3961561DBB@gmail.com>
 <A87E66F06E86F14B857F2EB047CDF93231450D47@prdassexch01.ad.linz.govt.nz>
Message-ID: <9BE1687A-7D63-4A3A-AA50-70F9DD8F4AB4@gmail.com>

Chris,

This is actually how it is done. Sorry for not stating that more clearly in my previous mail.

/Kristian

> On 27 Nov 2019, at 22:02, Chris Crook <ccrook at linz.govt.nz> wrote:
> 
> I'm not sure it makes sense to look in the current directory by default.  It seems to me this could inadvertently pick up a grid file that was not deliberately installed into the system.  Would it be safer to require that local grids are explicitly requested, eg ./grid_file
> 
> Cheers
> Chris
> 
> 
>> -----Original Message-----
>> From: PROJ [mailto:proj-bounces at lists.osgeo.org] On Behalf Of Kristian
>> Evers
>> Sent: Thursday, 28 November 2019 9:40 a.m.
>> To: Helmut Kudrnovsky
>> Cc: proj at lists.osgeo.org
>> Subject: Re: [PROJ] Management of datum grid files.
>> 
>> 
>> 
>>> On 27 Nov 2019, at 21:31, Helmut Kudrnovsky <hellik at web.de> wrote:
>>> 
>>>>> Keep in mind, in the most cases in windows,  proj  is bundled with
>>>>> other Software.
>>>>> 
>>>>> E.g. OSGeo4W where proj needed files are living in  e.g.
>>>>> c:\OSGeo4W\share\proj\ or in standalone winGRASS or qgis where  proj
>>>>> needed files are living in e.g. c:\programs\qgis\share-subfolder
>>>>> and %PROJ_LIB% is set accordingly.
>>>> 
>>>> That's one of the reason to propose an installation-independent
>> directory.
>>>> That way different installations may be able to use the same grids &
>> cache.
>>> 
>>> so the idea is:
>>> 
>>> that e.g. OSGeo4W puts the proj shared things into %LOCALAPPDATA%, a
>>> standalone GIS software depending on proj looks into %LOCALAPPDATA%
>> if
>>> there is a subfolder called e.g. proj? or the other way around, a
>>> standalone GIS software depending on proj puts needed files into
>>> %LOCALAPPDATA%\proj and OSGeo4W looks while updating/upgrading its
>>> proj version into %LOCALAPPDATA% if there is a proj subfolder with
>>> shared folders? what if in %LOCALAPPDATA%\proj are already files with
>>> the same name? should these be just overwritten? how will be there a
>>> track of updated/ugraded/changed shared proj files if different
>>> software are working/updating/upgrading them at the same time?
>>> 
>>> or should be set %PROJ_LIB% windows system wide (for all users? for
>>> just one user in a multiuser network?) and a standalone GIS software
>>> depending on proj/OSGeo4W while updating looks for %PROJ_LIB%
>> instead
>>> of %LOCALAPPDATA%\proj?
>>> 
>>> will this work in the windows side of the world? ;-)
>>> 
>>> I'm not against a consolidated way how to deal with proj supporting
>>> files like grids and their big file sizes; with a _co-maintainer of
>>> winGRASS_ hat on, I know, windows can be sometimes a hardly
>> manageable
>>> beast ... here just for well thought solution on the windows side of
>>> the world ;-)
>>> 
>> 
>> I would think that we would mostly just continue doing what we doing with
>> PROJ_LIB at the moment with the addition of looking for usable grids in
>> %APPDATA% (on Windows).
>> 
>> This is somewhat equivalent to what is done on unix-based installs already,
>> where the logic for finding grids is something like:
>> 
>> 1. Look in current dir
>> 2. Look in search paths set by API function 3. Look in PROJ_LIB 4. Look in
>> /usr/local/share/proj or whatever was specified with ./configure
>> 
>> On Windows step 4 would look for resources in %APPDATA%\PROJ
>> 
>> Is that a reasonable approach?
>> 
>> /Kristian
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> _______________________________________________
>> PROJ mailing list
>> PROJ at lists.osgeo.org
>> https://lists.osgeo.org/mailman/listinfo/proj
> 
> ________________________________
> 
> This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj


From martin.desruisseaux at geomatys.com  Wed Nov 27 14:54:50 2019
From: martin.desruisseaux at geomatys.com (Martin Desruisseaux)
Date: Wed, 27 Nov 2019 23:54:50 +0100
Subject: [PROJ] (Angular/Linear/Scale) speed in C++ API
Message-ID: <09ea0ce7-dca1-f287-ce5e-d66c034fa8a8@geomatys.com>

Hello

The C++ API defines the following enumeration:

    osgeo::proj::common::UnitOfMeasure::Type

With the following values:

    UNKNOWN, NONE, ANGULAR, LINEAR, SCALE, TIME, PARAMETRIC

The METRE unit for instance is of type LINEAR, which is fine. But I find 
the following more surprising:

  * METRE_PER_YEAR declared of type LINEAR
  * ARC_SECOND_PER_YEAR declared of type ANGULAR
  * PPM_PER_YEAR declared of type SCALE

I do not see an API for declaring that above units are rates of change 
(speed, angular velocity, etc.) rather than classic linear or angular 
units. Shouldn't the API contain something for that?

     Martin


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191127/1745583a/attachment.html>

From even.rouault at spatialys.com  Wed Nov 27 15:19:24 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 28 Nov 2019 00:19:24 +0100
Subject: [PROJ] (Angular/Linear/Scale) speed in C++ API
In-Reply-To: <09ea0ce7-dca1-f287-ce5e-d66c034fa8a8@geomatys.com>
References: <09ea0ce7-dca1-f287-ce5e-d66c034fa8a8@geomatys.com>
Message-ID: <1617043.kKiYMYljJr@even-i700>

Martin,

> But I find
> the following more surprising:
> 
>   * METRE_PER_YEAR declared of type LINEAR
>   * ARC_SECOND_PER_YEAR declared of type ANGULAR
>   * PPM_PER_YEAR declared of type SCALE
> 
> I do not see an API for declaring that above units are rates of change
> (speed, angular velocity, etc.) rather than classic linear or angular
> units. Shouldn't the API contain something for that?

Yes, that's indeed odd. I just followed what EPSG does:

  unit_of_meas_name (String) = metre per second
  unit_of_meas_type (String) = length
  target_uom_code (Integer) = 1026

  unit_of_meas_name (String) = arc-seconds per year
  unit_of_meas_type (String) = angle
  target_uom_code (Integer) = 1035

  unit_of_meas_name (String) = parts per million per year
  unit_of_meas_type (String) = scale
  target_uom_code (Integer) = 1036

As far as I can remember, there's no real functional impact of that arguable choice.
What matters for PROJ is that the factor_b/factor_c ratio is correct so that it
can normalize to the rate units it expects for the Helmert operator, which are,
unsurprisingly, the above ones :-) The only use of the unit type I can think
about now is when exporting to WKT: you need to know if you need to generate
a LENGTHUNIT[] vs ANGLEUNIT[] vs SCALE[] node.
Couldn't find in http://docs.opengeospatial.org/is/18-010r7/18-010r7.html an
example for a time-dependant operation nor more formal requirements, but 
https://www.epsg-registry.org/export.htm?wkt=urn:ogc:def:coordinateOperation:EPSG::8070
uses those type of nodes for the units of the rate of changes

Could perhaps be worth a clarification in 18-010r7.
CC'ing Roger in case he has anything to add about that.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From ccrook at linz.govt.nz  Wed Nov 27 17:06:44 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Thu, 28 Nov 2019 01:06:44 +0000
Subject: [PROJ] PROJ 6 vertical transformation confusion
Message-ID: <A87E66F06E86F14B857F2EB047CDF932314510CF@prdassexch01.ad.linz.govt.nz>

I am trying to sort out the grids required for NZ vertical datums and transformations, and particularly how the EPSG parameters are handled in PROJ.   I'm trying to ensure that all the grids are defined correctly in EPSG and installed in PROJ so that NZ users (or users of NZ data) can carry out these transformations and get the right results!

I find I am not completely understanding the way proj is using EPSG or seeking out! To explain my confusion I have four coordinate reference systems I am interested in:

One geodetic CRS

urn:ogc:def:crs:EPSG::4959 (NZGD2000) - geographic 3d datum.

Three vertical coordinate systems (based on corresponding vertical datums)

urn:ogc:def:crs:EPSG::4440 (NZ vertical datum 2009)
urn:ogc:def:crs:EPSG::7839 (NZ vertical datum 2016) and
urn:ogc:def:crs:EPSG::5759 (Auckland 1946 height datum)

Also I have four coordinate operations relating these:

urn:ogc:def:coordinateOperation:EPSG::4459 (NZGD2000-NZVD2009 - geoid transformation, accuracy 0.1m)
urn:ogc:def:coordinateOperation:EPSG::4442 (NZVD2009-AUCK1946 - vertical offset, accuracy 0.05m)
urn:ogc:def:coordinateOperation:EPSG::7840 (NZGD2000-NZVD2016 - geoid transformation, accuracy 0.1m)
urn:ogc:def:coordinateOperation:EPSG::7860 (NZVD2016-AUCK1946 - vertical offset file, accuracy 0.02m)


Question 1: is it possible that the vertical offset file transformation 7860 is not being recognized by PROJ.

When I run " projinfo -s EPSG:4959 -t EPSG:4959+5759" to transform NZGD2000 heights to AUCK1946  it only finds one candidate transformation, which is via NZVD2009 (4459+4442).  It doesn't seem to find the more accurate transformation via NZVD2016 (7840+7860).

Question 2: what determines how hard PROJ looks for transformation paths.

It can find a transformation from NZVD2016 to NZVD2009, ie "projinfo -s EPSG:4959+7839 -t EPSG:4959+4440", and from NZVD2009 to AUCK1946  with "projinfo -s EPSG:4959+4440 -t EPSG:4959+5759"  but it doesn't find the transformation path  NZVD2016 to AUCK1946 via NZVD2009 ie ie "projinfo -s EPSG:4959+7839 -t EPSG:4959+5759".

Instead fails as below:

# projinfo -s EPSG:4959+7839 -t EPSG:4959+5759
createOperations() failed with: Unimplemented

It shouldn't have to do this in any case as it should be able to get use 7860 operation directly  but even if it can't find that I would have thought it would be able to find the indirect path through  NZVD2009.

I am running all these operations on osgeo/proj docker image, proj version Rel. 6.3.0, January 1st, 2020.

BTW I am loving projinfo - it is saving my sanity!

Thanks in advance for any advice
Chris


________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.osgeo.org/pipermail/proj/attachments/20191128/073c96da/attachment.html>

From ccrook at linz.govt.nz  Wed Nov 27 17:49:35 2019
From: ccrook at linz.govt.nz (Chris Crook)
Date: Thu, 28 Nov 2019 01:49:35 +0000
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <48c9c7a521f846c484885bdc49ebad6a@sdfe.dk>
 <CAB28AshfN-+QQy=6LVd_w73-2kErbaL3H5q-XSMNC_+r90d5uA@mail.gmail.com>
 <2619535.AF0HQB3J75@even-i700> <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>
Message-ID: <A87E66F06E86F14B857F2EB047CDF932314511C4@prdassexch01.ad.linz.govt.nz>

Am I right in understanding that where proj (6) determines two or more possible transformation paths between CRSs it uses the accuracy to decide which is preferable?

If so steps the algorithm for combining accuracies could be significant for transformations involving multiple whether or not they are strictly comparable

Also geodetic agencies defining parameters will need to be careful that accuracies are configured to ensure the desired preference is achieved.  In the past it is likely that not much attention would have been given to this as it isn't necessarily very meaningful (certainly not as a single value) and until now possibly didn't make much difference to anything...

Cheers
Chris


> -----Original Message-----
> From: PROJ [mailto:proj-bounces at lists.osgeo.org] On Behalf Of Kristian
> Evers
> Sent: Wednesday, 27 November 2019 9:21 p.m.
> To: Even Rouault; proj at lists.osgeo.org
> Subject: Re: [PROJ] "Trustworthiness" of vertical transformations
>
> > The algorithm currently is rather
> > simple: just add the (in)accuracies of each step. I do have some vague
> > remembering from univ that this was not always the "right" thing to do
> > from a math point of view. I guess sometimes perhaps taking the max()
> > would be more appropriate. But given that we can potentially mix
> > uncomparable things, probably not that a big deal...
>
> Yeah, this can definitely be improved but it's a simple and effective solution
> that doesn't promise too much which is always better that saying that
> accuracy is better than it really is. I think this could be a fun topic to have a
> workshop on at the OSGeo code sprint in the spring.
>
> /Kristian
>
> -----Original Message-----
> From: Even Rouault <even.rouault at spatialys.com>
> Sent: 27. november 2019 01:06
> To: proj at lists.osgeo.org
> Cc: Nyall Dawson <nyall.dawson at gmail.com>; Kristian Evers
> <kreve at sdfe.dk>
> Subject: Re: [PROJ] "Trustworthiness" of vertical transformations
>
> On mercredi 27 novembre 2019 09:34:33 CET Nyall Dawson wrote:
> > On Tue, 26 Nov 2019 at 20:52, Kristian Evers <kreve at sdfe.dk> wrote:
> > > You can get the transformation accuracy using the API function
> > > proj_coordoperation_get_accuracy(). I think it would be cool if
> > > information about transformation accuracy where readily available in
> > > software like QGIS (nudge, nudge :-))
>
> I should mention that the information about accuracy should be taken with a
> grain of salt for several reasons:
> - the EPSG guidance note 7-1 [1] underlines that the exact definition of
> accuracy varies according to geodetic agencies
> - in a number of situations, PROJ will have to synthetize the resulting
> accuracy when chaining several steps. The algorithm currently is rather
> simple: just add the (in)accuracies of each step. I do have some vague
> remembering from univ that this was not always the "right" thing to do from
> a math point of view. I guess sometimes perhaps taking the max() would be
> more appropriate. But given that we can potentially mix uncomparable
> things, probably not that a big deal...
>
> > That's where I'm coming from now... I'm just wondering if and how we
> > should expose vertical transformation functionality. Do you have any
> > ideas on what functionality you would expect an end-user application
> > to expose for vertical transformations?
>
> Depends on the use cases. If you want to aggregate point cloud datasets that
> are referenced against several vertical CRS into a single dataset, you will
> probably want to convert them into a single Geographic CRS (ITRF2014,
> WGS84
> G1762) or a single CompoundCRS appropriate for the area of study so that
> they can be stashed together.
>
> Even
>
> [1] http://www.epsg.org/Portals/0/373-07-1.pdf , §6.5.4.1 Coordinate
> Operation accuracy
>
> --
> Spatialys - Geospatial professional services http://www.spatialys.com
> _______________________________________________
> PROJ mailing list
> PROJ at lists.osgeo.org
> https://lists.osgeo.org/mailman/listinfo/proj

________________________________

This message contains information, which may be in confidence and may be subject to legal privilege. If you are not the intended recipient, you must not peruse, use, disseminate, distribute or copy this message. If you have received this message in error, please notify us immediately (Phone 0800 665 463 or info at linz.govt.nz) and destroy the original message. LINZ accepts no responsibility for changes to this email, or for any attachments, after its transmission from LINZ. Thank You.

From even.rouault at spatialys.com  Thu Nov 28 03:25:55 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 28 Nov 2019 12:25:55 +0100
Subject: [PROJ] "Trustworthiness" of vertical transformations
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF932314511C4@prdassexch01.ad.linz.govt.nz>
References: <CAB28AsiCS50aO5JVwBxnj=PpFYkQUUCwfai5RHYOdFJ4=V4MfQ@mail.gmail.com>
 <f778ba428bdd434eaf29bc152da583b7@sdfe.dk>
 <A87E66F06E86F14B857F2EB047CDF932314511C4@prdassexch01.ad.linz.govt.nz>
Message-ID: <4183047.Ufz6Yc01hq@even-i700>

On jeudi 28 novembre 2019 01:49:35 CET Chris Crook wrote:
> Am I right in understanding that where proj (6) determines two or more
> possible transformation paths between CRSs it uses the accuracy to decide
> which is preferable?

The long answer would be long :-) Trying to do a medium one. There are several 
levels of API. In the low level of API, PROJ enumerates the possible 
transformation paths from its database and a set of heuristics, and then 
return them in a sorted way, trying to put the most relevant at top. The 
criterion include area of use, accuracy, availability of grids. The user can 
then decide which one is appropriate for its use case
The higher level of API ("black box") will use those results to automatically 
select the one that is "best" for the coordinate to transform.
So yes, given 2 transformation paths that have the same are of use and where 
the needed grid(s) are available, advertized accuracy will decide which one is 
to be used.
I didn't mention deprecation and supersession information coming from EPSG 
which are also taken into account.

> Also geodetic agencies defining parameters will need to be careful that
> accuracies are configured to ensure the desired preference is achieved.  In
> the past it is likely that not much attention would have been given to this
> as it isn't necessarily very meaningful (certainly not as a single value)
> and until now possibly didn't make much difference to anything...

Yes, an example of the consequence of this in:
https://github.com/OSGeo/PROJ/issues/1580#issuecomment-528042944

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Thu Nov 28 05:10:17 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 28 Nov 2019 14:10:17 +0100
Subject: [PROJ] PROJ 6 vertical transformation confusion
In-Reply-To: <A87E66F06E86F14B857F2EB047CDF932314510CF@prdassexch01.ad.linz.govt.nz>
References: <A87E66F06E86F14B857F2EB047CDF932314510CF@prdassexch01.ad.linz.govt.nz>
Message-ID: <2325844.s99iuqOPaD@even-i700>

Chris,

The answer to your 2 questions is closely linked

> Question 1: is it possible that the vertical offset file transformation 7860
> is not being recognized by PROJ.
> 
> When I run " projinfo -s EPSG:4959 -t EPSG:4959+5759" to transform NZGD2000
> heights to AUCK1946  it only finds one candidate transformation, which is
> via NZVD2009 (4459+4442).  It doesn't seem to find the more accurate
> transformation via NZVD2016 (7840+7860).

The issue is that EPSG:7860 'NZVD2016 height to Auckland 1946 height (1)' uses 
the EPSG:1071 'Vertical Offset by Grid Interpolation (NZLVD)' method which is 
not currently implemented by PROJ (cannot deal with .csv files). If the grid 
was available under a format that PROJ can understand (let's say .gtx), then 
some little code addition (extending the NADCON specific check in https://
github.com/OSGeo/PROJ/blob/master/src/iso19111/coordinateoperation.cpp#L8763) 
and a tweak in the database should make it available.

> 
> Question 2: what determines how hard PROJ looks for transformation paths.

That's a question whose answer is a lengthy document I'm in progress of 
writing :-) It is a subtle mix of logical steps and heuristics.

> Instead fails as below:
> 
> # projinfo -s EPSG:4959+7839 -t EPSG:4959+5759
> createOperations() failed with: Unimplemented

See answer to first point

> It shouldn't have to do this in any case as it should be able to get use
> 7860 operation directly  but even if it can't find that I would have
> thought it would be able to find the indirect path through  NZVD2009.

Well that's one of the many limitations to keep the computation time somewhat 
bounded (otherwise could probably be a travelling salesman-like problem. PROJ 
6 is a sort of routing engine I tend to joke about). As soon as there's a 
direct transformation found in the database, it doesn't try to compute 
concantenated operations through an intermediate. Could/should probably be 
tweaked a bit to check if the direct transformation found is actually 
supported.

Actually I just fixed that. So now it *does* try to use an intermediate when 
the direct path is not supported by PROJ .. but that doesn't still work. As 
far as I can see grepping in the EPSG dataset, one cannot do Auckland 46 -> 
NZVD2016 by using the NZVD2009 intermediate. There is EPSG:4442 "NZVD2009 
height to Auckland 1946 height (1)", but I can't see any direct transformation 
between NZVD2009 and NZVD2016. That would require going through the NZGD2000 
CRS by appling one geoid and one reverse geoid. PROJ only supports researching 
one intermediate CRS as I mentionned above. What could be done however is that 
LINZ would register in the EPSG dataset a NZVD2009 to NZVD2016 concatenated 
operation chaining EPSG:4459 and EPSG:7840 (for the sake of operation 
research, a concatenated operation is seen as a unique operation. It is 
expanded to its component steps afterwards). Of course, you're far better 
placed than me to determine if that's the best route to follow (I could also 
imagine a direct adjustment grid). 

> I am running all these operations on osgeo/proj docker image, proj version
> Rel. 6.3.0, January 1st, 2020.
> 
> BTW I am loving projinfo - it is saving my sanity!

Glad you like it !

If you really want to know what it does, because it just returns results 
filtered and sorted, you can build it with
-DENABLE_TRACING -DTRACE_DATABASE -DTRACE_CREATE_OPERATIONS
You'll get logs of thousands of lines of every step it tries.

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

From even.rouault at spatialys.com  Thu Nov 28 07:01:33 2019
From: even.rouault at spatialys.com (Even Rouault)
Date: Thu, 28 Nov 2019 16:01:33 +0100
Subject: [PROJ] RFC4: libtiff dependency required ?
Message-ID: <3829985.b26xA0xQZA@even-i700>

Hi,

I know RFC4 is big creamy pie to digest. There's one discussion point I identified
at least, which is if we make libtiff a required dependency or just an optional one.

https://github.com/rouault/PROJ/blob/rfc4_remote_and_geotiff_grid/docs/source/community/rfc/rfc-4.rst#discussion-points

"""The advantage of making it required is that proj-datumgrid could only ship TIFF grids. If we
don't make it a requirement, we will have to manage .gtx / .gsb for the .zip / .tar.gz
delivered in the proj-datumgrid-XXXXX packages, and a .tif version hosted on the CDN.""""

>From a pure PROJ developer point of view, having it required also simplifies the testing
story and maintenance burden.

Even if it is optional, I do think (hope!) that most binary distribution around would
build against it. Anyone building a C/C++ GIS stack has GDAL in it, and thus libtiff.
(The same holds for curl by the way.)

One thing I didn't mention is that support for reading .gtx/.gsb would remain, at least in a medium
term, as there are grids in those formats in the wild we don't (or can't) distribute. It is
just that we would only distribute .tif grids from now.

Small implementation detail: we would need to make sure that PROJ 6.3 database doesn't
point to the -latest.zip versions as it does currently - because after RFC4 would be done,
those would contain .TIF files -, but identify the last package versions that ship with .gtx/.gsb

Even

-- 
Spatialys - Geospatial professional services
http://www.spatialys.com

